{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==========================================================================================\n",
    "# PART 3: COVNET MODEL EVOLUTIONARY TRAINING\n",
    "### =========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project folder\n",
    "path_project = 'E:/DeepLearning/breast_cancer/IDC_regular_ps50_idx5/'\n",
    "\n",
    "# set train, validate, and test folders\n",
    "dir_train = os.path.join(path_project, '_train')\n",
    "dir_valid = os.path.join(path_project, '_validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_x, model_id, lr, epochs, epoch_steps, valid_steps, batch_size, image_size):\n",
    "    model = model_x(lr=lr, image_size=image_size)\n",
    "    \n",
    "    print('Model:', model_x)\n",
    "    print('Batch Size:', batch_size)\n",
    "    print('Learning Rate:', lr)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Steps per Epoch:', epoch_steps)\n",
    "    print('Validation Steps:', valid_steps)\n",
    "    print('Image Size:', image_size)\n",
    "    print('_' * 65, '\\n')\n",
    "        \n",
    "    print('Training Set:')    \n",
    "    datagen_train = ImageDataGenerator(rescale=1./255)\n",
    "    gen_train = datagen_train.flow_from_directory(dir_train, target_size=image_size, batch_size=batch_size, class_mode='binary')\n",
    "    \n",
    "    print('Validation Set:')    \n",
    "    datagen_valid = ImageDataGenerator(rescale=1./255)\n",
    "    gen_valid = datagen_valid.flow_from_directory(dir_valid, target_size=image_size, batch_size=batch_size, class_mode='binary')\n",
    "    print('_' * 65, '\\n')\n",
    "\n",
    "    print('Model training started...\\n')\n",
    "    \n",
    "    t0 = datetime.now()\n",
    "    with tf.device('/gpu:0'):\n",
    "        history = model.fit_generator(gen_train, steps_per_epoch=epoch_steps, epochs=epochs, validation_data=gen_valid, \n",
    "                                                                                                validation_steps=valid_steps)\n",
    "    \n",
    "    elpased_time = str(datetime.now() - t0).split('.')[0]    \n",
    "    hours = elpased_time.split(':')[0]\n",
    "    minutes = elpased_time.split(':')[1]\n",
    "    seconds = elpased_time.split(':')[2]\n",
    "    \n",
    "    print('\\nTraining process completed in:', int(hours), 'h', int(minutes), 'm', int(seconds), 's')            \n",
    "    \n",
    "    # save model\n",
    "    models_folder = 'MODELS'    \n",
    "    if not os.path.exists(os.path.join(path_project, models_folder)):\n",
    "        os.makedirs(os.path.join(path_project, models_folder))\n",
    "    filename = f\"model_breast_cancer_{model_id}.h5\"\n",
    "    model.save(os.path.join(path_project, models_folder, filename))\n",
    "    print('Model saved as: \"', models_folder, '/', filename, '\"')\n",
    "    \n",
    "    print('#' * 120, '\\n')\n",
    "    \n",
    "    return (history, elpased_time, model)\n",
    "\n",
    "\n",
    "def train_generation(model, image_size, gen):\n",
    "    # read generations file\n",
    "    df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')    \n",
    "\n",
    "    for row in df_generations.itertuples():\n",
    "        # process only untrained rows\n",
    "        if row.train_loss == '' and row.val_acc == '':\n",
    "            try:\n",
    "                print('Processing Model', row.Index + 1, 'of', len(df_generations))\n",
    "                logs = train_model(model, \n",
    "                                   model_id = row.Index,\n",
    "                                   lr = row.learning_rate, \n",
    "                                   epochs = row.epochs, \n",
    "                                   epoch_steps = row.steps_per_epoch, \n",
    "                                   valid_steps = row.validation_steps, \n",
    "                                   batch_size = row.batch_size, \n",
    "                                   image_size = image_size)\n",
    "\n",
    "                df_generations.loc[row.Index, 'train_loss'] = logs[0].history['loss'][-1]\n",
    "                df_generations.loc[row.Index, 'train_acc'] = logs[0].history['acc'][-1]\n",
    "                df_generations.loc[row.Index, 'val_loss'] = logs[0].history['val_loss'][-1]\n",
    "                df_generations.loc[row.Index, 'val_acc'] = logs[0].history['val_acc'][-1]\n",
    "                df_generations.loc[row.Index, 'time'] = logs[1]\n",
    "                df_generations.loc[row.Index, 'gen'] = gen\n",
    "\n",
    "                # save results to csv after each iteration\n",
    "                df_generations.to_csv(os.path.join(path_project, 'generations.csv'), index=None)    \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_generations             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7(lr, image_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['acc'])        \n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['batch_size', 'steps_per_epoch', 'validation_steps', 'epochs', 'learning_rate',  \n",
    "                                                    'train_loss', 'train_acc', 'val_loss', 'val_acc', 'time', 'gen', 'alive']\n",
    "\n",
    "def first_generation(size):    \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for i in range(size):\n",
    "    \n",
    "        # read generations file if it exists, or create new if it doesn't\n",
    "        if os.path.exists(os.path.join(path_project, 'generations.csv')):\n",
    "            df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv'))\n",
    "        else:\n",
    "            df_generations = pd.DataFrame(columns=colnames)\n",
    "\n",
    "        # create individual\n",
    "        df_new = pd.DataFrame([[random.choice(range_batch_size),\n",
    "                                random.choice(range_epoch_steps),\n",
    "                                random.choice(range_valid_steps),\n",
    "                                random.choice(range_epochs),\n",
    "                                1/10**random.choice(range_lr),\n",
    "                                '', '', '', '', '', '', '', '', '1', True]], columns=colnames)    \n",
    "        df_temp = df_generations.append(df_new)\n",
    "\n",
    "        # regenerate individual if already exists in df_generations\n",
    "        while len(df_temp[df_temp.duplicated(keep=False)]) > 0:  \n",
    "            df_generations = df_generations.drop_duplicates()\n",
    "            df_new = pd.DataFrame([[random.choice(range_batch_size),\n",
    "                                    random.choice(range_epoch_steps),\n",
    "                                    random.choice(range_valid_steps),\n",
    "                                    random.choice(range_epochs),\n",
    "                                    1/10**random.choice(range_lr),\n",
    "                                    '', '', '', '', '', '', '', '', '1', True]], columns=colnames)        \n",
    "            df_temp = df_generations.append(df_new)\n",
    "\n",
    "        df_out = df_out.append([df_new]).reset_index(drop=True)\n",
    "            \n",
    "        # save new parent to generations file\n",
    "        df_temp.to_csv(os.path.join(path_project, 'generations.csv'), index=None)\n",
    "            \n",
    "    return df_out\n",
    "\n",
    "\n",
    "def select_fittest(top_percent):\n",
    "    # read generations file\n",
    "    df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv'))\n",
    "    df_generations = df_generations.fillna('')\n",
    "\n",
    "    # select a pool of only alive individuals\n",
    "    df_alive = df_generations[df_generations.alive]\n",
    "\n",
    "    # extinguish non-fit algorithms based on validation accuracy\n",
    "    non_survivors = df_alive.nsmallest(round(len(df_alive) * (1 - top_percent / 100)), 'val_acc').index.tolist()    \n",
    "    df_generations.loc[non_survivors, 'alive'] = False\n",
    "\n",
    "    # save file\n",
    "    df_generations.to_csv(os.path.join(path_project, 'generations.csv'), index=None)\n",
    "    \n",
    "    return df_generations[df_generations.alive]\n",
    "\n",
    "\n",
    "def create_parents():    \n",
    "    # read generations file\n",
    "    df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv'))\n",
    "    \n",
    "    # select a pool of only alive individuals\n",
    "    df_pool = df_generations[df_generations.alive]\n",
    "    \n",
    "    # select parents at random from pool for as long as pairs can be matched \n",
    "    matched_parents = []\n",
    "    while len(df_pool) > 1:    \n",
    "        df_parents = df_pool.sample(2)\n",
    "        new_parents = tuple(df_parents.index)\n",
    "        matched_parents.append(new_parents)\n",
    "\n",
    "        # remove new parents from pool        \n",
    "        df_pool = df_pool.drop([new_parents[0], new_parents[1]], axis=0)\n",
    "\n",
    "    return matched_parents\n",
    "\n",
    "\n",
    "def create_child(df_parents, generation, mutate=False):\n",
    "    df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv'))\n",
    "            \n",
    "    mutate_choice = random.choice(['batch_size', 'steps_epoch', 'valid_steps', 'epochs', 'learning_rate'])  \n",
    "\n",
    "    if mutate and mutate_choice == 'batch_size':\n",
    "        batch_size = random.choice(range_batch_size)\n",
    "    else:\n",
    "        batch_size = int(df_parents.batch_size.sample())\n",
    "\n",
    "    if mutate and mutate_choice == 'steps_epoch':\n",
    "        steps_per_epoch = random.choice(range_epoch_steps)\n",
    "    else:\n",
    "        steps_per_epoch = int(df_parents.steps_per_epoch.sample())\n",
    "\n",
    "    if mutate and mutate_choice == 'valid_steps':\n",
    "        validation_steps = random.choice(range_valid_steps)\n",
    "    else:\n",
    "        validation_steps = int(df_parents.validation_steps.sample())\n",
    "\n",
    "    if mutate and mutate_choice == 'epochs':\n",
    "        epochs = random.choice(range_epochs)\n",
    "    else:\n",
    "        epochs = int(df_parents.epochs.sample())\n",
    "\n",
    "    if mutate and mutate_choice == 'learning_rate':\n",
    "        learning_rate = 1/10**random.choice(range_lr)\n",
    "    else:\n",
    "        learning_rate = float(df_parents.learning_rate.sample())            \n",
    "        \n",
    "    df_child = pd.DataFrame([[batch_size, steps_per_epoch, validation_steps, epochs, learning_rate,\n",
    "                                                      '', '', '', '', '', generation, True]], columns=colnames)    \n",
    "    df_temp = df_generations.append(df_child)\n",
    "    \n",
    "    # regenerate child if already exists in previous generations\n",
    "    while len(df_temp[df_temp.duplicated(keep=False)]) > 0:  \n",
    "        df_generations = df_generations.drop_duplicates()\n",
    "        df_child = pd.DataFrame([[batch_size, steps_per_epoch, validation_steps, epochs, learning_rate,\n",
    "                                      '', '', '', '', '', generation, True]], columns=colnames)    \n",
    "        df_temp = df_generations.append(df_child)\n",
    "        \n",
    "    # save new child to generations file\n",
    "    df_temp.to_csv(os.path.join(path_project, 'generations.csv'), index=None)\n",
    "        \n",
    "    return df_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Hyperparameter Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_epochs = range(10, 101, 10)\n",
    "range_epoch_steps = range(10, 201, 10)\n",
    "range_valid_steps = range(10, 101, 10)\n",
    "range_batch_size = range(20, 201, 20)\n",
    "range_lr = range(1, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st GENERATION ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0.100</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc val_loss val_acc time  gen  alive\n",
       "995         200              170                90      50          0.001                                               1   True\n",
       "996         160              140                10      80          0.001                                               1   True\n",
       "997         160              170               100      80          0.100                                               1   True\n",
       "998         180              190               100      70          0.001                                               1   True\n",
       "999         140               40                10      50          0.001                                               1   True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create first generation\n",
    "first_generation(1000).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 968 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 10\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.5729 - acc: 0.7177 - val_loss: 0.5276 - val_acc: 0.7218\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.4610 - acc: 0.7880 - val_loss: 0.4210 - val_acc: 0.8168\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.4177 - acc: 0.8207 - val_loss: 0.4245 - val_acc: 0.8150\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.4150 - acc: 0.8233 - val_loss: 0.4178 - val_acc: 0.8227\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.4139 - acc: 0.8227 - val_loss: 0.4077 - val_acc: 0.8234\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.4134 - acc: 0.8237 - val_loss: 0.4317 - val_acc: 0.8124\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.4118 - acc: 0.8249 - val_loss: 0.4028 - val_acc: 0.8265\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.4041 - acc: 0.8268 - val_loss: 0.4120 - val_acc: 0.8249\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.3984 - acc: 0.8301 - val_loss: 0.4168 - val_acc: 0.8231\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.4033 - acc: 0.8256 - val_loss: 0.4001 - val_acc: 0.8266\n",
      "\n",
      "Training process completed in: 0 h 2 m 6 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_967.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 969 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 11s 81ms/step - loss: 0.5637 - acc: 0.7188 - val_loss: 0.4567 - val_acc: 0.7920\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4311 - acc: 0.8121 - val_loss: 0.4185 - val_acc: 0.8200\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4171 - acc: 0.8198 - val_loss: 0.3970 - val_acc: 0.8325\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4136 - acc: 0.8226 - val_loss: 0.4004 - val_acc: 0.8215\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4093 - acc: 0.8233 - val_loss: 0.4265 - val_acc: 0.8093\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4023 - acc: 0.8262 - val_loss: 0.4237 - val_acc: 0.8120\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3977 - acc: 0.8286 - val_loss: 0.4046 - val_acc: 0.8209\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.4028 - acc: 0.8269 - val_loss: 0.4006 - val_acc: 0.8325\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3921 - acc: 0.8320 - val_loss: 0.4033 - val_acc: 0.8228\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3905 - acc: 0.8323 - val_loss: 0.3878 - val_acc: 0.8255\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3958 - acc: 0.8284 - val_loss: 0.3912 - val_acc: 0.8378\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3908 - acc: 0.8332 - val_loss: 0.4023 - val_acc: 0.8207\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3890 - acc: 0.8329 - val_loss: 0.3653 - val_acc: 0.8463\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3805 - acc: 0.8358 - val_loss: 0.4179 - val_acc: 0.8181\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3845 - acc: 0.8335 - val_loss: 0.3875 - val_acc: 0.8315\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3849 - acc: 0.8322 - val_loss: 0.3924 - val_acc: 0.8300\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3811 - acc: 0.8358 - val_loss: 0.3845 - val_acc: 0.8317\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3765 - acc: 0.8383 - val_loss: 0.3726 - val_acc: 0.8365\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3764 - acc: 0.8355 - val_loss: 0.3715 - val_acc: 0.8405\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3777 - acc: 0.8358 - val_loss: 0.3749 - val_acc: 0.8347\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3679 - acc: 0.8409 - val_loss: 0.3622 - val_acc: 0.8376\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3737 - acc: 0.8389 - val_loss: 0.3721 - val_acc: 0.8375\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3761 - acc: 0.8371 - val_loss: 0.3840 - val_acc: 0.8373\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3631 - acc: 0.8465 - val_loss: 0.3682 - val_acc: 0.8345\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3669 - acc: 0.8442 - val_loss: 0.3579 - val_acc: 0.8478\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3647 - acc: 0.8403 - val_loss: 0.3638 - val_acc: 0.8430\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3624 - acc: 0.8430 - val_loss: 0.3653 - val_acc: 0.8407\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3589 - acc: 0.8457 - val_loss: 0.3475 - val_acc: 0.8553\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3607 - acc: 0.8453 - val_loss: 0.3790 - val_acc: 0.8370\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3570 - acc: 0.8467 - val_loss: 0.3637 - val_acc: 0.8455\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3591 - acc: 0.8463 - val_loss: 0.3425 - val_acc: 0.8557\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3608 - acc: 0.8452 - val_loss: 0.3534 - val_acc: 0.8445\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3533 - acc: 0.8493 - val_loss: 0.3495 - val_acc: 0.8457\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3520 - acc: 0.8504 - val_loss: 0.3643 - val_acc: 0.8435\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3566 - acc: 0.8467 - val_loss: 0.3574 - val_acc: 0.8477\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3522 - acc: 0.8482 - val_loss: 0.3739 - val_acc: 0.8338\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3518 - acc: 0.8492 - val_loss: 0.3344 - val_acc: 0.8550\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3531 - acc: 0.8497 - val_loss: 0.3351 - val_acc: 0.8565\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3500 - acc: 0.8510 - val_loss: 0.3418 - val_acc: 0.8590\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3485 - acc: 0.8528 - val_loss: 0.3368 - val_acc: 0.8608\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3394 - acc: 0.8552 - val_loss: 0.3710 - val_acc: 0.8470\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3525 - acc: 0.8498 - val_loss: 0.3501 - val_acc: 0.8510\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3426 - acc: 0.8568 - val_loss: 0.3578 - val_acc: 0.8485\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3383 - acc: 0.8543 - val_loss: 0.3443 - val_acc: 0.8582\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3398 - acc: 0.8554 - val_loss: 0.3407 - val_acc: 0.8565\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3461 - acc: 0.8536 - val_loss: 0.3268 - val_acc: 0.8538\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3457 - acc: 0.8520 - val_loss: 0.3586 - val_acc: 0.8468\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3417 - acc: 0.8551 - val_loss: 0.3434 - val_acc: 0.8523\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3410 - acc: 0.8537 - val_loss: 0.3304 - val_acc: 0.8553\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3369 - acc: 0.8581 - val_loss: 0.3284 - val_acc: 0.8587\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3412 - acc: 0.8547 - val_loss: 0.3358 - val_acc: 0.8593\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3365 - acc: 0.8585 - val_loss: 0.3327 - val_acc: 0.8600\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3392 - acc: 0.8555 - val_loss: 0.3424 - val_acc: 0.8555\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3354 - acc: 0.8579 - val_loss: 0.3363 - val_acc: 0.8592\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3412 - acc: 0.8541 - val_loss: 0.3410 - val_acc: 0.8570\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3302 - acc: 0.8603 - val_loss: 0.3402 - val_acc: 0.8565\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3374 - acc: 0.8583 - val_loss: 0.3515 - val_acc: 0.8530\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3344 - acc: 0.8560 - val_loss: 0.3388 - val_acc: 0.8550\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3297 - acc: 0.8607 - val_loss: 0.3429 - val_acc: 0.8548\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3362 - acc: 0.8566 - val_loss: 0.3382 - val_acc: 0.8460\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3334 - acc: 0.8575 - val_loss: 0.3232 - val_acc: 0.8582\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3305 - acc: 0.8599 - val_loss: 0.3321 - val_acc: 0.8555\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3305 - acc: 0.8600 - val_loss: 0.3227 - val_acc: 0.8666\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3283 - acc: 0.8622 - val_loss: 0.3265 - val_acc: 0.8620\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3299 - acc: 0.8595 - val_loss: 0.3232 - val_acc: 0.8670\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3245 - acc: 0.8613 - val_loss: 0.3231 - val_acc: 0.8625\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3278 - acc: 0.8612 - val_loss: 0.3284 - val_acc: 0.8543\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3274 - acc: 0.8598 - val_loss: 0.3349 - val_acc: 0.8548\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3252 - acc: 0.8627 - val_loss: 0.3405 - val_acc: 0.8558\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3277 - acc: 0.8607 - val_loss: 0.3395 - val_acc: 0.8510\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3245 - acc: 0.8612 - val_loss: 0.3124 - val_acc: 0.8660\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3256 - acc: 0.8618 - val_loss: 0.3332 - val_acc: 0.8535\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3272 - acc: 0.8598 - val_loss: 0.3261 - val_acc: 0.8612\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3239 - acc: 0.8626 - val_loss: 0.3215 - val_acc: 0.8685\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3256 - acc: 0.8633 - val_loss: 0.3174 - val_acc: 0.8628\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3240 - acc: 0.8618 - val_loss: 0.3163 - val_acc: 0.8672\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 0.3282 - acc: 0.8590 - val_loss: 0.3389 - val_acc: 0.8560\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3227 - acc: 0.8628 - val_loss: 0.3021 - val_acc: 0.8678\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3170 - acc: 0.8674 - val_loss: 0.3196 - val_acc: 0.8633\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3176 - acc: 0.8655 - val_loss: 0.3305 - val_acc: 0.8588\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3227 - acc: 0.8628 - val_loss: 0.3407 - val_acc: 0.8613\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3221 - acc: 0.8625 - val_loss: 0.3271 - val_acc: 0.8582\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3117 - acc: 0.8687 - val_loss: 0.3092 - val_acc: 0.8670\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3207 - acc: 0.8640 - val_loss: 0.3228 - val_acc: 0.8568\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3232 - acc: 0.8621 - val_loss: 0.3291 - val_acc: 0.8630\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3252 - acc: 0.8617 - val_loss: 0.3218 - val_acc: 0.8697\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3122 - acc: 0.8676 - val_loss: 0.3283 - val_acc: 0.8565\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3177 - acc: 0.8675 - val_loss: 0.3162 - val_acc: 0.8635\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3163 - acc: 0.8637 - val_loss: 0.3208 - val_acc: 0.8665\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3159 - acc: 0.8655 - val_loss: 0.3049 - val_acc: 0.8752\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3198 - acc: 0.8662 - val_loss: 0.3237 - val_acc: 0.8651\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3215 - acc: 0.8633 - val_loss: 0.3236 - val_acc: 0.8597\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3134 - acc: 0.8661 - val_loss: 0.3106 - val_acc: 0.8705\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3117 - acc: 0.8680 - val_loss: 0.3291 - val_acc: 0.8580\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 0.3154 - acc: 0.8653 - val_loss: 0.3135 - val_acc: 0.8663\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3168 - acc: 0.8649 - val_loss: 0.3241 - val_acc: 0.8625\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3089 - acc: 0.8687 - val_loss: 0.3137 - val_acc: 0.8700\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3151 - acc: 0.8658 - val_loss: 0.3254 - val_acc: 0.8641\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3049 - acc: 0.8712 - val_loss: 0.2980 - val_acc: 0.8718\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3135 - acc: 0.8692 - val_loss: 0.3074 - val_acc: 0.8650\n",
      "\n",
      "Training process completed in: 0 h 16 m 25 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_968.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 970 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.01\n",
      "Epochs: 60\n",
      "Steps per Epoch: 80\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.6398 - acc: 0.7085 - val_loss: 0.6129 - val_acc: 0.6983\n",
      "Epoch 2/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6004 - acc: 0.7148 - val_loss: 0.5961 - val_acc: 0.7167\n",
      "Epoch 3/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6023 - acc: 0.7110 - val_loss: 0.5804 - val_acc: 0.7350\n",
      "Epoch 4/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5928 - acc: 0.7229 - val_loss: 0.6171 - val_acc: 0.6933\n",
      "Epoch 5/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5957 - acc: 0.7221 - val_loss: 0.6041 - val_acc: 0.7083\n",
      "Epoch 6/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5929 - acc: 0.7206 - val_loss: 0.6123 - val_acc: 0.6983\n",
      "Epoch 7/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5942 - acc: 0.7225 - val_loss: 0.5856 - val_acc: 0.7283\n",
      "Epoch 8/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5990 - acc: 0.7148 - val_loss: 0.6149 - val_acc: 0.6983\n",
      "Epoch 9/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5994 - acc: 0.7144 - val_loss: 0.6096 - val_acc: 0.7017\n",
      "Epoch 10/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5946 - acc: 0.7204 - val_loss: 0.5892 - val_acc: 0.7250\n",
      "Epoch 11/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5953 - acc: 0.7194 - val_loss: 0.5928 - val_acc: 0.7233\n",
      "Epoch 12/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5925 - acc: 0.7221 - val_loss: 0.6154 - val_acc: 0.6967\n",
      "Epoch 13/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5985 - acc: 0.7148 - val_loss: 0.5637 - val_acc: 0.7517\n",
      "Epoch 14/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5994 - acc: 0.7135 - val_loss: 0.6186 - val_acc: 0.6917\n",
      "Epoch 15/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5856 - acc: 0.7287 - val_loss: 0.6108 - val_acc: 0.7050\n",
      "Epoch 16/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5918 - acc: 0.7223 - val_loss: 0.5877 - val_acc: 0.7267\n",
      "Epoch 17/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6052 - acc: 0.7100 - val_loss: 0.5749 - val_acc: 0.7400\n",
      "Epoch 18/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6053 - acc: 0.7069 - val_loss: 0.5695 - val_acc: 0.7433\n",
      "Epoch 19/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5993 - acc: 0.7140 - val_loss: 0.5990 - val_acc: 0.7150\n",
      "Epoch 20/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5980 - acc: 0.7154 - val_loss: 0.5915 - val_acc: 0.7217\n",
      "Epoch 21/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6030 - acc: 0.7098 - val_loss: 0.6022 - val_acc: 0.7100\n",
      "Epoch 22/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5911 - acc: 0.7225 - val_loss: 0.6051 - val_acc: 0.7067\n",
      "Epoch 23/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5984 - acc: 0.7146 - val_loss: 0.6082 - val_acc: 0.7033\n",
      "Epoch 24/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5980 - acc: 0.7152 - val_loss: 0.6048 - val_acc: 0.7083\n",
      "Epoch 25/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5907 - acc: 0.7231 - val_loss: 0.6131 - val_acc: 0.7033\n",
      "Epoch 26/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5969 - acc: 0.7165 - val_loss: 0.5839 - val_acc: 0.7300\n",
      "Epoch 27/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6025 - acc: 0.7102 - val_loss: 0.5977 - val_acc: 0.7150\n",
      "Epoch 28/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5942 - acc: 0.7192 - val_loss: 0.6293 - val_acc: 0.6833\n",
      "Epoch 29/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5903 - acc: 0.7231 - val_loss: 0.5819 - val_acc: 0.7317\n",
      "Epoch 30/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5934 - acc: 0.7200 - val_loss: 0.6067 - val_acc: 0.7050\n",
      "Epoch 31/60\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.6041 - acc: 0.7079 - val_loss: 0.5912 - val_acc: 0.7233\n",
      "Epoch 32/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5955 - acc: 0.7179 - val_loss: 0.5945 - val_acc: 0.7183\n",
      "Epoch 33/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5991 - acc: 0.7133 - val_loss: 0.5866 - val_acc: 0.7283\n",
      "Epoch 34/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6025 - acc: 0.7094 - val_loss: 0.5899 - val_acc: 0.7233\n",
      "Epoch 35/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5970 - acc: 0.7160 - val_loss: 0.5992 - val_acc: 0.7133\n",
      "Epoch 36/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5986 - acc: 0.7144 - val_loss: 0.5849 - val_acc: 0.7283\n",
      "Epoch 37/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5983 - acc: 0.7146 - val_loss: 0.5961 - val_acc: 0.7167\n",
      "Epoch 38/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5984 - acc: 0.7144 - val_loss: 0.6007 - val_acc: 0.7117\n",
      "Epoch 39/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5980 - acc: 0.7148 - val_loss: 0.6110 - val_acc: 0.7000\n",
      "Epoch 40/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5977 - acc: 0.7154 - val_loss: 0.5653 - val_acc: 0.7500\n",
      "Epoch 41/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5953 - acc: 0.7179 - val_loss: 0.5763 - val_acc: 0.7383\n",
      "Epoch 42/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5908 - acc: 0.7225 - val_loss: 0.6040 - val_acc: 0.7083\n",
      "Epoch 43/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6023 - acc: 0.7104 - val_loss: 0.6054 - val_acc: 0.7067\n",
      "Epoch 44/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5935 - acc: 0.7196 - val_loss: 0.5882 - val_acc: 0.7250\n",
      "Epoch 45/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6070 - acc: 0.7050 - val_loss: 0.6198 - val_acc: 0.6900\n",
      "Epoch 46/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6003 - acc: 0.7121 - val_loss: 0.5753 - val_acc: 0.7383\n",
      "Epoch 47/60\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5959 - acc: 0.7173 - val_loss: 0.6025 - val_acc: 0.7098\n",
      "Epoch 48/60\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.5962 - acc: 0.7169 - val_loss: 0.5788 - val_acc: 0.7350\n",
      "Epoch 49/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5933 - acc: 0.7200 - val_loss: 0.5961 - val_acc: 0.7167\n",
      "Epoch 50/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5811 - acc: 0.7327 - val_loss: 0.6240 - val_acc: 0.6900\n",
      "Epoch 51/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5965 - acc: 0.7167 - val_loss: 0.5806 - val_acc: 0.7333\n",
      "Epoch 52/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5891 - acc: 0.7244 - val_loss: 0.5743 - val_acc: 0.7400\n",
      "Epoch 53/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6003 - acc: 0.7125 - val_loss: 0.5825 - val_acc: 0.7317\n",
      "Epoch 54/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5916 - acc: 0.7217 - val_loss: 0.5618 - val_acc: 0.7533\n",
      "Epoch 55/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6030 - acc: 0.7094 - val_loss: 0.5992 - val_acc: 0.7133\n",
      "Epoch 56/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6112 - acc: 0.7000 - val_loss: 0.5880 - val_acc: 0.7267\n",
      "Epoch 57/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5929 - acc: 0.7208 - val_loss: 0.5788 - val_acc: 0.7350\n",
      "Epoch 58/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5924 - acc: 0.7212 - val_loss: 0.5946 - val_acc: 0.7183\n",
      "Epoch 59/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6021 - acc: 0.7104 - val_loss: 0.5891 - val_acc: 0.7250\n",
      "Epoch 60/60\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6030 - acc: 0.7094 - val_loss: 0.5863 - val_acc: 0.7283\n",
      "\n",
      "Training process completed in: 0 h 1 m 52 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_969.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 971 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.01\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.6191 - acc: 0.7075 - val_loss: 0.5994 - val_acc: 0.7141\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.6004 - acc: 0.7129 - val_loss: 0.5878 - val_acc: 0.7254\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5948 - acc: 0.7190 - val_loss: 0.6046 - val_acc: 0.7074\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.5952 - acc: 0.7187 - val_loss: 0.5970 - val_acc: 0.7157\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.5967 - acc: 0.7168 - val_loss: 0.5983 - val_acc: 0.7153\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.6000 - acc: 0.7134 - val_loss: 0.5947 - val_acc: 0.7200\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5926 - acc: 0.7210 - val_loss: 0.5940 - val_acc: 0.7189\n",
      "Epoch 8/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.6008 - acc: 0.7121 - val_loss: 0.6025 - val_acc: 0.7117\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5954 - acc: 0.7177 - val_loss: 0.5928 - val_acc: 0.7204\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5943 - acc: 0.7195 - val_loss: 0.5995 - val_acc: 0.7133\n",
      "Epoch 11/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5960 - acc: 0.7171 - val_loss: 0.5967 - val_acc: 0.7160\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5975 - acc: 0.7155 - val_loss: 0.5961 - val_acc: 0.7176\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5958 - acc: 0.7177 - val_loss: 0.6017 - val_acc: 0.7115\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5959 - acc: 0.7173 - val_loss: 0.5951 - val_acc: 0.7178\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5982 - acc: 0.7146 - val_loss: 0.5935 - val_acc: 0.7197\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5964 - acc: 0.7167 - val_loss: 0.6005 - val_acc: 0.7122\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5992 - acc: 0.7137 - val_loss: 0.5955 - val_acc: 0.7173\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5998 - acc: 0.7129 - val_loss: 0.5948 - val_acc: 0.7181\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5957 - acc: 0.7173 - val_loss: 0.5946 - val_acc: 0.7191\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5926 - acc: 0.7208 - val_loss: 0.6032 - val_acc: 0.7099\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5981 - acc: 0.7146 - val_loss: 0.5917 - val_acc: 0.7214\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5964 - acc: 0.7165 - val_loss: 0.5985 - val_acc: 0.7150\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5957 - acc: 0.7175 - val_loss: 0.6007 - val_acc: 0.7121\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5971 - acc: 0.7159 - val_loss: 0.5970 - val_acc: 0.7157\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5934 - acc: 0.7198 - val_loss: 0.5973 - val_acc: 0.7154\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5987 - acc: 0.7140 - val_loss: 0.5947 - val_acc: 0.7181\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5949 - acc: 0.7183 - val_loss: 0.5960 - val_acc: 0.7168\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5968 - acc: 0.7160 - val_loss: 0.5977 - val_acc: 0.7152\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.6001 - acc: 0.7125 - val_loss: 0.5957 - val_acc: 0.7171\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5982 - acc: 0.7146 - val_loss: 0.5964 - val_acc: 0.7163\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5964 - acc: 0.7164 - val_loss: 0.5983 - val_acc: 0.7147\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5978 - acc: 0.7150 - val_loss: 0.5947 - val_acc: 0.7181\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5939 - acc: 0.7191 - val_loss: 0.5969 - val_acc: 0.7160\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5995 - acc: 0.7132 - val_loss: 0.5953 - val_acc: 0.7176\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5966 - acc: 0.7162 - val_loss: 0.6001 - val_acc: 0.7122\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.5985 - acc: 0.7142 - val_loss: 0.5966 - val_acc: 0.7161\n",
      "Epoch 37/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.5920 - acc: 0.7212 - val_loss: 0.5950 - val_acc: 0.7178\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5944 - acc: 0.7186 - val_loss: 0.5953 - val_acc: 0.7174\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.6047 - acc: 0.7074 - val_loss: 0.5997 - val_acc: 0.7131\n",
      "Epoch 40/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5938 - acc: 0.7192 - val_loss: 0.5955 - val_acc: 0.7176\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5937 - acc: 0.7194 - val_loss: 0.5941 - val_acc: 0.7189\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5984 - acc: 0.7143 - val_loss: 0.5981 - val_acc: 0.7145\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5904 - acc: 0.7229 - val_loss: 0.5991 - val_acc: 0.7135\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.5967 - acc: 0.7161 - val_loss: 0.5957 - val_acc: 0.7170\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.5960 - acc: 0.7168 - val_loss: 0.5930 - val_acc: 0.7200\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.5970 - acc: 0.7158 - val_loss: 0.6027 - val_acc: 0.7093\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5990 - acc: 0.7136 - val_loss: 0.5971 - val_acc: 0.7155\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5981 - acc: 0.7146 - val_loss: 0.5932 - val_acc: 0.7198\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.6018 - acc: 0.7105 - val_loss: 0.5982 - val_acc: 0.7144\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5961 - acc: 0.7168 - val_loss: 0.5990 - val_acc: 0.7136\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.6001 - acc: 0.7124 - val_loss: 0.5923 - val_acc: 0.7207\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5982 - acc: 0.7145 - val_loss: 0.5943 - val_acc: 0.7185\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5993 - acc: 0.7133 - val_loss: 0.5963 - val_acc: 0.7164\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5948 - acc: 0.7183 - val_loss: 0.5993 - val_acc: 0.7135\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.5934 - acc: 0.7196 - val_loss: 0.5977 - val_acc: 0.7150\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5960 - acc: 0.7169 - val_loss: 0.5905 - val_acc: 0.7228\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5957 - acc: 0.7171 - val_loss: 0.6043 - val_acc: 0.7078\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5943 - acc: 0.7187 - val_loss: 0.5912 - val_acc: 0.7218\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5967 - acc: 0.7161 - val_loss: 0.5945 - val_acc: 0.7184\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5967 - acc: 0.7161 - val_loss: 0.6065 - val_acc: 0.7063\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5971 - acc: 0.7156 - val_loss: 0.5922 - val_acc: 0.7209\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5976 - acc: 0.7151 - val_loss: 0.5962 - val_acc: 0.7165\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.6012 - acc: 0.7112 - val_loss: 0.5967 - val_acc: 0.7161\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5977 - acc: 0.7150 - val_loss: 0.5984 - val_acc: 0.7143\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5975 - acc: 0.7153 - val_loss: 0.5987 - val_acc: 0.7138\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.5943 - acc: 0.7186 - val_loss: 0.5993 - val_acc: 0.7137\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5925 - acc: 0.7206 - val_loss: 0.5981 - val_acc: 0.7147\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.5962 - acc: 0.7168 - val_loss: 0.5921 - val_acc: 0.7213\n",
      "Epoch 69/70\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.5967 - acc: 0.7162 - val_loss: 0.5908 - val_acc: 0.7232\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.6013 - acc: 0.7110 - val_loss: 0.5975 - val_acc: 0.7154\n",
      "\n",
      "Training process completed in: 0 h 12 m 40 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_970.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 972 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 60\n",
      "Learning Rate: 1e-05\n",
      "Epochs: 70\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "150/150 [==============================] - 5s 33ms/step - loss: 0.6418 - acc: 0.6980 - val_loss: 0.5860 - val_acc: 0.7147\n",
      "Epoch 2/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.5868 - acc: 0.7087 - val_loss: 0.5691 - val_acc: 0.7219\n",
      "Epoch 3/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.5732 - acc: 0.7186 - val_loss: 0.5756 - val_acc: 0.7111\n",
      "Epoch 4/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.5783 - acc: 0.7111 - val_loss: 0.5730 - val_acc: 0.7114\n",
      "Epoch 5/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.5734 - acc: 0.7104 - val_loss: 0.5512 - val_acc: 0.7294\n",
      "Epoch 6/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.5554 - acc: 0.7244 - val_loss: 0.5668 - val_acc: 0.6989\n",
      "Epoch 7/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.5453 - acc: 0.7208 - val_loss: 0.5266 - val_acc: 0.7283\n",
      "Epoch 8/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.5350 - acc: 0.7177 - val_loss: 0.5150 - val_acc: 0.7150\n",
      "Epoch 9/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.5101 - acc: 0.7259 - val_loss: 0.4797 - val_acc: 0.7556\n",
      "Epoch 10/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4760 - acc: 0.7619 - val_loss: 0.4574 - val_acc: 0.7869\n",
      "Epoch 11/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4598 - acc: 0.7849 - val_loss: 0.4512 - val_acc: 0.7958\n",
      "Epoch 12/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4528 - acc: 0.7957 - val_loss: 0.4276 - val_acc: 0.8150\n",
      "Epoch 13/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4304 - acc: 0.8099 - val_loss: 0.4153 - val_acc: 0.8164\n",
      "Epoch 14/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4421 - acc: 0.8060 - val_loss: 0.4298 - val_acc: 0.8183\n",
      "Epoch 15/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4254 - acc: 0.8151 - val_loss: 0.4426 - val_acc: 0.8036\n",
      "Epoch 16/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4265 - acc: 0.8137 - val_loss: 0.4175 - val_acc: 0.8161\n",
      "Epoch 17/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4229 - acc: 0.8181 - val_loss: 0.4179 - val_acc: 0.8167\n",
      "Epoch 18/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4250 - acc: 0.8134 - val_loss: 0.4368 - val_acc: 0.8075\n",
      "Epoch 19/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4190 - acc: 0.8220 - val_loss: 0.4325 - val_acc: 0.8061\n",
      "Epoch 20/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4172 - acc: 0.8219 - val_loss: 0.4338 - val_acc: 0.8125\n",
      "Epoch 21/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4179 - acc: 0.8252 - val_loss: 0.4104 - val_acc: 0.8256\n",
      "Epoch 22/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4288 - acc: 0.8154 - val_loss: 0.3967 - val_acc: 0.8358\n",
      "Epoch 23/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4123 - acc: 0.8282 - val_loss: 0.4142 - val_acc: 0.8219\n",
      "Epoch 24/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4126 - acc: 0.8217 - val_loss: 0.4259 - val_acc: 0.8119\n",
      "Epoch 25/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4147 - acc: 0.8259 - val_loss: 0.4135 - val_acc: 0.8211\n",
      "Epoch 26/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4236 - acc: 0.8162 - val_loss: 0.4093 - val_acc: 0.8250\n",
      "Epoch 27/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4044 - acc: 0.8248 - val_loss: 0.4341 - val_acc: 0.8156\n",
      "Epoch 28/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4161 - acc: 0.8206 - val_loss: 0.4094 - val_acc: 0.8203\n",
      "Epoch 29/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4147 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8153\n",
      "Epoch 30/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4122 - acc: 0.8256 - val_loss: 0.4186 - val_acc: 0.8203\n",
      "Epoch 31/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4054 - acc: 0.8298 - val_loss: 0.4079 - val_acc: 0.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4131 - acc: 0.8271 - val_loss: 0.4215 - val_acc: 0.8178\n",
      "Epoch 33/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4181 - acc: 0.8214 - val_loss: 0.4019 - val_acc: 0.8300\n",
      "Epoch 34/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4185 - acc: 0.8197 - val_loss: 0.4249 - val_acc: 0.8172\n",
      "Epoch 35/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4222 - acc: 0.8182 - val_loss: 0.4258 - val_acc: 0.8078\n",
      "Epoch 36/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4155 - acc: 0.8206 - val_loss: 0.4088 - val_acc: 0.8244\n",
      "Epoch 37/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4182 - acc: 0.8180 - val_loss: 0.4117 - val_acc: 0.8178\n",
      "Epoch 38/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4042 - acc: 0.8277 - val_loss: 0.3979 - val_acc: 0.8275\n",
      "Epoch 39/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4163 - acc: 0.8200 - val_loss: 0.4103 - val_acc: 0.8264\n",
      "Epoch 40/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4084 - acc: 0.8282 - val_loss: 0.4230 - val_acc: 0.8150\n",
      "Epoch 41/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4183 - acc: 0.8212 - val_loss: 0.4120 - val_acc: 0.8206\n",
      "Epoch 42/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4080 - acc: 0.8248 - val_loss: 0.4130 - val_acc: 0.8208\n",
      "Epoch 43/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4111 - acc: 0.8278 - val_loss: 0.4135 - val_acc: 0.8189\n",
      "Epoch 44/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4028 - acc: 0.8257 - val_loss: 0.4066 - val_acc: 0.8250\n",
      "Epoch 45/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.3942 - acc: 0.8289 - val_loss: 0.4059 - val_acc: 0.8233\n",
      "Epoch 46/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4028 - acc: 0.8256 - val_loss: 0.3998 - val_acc: 0.8289\n",
      "Epoch 47/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4123 - acc: 0.8220 - val_loss: 0.3969 - val_acc: 0.8270\n",
      "Epoch 48/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4109 - acc: 0.8251 - val_loss: 0.4102 - val_acc: 0.8247\n",
      "Epoch 49/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4082 - acc: 0.8227 - val_loss: 0.4086 - val_acc: 0.8267\n",
      "Epoch 50/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.3973 - acc: 0.8289 - val_loss: 0.4090 - val_acc: 0.8272\n",
      "Epoch 51/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4127 - acc: 0.8241 - val_loss: 0.4087 - val_acc: 0.8239\n",
      "Epoch 52/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4008 - acc: 0.8311 - val_loss: 0.4287 - val_acc: 0.8164\n",
      "Epoch 53/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4049 - acc: 0.8278 - val_loss: 0.3969 - val_acc: 0.8258\n",
      "Epoch 54/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.3988 - acc: 0.8270 - val_loss: 0.4190 - val_acc: 0.8125\n",
      "Epoch 55/70\n",
      "150/150 [==============================] - 4s 30ms/step - loss: 0.4180 - acc: 0.8191 - val_loss: 0.4173 - val_acc: 0.8186\n",
      "Epoch 56/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4015 - acc: 0.8279 - val_loss: 0.4039 - val_acc: 0.8264\n",
      "Epoch 57/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4064 - acc: 0.8277 - val_loss: 0.3983 - val_acc: 0.8239\n",
      "Epoch 58/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4067 - acc: 0.8271 - val_loss: 0.4202 - val_acc: 0.8150\n",
      "Epoch 59/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4070 - acc: 0.8227 - val_loss: 0.4112 - val_acc: 0.8194\n",
      "Epoch 60/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4154 - acc: 0.8217 - val_loss: 0.3893 - val_acc: 0.8344\n",
      "Epoch 61/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.3983 - acc: 0.8292 - val_loss: 0.4057 - val_acc: 0.8297\n",
      "Epoch 62/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4040 - acc: 0.8293 - val_loss: 0.3980 - val_acc: 0.8298\n",
      "Epoch 63/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.3942 - acc: 0.8307 - val_loss: 0.4185 - val_acc: 0.8144\n",
      "Epoch 64/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.3951 - acc: 0.8314 - val_loss: 0.3951 - val_acc: 0.8308\n",
      "Epoch 65/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4027 - acc: 0.8284 - val_loss: 0.3997 - val_acc: 0.8286\n",
      "Epoch 66/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4009 - acc: 0.8303 - val_loss: 0.4204 - val_acc: 0.8189\n",
      "Epoch 67/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4016 - acc: 0.8257 - val_loss: 0.4055 - val_acc: 0.8258\n",
      "Epoch 68/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.4018 - acc: 0.8243 - val_loss: 0.4104 - val_acc: 0.8131\n",
      "Epoch 69/70\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.3930 - acc: 0.8314 - val_loss: 0.3897 - val_acc: 0.8300\n",
      "Epoch 70/70\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.4035 - acc: 0.8262 - val_loss: 0.3957 - val_acc: 0.8309\n",
      "\n",
      "Training process completed in: 0 h 5 m 2 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_971.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 973 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.01\n",
      "Epochs: 30\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 0.5446 - acc: 0.7400 - val_loss: 0.5141 - val_acc: 0.7950\n",
      "Epoch 2/30\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.4659 - acc: 0.7998 - val_loss: 0.4553 - val_acc: 0.7935\n",
      "Epoch 3/30\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.4591 - acc: 0.8035 - val_loss: 0.4582 - val_acc: 0.7857\n",
      "Epoch 4/30\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.4507 - acc: 0.8059 - val_loss: 0.4322 - val_acc: 0.8105\n",
      "Epoch 5/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4451 - acc: 0.8095 - val_loss: 0.4406 - val_acc: 0.8151\n",
      "Epoch 6/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4436 - acc: 0.8073 - val_loss: 0.4323 - val_acc: 0.8129\n",
      "Epoch 7/30\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.4451 - acc: 0.8101 - val_loss: 0.4570 - val_acc: 0.8125\n",
      "Epoch 8/30\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.4365 - acc: 0.8119 - val_loss: 0.5124 - val_acc: 0.7909\n",
      "Epoch 9/30\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.4393 - acc: 0.8128 - val_loss: 0.4303 - val_acc: 0.8162\n",
      "Epoch 10/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4215 - acc: 0.8223 - val_loss: 0.4313 - val_acc: 0.8131\n",
      "Epoch 11/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4407 - acc: 0.8103 - val_loss: 0.4643 - val_acc: 0.8042\n",
      "Epoch 12/30\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.4280 - acc: 0.8179 - val_loss: 0.4587 - val_acc: 0.7965\n",
      "Epoch 13/30\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.4353 - acc: 0.8128 - val_loss: 0.4363 - val_acc: 0.8114\n",
      "Epoch 14/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4232 - acc: 0.8192 - val_loss: 0.4456 - val_acc: 0.8204\n",
      "Epoch 15/30\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.4272 - acc: 0.8194 - val_loss: 0.4248 - val_acc: 0.8152\n",
      "Epoch 16/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4206 - acc: 0.8211 - val_loss: 0.4270 - val_acc: 0.8158\n",
      "Epoch 17/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4322 - acc: 0.8147 - val_loss: 0.4165 - val_acc: 0.8222\n",
      "Epoch 18/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4273 - acc: 0.8179 - val_loss: 0.4317 - val_acc: 0.8246\n",
      "Epoch 19/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4101 - acc: 0.8257 - val_loss: 0.4261 - val_acc: 0.8129\n",
      "Epoch 20/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4225 - acc: 0.8212 - val_loss: 0.4980 - val_acc: 0.7968\n",
      "Epoch 21/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4180 - acc: 0.8211 - val_loss: 0.4116 - val_acc: 0.8249\n",
      "Epoch 22/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4208 - acc: 0.8203 - val_loss: 0.4555 - val_acc: 0.8138\n",
      "Epoch 23/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4188 - acc: 0.8242 - val_loss: 0.4309 - val_acc: 0.8190\n",
      "Epoch 24/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4179 - acc: 0.8232 - val_loss: 0.4126 - val_acc: 0.8249\n",
      "Epoch 25/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4173 - acc: 0.8223 - val_loss: 0.4693 - val_acc: 0.7907\n",
      "Epoch 26/30\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.4122 - acc: 0.8239 - val_loss: 0.4426 - val_acc: 0.8074\n",
      "Epoch 27/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4139 - acc: 0.8263 - val_loss: 0.4044 - val_acc: 0.8290\n",
      "Epoch 28/30\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4176 - acc: 0.8215 - val_loss: 0.4265 - val_acc: 0.8218\n",
      "Epoch 29/30\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.4063 - acc: 0.8277 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 30/30\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.4127 - acc: 0.8252 - val_loss: 0.4181 - val_acc: 0.8287\n",
      "\n",
      "Training process completed in: 0 h 7 m 50 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_972.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 974 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 1e-05\n",
      "Epochs: 90\n",
      "Steps per Epoch: 40\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.7034 - acc: 0.3789 - val_loss: 0.6781 - val_acc: 0.7163\n",
      "Epoch 2/90\n",
      "40/40 [==============================] - 6s 151ms/step - loss: 0.6701 - acc: 0.7046 - val_loss: 0.6458 - val_acc: 0.7154\n",
      "Epoch 3/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.6393 - acc: 0.7085 - val_loss: 0.6076 - val_acc: 0.7211\n",
      "Epoch 4/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.6029 - acc: 0.7205 - val_loss: 0.5889 - val_acc: 0.7097\n",
      "Epoch 5/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.5809 - acc: 0.7228 - val_loss: 0.5764 - val_acc: 0.7190\n",
      "Epoch 6/90\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5889 - acc: 0.7103 - val_loss: 0.5811 - val_acc: 0.7145\n",
      "Epoch 7/90\n",
      "40/40 [==============================] - 6s 145ms/step - loss: 0.5799 - acc: 0.7184 - val_loss: 0.5768 - val_acc: 0.7179\n",
      "Epoch 8/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.5816 - acc: 0.7172 - val_loss: 0.5773 - val_acc: 0.7167\n",
      "Epoch 9/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5816 - acc: 0.7146 - val_loss: 0.5809 - val_acc: 0.7132\n",
      "Epoch 10/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5817 - acc: 0.7156 - val_loss: 0.5754 - val_acc: 0.7175\n",
      "Epoch 11/90\n",
      "40/40 [==============================] - 6s 146ms/step - loss: 0.5740 - acc: 0.7208 - val_loss: 0.5784 - val_acc: 0.7132\n",
      "Epoch 12/90\n",
      "40/40 [==============================] - 6s 146ms/step - loss: 0.5828 - acc: 0.7108 - val_loss: 0.5650 - val_acc: 0.7249\n",
      "Epoch 13/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5776 - acc: 0.7145 - val_loss: 0.5776 - val_acc: 0.7121\n",
      "Epoch 14/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5788 - acc: 0.7136 - val_loss: 0.5710 - val_acc: 0.7151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/90\n",
      "40/40 [==============================] - 6s 143ms/step - loss: 0.5816 - acc: 0.7069 - val_loss: 0.5678 - val_acc: 0.7183\n",
      "Epoch 16/90\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5696 - acc: 0.7190 - val_loss: 0.5728 - val_acc: 0.7105\n",
      "Epoch 17/90\n",
      "40/40 [==============================] - 6s 148ms/step - loss: 0.5698 - acc: 0.7141 - val_loss: 0.5565 - val_acc: 0.7221\n",
      "Epoch 18/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.5639 - acc: 0.7189 - val_loss: 0.5662 - val_acc: 0.7115\n",
      "Epoch 19/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5591 - acc: 0.7221 - val_loss: 0.5551 - val_acc: 0.7175\n",
      "Epoch 20/90\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5573 - acc: 0.7170 - val_loss: 0.5502 - val_acc: 0.7185\n",
      "Epoch 21/90\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5552 - acc: 0.7151 - val_loss: 0.5462 - val_acc: 0.7147\n",
      "Epoch 22/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5469 - acc: 0.7150 - val_loss: 0.5378 - val_acc: 0.7169\n",
      "Epoch 23/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.5388 - acc: 0.7179 - val_loss: 0.5278 - val_acc: 0.7167\n",
      "Epoch 24/90\n",
      "40/40 [==============================] - 6s 151ms/step - loss: 0.5324 - acc: 0.7125 - val_loss: 0.5168 - val_acc: 0.7194\n",
      "Epoch 25/90\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5093 - acc: 0.7275 - val_loss: 0.5113 - val_acc: 0.7086\n",
      "Epoch 26/90\n",
      "40/40 [==============================] - 6s 146ms/step - loss: 0.4948 - acc: 0.7364 - val_loss: 0.4962 - val_acc: 0.7306\n",
      "Epoch 27/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4939 - acc: 0.7446 - val_loss: 0.4789 - val_acc: 0.7568\n",
      "Epoch 28/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4811 - acc: 0.7616 - val_loss: 0.4683 - val_acc: 0.7770\n",
      "Epoch 29/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4723 - acc: 0.7728 - val_loss: 0.4571 - val_acc: 0.7839\n",
      "Epoch 30/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4614 - acc: 0.7870 - val_loss: 0.4564 - val_acc: 0.7958\n",
      "Epoch 31/90\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.4586 - acc: 0.7970 - val_loss: 0.4486 - val_acc: 0.7897\n",
      "Epoch 32/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4407 - acc: 0.8001 - val_loss: 0.4415 - val_acc: 0.7997\n",
      "Epoch 33/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4440 - acc: 0.8066 - val_loss: 0.4395 - val_acc: 0.8033\n",
      "Epoch 34/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4406 - acc: 0.8112 - val_loss: 0.4346 - val_acc: 0.8075\n",
      "Epoch 35/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4458 - acc: 0.8020 - val_loss: 0.4321 - val_acc: 0.8133\n",
      "Epoch 36/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4357 - acc: 0.8152 - val_loss: 0.4314 - val_acc: 0.8128\n",
      "Epoch 37/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4170 - acc: 0.8231 - val_loss: 0.4234 - val_acc: 0.8189\n",
      "Epoch 38/90\n",
      "40/40 [==============================] - 6s 161ms/step - loss: 0.4232 - acc: 0.8179 - val_loss: 0.4305 - val_acc: 0.8138\n",
      "Epoch 39/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4208 - acc: 0.8191 - val_loss: 0.4190 - val_acc: 0.8192\n",
      "Epoch 40/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4385 - acc: 0.8118 - val_loss: 0.4344 - val_acc: 0.8132\n",
      "Epoch 41/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4227 - acc: 0.8179 - val_loss: 0.4216 - val_acc: 0.8178\n",
      "Epoch 42/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4395 - acc: 0.8125 - val_loss: 0.4208 - val_acc: 0.8200\n",
      "Epoch 43/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4273 - acc: 0.8150 - val_loss: 0.4239 - val_acc: 0.8176\n",
      "Epoch 44/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4224 - acc: 0.8178 - val_loss: 0.4325 - val_acc: 0.8147\n",
      "Epoch 45/90\n",
      "40/40 [==============================] - 7s 163ms/step - loss: 0.4237 - acc: 0.8192 - val_loss: 0.4230 - val_acc: 0.8184\n",
      "Epoch 46/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4128 - acc: 0.8255 - val_loss: 0.4264 - val_acc: 0.8173\n",
      "Epoch 47/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4153 - acc: 0.8246 - val_loss: 0.4254 - val_acc: 0.8153\n",
      "Epoch 48/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4189 - acc: 0.8245 - val_loss: 0.4208 - val_acc: 0.8158\n",
      "Epoch 49/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4222 - acc: 0.8227 - val_loss: 0.4115 - val_acc: 0.8257\n",
      "Epoch 50/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4269 - acc: 0.8189 - val_loss: 0.4241 - val_acc: 0.8168\n",
      "Epoch 51/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4276 - acc: 0.8146 - val_loss: 0.4237 - val_acc: 0.8184\n",
      "Epoch 52/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4205 - acc: 0.8240 - val_loss: 0.4362 - val_acc: 0.8116\n",
      "Epoch 53/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4187 - acc: 0.8210 - val_loss: 0.4123 - val_acc: 0.8234\n",
      "Epoch 54/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4213 - acc: 0.8175 - val_loss: 0.4161 - val_acc: 0.8215\n",
      "Epoch 55/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4255 - acc: 0.8224 - val_loss: 0.4167 - val_acc: 0.8231\n",
      "Epoch 56/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4074 - acc: 0.8310 - val_loss: 0.4278 - val_acc: 0.8179\n",
      "Epoch 57/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4272 - acc: 0.8202 - val_loss: 0.4170 - val_acc: 0.8206\n",
      "Epoch 58/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4136 - acc: 0.8291 - val_loss: 0.4165 - val_acc: 0.8244\n",
      "Epoch 59/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4331 - acc: 0.8168 - val_loss: 0.4166 - val_acc: 0.8183\n",
      "Epoch 60/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4177 - acc: 0.8218 - val_loss: 0.4198 - val_acc: 0.8208\n",
      "Epoch 61/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4157 - acc: 0.8206 - val_loss: 0.4144 - val_acc: 0.8213\n",
      "Epoch 62/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4189 - acc: 0.8249 - val_loss: 0.4213 - val_acc: 0.8215\n",
      "Epoch 63/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4274 - acc: 0.8184 - val_loss: 0.4121 - val_acc: 0.8215\n",
      "Epoch 64/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4120 - acc: 0.8277 - val_loss: 0.4223 - val_acc: 0.8156\n",
      "Epoch 65/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4348 - acc: 0.8120 - val_loss: 0.4146 - val_acc: 0.8238\n",
      "Epoch 66/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4329 - acc: 0.8163 - val_loss: 0.4105 - val_acc: 0.8207\n",
      "Epoch 67/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4074 - acc: 0.8256 - val_loss: 0.4220 - val_acc: 0.8193\n",
      "Epoch 68/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4167 - acc: 0.8238 - val_loss: 0.4114 - val_acc: 0.8252\n",
      "Epoch 69/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4133 - acc: 0.8210 - val_loss: 0.4203 - val_acc: 0.8179\n",
      "Epoch 70/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4168 - acc: 0.8198 - val_loss: 0.4146 - val_acc: 0.8214\n",
      "Epoch 71/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4113 - acc: 0.8233 - val_loss: 0.4139 - val_acc: 0.8215\n",
      "Epoch 72/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4156 - acc: 0.8229 - val_loss: 0.4168 - val_acc: 0.8225\n",
      "Epoch 73/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4112 - acc: 0.8281 - val_loss: 0.4247 - val_acc: 0.8159\n",
      "Epoch 74/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4067 - acc: 0.8249 - val_loss: 0.4078 - val_acc: 0.8232\n",
      "Epoch 75/90\n",
      "40/40 [==============================] - 6s 156ms/step - loss: 0.3918 - acc: 0.8379 - val_loss: 0.4179 - val_acc: 0.8172\n",
      "Epoch 76/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4108 - acc: 0.8239 - val_loss: 0.4140 - val_acc: 0.8218\n",
      "Epoch 77/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4170 - acc: 0.8230 - val_loss: 0.4109 - val_acc: 0.8260\n",
      "Epoch 78/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4070 - acc: 0.8267 - val_loss: 0.4054 - val_acc: 0.8282\n",
      "Epoch 79/90\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4037 - acc: 0.8305 - val_loss: 0.4183 - val_acc: 0.8174\n",
      "Epoch 80/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4284 - acc: 0.8160 - val_loss: 0.4199 - val_acc: 0.8147\n",
      "Epoch 81/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4174 - acc: 0.8201 - val_loss: 0.4032 - val_acc: 0.8292\n",
      "Epoch 82/90\n",
      "40/40 [==============================] - 6s 159ms/step - loss: 0.4109 - acc: 0.8211 - val_loss: 0.4175 - val_acc: 0.8209\n",
      "Epoch 83/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4140 - acc: 0.8256 - val_loss: 0.4135 - val_acc: 0.8209\n",
      "Epoch 84/90\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.4057 - acc: 0.8247 - val_loss: 0.4047 - val_acc: 0.8255\n",
      "Epoch 85/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4139 - acc: 0.8182 - val_loss: 0.4138 - val_acc: 0.8223\n",
      "Epoch 86/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4066 - acc: 0.8294 - val_loss: 0.4132 - val_acc: 0.8219\n",
      "Epoch 87/90\n",
      "40/40 [==============================] - 6s 156ms/step - loss: 0.4228 - acc: 0.8185 - val_loss: 0.4066 - val_acc: 0.8243\n",
      "Epoch 88/90\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4082 - acc: 0.8263 - val_loss: 0.4164 - val_acc: 0.8195\n",
      "Epoch 89/90\n",
      "40/40 [==============================] - 6s 162ms/step - loss: 0.4095 - acc: 0.8256 - val_loss: 0.4099 - val_acc: 0.8252\n",
      "Epoch 90/90\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4051 - acc: 0.8260 - val_loss: 0.4169 - val_acc: 0.8189\n",
      "\n",
      "Training process completed in: 0 h 9 m 10 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_973.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 975 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.1\n",
      "Epochs: 40\n",
      "Steps per Epoch: 20\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 4.1941 - acc: 0.7095 - val_loss: 4.5372 - val_acc: 0.7185\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.6904 - acc: 0.7090 - val_loss: 4.6850 - val_acc: 0.7093\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 2s 122ms/step - loss: 4.5775 - acc: 0.7160 - val_loss: 4.5426 - val_acc: 0.7182\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 2s 122ms/step - loss: 4.7307 - acc: 0.7065 - val_loss: 4.5050 - val_acc: 0.7205\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 2s 124ms/step - loss: 4.7307 - acc: 0.7065 - val_loss: 4.5982 - val_acc: 0.7147\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.6635 - val_acc: 0.7107\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.5158 - val_acc: 0.7198\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 4.3277 - acc: 0.7315 - val_loss: 4.4701 - val_acc: 0.7227\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.8757 - acc: 0.6975 - val_loss: 4.6393 - val_acc: 0.7122\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 2s 117ms/step - loss: 4.5050 - acc: 0.7205 - val_loss: 4.6199 - val_acc: 0.7134\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.5775 - acc: 0.7160 - val_loss: 4.6393 - val_acc: 0.7122\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.8354 - acc: 0.7000 - val_loss: 4.4781 - val_acc: 0.7222\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.5211 - acc: 0.7195 - val_loss: 4.5641 - val_acc: 0.7168\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 4.4567 - acc: 0.7235 - val_loss: 4.6117 - val_acc: 0.7139\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.6742 - acc: 0.7100 - val_loss: 4.4728 - val_acc: 0.7225\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.6796 - val_acc: 0.7097\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.6366 - val_acc: 0.7123\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.2955 - acc: 0.7335 - val_loss: 4.4916 - val_acc: 0.7213\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 4.6340 - acc: 0.7125 - val_loss: 4.5034 - val_acc: 0.7206\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.8113 - acc: 0.7015 - val_loss: 4.6528 - val_acc: 0.7113\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.8596 - acc: 0.6985 - val_loss: 4.5077 - val_acc: 0.7203\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.4647 - acc: 0.7230 - val_loss: 4.6716 - val_acc: 0.7102\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.5695 - acc: 0.7165 - val_loss: 4.5319 - val_acc: 0.7188\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 4.4141 - val_acc: 0.7261\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.5372 - acc: 0.7185 - val_loss: 4.5480 - val_acc: 0.7178\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.5614 - acc: 0.7170 - val_loss: 4.5829 - val_acc: 0.7157\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 4.4244 - acc: 0.7255 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 117ms/step - loss: 4.4244 - acc: 0.7255 - val_loss: 4.6036 - val_acc: 0.7144\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.6984 - acc: 0.7085 - val_loss: 4.6232 - val_acc: 0.7132\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.5695 - acc: 0.7165 - val_loss: 4.5372 - val_acc: 0.7185\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.4567 - acc: 0.7235 - val_loss: 4.5507 - val_acc: 0.7177\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 2s 120ms/step - loss: 4.5775 - acc: 0.7160 - val_loss: 4.6420 - val_acc: 0.7120\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 2s 122ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 4.5034 - val_acc: 0.7206\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.7307 - acc: 0.7065 - val_loss: 4.5211 - val_acc: 0.7195\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 4.5587 - val_acc: 0.7172\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 4.6984 - acc: 0.7085 - val_loss: 4.6232 - val_acc: 0.7132\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 2s 117ms/step - loss: 4.2552 - acc: 0.7360 - val_loss: 4.6581 - val_acc: 0.7110\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 3s 128ms/step - loss: 5.0691 - acc: 0.6855 - val_loss: 4.5820 - val_acc: 0.7157\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 2s 122ms/step - loss: 4.2874 - acc: 0.7340 - val_loss: 4.5963 - val_acc: 0.7148\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 4.5050 - acc: 0.7205 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "\n",
      "Training process completed in: 0 h 1 m 36 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_974.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 976 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 40\n",
      "Learning Rate: 1e-05\n",
      "Epochs: 90\n",
      "Steps per Epoch: 40\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6746 - acc: 0.6981 - val_loss: 0.6555 - val_acc: 0.7206\n",
      "Epoch 2/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6484 - acc: 0.7037 - val_loss: 0.6315 - val_acc: 0.6988\n",
      "Epoch 3/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6251 - acc: 0.7006 - val_loss: 0.6019 - val_acc: 0.7112\n",
      "Epoch 4/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6009 - acc: 0.7056 - val_loss: 0.5878 - val_acc: 0.7112\n",
      "Epoch 5/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5759 - acc: 0.7294 - val_loss: 0.5785 - val_acc: 0.7156\n",
      "Epoch 6/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5666 - acc: 0.7350 - val_loss: 0.5905 - val_acc: 0.7069\n",
      "Epoch 7/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5760 - acc: 0.7225 - val_loss: 0.5722 - val_acc: 0.7200\n",
      "Epoch 8/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5485 - acc: 0.7481 - val_loss: 0.5973 - val_acc: 0.6994\n",
      "Epoch 9/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5837 - acc: 0.7106 - val_loss: 0.5722 - val_acc: 0.7213\n",
      "Epoch 10/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5787 - acc: 0.7156 - val_loss: 0.5866 - val_acc: 0.7063\n",
      "Epoch 11/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5652 - acc: 0.7319 - val_loss: 0.5513 - val_acc: 0.7388\n",
      "Epoch 12/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5814 - acc: 0.7131 - val_loss: 0.5773 - val_acc: 0.7169\n",
      "Epoch 13/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5588 - acc: 0.7306 - val_loss: 0.5600 - val_acc: 0.7294\n",
      "Epoch 14/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5660 - acc: 0.7244 - val_loss: 0.5645 - val_acc: 0.7244\n",
      "Epoch 15/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5881 - acc: 0.7063 - val_loss: 0.5553 - val_acc: 0.7331\n",
      "Epoch 16/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5754 - acc: 0.7188 - val_loss: 0.5558 - val_acc: 0.7312\n",
      "Epoch 17/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5768 - acc: 0.7156 - val_loss: 0.5811 - val_acc: 0.7025\n",
      "Epoch 18/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5859 - acc: 0.6988 - val_loss: 0.5669 - val_acc: 0.7173\n",
      "Epoch 19/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5715 - acc: 0.7106 - val_loss: 0.5702 - val_acc: 0.7144\n",
      "Epoch 20/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5656 - acc: 0.7194 - val_loss: 0.5630 - val_acc: 0.7156\n",
      "Epoch 21/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5728 - acc: 0.7106 - val_loss: 0.5655 - val_acc: 0.7119\n",
      "Epoch 22/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5664 - acc: 0.7119 - val_loss: 0.5666 - val_acc: 0.7050\n",
      "Epoch 23/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5529 - acc: 0.7256 - val_loss: 0.5424 - val_acc: 0.7306\n",
      "Epoch 24/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5644 - acc: 0.7125 - val_loss: 0.5379 - val_acc: 0.7331\n",
      "Epoch 25/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5526 - acc: 0.7163 - val_loss: 0.5371 - val_acc: 0.7281\n",
      "Epoch 26/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5364 - acc: 0.7325 - val_loss: 0.5447 - val_acc: 0.7175\n",
      "Epoch 27/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5564 - acc: 0.7100 - val_loss: 0.5556 - val_acc: 0.6925\n",
      "Epoch 28/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5458 - acc: 0.7138 - val_loss: 0.5429 - val_acc: 0.7125\n",
      "Epoch 29/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5383 - acc: 0.7144 - val_loss: 0.5287 - val_acc: 0.7125\n",
      "Epoch 30/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5457 - acc: 0.7044 - val_loss: 0.5246 - val_acc: 0.7162\n",
      "Epoch 31/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5207 - acc: 0.7169 - val_loss: 0.5289 - val_acc: 0.7131\n",
      "Epoch 32/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5170 - acc: 0.7156 - val_loss: 0.5086 - val_acc: 0.7319\n",
      "Epoch 33/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5089 - acc: 0.7406 - val_loss: 0.5155 - val_acc: 0.7187\n",
      "Epoch 34/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5099 - acc: 0.7331 - val_loss: 0.5105 - val_acc: 0.7275\n",
      "Epoch 35/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5088 - acc: 0.7325 - val_loss: 0.4983 - val_acc: 0.7456\n",
      "Epoch 36/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5043 - acc: 0.7469 - val_loss: 0.5109 - val_acc: 0.7337\n",
      "Epoch 37/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.5006 - acc: 0.7525 - val_loss: 0.4889 - val_acc: 0.7588\n",
      "Epoch 38/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.5017 - acc: 0.7494 - val_loss: 0.4850 - val_acc: 0.7594\n",
      "Epoch 39/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4861 - acc: 0.7725 - val_loss: 0.4964 - val_acc: 0.7544\n",
      "Epoch 40/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4808 - acc: 0.7725 - val_loss: 0.4908 - val_acc: 0.7494\n",
      "Epoch 41/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4916 - acc: 0.7587 - val_loss: 0.4770 - val_acc: 0.7738\n",
      "Epoch 42/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4663 - acc: 0.7850 - val_loss: 0.4586 - val_acc: 0.7906\n",
      "Epoch 43/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4739 - acc: 0.7700 - val_loss: 0.4425 - val_acc: 0.8056\n",
      "Epoch 44/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4465 - acc: 0.7944 - val_loss: 0.4835 - val_acc: 0.7706\n",
      "Epoch 45/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4652 - acc: 0.7788 - val_loss: 0.4487 - val_acc: 0.7975\n",
      "Epoch 46/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4635 - acc: 0.7806 - val_loss: 0.4649 - val_acc: 0.7894\n",
      "Epoch 47/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4582 - acc: 0.7912 - val_loss: 0.4498 - val_acc: 0.7913\n",
      "Epoch 48/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4443 - acc: 0.8050 - val_loss: 0.4481 - val_acc: 0.8025\n",
      "Epoch 49/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4588 - acc: 0.7863 - val_loss: 0.4230 - val_acc: 0.8088\n",
      "Epoch 50/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4495 - acc: 0.7938 - val_loss: 0.4429 - val_acc: 0.7900\n",
      "Epoch 51/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4455 - acc: 0.7994 - val_loss: 0.4436 - val_acc: 0.8069\n",
      "Epoch 52/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4645 - acc: 0.7906 - val_loss: 0.4271 - val_acc: 0.8244\n",
      "Epoch 53/90\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.4240 - acc: 0.8081 - val_loss: 0.4336 - val_acc: 0.8028\n",
      "Epoch 54/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4470 - acc: 0.7925 - val_loss: 0.4511 - val_acc: 0.7944\n",
      "Epoch 55/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4142 - acc: 0.8244 - val_loss: 0.4572 - val_acc: 0.7944\n",
      "Epoch 56/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4478 - acc: 0.7925 - val_loss: 0.4522 - val_acc: 0.7913\n",
      "Epoch 57/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4313 - acc: 0.8087 - val_loss: 0.4278 - val_acc: 0.8013\n",
      "Epoch 58/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4646 - acc: 0.7775 - val_loss: 0.4247 - val_acc: 0.8106\n",
      "Epoch 59/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4418 - acc: 0.8050 - val_loss: 0.4421 - val_acc: 0.7994\n",
      "Epoch 60/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4149 - acc: 0.8169 - val_loss: 0.4246 - val_acc: 0.8262\n",
      "Epoch 61/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4506 - acc: 0.8050 - val_loss: 0.4381 - val_acc: 0.8150\n",
      "Epoch 62/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4431 - acc: 0.8044 - val_loss: 0.4239 - val_acc: 0.8137\n",
      "Epoch 63/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4160 - acc: 0.8194 - val_loss: 0.4260 - val_acc: 0.8081\n",
      "Epoch 64/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4504 - acc: 0.8069 - val_loss: 0.4360 - val_acc: 0.8106\n",
      "Epoch 65/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4289 - acc: 0.8106 - val_loss: 0.4235 - val_acc: 0.8119\n",
      "Epoch 66/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4136 - acc: 0.8181 - val_loss: 0.4458 - val_acc: 0.8100\n",
      "Epoch 67/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4275 - acc: 0.8081 - val_loss: 0.4324 - val_acc: 0.8125\n",
      "Epoch 68/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4398 - acc: 0.8025 - val_loss: 0.4272 - val_acc: 0.8225\n",
      "Epoch 69/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4111 - acc: 0.8231 - val_loss: 0.4048 - val_acc: 0.8306\n",
      "Epoch 70/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4226 - acc: 0.8181 - val_loss: 0.4301 - val_acc: 0.8109\n",
      "Epoch 71/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4414 - acc: 0.8150 - val_loss: 0.4301 - val_acc: 0.8075\n",
      "Epoch 72/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4180 - acc: 0.8250 - val_loss: 0.4331 - val_acc: 0.8119\n",
      "Epoch 73/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4348 - acc: 0.8044 - val_loss: 0.3738 - val_acc: 0.8394\n",
      "Epoch 74/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.3999 - acc: 0.8294 - val_loss: 0.4191 - val_acc: 0.8263\n",
      "Epoch 75/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4413 - acc: 0.8150 - val_loss: 0.4324 - val_acc: 0.8169\n",
      "Epoch 76/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4467 - acc: 0.8025 - val_loss: 0.4572 - val_acc: 0.7925\n",
      "Epoch 77/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4229 - acc: 0.8138 - val_loss: 0.4165 - val_acc: 0.8169\n",
      "Epoch 78/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4462 - acc: 0.7987 - val_loss: 0.4222 - val_acc: 0.8175\n",
      "Epoch 79/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.3977 - acc: 0.8319 - val_loss: 0.3949 - val_acc: 0.8438\n",
      "Epoch 80/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4367 - acc: 0.8125 - val_loss: 0.4122 - val_acc: 0.8306\n",
      "Epoch 81/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4130 - acc: 0.8187 - val_loss: 0.4193 - val_acc: 0.8137\n",
      "Epoch 82/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4420 - acc: 0.8075 - val_loss: 0.4288 - val_acc: 0.8044\n",
      "Epoch 83/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4345 - acc: 0.8138 - val_loss: 0.4165 - val_acc: 0.8294\n",
      "Epoch 84/90\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4161 - acc: 0.8225 - val_loss: 0.4744 - val_acc: 0.7888\n",
      "Epoch 85/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4172 - acc: 0.8275 - val_loss: 0.4192 - val_acc: 0.8106\n",
      "Epoch 86/90\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.4161 - acc: 0.8231 - val_loss: 0.4574 - val_acc: 0.7950\n",
      "Epoch 87/90\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.4058 - acc: 0.8275 - val_loss: 0.4306 - val_acc: 0.8103\n",
      "Epoch 88/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4419 - acc: 0.8125 - val_loss: 0.4041 - val_acc: 0.8225\n",
      "Epoch 89/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4435 - acc: 0.8031 - val_loss: 0.3894 - val_acc: 0.8450\n",
      "Epoch 90/90\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4322 - acc: 0.8075 - val_loss: 0.4137 - val_acc: 0.8194\n",
      "\n",
      "Training process completed in: 0 h 1 m 30 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_975.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 977 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.01\n",
      "Epochs: 70\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "130/130 [==============================] - 6s 48ms/step - loss: 0.6118 - acc: 0.7129 - val_loss: 0.6024 - val_acc: 0.7181\n",
      "Epoch 2/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6040 - acc: 0.7125 - val_loss: 0.5905 - val_acc: 0.7279\n",
      "Epoch 3/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6030 - acc: 0.7108 - val_loss: 0.6007 - val_acc: 0.7117\n",
      "Epoch 4/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5970 - acc: 0.7166 - val_loss: 0.6063 - val_acc: 0.7069\n",
      "Epoch 5/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5989 - acc: 0.7144 - val_loss: 0.6008 - val_acc: 0.7129\n",
      "Epoch 6/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5969 - acc: 0.7168 - val_loss: 0.6004 - val_acc: 0.7120\n",
      "Epoch 7/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5932 - acc: 0.7204 - val_loss: 0.5933 - val_acc: 0.7198\n",
      "Epoch 8/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5957 - acc: 0.7178 - val_loss: 0.6025 - val_acc: 0.7123\n",
      "Epoch 9/70\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.5945 - acc: 0.7192 - val_loss: 0.5827 - val_acc: 0.7306\n",
      "Epoch 10/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5984 - acc: 0.7160 - val_loss: 0.5898 - val_acc: 0.7237\n",
      "Epoch 11/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5972 - acc: 0.7162 - val_loss: 0.6058 - val_acc: 0.7063\n",
      "Epoch 12/70\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.5932 - acc: 0.7205 - val_loss: 0.6017 - val_acc: 0.7126\n",
      "Epoch 13/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6017 - acc: 0.7112 - val_loss: 0.6016 - val_acc: 0.7123\n",
      "Epoch 14/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5974 - acc: 0.7158 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 15/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6047 - acc: 0.7077 - val_loss: 0.5826 - val_acc: 0.7319\n",
      "Epoch 16/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5921 - acc: 0.7213 - val_loss: 0.6064 - val_acc: 0.7052\n",
      "Epoch 17/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6001 - acc: 0.7126 - val_loss: 0.5984 - val_acc: 0.7146\n",
      "Epoch 18/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6024 - acc: 0.7105 - val_loss: 0.5956 - val_acc: 0.7172\n",
      "Epoch 19/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5913 - acc: 0.7221 - val_loss: 0.5958 - val_acc: 0.7171\n",
      "Epoch 20/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5912 - acc: 0.7222 - val_loss: 0.5912 - val_acc: 0.7219\n",
      "Epoch 21/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5972 - acc: 0.7157 - val_loss: 0.5915 - val_acc: 0.7217\n",
      "Epoch 22/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5960 - acc: 0.7173 - val_loss: 0.5965 - val_acc: 0.7165\n",
      "Epoch 23/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5984 - acc: 0.7146 - val_loss: 0.6077 - val_acc: 0.7038\n",
      "Epoch 24/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5949 - acc: 0.7185 - val_loss: 0.5947 - val_acc: 0.7185\n",
      "Epoch 25/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5984 - acc: 0.7147 - val_loss: 0.6005 - val_acc: 0.7121\n",
      "Epoch 26/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5999 - acc: 0.7128 - val_loss: 0.6034 - val_acc: 0.7088\n",
      "Epoch 27/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5949 - acc: 0.7186 - val_loss: 0.6003 - val_acc: 0.7121\n",
      "Epoch 28/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5973 - acc: 0.7156 - val_loss: 0.5935 - val_acc: 0.7194\n",
      "Epoch 29/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5974 - acc: 0.7155 - val_loss: 0.5862 - val_acc: 0.7277\n",
      "Epoch 30/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6007 - acc: 0.7119 - val_loss: 0.5969 - val_acc: 0.7158\n",
      "Epoch 31/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5967 - acc: 0.7163 - val_loss: 0.5928 - val_acc: 0.7206\n",
      "Epoch 32/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5961 - acc: 0.7170 - val_loss: 0.6071 - val_acc: 0.7044\n",
      "Epoch 33/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5997 - acc: 0.7130 - val_loss: 0.5884 - val_acc: 0.7256\n",
      "Epoch 34/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5944 - acc: 0.7189 - val_loss: 0.5988 - val_acc: 0.7137\n",
      "Epoch 35/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6012 - acc: 0.7112 - val_loss: 0.5981 - val_acc: 0.7147\n",
      "Epoch 36/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5950 - acc: 0.7181 - val_loss: 0.5906 - val_acc: 0.7227\n",
      "Epoch 37/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5943 - acc: 0.7187 - val_loss: 0.5878 - val_acc: 0.7254\n",
      "Epoch 38/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5888 - acc: 0.7243 - val_loss: 0.6007 - val_acc: 0.7117\n",
      "Epoch 39/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5970 - acc: 0.7160 - val_loss: 0.5983 - val_acc: 0.7146\n",
      "Epoch 40/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5916 - acc: 0.7216 - val_loss: 0.6029 - val_acc: 0.7092\n",
      "Epoch 41/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5936 - acc: 0.7194 - val_loss: 0.5989 - val_acc: 0.7137\n",
      "Epoch 42/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6025 - acc: 0.7097 - val_loss: 0.6038 - val_acc: 0.7083\n",
      "Epoch 43/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5987 - acc: 0.7138 - val_loss: 0.6038 - val_acc: 0.7088\n",
      "Epoch 44/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6010 - acc: 0.7115 - val_loss: 0.5951 - val_acc: 0.7177\n",
      "Epoch 45/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5968 - acc: 0.7160 - val_loss: 0.5892 - val_acc: 0.7248\n",
      "Epoch 46/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5936 - acc: 0.7197 - val_loss: 0.5960 - val_acc: 0.7169\n",
      "Epoch 47/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5966 - acc: 0.7163 - val_loss: 0.5911 - val_acc: 0.7220\n",
      "Epoch 48/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5940 - acc: 0.7191 - val_loss: 0.6031 - val_acc: 0.7090\n",
      "Epoch 49/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5975 - acc: 0.7153 - val_loss: 0.5885 - val_acc: 0.7250\n",
      "Epoch 50/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6003 - acc: 0.7123 - val_loss: 0.5879 - val_acc: 0.7267\n",
      "Epoch 51/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5999 - acc: 0.7127 - val_loss: 0.6042 - val_acc: 0.7079\n",
      "Epoch 52/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6048 - acc: 0.7071 - val_loss: 0.6022 - val_acc: 0.7100\n",
      "Epoch 53/70\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.5947 - acc: 0.7184 - val_loss: 0.6002 - val_acc: 0.7122\n",
      "Epoch 54/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5920 - acc: 0.7213 - val_loss: 0.5848 - val_acc: 0.7287\n",
      "Epoch 55/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5883 - acc: 0.7250 - val_loss: 0.6046 - val_acc: 0.7083\n",
      "Epoch 56/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5960 - acc: 0.7170 - val_loss: 0.5906 - val_acc: 0.7225\n",
      "Epoch 57/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5931 - acc: 0.7198 - val_loss: 0.6058 - val_acc: 0.7058\n",
      "Epoch 58/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5976 - acc: 0.7152 - val_loss: 0.5998 - val_acc: 0.7126\n",
      "Epoch 59/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5992 - acc: 0.7134 - val_loss: 0.6023 - val_acc: 0.7100\n",
      "Epoch 60/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5984 - acc: 0.7144 - val_loss: 0.5936 - val_acc: 0.7194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5979 - acc: 0.7149 - val_loss: 0.5920 - val_acc: 0.7210\n",
      "Epoch 62/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6016 - acc: 0.7109 - val_loss: 0.5972 - val_acc: 0.7156\n",
      "Epoch 63/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.6017 - acc: 0.7108 - val_loss: 0.5948 - val_acc: 0.7183\n",
      "Epoch 64/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5907 - acc: 0.7224 - val_loss: 0.5976 - val_acc: 0.7154\n",
      "Epoch 65/70\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.5902 - acc: 0.7231 - val_loss: 0.5930 - val_acc: 0.7200\n",
      "Epoch 66/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5882 - acc: 0.7251 - val_loss: 0.5938 - val_acc: 0.7192\n",
      "Epoch 67/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5935 - acc: 0.7197 - val_loss: 0.6031 - val_acc: 0.7092\n",
      "Epoch 68/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6056 - acc: 0.7063 - val_loss: 0.5996 - val_acc: 0.7129\n",
      "Epoch 69/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.5878 - acc: 0.7258 - val_loss: 0.5942 - val_acc: 0.7190\n",
      "Epoch 70/70\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6003 - acc: 0.7123 - val_loss: 0.5900 - val_acc: 0.7241\n",
      "\n",
      "Training process completed in: 0 h 6 m 10 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_976.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 978 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.5806 - acc: 0.7166 - val_loss: 0.5593 - val_acc: 0.7152\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.4836 - acc: 0.7674 - val_loss: 0.4255 - val_acc: 0.8127\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.4220 - acc: 0.8189 - val_loss: 0.4085 - val_acc: 0.8238\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.4198 - acc: 0.8206 - val_loss: 0.4109 - val_acc: 0.8203\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.4145 - acc: 0.8244 - val_loss: 0.4173 - val_acc: 0.8199\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.4044 - acc: 0.8277 - val_loss: 0.4083 - val_acc: 0.8243\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.4050 - acc: 0.8250 - val_loss: 0.3975 - val_acc: 0.8286\n",
      "Epoch 8/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3999 - acc: 0.8266 - val_loss: 0.3950 - val_acc: 0.8298\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3932 - acc: 0.8317 - val_loss: 0.4033 - val_acc: 0.8277\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3936 - acc: 0.8315 - val_loss: 0.3875 - val_acc: 0.8326\n",
      "Epoch 11/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3989 - acc: 0.8288 - val_loss: 0.3976 - val_acc: 0.8227\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3923 - acc: 0.8318 - val_loss: 0.3833 - val_acc: 0.8321\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3891 - acc: 0.8338 - val_loss: 0.4002 - val_acc: 0.8288\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3874 - acc: 0.8353 - val_loss: 0.4012 - val_acc: 0.8231\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3900 - acc: 0.8328 - val_loss: 0.3891 - val_acc: 0.8323\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3798 - acc: 0.8382 - val_loss: 0.3982 - val_acc: 0.8297\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3822 - acc: 0.8380 - val_loss: 0.3711 - val_acc: 0.8382\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3834 - acc: 0.8355 - val_loss: 0.3813 - val_acc: 0.8353\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3714 - acc: 0.8402 - val_loss: 0.3703 - val_acc: 0.8397\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3725 - acc: 0.8395 - val_loss: 0.3700 - val_acc: 0.8393\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3716 - acc: 0.8427 - val_loss: 0.3667 - val_acc: 0.8428\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3691 - acc: 0.8401 - val_loss: 0.3653 - val_acc: 0.8427\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3660 - acc: 0.8461 - val_loss: 0.3670 - val_acc: 0.8417\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3647 - acc: 0.8451 - val_loss: 0.3687 - val_acc: 0.8391\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3572 - acc: 0.8487 - val_loss: 0.3563 - val_acc: 0.8494\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3711 - acc: 0.8435 - val_loss: 0.3628 - val_acc: 0.8453\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3606 - acc: 0.8461 - val_loss: 0.3561 - val_acc: 0.8499\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3597 - acc: 0.8487 - val_loss: 0.3586 - val_acc: 0.8444\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3571 - acc: 0.8459 - val_loss: 0.3612 - val_acc: 0.8470\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3594 - acc: 0.8492 - val_loss: 0.3537 - val_acc: 0.8495\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3563 - acc: 0.8476 - val_loss: 0.3533 - val_acc: 0.8528\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3502 - acc: 0.8535 - val_loss: 0.3520 - val_acc: 0.8524\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3485 - acc: 0.8525 - val_loss: 0.3671 - val_acc: 0.8444\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3582 - acc: 0.8471 - val_loss: 0.3660 - val_acc: 0.8443\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3622 - acc: 0.8456 - val_loss: 0.3507 - val_acc: 0.8503\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3537 - acc: 0.8493 - val_loss: 0.4207 - val_acc: 0.8134\n",
      "Epoch 37/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3439 - acc: 0.8546 - val_loss: 0.3451 - val_acc: 0.8563\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3466 - acc: 0.8542 - val_loss: 0.3704 - val_acc: 0.8449\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3514 - acc: 0.8523 - val_loss: 0.3786 - val_acc: 0.8374\n",
      "Epoch 40/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3457 - acc: 0.8541 - val_loss: 0.3449 - val_acc: 0.8552\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3472 - acc: 0.8527 - val_loss: 0.3456 - val_acc: 0.8542\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3441 - acc: 0.8555 - val_loss: 0.3520 - val_acc: 0.8507\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3476 - acc: 0.8532 - val_loss: 0.3678 - val_acc: 0.8451\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3519 - acc: 0.8506 - val_loss: 0.3403 - val_acc: 0.8567\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3435 - acc: 0.8547 - val_loss: 0.3462 - val_acc: 0.8547\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3403 - acc: 0.8554 - val_loss: 0.3411 - val_acc: 0.8571\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3417 - acc: 0.8563 - val_loss: 0.3438 - val_acc: 0.8568\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3384 - acc: 0.8580 - val_loss: 0.3404 - val_acc: 0.8594\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3421 - acc: 0.8573 - val_loss: 0.3432 - val_acc: 0.8549\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3396 - acc: 0.8553 - val_loss: 0.3355 - val_acc: 0.8579\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3438 - acc: 0.8531 - val_loss: 0.3380 - val_acc: 0.8553\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3448 - acc: 0.8533 - val_loss: 0.3360 - val_acc: 0.8576\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3377 - acc: 0.8567 - val_loss: 0.3354 - val_acc: 0.8573\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3371 - acc: 0.8586 - val_loss: 0.3476 - val_acc: 0.8537\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3369 - acc: 0.8582 - val_loss: 0.3423 - val_acc: 0.8550\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3377 - acc: 0.8596 - val_loss: 0.3326 - val_acc: 0.8601\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3371 - acc: 0.8555 - val_loss: 0.3352 - val_acc: 0.8586\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3319 - acc: 0.8585 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3299 - acc: 0.8606 - val_loss: 0.3441 - val_acc: 0.8544\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3386 - acc: 0.8575 - val_loss: 0.3360 - val_acc: 0.8595\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3373 - acc: 0.8570 - val_loss: 0.3323 - val_acc: 0.8607\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3319 - acc: 0.8603 - val_loss: 0.3424 - val_acc: 0.8548\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3309 - acc: 0.8598 - val_loss: 0.3346 - val_acc: 0.8592\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3348 - acc: 0.8587 - val_loss: 0.3462 - val_acc: 0.8530\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3278 - acc: 0.8616 - val_loss: 0.3608 - val_acc: 0.8451\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3304 - acc: 0.8609 - val_loss: 0.3260 - val_acc: 0.8638\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3264 - acc: 0.8604 - val_loss: 0.3395 - val_acc: 0.8581\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3331 - acc: 0.8585 - val_loss: 0.3313 - val_acc: 0.8601\n",
      "Epoch 69/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3363 - acc: 0.8585 - val_loss: 0.3401 - val_acc: 0.8575\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3268 - acc: 0.8635 - val_loss: 0.3337 - val_acc: 0.8600\n",
      "\n",
      "Training process completed in: 0 h 18 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_977.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 979 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.1\n",
      "Epochs: 80\n",
      "Steps per Epoch: 30\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "30/30 [==============================] - 8s 256ms/step - loss: 4.3851 - acc: 0.7119 - val_loss: 4.6289 - val_acc: 0.7128\n",
      "Epoch 2/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.5970 - acc: 0.7148 - val_loss: 4.5461 - val_acc: 0.7179\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 213ms/step - loss: 4.6944 - acc: 0.7087 - val_loss: 4.5947 - val_acc: 0.7149\n",
      "Epoch 4/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.5998 - val_acc: 0.7146\n",
      "Epoch 5/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.7313 - acc: 0.7065 - val_loss: 4.5544 - val_acc: 0.7174\n",
      "Epoch 6/80\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 4.5836 - acc: 0.7156 - val_loss: 4.4702 - val_acc: 0.7227\n",
      "Epoch 7/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.5970 - acc: 0.7148 - val_loss: 4.6180 - val_acc: 0.7135\n",
      "Epoch 8/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.6910 - acc: 0.7090 - val_loss: 4.5967 - val_acc: 0.7148\n",
      "Epoch 9/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.7548 - acc: 0.7050 - val_loss: 4.5411 - val_acc: 0.7183\n",
      "Epoch 10/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.4190 - acc: 0.7258 - val_loss: 4.5584 - val_acc: 0.7172\n",
      "Epoch 11/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.5903 - acc: 0.7152 - val_loss: 4.5816 - val_acc: 0.7157\n",
      "Epoch 12/80\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 4.6172 - acc: 0.7135 - val_loss: 4.6198 - val_acc: 0.7134\n",
      "Epoch 13/80\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 4.6340 - acc: 0.7125 - val_loss: 4.5097 - val_acc: 0.7202\n",
      "Epoch 14/80\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 4.5869 - acc: 0.7154 - val_loss: 4.6302 - val_acc: 0.7127\n",
      "Epoch 15/80\n",
      "30/30 [==============================] - 7s 225ms/step - loss: 4.4224 - acc: 0.7256 - val_loss: 4.6178 - val_acc: 0.7135\n",
      "Epoch 16/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.7145 - acc: 0.7075 - val_loss: 4.5998 - val_acc: 0.7146\n",
      "Epoch 17/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.6407 - acc: 0.7121 - val_loss: 4.5665 - val_acc: 0.7167\n",
      "Epoch 18/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.4023 - acc: 0.7269 - val_loss: 4.5340 - val_acc: 0.7187\n",
      "Epoch 19/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.5332 - acc: 0.7188 - val_loss: 4.5544 - val_acc: 0.7174\n",
      "Epoch 20/80\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 4.6172 - acc: 0.7135 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 21/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.5903 - acc: 0.7152 - val_loss: 4.5877 - val_acc: 0.7154\n",
      "Epoch 22/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5198 - acc: 0.7196 - val_loss: 4.5483 - val_acc: 0.7178\n",
      "Epoch 23/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.6776 - acc: 0.7098 - val_loss: 4.6211 - val_acc: 0.7133\n",
      "Epoch 24/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.5634 - acc: 0.7169 - val_loss: 4.5896 - val_acc: 0.7153\n",
      "Epoch 25/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.5064 - acc: 0.7204 - val_loss: 4.4610 - val_acc: 0.7232\n",
      "Epoch 26/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5869 - acc: 0.7154 - val_loss: 4.6350 - val_acc: 0.7124\n",
      "Epoch 27/80\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 4.3217 - acc: 0.7319 - val_loss: 4.5907 - val_acc: 0.7152\n",
      "Epoch 28/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.5131 - acc: 0.7200 - val_loss: 4.5563 - val_acc: 0.7173\n",
      "Epoch 29/80\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 4.6843 - acc: 0.7094 - val_loss: 4.5755 - val_acc: 0.7161\n",
      "Epoch 30/80\n",
      "30/30 [==============================] - 7s 225ms/step - loss: 4.6810 - acc: 0.7096 - val_loss: 4.5846 - val_acc: 0.7156\n",
      "Epoch 31/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.6978 - acc: 0.7085 - val_loss: 4.5725 - val_acc: 0.7163\n",
      "Epoch 32/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.7078 - acc: 0.7079 - val_loss: 4.5401 - val_acc: 0.7183\n",
      "Epoch 33/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.5231 - acc: 0.7194 - val_loss: 4.6188 - val_acc: 0.7134\n",
      "Epoch 34/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.6272 - acc: 0.7129 - val_loss: 4.5512 - val_acc: 0.7176\n",
      "Epoch 35/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.6407 - acc: 0.7121 - val_loss: 4.6059 - val_acc: 0.7142\n",
      "Epoch 36/80\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 4.5030 - acc: 0.7206 - val_loss: 4.5423 - val_acc: 0.7182\n",
      "Epoch 37/80\n",
      "30/30 [==============================] - 7s 225ms/step - loss: 4.4526 - acc: 0.7238 - val_loss: 4.6707 - val_acc: 0.7102\n",
      "Epoch 38/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.7246 - acc: 0.7069 - val_loss: 4.5403 - val_acc: 0.7183\n",
      "Epoch 39/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.5500 - acc: 0.7177 - val_loss: 4.4833 - val_acc: 0.7218\n",
      "Epoch 40/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.7716 - acc: 0.7040 - val_loss: 4.6239 - val_acc: 0.7131\n",
      "Epoch 41/80\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 4.5340 - val_acc: 0.7187\n",
      "Epoch 42/80\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 4.4157 - acc: 0.7260 - val_loss: 4.6413 - val_acc: 0.7120\n",
      "Epoch 43/80\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 4.5097 - acc: 0.7202 - val_loss: 4.5383 - val_acc: 0.7184\n",
      "Epoch 44/80\n",
      "30/30 [==============================] - 7s 225ms/step - loss: 4.3787 - acc: 0.7283 - val_loss: 4.5654 - val_acc: 0.7168\n",
      "Epoch 45/80\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 4.4661 - acc: 0.7229 - val_loss: 4.6239 - val_acc: 0.7131\n",
      "Epoch 46/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 4.5664 - val_acc: 0.7167\n",
      "Epoch 47/80\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 4.6407 - acc: 0.7121 - val_loss: 4.5633 - val_acc: 0.7169\n",
      "Epoch 48/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.7548 - acc: 0.7050 - val_loss: 4.5574 - val_acc: 0.7173\n",
      "Epoch 49/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5634 - acc: 0.7169 - val_loss: 4.6120 - val_acc: 0.7139\n",
      "Epoch 50/80\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 4.4929 - acc: 0.7212 - val_loss: 4.5383 - val_acc: 0.7184\n",
      "Epoch 51/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.4190 - acc: 0.7258 - val_loss: 4.6201 - val_acc: 0.7134\n",
      "Epoch 52/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.4560 - acc: 0.7235 - val_loss: 4.5513 - val_acc: 0.7176\n",
      "Epoch 53/80\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 4.5433 - acc: 0.7181 - val_loss: 4.5289 - val_acc: 0.7190\n",
      "Epoch 54/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.7078 - acc: 0.7079 - val_loss: 4.6191 - val_acc: 0.7134\n",
      "Epoch 55/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.6205 - acc: 0.7133 - val_loss: 4.6138 - val_acc: 0.7137\n",
      "Epoch 56/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.5802 - acc: 0.7158 - val_loss: 4.5157 - val_acc: 0.7198\n",
      "Epoch 57/80\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 4.5198 - acc: 0.7196 - val_loss: 4.5906 - val_acc: 0.7152\n",
      "Epoch 58/80\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 4.5231 - acc: 0.7194 - val_loss: 4.5968 - val_acc: 0.7148\n",
      "Epoch 59/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.6575 - acc: 0.7110 - val_loss: 4.5785 - val_acc: 0.7159\n",
      "Epoch 60/80\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 4.5265 - acc: 0.7192 - val_loss: 4.5097 - val_acc: 0.7202\n",
      "Epoch 61/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.6071 - acc: 0.7142 - val_loss: 4.6413 - val_acc: 0.7120\n",
      "Epoch 62/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.5399 - acc: 0.7183 - val_loss: 4.5806 - val_acc: 0.7158\n",
      "Epoch 63/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.6742 - acc: 0.7100 - val_loss: 4.5259 - val_acc: 0.7192\n",
      "Epoch 64/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.7347 - acc: 0.7063 - val_loss: 4.6299 - val_acc: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.7683 - acc: 0.7042 - val_loss: 4.5441 - val_acc: 0.7181\n",
      "Epoch 66/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5601 - acc: 0.7171 - val_loss: 4.5604 - val_acc: 0.7171\n",
      "Epoch 67/80\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 4.8287 - acc: 0.7004 - val_loss: 4.5796 - val_acc: 0.7159\n",
      "Epoch 68/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.6944 - acc: 0.7088 - val_loss: 4.6383 - val_acc: 0.7122\n",
      "Epoch 69/80\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 4.5500 - acc: 0.7177 - val_loss: 4.5685 - val_acc: 0.7166\n",
      "Epoch 70/80\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 4.5231 - acc: 0.7194 - val_loss: 4.5218 - val_acc: 0.7195\n",
      "Epoch 71/80\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 4.6978 - acc: 0.7085 - val_loss: 4.5735 - val_acc: 0.7163\n",
      "Epoch 72/80\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 4.4996 - acc: 0.7208 - val_loss: 4.6332 - val_acc: 0.7125\n",
      "Epoch 73/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.4316 - acc: 0.7251 - val_loss: 4.5624 - val_acc: 0.7169\n",
      "Epoch 74/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5567 - acc: 0.7173 - val_loss: 4.5259 - val_acc: 0.7192\n",
      "Epoch 75/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.3989 - acc: 0.7271 - val_loss: 4.6292 - val_acc: 0.7128\n",
      "Epoch 76/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.6104 - acc: 0.7140 - val_loss: 4.5524 - val_acc: 0.7176\n",
      "Epoch 77/80\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 4.5231 - acc: 0.7194 - val_loss: 4.5775 - val_acc: 0.7160\n",
      "Epoch 78/80\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 4.4929 - acc: 0.7212 - val_loss: 4.5876 - val_acc: 0.7154\n",
      "Epoch 79/80\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 4.6440 - acc: 0.7119 - val_loss: 4.5299 - val_acc: 0.7190\n",
      "Epoch 80/80\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 4.5131 - acc: 0.7200 - val_loss: 4.5896 - val_acc: 0.7152\n",
      "\n",
      "Training process completed in: 0 h 8 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_978.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 980 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.01\n",
      "Epochs: 40\n",
      "Steps per Epoch: 60\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "60/60 [==============================] - 5s 79ms/step - loss: 0.6682 - acc: 0.7192 - val_loss: 0.6044 - val_acc: 0.7077\n",
      "Epoch 2/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.6003 - acc: 0.7163 - val_loss: 0.5915 - val_acc: 0.7216\n",
      "Epoch 3/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5895 - acc: 0.7265 - val_loss: 0.6011 - val_acc: 0.7116\n",
      "Epoch 4/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5980 - acc: 0.7173 - val_loss: 0.5920 - val_acc: 0.7228\n",
      "Epoch 5/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5947 - acc: 0.7198 - val_loss: 0.5977 - val_acc: 0.7150\n",
      "Epoch 6/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5981 - acc: 0.7154 - val_loss: 0.6066 - val_acc: 0.7086\n",
      "Epoch 7/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.6007 - acc: 0.7129 - val_loss: 0.5922 - val_acc: 0.7223\n",
      "Epoch 8/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5943 - acc: 0.7204 - val_loss: 0.5946 - val_acc: 0.7184\n",
      "Epoch 9/40\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.6085 - acc: 0.7033 - val_loss: 0.5989 - val_acc: 0.7251\n",
      "Epoch 10/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5941 - acc: 0.7192 - val_loss: 0.6007 - val_acc: 0.7120\n",
      "Epoch 11/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5943 - acc: 0.7194 - val_loss: 0.6067 - val_acc: 0.7067\n",
      "Epoch 12/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5929 - acc: 0.7208 - val_loss: 0.5923 - val_acc: 0.7233\n",
      "Epoch 13/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.6109 - acc: 0.7015 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 14/40\n",
      "60/60 [==============================] - 4s 66ms/step - loss: 0.5970 - acc: 0.7167 - val_loss: 0.5921 - val_acc: 0.7222\n",
      "Epoch 15/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.6036 - acc: 0.7092 - val_loss: 0.6029 - val_acc: 0.7097\n",
      "Epoch 16/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5984 - acc: 0.7148 - val_loss: 0.5976 - val_acc: 0.7159\n",
      "Epoch 17/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5972 - acc: 0.7163 - val_loss: 0.5938 - val_acc: 0.7191\n",
      "Epoch 18/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5999 - acc: 0.7133 - val_loss: 0.5984 - val_acc: 0.7151\n",
      "Epoch 19/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5955 - acc: 0.7177 - val_loss: 0.5987 - val_acc: 0.7147\n",
      "Epoch 20/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5883 - acc: 0.7260 - val_loss: 0.5979 - val_acc: 0.7147\n",
      "Epoch 21/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5887 - acc: 0.7250 - val_loss: 0.6004 - val_acc: 0.7127\n",
      "Epoch 22/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5915 - acc: 0.7221 - val_loss: 0.5919 - val_acc: 0.7212\n",
      "Epoch 23/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5877 - acc: 0.7260 - val_loss: 0.5980 - val_acc: 0.7170\n",
      "Epoch 24/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.6029 - acc: 0.7100 - val_loss: 0.5982 - val_acc: 0.7144\n",
      "Epoch 25/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5952 - acc: 0.7181 - val_loss: 0.5970 - val_acc: 0.7158\n",
      "Epoch 26/40\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.6004 - acc: 0.7125 - val_loss: 0.5961 - val_acc: 0.7169\n",
      "Epoch 27/40\n",
      "60/60 [==============================] - 4s 68ms/step - loss: 0.6048 - acc: 0.7077 - val_loss: 0.5969 - val_acc: 0.7159\n",
      "Epoch 28/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5935 - acc: 0.7202 - val_loss: 0.5965 - val_acc: 0.7170\n",
      "Epoch 29/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5990 - acc: 0.7142 - val_loss: 0.5969 - val_acc: 0.7181\n",
      "Epoch 30/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.6018 - acc: 0.7113 - val_loss: 0.5995 - val_acc: 0.7130\n",
      "Epoch 31/40\n",
      "60/60 [==============================] - 4s 64ms/step - loss: 0.6016 - acc: 0.7110 - val_loss: 0.5969 - val_acc: 0.7165\n",
      "Epoch 32/40\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.5934 - acc: 0.7200 - val_loss: 0.5909 - val_acc: 0.7222\n",
      "Epoch 33/40\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.5940 - acc: 0.7196 - val_loss: 0.5942 - val_acc: 0.7187\n",
      "Epoch 34/40\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.6034 - acc: 0.7092 - val_loss: 0.6029 - val_acc: 0.7092\n",
      "Epoch 35/40\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.5777 - acc: 0.7362 - val_loss: 0.6007 - val_acc: 0.7148\n",
      "Epoch 36/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.6010 - acc: 0.7127 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 37/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.6015 - acc: 0.7115 - val_loss: 0.5954 - val_acc: 0.7177\n",
      "Epoch 38/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.6031 - acc: 0.7094 - val_loss: 0.6045 - val_acc: 0.7073\n",
      "Epoch 39/40\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.5952 - acc: 0.7188 - val_loss: 0.5902 - val_acc: 0.7230\n",
      "Epoch 40/40\n",
      "60/60 [==============================] - 4s 65ms/step - loss: 0.5965 - acc: 0.7171 - val_loss: 0.6013 - val_acc: 0.7110\n",
      "\n",
      "Training process completed in: 0 h 2 m 31 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_979.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 981 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 0.5180 - acc: 0.7539 - val_loss: 0.4701 - val_acc: 0.7943\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4530 - acc: 0.8044 - val_loss: 0.4137 - val_acc: 0.8239\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4161 - acc: 0.8194 - val_loss: 0.4226 - val_acc: 0.8195\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4072 - acc: 0.8271 - val_loss: 0.4076 - val_acc: 0.8265\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4130 - acc: 0.8281 - val_loss: 0.4037 - val_acc: 0.8223\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4079 - acc: 0.8235 - val_loss: 0.4146 - val_acc: 0.8376\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.4045 - acc: 0.8280 - val_loss: 0.3990 - val_acc: 0.8277\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3858 - acc: 0.8336 - val_loss: 0.3806 - val_acc: 0.8337\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3894 - acc: 0.8356 - val_loss: 0.3818 - val_acc: 0.8427\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3866 - acc: 0.8340 - val_loss: 0.4699 - val_acc: 0.8121\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3775 - acc: 0.8402 - val_loss: 0.3750 - val_acc: 0.8417\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3731 - acc: 0.8425 - val_loss: 0.3724 - val_acc: 0.8436\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3812 - acc: 0.8376 - val_loss: 0.3654 - val_acc: 0.8454\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3676 - acc: 0.8433 - val_loss: 0.3764 - val_acc: 0.8380\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3658 - acc: 0.8473 - val_loss: 0.3577 - val_acc: 0.8487\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3744 - acc: 0.8390 - val_loss: 0.3801 - val_acc: 0.8501\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3690 - acc: 0.8424 - val_loss: 0.3717 - val_acc: 0.8415\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3620 - acc: 0.8482 - val_loss: 0.3460 - val_acc: 0.8525\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3545 - acc: 0.8496 - val_loss: 0.3599 - val_acc: 0.8536\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3580 - acc: 0.8486 - val_loss: 0.3671 - val_acc: 0.8439\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3636 - acc: 0.8435 - val_loss: 0.3807 - val_acc: 0.8495\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3578 - acc: 0.8496 - val_loss: 0.3738 - val_acc: 0.8448\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3550 - acc: 0.8511 - val_loss: 0.3523 - val_acc: 0.8523\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3500 - acc: 0.8536 - val_loss: 0.3486 - val_acc: 0.8479\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3508 - acc: 0.8512 - val_loss: 0.3577 - val_acc: 0.8452\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3501 - acc: 0.8530 - val_loss: 0.3591 - val_acc: 0.8470\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3494 - acc: 0.8524 - val_loss: 0.3446 - val_acc: 0.8507\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3528 - acc: 0.8476 - val_loss: 0.3631 - val_acc: 0.8499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3561 - acc: 0.8496 - val_loss: 0.3532 - val_acc: 0.8514\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3448 - acc: 0.8536 - val_loss: 0.3554 - val_acc: 0.8535\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3586 - acc: 0.8465 - val_loss: 0.3553 - val_acc: 0.8583\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3412 - acc: 0.8536 - val_loss: 0.3441 - val_acc: 0.8560\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3373 - acc: 0.8586 - val_loss: 0.3762 - val_acc: 0.8461\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3383 - acc: 0.8546 - val_loss: 0.3405 - val_acc: 0.8568\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3341 - acc: 0.8588 - val_loss: 0.3600 - val_acc: 0.8430\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3381 - acc: 0.8536 - val_loss: 0.3416 - val_acc: 0.8595\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3509 - acc: 0.8496 - val_loss: 0.3408 - val_acc: 0.8596\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3388 - acc: 0.8557 - val_loss: 0.3560 - val_acc: 0.8455\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3421 - acc: 0.8571 - val_loss: 0.3584 - val_acc: 0.8602\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3367 - acc: 0.8575 - val_loss: 0.3487 - val_acc: 0.8587\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3332 - acc: 0.8592 - val_loss: 0.4018 - val_acc: 0.8215\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3427 - acc: 0.8554 - val_loss: 0.3455 - val_acc: 0.8552\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3382 - acc: 0.8577 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.3303 - acc: 0.8592 - val_loss: 0.3446 - val_acc: 0.8597\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3455 - acc: 0.8532 - val_loss: 0.3368 - val_acc: 0.8560\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 9s 76ms/step - loss: 0.3273 - acc: 0.8598 - val_loss: 0.3289 - val_acc: 0.8613\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3337 - acc: 0.8550 - val_loss: 0.3617 - val_acc: 0.8517\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3270 - acc: 0.8627 - val_loss: 0.3405 - val_acc: 0.8601\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3398 - acc: 0.8573 - val_loss: 0.3437 - val_acc: 0.8605\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.3288 - acc: 0.8601 - val_loss: 0.3262 - val_acc: 0.8622\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 9s 76ms/step - loss: 0.3349 - acc: 0.8583 - val_loss: 0.3546 - val_acc: 0.8579\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 0.3386 - acc: 0.8559 - val_loss: 0.3830 - val_acc: 0.8539\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3330 - acc: 0.8582 - val_loss: 0.3330 - val_acc: 0.8604\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3300 - acc: 0.8621 - val_loss: 0.3360 - val_acc: 0.8576\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3215 - acc: 0.8617 - val_loss: 0.3263 - val_acc: 0.8601\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3270 - acc: 0.8611 - val_loss: 0.3346 - val_acc: 0.8593\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3156 - acc: 0.8643 - val_loss: 0.3291 - val_acc: 0.8610\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3210 - acc: 0.8651 - val_loss: 0.3320 - val_acc: 0.8643\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3304 - acc: 0.8601 - val_loss: 0.3154 - val_acc: 0.8671\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3257 - acc: 0.8596 - val_loss: 0.3227 - val_acc: 0.8652\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3256 - acc: 0.8600 - val_loss: 0.3350 - val_acc: 0.8630\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3208 - acc: 0.8632 - val_loss: 0.3448 - val_acc: 0.8569\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3239 - acc: 0.8630 - val_loss: 0.3457 - val_acc: 0.8521\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3215 - acc: 0.8672 - val_loss: 0.3366 - val_acc: 0.8588\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3319 - acc: 0.8609 - val_loss: 0.3256 - val_acc: 0.8662\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3239 - acc: 0.8631 - val_loss: 0.3334 - val_acc: 0.8588\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 0.3262 - acc: 0.8611 - val_loss: 0.3501 - val_acc: 0.8581\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3198 - acc: 0.8639 - val_loss: 0.3222 - val_acc: 0.8689\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3241 - acc: 0.8612 - val_loss: 0.3371 - val_acc: 0.8579\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3186 - acc: 0.8669 - val_loss: 0.3371 - val_acc: 0.8673\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.3245 - acc: 0.8632 - val_loss: 0.3265 - val_acc: 0.8626\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3183 - acc: 0.8660 - val_loss: 0.3393 - val_acc: 0.8645\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.3154 - acc: 0.8685 - val_loss: 0.3223 - val_acc: 0.8612\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3234 - acc: 0.8641 - val_loss: 0.3325 - val_acc: 0.8523\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 9s 76ms/step - loss: 0.3205 - acc: 0.8627 - val_loss: 0.3221 - val_acc: 0.8701\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3180 - acc: 0.8660 - val_loss: 0.3177 - val_acc: 0.8664\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3260 - acc: 0.8629 - val_loss: 0.3369 - val_acc: 0.8648\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3227 - acc: 0.8636 - val_loss: 0.3256 - val_acc: 0.8681\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3173 - acc: 0.8663 - val_loss: 0.3207 - val_acc: 0.8681\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3156 - acc: 0.8660 - val_loss: 0.3377 - val_acc: 0.8595\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3206 - acc: 0.8622 - val_loss: 0.3327 - val_acc: 0.8539\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3269 - acc: 0.8627 - val_loss: 0.3298 - val_acc: 0.8631\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3214 - acc: 0.8611 - val_loss: 0.3218 - val_acc: 0.8677\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3186 - acc: 0.8661 - val_loss: 0.3300 - val_acc: 0.8679\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3202 - acc: 0.8654 - val_loss: 0.3317 - val_acc: 0.8635\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3186 - acc: 0.8660 - val_loss: 0.3282 - val_acc: 0.8683\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3100 - acc: 0.8692 - val_loss: 0.3235 - val_acc: 0.8625\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3186 - acc: 0.8629 - val_loss: 0.3137 - val_acc: 0.8683\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3108 - acc: 0.8718 - val_loss: 0.3231 - val_acc: 0.8682\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3212 - acc: 0.8622 - val_loss: 0.3267 - val_acc: 0.8568\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3131 - acc: 0.8658 - val_loss: 0.3234 - val_acc: 0.8673\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3125 - acc: 0.8681 - val_loss: 0.3254 - val_acc: 0.8674\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3075 - acc: 0.8690 - val_loss: 0.3129 - val_acc: 0.8677\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3032 - acc: 0.8732 - val_loss: 0.3154 - val_acc: 0.8687\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.3174 - acc: 0.8645 - val_loss: 0.3131 - val_acc: 0.8712\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3125 - acc: 0.8675 - val_loss: 0.3305 - val_acc: 0.8583\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3186 - acc: 0.8664 - val_loss: 0.3236 - val_acc: 0.8607\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3177 - acc: 0.8684 - val_loss: 0.3372 - val_acc: 0.8536\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3160 - acc: 0.8651 - val_loss: 0.3137 - val_acc: 0.8706\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.3104 - acc: 0.8704 - val_loss: 0.3234 - val_acc: 0.8670\n",
      "\n",
      "Training process completed in: 0 h 14 m 44 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_980.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 982 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 40\n",
      "Learning Rate: 1e-05\n",
      "Epochs: 30\n",
      "Steps per Epoch: 60\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.6529 - acc: 0.7104 - val_loss: 0.6363 - val_acc: 0.7104\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5973 - acc: 0.7367 - val_loss: 0.5874 - val_acc: 0.7163\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5849 - acc: 0.7142 - val_loss: 0.5638 - val_acc: 0.7296\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5617 - acc: 0.7308 - val_loss: 0.5720 - val_acc: 0.7196\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5809 - acc: 0.7125 - val_loss: 0.5859 - val_acc: 0.7046\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5822 - acc: 0.7079 - val_loss: 0.5792 - val_acc: 0.7083\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5715 - acc: 0.7154 - val_loss: 0.5562 - val_acc: 0.7300\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5901 - acc: 0.6913 - val_loss: 0.5692 - val_acc: 0.7167\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5642 - acc: 0.7212 - val_loss: 0.5612 - val_acc: 0.7208\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5587 - acc: 0.7246 - val_loss: 0.5621 - val_acc: 0.7129\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5670 - acc: 0.7108 - val_loss: 0.5578 - val_acc: 0.7150\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.5538 - acc: 0.7204 - val_loss: 0.5697 - val_acc: 0.6982\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5698 - acc: 0.6983 - val_loss: 0.5396 - val_acc: 0.7292\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5471 - acc: 0.7229 - val_loss: 0.5323 - val_acc: 0.7283\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5416 - acc: 0.7229 - val_loss: 0.5383 - val_acc: 0.7137\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5354 - acc: 0.7162 - val_loss: 0.5238 - val_acc: 0.7200\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5238 - acc: 0.7258 - val_loss: 0.5233 - val_acc: 0.7175\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5182 - acc: 0.7212 - val_loss: 0.5266 - val_acc: 0.7150\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5092 - acc: 0.7208 - val_loss: 0.5027 - val_acc: 0.7412\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.4980 - acc: 0.7300 - val_loss: 0.5065 - val_acc: 0.7525\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5085 - acc: 0.7375 - val_loss: 0.4728 - val_acc: 0.7762\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.4730 - acc: 0.7708 - val_loss: 0.4667 - val_acc: 0.7904\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.4618 - acc: 0.7858 - val_loss: 0.5102 - val_acc: 0.7512\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.4826 - acc: 0.7737 - val_loss: 0.4675 - val_acc: 0.7931\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4670 - acc: 0.7842 - val_loss: 0.4543 - val_acc: 0.7904\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4637 - acc: 0.7892 - val_loss: 0.4540 - val_acc: 0.7942\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4677 - acc: 0.7800 - val_loss: 0.4539 - val_acc: 0.7904\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4536 - acc: 0.7992 - val_loss: 0.4628 - val_acc: 0.7858\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4608 - acc: 0.7946 - val_loss: 0.4397 - val_acc: 0.7967\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4546 - acc: 0.7879 - val_loss: 0.4661 - val_acc: 0.7858\n",
      "\n",
      "Training process completed in: 0 h 0 m 51 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: \" MODELS / model_breast_cancer_981.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 983 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 120\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.5074 - acc: 0.7650 - val_loss: 0.4307 - val_acc: 0.8140\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.4297 - acc: 0.8195 - val_loss: 0.4113 - val_acc: 0.8181\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.4291 - acc: 0.8140 - val_loss: 0.4013 - val_acc: 0.8219\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.4081 - acc: 0.8274 - val_loss: 0.4509 - val_acc: 0.8125\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.4096 - acc: 0.8253 - val_loss: 0.4485 - val_acc: 0.7846\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.4089 - acc: 0.8252 - val_loss: 0.4218 - val_acc: 0.8314\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.4101 - acc: 0.8237 - val_loss: 0.4333 - val_acc: 0.8260\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.4071 - acc: 0.8265 - val_loss: 0.3831 - val_acc: 0.8321\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3894 - acc: 0.8309 - val_loss: 0.4044 - val_acc: 0.8361\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3865 - acc: 0.8351 - val_loss: 0.3883 - val_acc: 0.8329\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3830 - acc: 0.8351 - val_loss: 0.3920 - val_acc: 0.8400\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3845 - acc: 0.8341 - val_loss: 0.3967 - val_acc: 0.8336\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3880 - acc: 0.8349 - val_loss: 0.3728 - val_acc: 0.8376\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3699 - acc: 0.8427 - val_loss: 0.3784 - val_acc: 0.8421\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3747 - acc: 0.8362 - val_loss: 0.3879 - val_acc: 0.8216\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3544 - acc: 0.8501 - val_loss: 0.3816 - val_acc: 0.8384\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3638 - acc: 0.8433 - val_loss: 0.3679 - val_acc: 0.8450\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3712 - acc: 0.8407 - val_loss: 0.3676 - val_acc: 0.8387\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3915 - acc: 0.8286 - val_loss: 0.3771 - val_acc: 0.8451\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3772 - acc: 0.8363 - val_loss: 0.3790 - val_acc: 0.8426\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3489 - acc: 0.8524 - val_loss: 0.3594 - val_acc: 0.8455\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3515 - acc: 0.8491 - val_loss: 0.3617 - val_acc: 0.8444\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3640 - acc: 0.8440 - val_loss: 0.3602 - val_acc: 0.8505\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3663 - acc: 0.8460 - val_loss: 0.3865 - val_acc: 0.8470\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3477 - acc: 0.8515 - val_loss: 0.3515 - val_acc: 0.8474\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3515 - acc: 0.8517 - val_loss: 0.3691 - val_acc: 0.8557\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3617 - acc: 0.8471 - val_loss: 0.3961 - val_acc: 0.8320\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3515 - acc: 0.8528 - val_loss: 0.3515 - val_acc: 0.8569\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3406 - acc: 0.8565 - val_loss: 0.3591 - val_acc: 0.8517\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3460 - acc: 0.8533 - val_loss: 0.3508 - val_acc: 0.8552\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3431 - acc: 0.8548 - val_loss: 0.3436 - val_acc: 0.8543\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3323 - acc: 0.8637 - val_loss: 0.3442 - val_acc: 0.8578\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3392 - acc: 0.8548 - val_loss: 0.3583 - val_acc: 0.8467\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3377 - acc: 0.8567 - val_loss: 0.3452 - val_acc: 0.8617\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3465 - acc: 0.8541 - val_loss: 0.3687 - val_acc: 0.8544\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3421 - acc: 0.8526 - val_loss: 0.3596 - val_acc: 0.8579\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3399 - acc: 0.8537 - val_loss: 0.3448 - val_acc: 0.8564\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3283 - acc: 0.8616 - val_loss: 0.3343 - val_acc: 0.8591\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3336 - acc: 0.8573 - val_loss: 0.3319 - val_acc: 0.8574\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3397 - acc: 0.8583 - val_loss: 0.3362 - val_acc: 0.8634\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3332 - acc: 0.8574 - val_loss: 0.3468 - val_acc: 0.8472\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3429 - acc: 0.8541 - val_loss: 0.3386 - val_acc: 0.8517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3293 - acc: 0.8604 - val_loss: 0.3378 - val_acc: 0.8568\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3401 - acc: 0.8538 - val_loss: 0.3417 - val_acc: 0.8581\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3285 - acc: 0.8618 - val_loss: 0.3321 - val_acc: 0.8617\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3277 - acc: 0.8631 - val_loss: 0.3458 - val_acc: 0.8569\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3293 - acc: 0.8640 - val_loss: 0.3397 - val_acc: 0.8640\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3306 - acc: 0.8576 - val_loss: 0.3460 - val_acc: 0.8599\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3215 - acc: 0.8670 - val_loss: 0.3412 - val_acc: 0.8576\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3246 - acc: 0.8628 - val_loss: 0.3288 - val_acc: 0.8590\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3182 - acc: 0.8642 - val_loss: 0.3436 - val_acc: 0.8645\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3260 - acc: 0.8631 - val_loss: 0.3396 - val_acc: 0.8575\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3271 - acc: 0.8610 - val_loss: 0.3444 - val_acc: 0.8582\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3237 - acc: 0.8633 - val_loss: 0.3502 - val_acc: 0.8545\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3272 - acc: 0.8617 - val_loss: 0.3358 - val_acc: 0.8591\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3342 - acc: 0.8580 - val_loss: 0.3447 - val_acc: 0.8601\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3269 - acc: 0.8622 - val_loss: 0.3267 - val_acc: 0.8656\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3267 - acc: 0.8632 - val_loss: 0.3235 - val_acc: 0.8631\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3336 - acc: 0.8586 - val_loss: 0.3327 - val_acc: 0.8576\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3321 - acc: 0.8585 - val_loss: 0.3200 - val_acc: 0.8701\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3208 - acc: 0.8663 - val_loss: 0.3297 - val_acc: 0.8640\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3297 - acc: 0.8614 - val_loss: 0.3290 - val_acc: 0.8621\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3183 - acc: 0.8647 - val_loss: 0.3301 - val_acc: 0.8570\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3153 - acc: 0.8709 - val_loss: 0.3341 - val_acc: 0.8644\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3178 - acc: 0.8674 - val_loss: 0.3251 - val_acc: 0.8666\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3255 - acc: 0.8631 - val_loss: 0.3284 - val_acc: 0.8645\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3244 - acc: 0.8638 - val_loss: 0.3519 - val_acc: 0.8592\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3197 - acc: 0.8662 - val_loss: 0.3399 - val_acc: 0.8538\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3204 - acc: 0.8676 - val_loss: 0.3187 - val_acc: 0.8700\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3204 - acc: 0.8639 - val_loss: 0.3508 - val_acc: 0.8704\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3141 - acc: 0.8660 - val_loss: 0.3192 - val_acc: 0.8666\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3255 - acc: 0.8649 - val_loss: 0.3223 - val_acc: 0.8633\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3199 - acc: 0.8639 - val_loss: 0.3191 - val_acc: 0.8675\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3180 - acc: 0.8643 - val_loss: 0.3290 - val_acc: 0.8630\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3257 - acc: 0.8623 - val_loss: 0.3402 - val_acc: 0.8612\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3250 - acc: 0.8601 - val_loss: 0.3343 - val_acc: 0.8640\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3219 - acc: 0.8657 - val_loss: 0.3384 - val_acc: 0.8606\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3043 - acc: 0.8733 - val_loss: 0.3292 - val_acc: 0.8603\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3138 - acc: 0.8662 - val_loss: 0.3216 - val_acc: 0.8700\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3180 - acc: 0.8673 - val_loss: 0.3194 - val_acc: 0.8708\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3211 - acc: 0.8642 - val_loss: 0.3344 - val_acc: 0.8625\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3250 - acc: 0.8637 - val_loss: 0.3348 - val_acc: 0.8651\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3150 - acc: 0.8678 - val_loss: 0.3163 - val_acc: 0.8697\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3082 - acc: 0.8698 - val_loss: 0.3321 - val_acc: 0.8578\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3182 - acc: 0.8681 - val_loss: 0.3210 - val_acc: 0.8628\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3112 - acc: 0.8691 - val_loss: 0.3274 - val_acc: 0.8595\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3097 - acc: 0.8683 - val_loss: 0.3169 - val_acc: 0.8690\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3214 - acc: 0.8638 - val_loss: 0.3147 - val_acc: 0.8750\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3055 - acc: 0.8727 - val_loss: 0.3346 - val_acc: 0.8611\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3062 - acc: 0.8706 - val_loss: 0.3482 - val_acc: 0.8532\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3230 - acc: 0.8627 - val_loss: 0.3588 - val_acc: 0.8519\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.3138 - acc: 0.8686 - val_loss: 0.3137 - val_acc: 0.8742\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.3053 - acc: 0.8724 - val_loss: 0.3281 - val_acc: 0.8613\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3097 - acc: 0.8678 - val_loss: 0.3133 - val_acc: 0.8721\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3111 - acc: 0.8707 - val_loss: 0.3099 - val_acc: 0.8701\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3062 - acc: 0.8708 - val_loss: 0.3250 - val_acc: 0.8609\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3072 - acc: 0.8698 - val_loss: 0.3188 - val_acc: 0.8689\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3161 - acc: 0.8676 - val_loss: 0.3236 - val_acc: 0.8671\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3117 - acc: 0.8710 - val_loss: 0.3199 - val_acc: 0.8620\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.3125 - acc: 0.8685 - val_loss: 0.3116 - val_acc: 0.8678\n",
      "\n",
      "Training process completed in: 0 h 13 m 52 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_982.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 984 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "170/170 [==============================] - 7s 40ms/step - loss: 0.5096 - acc: 0.7622 - val_loss: 0.5168 - val_acc: 0.7535\n",
      "Epoch 2/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.4552 - acc: 0.8043 - val_loss: 0.4560 - val_acc: 0.7819\n",
      "Epoch 3/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.4294 - acc: 0.8172 - val_loss: 0.4922 - val_acc: 0.7994\n",
      "Epoch 4/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.4327 - acc: 0.8180 - val_loss: 0.4549 - val_acc: 0.7927\n",
      "Epoch 5/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.4209 - acc: 0.8214 - val_loss: 0.4145 - val_acc: 0.8185\n",
      "Epoch 6/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.4137 - acc: 0.8214 - val_loss: 0.4385 - val_acc: 0.8317\n",
      "Epoch 7/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.4127 - acc: 0.8200 - val_loss: 0.4292 - val_acc: 0.8146\n",
      "Epoch 8/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.4030 - acc: 0.8279 - val_loss: 0.4024 - val_acc: 0.8263\n",
      "Epoch 9/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3997 - acc: 0.8283 - val_loss: 0.3877 - val_acc: 0.8315\n",
      "Epoch 10/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3959 - acc: 0.8293 - val_loss: 0.4165 - val_acc: 0.8288\n",
      "Epoch 11/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3929 - acc: 0.8297 - val_loss: 0.4102 - val_acc: 0.8210\n",
      "Epoch 12/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3956 - acc: 0.8315 - val_loss: 0.3959 - val_acc: 0.8192\n",
      "Epoch 13/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3938 - acc: 0.8275 - val_loss: 0.4167 - val_acc: 0.8360\n",
      "Epoch 14/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3804 - acc: 0.8404 - val_loss: 0.4352 - val_acc: 0.8231\n",
      "Epoch 15/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3935 - acc: 0.8329 - val_loss: 0.4206 - val_acc: 0.8323\n",
      "Epoch 16/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3930 - acc: 0.8320 - val_loss: 0.4391 - val_acc: 0.8296\n",
      "Epoch 17/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3774 - acc: 0.8375 - val_loss: 0.3775 - val_acc: 0.8415\n",
      "Epoch 18/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3909 - acc: 0.8299 - val_loss: 0.3992 - val_acc: 0.8355\n",
      "Epoch 19/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3890 - acc: 0.8331 - val_loss: 0.4152 - val_acc: 0.8417\n",
      "Epoch 20/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3768 - acc: 0.8410 - val_loss: 0.3848 - val_acc: 0.8440\n",
      "Epoch 21/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3839 - acc: 0.8359 - val_loss: 0.3849 - val_acc: 0.8346\n",
      "Epoch 22/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3651 - acc: 0.8463 - val_loss: 0.4605 - val_acc: 0.8135\n",
      "Epoch 23/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3789 - acc: 0.8374 - val_loss: 0.4214 - val_acc: 0.8471\n",
      "Epoch 24/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3716 - acc: 0.8402 - val_loss: 0.3861 - val_acc: 0.8483\n",
      "Epoch 25/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3839 - acc: 0.8348 - val_loss: 0.3896 - val_acc: 0.8519\n",
      "Epoch 26/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3669 - acc: 0.8398 - val_loss: 0.3764 - val_acc: 0.8490\n",
      "Epoch 27/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3597 - acc: 0.8503 - val_loss: 0.3806 - val_acc: 0.8315\n",
      "Epoch 28/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3694 - acc: 0.8456 - val_loss: 0.3931 - val_acc: 0.8363\n",
      "Epoch 29/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3721 - acc: 0.8430 - val_loss: 0.3790 - val_acc: 0.8435\n",
      "Epoch 30/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3581 - acc: 0.8489 - val_loss: 0.3596 - val_acc: 0.8508\n",
      "Epoch 31/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3712 - acc: 0.8418 - val_loss: 0.3726 - val_acc: 0.8381\n",
      "Epoch 32/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3708 - acc: 0.8466 - val_loss: 0.4090 - val_acc: 0.8310\n",
      "Epoch 33/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3685 - acc: 0.8464 - val_loss: 0.4033 - val_acc: 0.8419\n",
      "Epoch 34/40\n",
      "170/170 [==============================] - 5s 32ms/step - loss: 0.3549 - acc: 0.8469 - val_loss: 0.3579 - val_acc: 0.8431\n",
      "Epoch 35/40\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.3583 - acc: 0.8504 - val_loss: 0.3766 - val_acc: 0.8378\n",
      "Epoch 36/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3574 - acc: 0.8470 - val_loss: 0.3999 - val_acc: 0.8363\n",
      "Epoch 37/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3577 - acc: 0.8482 - val_loss: 0.3443 - val_acc: 0.8535\n",
      "Epoch 38/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3438 - acc: 0.8575 - val_loss: 0.3656 - val_acc: 0.8542\n",
      "Epoch 39/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3625 - acc: 0.8457 - val_loss: 0.3760 - val_acc: 0.8281\n",
      "Epoch 40/40\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.3612 - acc: 0.8449 - val_loss: 0.3756 - val_acc: 0.8500\n",
      "\n",
      "Training process completed in: 0 h 3 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_983.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 985 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 20\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.4875 - acc: 0.7778 - val_loss: 0.4208 - val_acc: 0.8189\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.4289 - acc: 0.8146 - val_loss: 0.4210 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.4127 - acc: 0.8241 - val_loss: 0.3999 - val_acc: 0.8273\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.4003 - acc: 0.8278 - val_loss: 0.3973 - val_acc: 0.8236\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.4018 - acc: 0.8302 - val_loss: 0.4524 - val_acc: 0.8310\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.3985 - acc: 0.8298 - val_loss: 0.4233 - val_acc: 0.8337\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3894 - acc: 0.8320 - val_loss: 0.4345 - val_acc: 0.8251\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.3912 - acc: 0.8327 - val_loss: 0.4473 - val_acc: 0.8278\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3848 - acc: 0.8355 - val_loss: 0.3851 - val_acc: 0.8411\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3761 - acc: 0.8397 - val_loss: 0.3863 - val_acc: 0.8330\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3779 - acc: 0.8399 - val_loss: 0.4153 - val_acc: 0.8327\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3723 - acc: 0.8408 - val_loss: 0.4235 - val_acc: 0.8051\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3716 - acc: 0.8426 - val_loss: 0.3784 - val_acc: 0.8416\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3670 - acc: 0.8416 - val_loss: 0.4287 - val_acc: 0.8410\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3635 - acc: 0.8456 - val_loss: 0.3856 - val_acc: 0.8539\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3576 - acc: 0.8471 - val_loss: 0.3741 - val_acc: 0.8418\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3509 - acc: 0.8503 - val_loss: 0.3919 - val_acc: 0.8447\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3509 - acc: 0.8518 - val_loss: 0.3673 - val_acc: 0.8489\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3500 - acc: 0.8519 - val_loss: 0.3941 - val_acc: 0.8521\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3463 - acc: 0.8521 - val_loss: 0.3640 - val_acc: 0.8598\n",
      "\n",
      "Training process completed in: 0 h 3 m 20 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_984.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 986 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 20\n",
      "Learning Rate: 0.01\n",
      "Epochs: 80\n",
      "Steps per Epoch: 50\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "50/50 [==============================] - 2s 50ms/step - loss: 4.6393 - acc: 0.7080 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 2/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.8444 - val_acc: 0.6994\n",
      "Epoch 3/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.4164 - acc: 0.7260 - val_loss: 4.7907 - val_acc: 0.7028\n",
      "Epoch 4/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.3877 - val_acc: 0.7278\n",
      "Epoch 5/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.3698 - val_acc: 0.7289\n",
      "Epoch 6/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.7226 - acc: 0.7070 - val_loss: 4.5310 - val_acc: 0.7189\n",
      "Epoch 7/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 3.9973 - acc: 0.7520 - val_loss: 4.3787 - val_acc: 0.7283\n",
      "Epoch 8/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3358 - acc: 0.7310 - val_loss: 4.6742 - val_acc: 0.7100\n",
      "Epoch 9/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3841 - acc: 0.7280 - val_loss: 4.3071 - val_acc: 0.7328\n",
      "Epoch 10/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4969 - acc: 0.7210 - val_loss: 4.4772 - val_acc: 0.7222\n",
      "Epoch 11/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4325 - acc: 0.7250 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 12/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5131 - acc: 0.7200 - val_loss: 4.3787 - val_acc: 0.7283\n",
      "Epoch 13/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8193 - acc: 0.7010 - val_loss: 4.4952 - val_acc: 0.7211\n",
      "Epoch 14/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.7387 - acc: 0.7060 - val_loss: 5.0324 - val_acc: 0.6878\n",
      "Epoch 15/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.6581 - acc: 0.7110 - val_loss: 4.8086 - val_acc: 0.7017\n",
      "Epoch 16/80\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 4.1424 - acc: 0.7430 - val_loss: 4.4882 - val_acc: 0.7215\n",
      "Epoch 17/80\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 4.4486 - acc: 0.7240 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 18/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3519 - acc: 0.7300 - val_loss: 4.3698 - val_acc: 0.7289\n",
      "Epoch 19/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.7065 - acc: 0.7080 - val_loss: 4.7817 - val_acc: 0.7033\n",
      "Epoch 20/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.6098 - acc: 0.7140 - val_loss: 4.5847 - val_acc: 0.7156\n",
      "Epoch 21/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5614 - acc: 0.7170 - val_loss: 4.4414 - val_acc: 0.7244\n",
      "Epoch 22/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 5.0450 - acc: 0.6870 - val_loss: 4.5220 - val_acc: 0.7194\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 22ms/step - loss: 4.7548 - acc: 0.7050 - val_loss: 4.6653 - val_acc: 0.7106\n",
      "Epoch 24/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8354 - acc: 0.7000 - val_loss: 4.6653 - val_acc: 0.7106\n",
      "Epoch 25/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.6116 - val_acc: 0.7139\n",
      "Epoch 26/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4002 - acc: 0.7270 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 27/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.6742 - acc: 0.7100 - val_loss: 4.1907 - val_acc: 0.7400\n",
      "Epoch 28/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 5.1094 - acc: 0.6830 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 29/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3680 - acc: 0.7290 - val_loss: 4.7459 - val_acc: 0.7056\n",
      "Epoch 30/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 31/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4647 - acc: 0.7230 - val_loss: 4.7401 - val_acc: 0.7059\n",
      "Epoch 32/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.0288 - acc: 0.6880 - val_loss: 4.4325 - val_acc: 0.7250\n",
      "Epoch 33/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.4325 - acc: 0.7250 - val_loss: 4.3787 - val_acc: 0.7283\n",
      "Epoch 34/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.7727 - val_acc: 0.7039\n",
      "Epoch 35/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2552 - acc: 0.7360 - val_loss: 4.7817 - val_acc: 0.7033\n",
      "Epoch 36/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.7387 - acc: 0.7060 - val_loss: 4.4504 - val_acc: 0.7239\n",
      "Epoch 37/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.0933 - acc: 0.6840 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 38/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.3035 - acc: 0.7330 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 39/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.7907 - val_acc: 0.7028\n",
      "Epoch 40/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.8193 - acc: 0.7010 - val_loss: 4.3071 - val_acc: 0.7328\n",
      "Epoch 41/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2874 - acc: 0.7340 - val_loss: 4.6653 - val_acc: 0.7106\n",
      "Epoch 42/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.3035 - acc: 0.7330 - val_loss: 4.5399 - val_acc: 0.7183\n",
      "Epoch 43/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.1094 - acc: 0.6830 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 44/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.1094 - acc: 0.6830 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 45/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 5.1578 - acc: 0.6800 - val_loss: 4.6116 - val_acc: 0.7139\n",
      "Epoch 46/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.5041 - val_acc: 0.7206\n",
      "Epoch 47/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.8193 - acc: 0.7010 - val_loss: 4.4613 - val_acc: 0.7232\n",
      "Epoch 48/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3680 - acc: 0.7290 - val_loss: 4.7369 - val_acc: 0.7061\n",
      "Epoch 49/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3035 - acc: 0.7330 - val_loss: 4.5847 - val_acc: 0.7156\n",
      "Epoch 50/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 5.0127 - acc: 0.6890 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 51/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8515 - acc: 0.6990 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 52/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8677 - acc: 0.6980 - val_loss: 4.4146 - val_acc: 0.7261\n",
      "Epoch 53/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.3680 - acc: 0.7290 - val_loss: 4.5578 - val_acc: 0.7172\n",
      "Epoch 54/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.9321 - acc: 0.6940 - val_loss: 4.6742 - val_acc: 0.7100\n",
      "Epoch 55/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 56/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.0456 - acc: 0.7490 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 57/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8999 - acc: 0.6960 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 58/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.0779 - acc: 0.7470 - val_loss: 4.5041 - val_acc: 0.7206\n",
      "Epoch 59/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.6259 - acc: 0.7130 - val_loss: 4.5310 - val_acc: 0.7189\n",
      "Epoch 60/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.2229 - acc: 0.7380 - val_loss: 4.4862 - val_acc: 0.7217\n",
      "Epoch 61/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4647 - acc: 0.7230 - val_loss: 4.8981 - val_acc: 0.6961\n",
      "Epoch 62/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4647 - acc: 0.7230 - val_loss: 4.3623 - val_acc: 0.7294\n",
      "Epoch 63/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2229 - acc: 0.7380 - val_loss: 4.8444 - val_acc: 0.6994\n",
      "Epoch 64/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.7065 - acc: 0.7080 - val_loss: 4.3250 - val_acc: 0.7317\n",
      "Epoch 65/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5292 - acc: 0.7190 - val_loss: 4.3608 - val_acc: 0.7294\n",
      "Epoch 66/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2552 - acc: 0.7360 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 67/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.6904 - acc: 0.7090 - val_loss: 4.6116 - val_acc: 0.7139\n",
      "Epoch 68/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.5310 - val_acc: 0.7189\n",
      "Epoch 69/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5614 - acc: 0.7170 - val_loss: 4.2355 - val_acc: 0.7372\n",
      "Epoch 70/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.4164 - acc: 0.7260 - val_loss: 4.7817 - val_acc: 0.7033\n",
      "Epoch 71/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.9483 - acc: 0.6930 - val_loss: 4.9071 - val_acc: 0.6956\n",
      "Epoch 72/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2713 - acc: 0.7350 - val_loss: 4.7280 - val_acc: 0.7067\n",
      "Epoch 73/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.5131 - acc: 0.7200 - val_loss: 4.7817 - val_acc: 0.7033\n",
      "Epoch 74/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.8193 - acc: 0.7010 - val_loss: 4.2982 - val_acc: 0.7333\n",
      "Epoch 75/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.2874 - acc: 0.7340 - val_loss: 4.5578 - val_acc: 0.7172\n",
      "Epoch 76/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.4969 - acc: 0.7210 - val_loss: 4.4683 - val_acc: 0.7228\n",
      "Epoch 77/80\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 4.6904 - acc: 0.7090 - val_loss: 4.6026 - val_acc: 0.7144\n",
      "Epoch 78/80\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 4.9966 - acc: 0.6900 - val_loss: 4.7401 - val_acc: 0.7059\n",
      "Epoch 79/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.4808 - acc: 0.7220 - val_loss: 4.5489 - val_acc: 0.7178\n",
      "Epoch 80/80\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 4.8515 - acc: 0.6990 - val_loss: 5.0414 - val_acc: 0.6872\n",
      "\n",
      "Training process completed in: 0 h 1 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_985.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 987 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.1\n",
      "Epochs: 40\n",
      "Steps per Epoch: 60\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 4.5030 - acc: 0.7154 - val_loss: 4.5766 - val_acc: 0.7161\n",
      "Epoch 2/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.5655 - acc: 0.7167 - val_loss: 4.5278 - val_acc: 0.7191\n",
      "Epoch 3/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.5601 - acc: 0.7171 - val_loss: 4.6169 - val_acc: 0.7136\n",
      "Epoch 4/40\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 4.5464 - acc: 0.7179 - val_loss: 4.5458 - val_acc: 0.7180\n",
      "Epoch 5/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.6595 - acc: 0.7109 - val_loss: 4.6939 - val_acc: 0.7088\n",
      "Epoch 6/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.5628 - acc: 0.7169 - val_loss: 4.4996 - val_acc: 0.7208\n",
      "Epoch 7/40\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 4.5252 - acc: 0.7193 - val_loss: 4.6006 - val_acc: 0.7146\n",
      "Epoch 8/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.5547 - acc: 0.7174 - val_loss: 4.5467 - val_acc: 0.7179\n",
      "Epoch 9/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.4996 - acc: 0.7208 - val_loss: 4.5731 - val_acc: 0.7163\n",
      "Epoch 10/40\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 4.6501 - acc: 0.7115 - val_loss: 4.5943 - val_acc: 0.7150\n",
      "Epoch 11/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.5426 - acc: 0.7182 - val_loss: 4.5359 - val_acc: 0.7186\n",
      "Epoch 12/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.6366 - acc: 0.7123 - val_loss: 4.6017 - val_acc: 0.7145\n",
      "Epoch 13/40\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 4.5493 - acc: 0.7178 - val_loss: 4.5575 - val_acc: 0.7172\n",
      "Epoch 14/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.6635 - acc: 0.7107 - val_loss: 4.5566 - val_acc: 0.7173\n",
      "Epoch 15/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.5628 - acc: 0.7169 - val_loss: 4.6223 - val_acc: 0.7132\n",
      "Epoch 16/40\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 4.6165 - acc: 0.7136 - val_loss: 4.5386 - val_acc: 0.7184\n",
      "Epoch 17/40\n",
      "60/60 [==============================] - 10s 169ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.5889 - val_acc: 0.7153\n",
      "Epoch 18/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.5104 - acc: 0.7202 - val_loss: 4.5560 - val_acc: 0.7173\n",
      "Epoch 19/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.5238 - acc: 0.7193 - val_loss: 4.6149 - val_acc: 0.7137\n",
      "Epoch 20/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.4456 - acc: 0.7242 - val_loss: 4.5650 - val_acc: 0.7168\n",
      "Epoch 21/40\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 4.5574 - acc: 0.7173 - val_loss: 4.6338 - val_acc: 0.7125\n",
      "Epoch 22/40\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 4.5453 - acc: 0.7180 - val_loss: 4.5628 - val_acc: 0.7169\n",
      "Epoch 23/40\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 4.6031 - acc: 0.7144 - val_loss: 4.5426 - val_acc: 0.7182\n",
      "Epoch 24/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.6192 - acc: 0.7134 - val_loss: 4.5395 - val_acc: 0.7184\n",
      "Epoch 25/40\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 4.6380 - acc: 0.7123 - val_loss: 4.5637 - val_acc: 0.7169\n",
      "Epoch 26/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.6326 - acc: 0.7126 - val_loss: 4.5829 - val_acc: 0.7157\n",
      "Epoch 27/40\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 4.5990 - acc: 0.7147 - val_loss: 4.5844 - val_acc: 0.7156\n",
      "Epoch 28/40\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 4.5466 - acc: 0.7179 - val_loss: 4.6122 - val_acc: 0.7138\n",
      "Epoch 29/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.6071 - acc: 0.7142 - val_loss: 4.5569 - val_acc: 0.7173\n",
      "Epoch 30/40\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 4.5789 - acc: 0.7159 - val_loss: 4.6814 - val_acc: 0.7096\n",
      "Epoch 31/40\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 4.6259 - acc: 0.7130 - val_loss: 4.4847 - val_acc: 0.7218\n",
      "Epoch 32/40\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 4.5950 - acc: 0.7149 - val_loss: 4.5122 - val_acc: 0.7201\n",
      "Epoch 33/40\n",
      "60/60 [==============================] - 10s 173ms/step - loss: 4.5681 - acc: 0.7166 - val_loss: 4.6392 - val_acc: 0.7122\n",
      "Epoch 34/40\n",
      "60/60 [==============================] - 10s 168ms/step - loss: 4.6138 - acc: 0.7138 - val_loss: 4.5449 - val_acc: 0.7180\n",
      "Epoch 35/40\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 4.5708 - acc: 0.7164 - val_loss: 4.6214 - val_acc: 0.7133\n",
      "Epoch 36/40\n",
      "60/60 [==============================] - 10s 172ms/step - loss: 4.5614 - acc: 0.7170 - val_loss: 4.5305 - val_acc: 0.7189\n",
      "Epoch 37/40\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 4.5010 - acc: 0.7207 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 38/40\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 4.6017 - acc: 0.7145 - val_loss: 4.6104 - val_acc: 0.7140\n",
      "Epoch 39/40\n",
      "60/60 [==============================] - 10s 171ms/step - loss: 4.6084 - acc: 0.7141 - val_loss: 4.5476 - val_acc: 0.7179\n",
      "Epoch 40/40\n",
      "60/60 [==============================] - 10s 163ms/step - loss: 4.5896 - acc: 0.7153 - val_loss: 4.5516 - val_acc: 0.7176\n",
      "\n",
      "Training process completed in: 0 h 6 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_986.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 988 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.1\n",
      "Epochs: 30\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 4.5108 - acc: 0.7124 - val_loss: 4.6340 - val_acc: 0.7125\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.4581 - acc: 0.7234 - val_loss: 4.5399 - val_acc: 0.7183\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.5412 - acc: 0.7183 - val_loss: 4.6013 - val_acc: 0.7145\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 7s 81ms/step - loss: 4.5630 - acc: 0.7169 - val_loss: 4.5233 - val_acc: 0.7194\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.7395 - acc: 0.7060 - val_loss: 4.6013 - val_acc: 0.7145\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 7s 81ms/step - loss: 4.5553 - acc: 0.7174 - val_loss: 4.5035 - val_acc: 0.7206\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 7s 81ms/step - loss: 4.4849 - acc: 0.7217 - val_loss: 4.5952 - val_acc: 0.7149\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.5862 - acc: 0.7155 - val_loss: 4.6474 - val_acc: 0.7117\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.6397 - acc: 0.7121 - val_loss: 4.5188 - val_acc: 0.7196\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.6896 - acc: 0.7090 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 7s 81ms/step - loss: 4.5885 - acc: 0.7153 - val_loss: 4.6378 - val_acc: 0.7123\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.6308 - acc: 0.7127 - val_loss: 4.5476 - val_acc: 0.7179\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.5578 - acc: 0.7172 - val_loss: 4.5821 - val_acc: 0.7157\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.5143 - acc: 0.7199 - val_loss: 4.5874 - val_acc: 0.7154\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.6934 - acc: 0.7088 - val_loss: 4.6148 - val_acc: 0.7137\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 8s 84ms/step - loss: 4.5118 - acc: 0.7201 - val_loss: 4.5687 - val_acc: 0.7165\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.5118 - acc: 0.7201 - val_loss: 4.5446 - val_acc: 0.7180\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.5924 - acc: 0.7151 - val_loss: 4.5476 - val_acc: 0.7179\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.5476 - acc: 0.7179 - val_loss: 4.4996 - val_acc: 0.7208\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.6448 - acc: 0.7118 - val_loss: 4.6477 - val_acc: 0.7116\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.6551 - acc: 0.7112 - val_loss: 4.7107 - val_acc: 0.7077\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.4325 - acc: 0.7250 - val_loss: 4.4632 - val_acc: 0.7231\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 4.5988 - acc: 0.7147 - val_loss: 4.5630 - val_acc: 0.7169\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 7s 81ms/step - loss: 4.5514 - acc: 0.7176 - val_loss: 4.6749 - val_acc: 0.7100\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.5898 - acc: 0.7152 - val_loss: 4.4363 - val_acc: 0.7248\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.5834 - acc: 0.7156 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 4.5668 - acc: 0.7167 - val_loss: 4.5194 - val_acc: 0.7196\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.6103 - acc: 0.7140 - val_loss: 4.5016 - val_acc: 0.7207\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.6077 - acc: 0.7141 - val_loss: 4.6493 - val_acc: 0.7115\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 7s 82ms/step - loss: 4.5681 - acc: 0.7166 - val_loss: 4.7001 - val_acc: 0.7084\n",
      "\n",
      "Training process completed in: 0 h 3 m 41 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_987.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 989 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.01\n",
      "Epochs: 70\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 0.6018 - acc: 0.7170 - val_loss: 0.5171 - val_acc: 0.7446\n",
      "Epoch 2/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5174 - acc: 0.7551 - val_loss: 0.4943 - val_acc: 0.7817\n",
      "Epoch 3/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5222 - acc: 0.7557 - val_loss: 0.6076 - val_acc: 0.7117\n",
      "Epoch 4/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5993 - acc: 0.7147 - val_loss: 0.5991 - val_acc: 0.7155\n",
      "Epoch 5/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5966 - acc: 0.7167 - val_loss: 0.5969 - val_acc: 0.7162\n",
      "Epoch 6/70\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.6000 - acc: 0.7131 - val_loss: 0.5929 - val_acc: 0.7204\n",
      "Epoch 7/70\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.5965 - acc: 0.7166 - val_loss: 0.6031 - val_acc: 0.7095\n",
      "Epoch 8/70\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.5927 - acc: 0.7209 - val_loss: 0.6010 - val_acc: 0.7140\n",
      "Epoch 9/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6018 - acc: 0.7110 - val_loss: 0.5922 - val_acc: 0.7223\n",
      "Epoch 10/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5955 - acc: 0.7177 - val_loss: 0.5992 - val_acc: 0.7163\n",
      "Epoch 11/70\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.5964 - acc: 0.7174 - val_loss: 0.5935 - val_acc: 0.7201\n",
      "Epoch 12/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6010 - acc: 0.7118 - val_loss: 0.6051 - val_acc: 0.7067\n",
      "Epoch 13/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6017 - acc: 0.7109 - val_loss: 0.5939 - val_acc: 0.7200\n",
      "Epoch 14/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6010 - acc: 0.7117 - val_loss: 0.5957 - val_acc: 0.7173\n",
      "Epoch 15/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5971 - acc: 0.7159 - val_loss: 0.5996 - val_acc: 0.7130\n",
      "Epoch 16/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5937 - acc: 0.7197 - val_loss: 0.5994 - val_acc: 0.7148\n",
      "Epoch 17/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5970 - acc: 0.7162 - val_loss: 0.5968 - val_acc: 0.7161\n",
      "Epoch 18/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5971 - acc: 0.7162 - val_loss: 0.5956 - val_acc: 0.7172\n",
      "Epoch 19/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5942 - acc: 0.7190 - val_loss: 0.5981 - val_acc: 0.7150\n",
      "Epoch 20/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5944 - acc: 0.7187 - val_loss: 0.5916 - val_acc: 0.7215\n",
      "Epoch 21/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5953 - acc: 0.7180 - val_loss: 0.5976 - val_acc: 0.7150\n",
      "Epoch 22/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5918 - acc: 0.7214 - val_loss: 0.6005 - val_acc: 0.7119\n",
      "Epoch 23/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5976 - acc: 0.7154 - val_loss: 0.5963 - val_acc: 0.7169\n",
      "Epoch 24/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5946 - acc: 0.7185 - val_loss: 0.5952 - val_acc: 0.7176\n",
      "Epoch 25/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5992 - acc: 0.7136 - val_loss: 0.5953 - val_acc: 0.7175\n",
      "Epoch 26/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5972 - acc: 0.7157 - val_loss: 0.5974 - val_acc: 0.7153\n",
      "Epoch 27/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5926 - acc: 0.7206 - val_loss: 0.5981 - val_acc: 0.7145\n",
      "Epoch 28/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5970 - acc: 0.7160 - val_loss: 0.5933 - val_acc: 0.7202\n",
      "Epoch 29/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5926 - acc: 0.7209 - val_loss: 0.5948 - val_acc: 0.7182\n",
      "Epoch 30/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6031 - acc: 0.7169 - val_loss: 0.6012 - val_acc: 0.7116\n",
      "Epoch 31/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5961 - acc: 0.7170 - val_loss: 0.5956 - val_acc: 0.7175\n",
      "Epoch 32/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5975 - acc: 0.7154 - val_loss: 0.5966 - val_acc: 0.7161\n",
      "Epoch 33/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.6020 - acc: 0.7104 - val_loss: 0.5956 - val_acc: 0.7174\n",
      "Epoch 34/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.6005 - acc: 0.7120 - val_loss: 0.5974 - val_acc: 0.7153\n",
      "Epoch 35/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5944 - acc: 0.7186 - val_loss: 0.5970 - val_acc: 0.7157\n",
      "Epoch 36/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5950 - acc: 0.7179 - val_loss: 0.5990 - val_acc: 0.7136\n",
      "Epoch 37/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6006 - acc: 0.7119 - val_loss: 0.5946 - val_acc: 0.7183\n",
      "Epoch 38/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5981 - acc: 0.7145 - val_loss: 0.5970 - val_acc: 0.7158\n",
      "Epoch 39/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5950 - acc: 0.7181 - val_loss: 0.5960 - val_acc: 0.7168\n",
      "Epoch 40/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.6026 - acc: 0.7096 - val_loss: 0.5978 - val_acc: 0.7148\n",
      "Epoch 41/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5985 - acc: 0.7142 - val_loss: 0.5984 - val_acc: 0.7141\n",
      "Epoch 42/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5895 - acc: 0.7239 - val_loss: 0.5964 - val_acc: 0.7164\n",
      "Epoch 43/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5941 - acc: 0.7190 - val_loss: 0.5947 - val_acc: 0.7184\n",
      "Epoch 44/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5957 - acc: 0.7172 - val_loss: 0.6010 - val_acc: 0.7115\n",
      "Epoch 45/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5982 - acc: 0.7145 - val_loss: 0.5953 - val_acc: 0.7175\n",
      "Epoch 46/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5963 - acc: 0.7166 - val_loss: 0.5947 - val_acc: 0.7183\n",
      "Epoch 47/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5966 - acc: 0.7162 - val_loss: 0.5947 - val_acc: 0.7188\n",
      "Epoch 48/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5954 - acc: 0.7177 - val_loss: 0.5980 - val_acc: 0.7146\n",
      "Epoch 49/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6010 - acc: 0.7114 - val_loss: 0.5989 - val_acc: 0.7137\n",
      "Epoch 50/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5985 - acc: 0.7141 - val_loss: 0.5923 - val_acc: 0.7209\n",
      "Epoch 51/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5938 - acc: 0.7191 - val_loss: 0.5965 - val_acc: 0.7163\n",
      "Epoch 52/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5964 - acc: 0.7164 - val_loss: 0.6000 - val_acc: 0.7126\n",
      "Epoch 53/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5984 - acc: 0.7142 - val_loss: 0.5992 - val_acc: 0.7132\n",
      "Epoch 54/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5957 - acc: 0.7172 - val_loss: 0.5980 - val_acc: 0.7146\n",
      "Epoch 55/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6015 - acc: 0.7109 - val_loss: 0.5915 - val_acc: 0.7219\n",
      "Epoch 56/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5946 - acc: 0.7185 - val_loss: 0.5965 - val_acc: 0.7164\n",
      "Epoch 57/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5942 - acc: 0.7188 - val_loss: 0.5969 - val_acc: 0.7158\n",
      "Epoch 58/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.6022 - acc: 0.7100 - val_loss: 0.5995 - val_acc: 0.7129\n",
      "Epoch 59/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.5961 - acc: 0.7168 - val_loss: 0.5949 - val_acc: 0.7180\n",
      "Epoch 60/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5962 - acc: 0.7166 - val_loss: 0.5939 - val_acc: 0.7192\n",
      "Epoch 61/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5975 - acc: 0.7152 - val_loss: 0.5976 - val_acc: 0.7150\n",
      "Epoch 62/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5925 - acc: 0.7206 - val_loss: 0.5969 - val_acc: 0.7158\n",
      "Epoch 63/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5965 - acc: 0.7163 - val_loss: 0.5978 - val_acc: 0.7147\n",
      "Epoch 64/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5931 - acc: 0.7199 - val_loss: 0.5982 - val_acc: 0.7144\n",
      "Epoch 65/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5983 - acc: 0.7144 - val_loss: 0.5940 - val_acc: 0.7190\n",
      "Epoch 66/70\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 0.5989 - acc: 0.7139 - val_loss: 0.5998 - val_acc: 0.7126\n",
      "Epoch 67/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5943 - acc: 0.7185 - val_loss: 0.5943 - val_acc: 0.7188\n",
      "Epoch 68/70\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 0.5966 - acc: 0.7162 - val_loss: 0.5995 - val_acc: 0.7130\n",
      "Epoch 69/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.6058 - acc: 0.7061 - val_loss: 0.5991 - val_acc: 0.7135\n",
      "Epoch 70/70\n",
      "140/140 [==============================] - 11s 81ms/step - loss: 0.6004 - acc: 0.7120 - val_loss: 0.5893 - val_acc: 0.7239\n",
      "\n",
      "Training process completed in: 0 h 13 m 3 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_988.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 990 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_89 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.01\n",
      "Epochs: 80\n",
      "Steps per Epoch: 70\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.6376 - acc: 0.7013 - val_loss: 0.5881 - val_acc: 0.7177\n",
      "Epoch 2/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.5615 - acc: 0.7156 - val_loss: 0.5246 - val_acc: 0.7148\n",
      "Epoch 3/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.5232 - acc: 0.7304 - val_loss: 0.5122 - val_acc: 0.7479\n",
      "Epoch 4/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.5253 - acc: 0.7491 - val_loss: 0.5227 - val_acc: 0.7728\n",
      "Epoch 5/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.5094 - acc: 0.7614 - val_loss: 0.4976 - val_acc: 0.7566\n",
      "Epoch 6/80\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.4874 - acc: 0.7848 - val_loss: 0.4970 - val_acc: 0.8017\n",
      "Epoch 7/80\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.4702 - acc: 0.7939 - val_loss: 0.4629 - val_acc: 0.7916\n",
      "Epoch 8/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4820 - acc: 0.7928 - val_loss: 0.5553 - val_acc: 0.7760\n",
      "Epoch 9/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4712 - acc: 0.7954 - val_loss: 0.4780 - val_acc: 0.7972\n",
      "Epoch 10/80\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.4906 - acc: 0.7887 - val_loss: 0.4521 - val_acc: 0.7960\n",
      "Epoch 11/80\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.4469 - acc: 0.8132 - val_loss: 0.4888 - val_acc: 0.7683\n",
      "Epoch 12/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4616 - acc: 0.7949 - val_loss: 0.4438 - val_acc: 0.8052\n",
      "Epoch 13/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4491 - acc: 0.8061 - val_loss: 0.4446 - val_acc: 0.8029\n",
      "Epoch 14/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4509 - acc: 0.8088 - val_loss: 0.5179 - val_acc: 0.8101\n",
      "Epoch 15/80\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.4478 - acc: 0.8112 - val_loss: 0.5138 - val_acc: 0.7971\n",
      "Epoch 16/80\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.4384 - acc: 0.8110 - val_loss: 0.4634 - val_acc: 0.8036\n",
      "Epoch 17/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4339 - acc: 0.8099 - val_loss: 0.4458 - val_acc: 0.8113\n",
      "Epoch 18/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4550 - acc: 0.8026 - val_loss: 0.4652 - val_acc: 0.8100\n",
      "Epoch 19/80\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.4378 - acc: 0.8170 - val_loss: 0.5076 - val_acc: 0.7897\n",
      "Epoch 20/80\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.4389 - acc: 0.8166 - val_loss: 0.4631 - val_acc: 0.8188\n",
      "Epoch 21/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4486 - acc: 0.8093 - val_loss: 0.5234 - val_acc: 0.7907\n",
      "Epoch 22/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4322 - acc: 0.8178 - val_loss: 0.4494 - val_acc: 0.8111\n",
      "Epoch 23/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4620 - acc: 0.8137 - val_loss: 0.4293 - val_acc: 0.8144\n",
      "Epoch 24/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4331 - acc: 0.8150 - val_loss: 0.4539 - val_acc: 0.8112\n",
      "Epoch 25/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4546 - acc: 0.8079 - val_loss: 0.4558 - val_acc: 0.7918\n",
      "Epoch 26/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4472 - acc: 0.8066 - val_loss: 0.4497 - val_acc: 0.8099\n",
      "Epoch 27/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4592 - acc: 0.8022 - val_loss: 0.4456 - val_acc: 0.8122\n",
      "Epoch 28/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4488 - acc: 0.8061 - val_loss: 0.4304 - val_acc: 0.8125\n",
      "Epoch 29/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4546 - acc: 0.8022 - val_loss: 0.4526 - val_acc: 0.8163\n",
      "Epoch 30/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4475 - acc: 0.8108 - val_loss: 0.4594 - val_acc: 0.8097\n",
      "Epoch 31/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4322 - acc: 0.8178 - val_loss: 0.4484 - val_acc: 0.8097\n",
      "Epoch 32/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4374 - acc: 0.8165 - val_loss: 0.4457 - val_acc: 0.8150\n",
      "Epoch 33/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4355 - acc: 0.8113 - val_loss: 0.4361 - val_acc: 0.8166\n",
      "Epoch 34/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4294 - acc: 0.8169 - val_loss: 0.4404 - val_acc: 0.81690s - loss: 0.4294 - acc: 0.817\n",
      "Epoch 35/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4388 - acc: 0.8147 - val_loss: 0.4625 - val_acc: 0.8070\n",
      "Epoch 36/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4325 - acc: 0.8169 - val_loss: 0.4627 - val_acc: 0.8124\n",
      "Epoch 37/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4376 - acc: 0.8142 - val_loss: 0.4298 - val_acc: 0.8149\n",
      "Epoch 38/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4305 - acc: 0.8185 - val_loss: 0.4891 - val_acc: 0.7915\n",
      "Epoch 39/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4361 - acc: 0.8148 - val_loss: 0.4558 - val_acc: 0.8171\n",
      "Epoch 40/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4431 - acc: 0.8065 - val_loss: 0.4402 - val_acc: 0.8121\n",
      "Epoch 41/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4504 - acc: 0.8097 - val_loss: 0.4839 - val_acc: 0.8080\n",
      "Epoch 42/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4424 - acc: 0.8135 - val_loss: 0.5400 - val_acc: 0.7587\n",
      "Epoch 43/80\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 0.4270 - acc: 0.8208 - val_loss: 0.4407 - val_acc: 0.8133\n",
      "Epoch 44/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4336 - acc: 0.8168 - val_loss: 0.4420 - val_acc: 0.8064\n",
      "Epoch 45/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4394 - acc: 0.8111 - val_loss: 0.4422 - val_acc: 0.8088\n",
      "Epoch 46/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4423 - acc: 0.8153 - val_loss: 0.4434 - val_acc: 0.8168\n",
      "Epoch 47/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4435 - acc: 0.8084 - val_loss: 0.4650 - val_acc: 0.8153\n",
      "Epoch 48/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4256 - acc: 0.8181 - val_loss: 0.4278 - val_acc: 0.8209\n",
      "Epoch 49/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4288 - acc: 0.8162 - val_loss: 0.4249 - val_acc: 0.8131\n",
      "Epoch 50/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4390 - acc: 0.8130 - val_loss: 0.4419 - val_acc: 0.8185\n",
      "Epoch 51/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4375 - acc: 0.8131 - val_loss: 0.4341 - val_acc: 0.8220\n",
      "Epoch 52/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4349 - acc: 0.8136 - val_loss: 0.4229 - val_acc: 0.8215\n",
      "Epoch 53/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4325 - acc: 0.8110 - val_loss: 0.4501 - val_acc: 0.8144\n",
      "Epoch 54/80\n",
      "70/70 [==============================] - 8s 118ms/step - loss: 0.4584 - acc: 0.8101 - val_loss: 0.4310 - val_acc: 0.8123\n",
      "Epoch 55/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4514 - acc: 0.8132 - val_loss: 0.4581 - val_acc: 0.8097\n",
      "Epoch 56/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4276 - acc: 0.8184 - val_loss: 0.4483 - val_acc: 0.7986\n",
      "Epoch 57/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4406 - acc: 0.8108 - val_loss: 0.4377 - val_acc: 0.8172\n",
      "Epoch 58/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4350 - acc: 0.8133 - val_loss: 0.4604 - val_acc: 0.8141\n",
      "Epoch 59/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4365 - acc: 0.8161 - val_loss: 0.4321 - val_acc: 0.8140\n",
      "Epoch 60/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4307 - acc: 0.8122 - val_loss: 0.4747 - val_acc: 0.8087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4486 - acc: 0.8092 - val_loss: 0.4402 - val_acc: 0.8164\n",
      "Epoch 62/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4283 - acc: 0.8189 - val_loss: 0.4337 - val_acc: 0.8143\n",
      "Epoch 63/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4282 - acc: 0.8206 - val_loss: 0.4458 - val_acc: 0.8137\n",
      "Epoch 64/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4225 - acc: 0.8165 - val_loss: 0.4482 - val_acc: 0.8186\n",
      "Epoch 65/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4243 - acc: 0.8152 - val_loss: 0.4592 - val_acc: 0.8179\n",
      "Epoch 66/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4340 - acc: 0.8144 - val_loss: 0.4386 - val_acc: 0.8032\n",
      "Epoch 67/80\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.4429 - acc: 0.8133 - val_loss: 0.4426 - val_acc: 0.8009\n",
      "Epoch 68/80\n",
      "70/70 [==============================] - 8s 118ms/step - loss: 0.4370 - acc: 0.8108 - val_loss: 0.4428 - val_acc: 0.8159\n",
      "Epoch 69/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4341 - acc: 0.8161 - val_loss: 0.4304 - val_acc: 0.8193\n",
      "Epoch 70/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4280 - acc: 0.8164 - val_loss: 0.4430 - val_acc: 0.8197\n",
      "Epoch 71/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4322 - acc: 0.8186 - val_loss: 0.4378 - val_acc: 0.8188\n",
      "Epoch 72/80\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 0.4409 - acc: 0.8111 - val_loss: 0.4348 - val_acc: 0.8089\n",
      "Epoch 73/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4245 - acc: 0.8213 - val_loss: 0.4465 - val_acc: 0.8184\n",
      "Epoch 74/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4348 - acc: 0.8137 - val_loss: 0.4603 - val_acc: 0.8174\n",
      "Epoch 75/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4337 - acc: 0.8115 - val_loss: 0.4296 - val_acc: 0.8163\n",
      "Epoch 76/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4532 - acc: 0.8007 - val_loss: 0.4404 - val_acc: 0.7981\n",
      "Epoch 77/80\n",
      "70/70 [==============================] - 8s 114ms/step - loss: 0.4339 - acc: 0.8134 - val_loss: 0.4369 - val_acc: 0.8130\n",
      "Epoch 78/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4407 - acc: 0.8058 - val_loss: 0.4772 - val_acc: 0.8034\n",
      "Epoch 79/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4376 - acc: 0.8105 - val_loss: 0.4271 - val_acc: 0.8163\n",
      "Epoch 80/80\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.4292 - acc: 0.8120 - val_loss: 0.4452 - val_acc: 0.8136\n",
      "\n",
      "Training process completed in: 0 h 10 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_989.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 991 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_93 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.01\n",
      "Epochs: 30\n",
      "Steps per Epoch: 100\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.6197 - acc: 0.7160 - val_loss: 0.5964 - val_acc: 0.7204\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5955 - acc: 0.7216 - val_loss: 0.6023 - val_acc: 0.7106\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5994 - acc: 0.7149 - val_loss: 0.5918 - val_acc: 0.7237\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5912 - acc: 0.7239 - val_loss: 0.5990 - val_acc: 0.7135\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5956 - acc: 0.7189 - val_loss: 0.6032 - val_acc: 0.7148\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 0.6015 - acc: 0.7129 - val_loss: 0.5990 - val_acc: 0.7145\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.5989 - acc: 0.7151 - val_loss: 0.5915 - val_acc: 0.7217\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.5940 - acc: 0.7200 - val_loss: 0.6063 - val_acc: 0.7054\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.5972 - acc: 0.7163 - val_loss: 0.6051 - val_acc: 0.7069\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.5957 - acc: 0.7177 - val_loss: 0.6024 - val_acc: 0.7146\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.5891 - acc: 0.7246 - val_loss: 0.5887 - val_acc: 0.7290\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.5931 - acc: 0.7212 - val_loss: 0.5989 - val_acc: 0.7156\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.6029 - acc: 0.7100 - val_loss: 0.5835 - val_acc: 0.7300\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.5954 - acc: 0.7181 - val_loss: 0.5959 - val_acc: 0.7173\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.5983 - acc: 0.7146 - val_loss: 0.6066 - val_acc: 0.7050\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5901 - acc: 0.7234 - val_loss: 0.5984 - val_acc: 0.7142\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5998 - acc: 0.7129 - val_loss: 0.5940 - val_acc: 0.7190\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5967 - acc: 0.7165 - val_loss: 0.5996 - val_acc: 0.7133\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.5896 - acc: 0.7240 - val_loss: 0.5977 - val_acc: 0.7150\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.6066 - acc: 0.7050 - val_loss: 0.6015 - val_acc: 0.7117\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.5949 - acc: 0.7184 - val_loss: 0.5951 - val_acc: 0.7177\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.6010 - acc: 0.7118 - val_loss: 0.5984 - val_acc: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.6017 - acc: 0.7109 - val_loss: 0.5962 - val_acc: 0.7177\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.6059 - acc: 0.7061 - val_loss: 0.5913 - val_acc: 0.7222\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.6003 - acc: 0.7123 - val_loss: 0.5901 - val_acc: 0.7244\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5949 - acc: 0.7185 - val_loss: 0.6012 - val_acc: 0.7115\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5944 - acc: 0.7187 - val_loss: 0.6083 - val_acc: 0.7031\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 0.6045 - acc: 0.7076 - val_loss: 0.5962 - val_acc: 0.7167\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 0.5947 - acc: 0.7184 - val_loss: 0.5877 - val_acc: 0.7260\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 0.5924 - acc: 0.7212 - val_loss: 0.6004 - val_acc: 0.7121\n",
      "\n",
      "Training process completed in: 0 h 2 m 24 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_990.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 992 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 40\n",
      "Learning Rate: 0.1\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 5s 27ms/step - loss: 4.6143 - acc: 0.7108 - val_loss: 4.3922 - val_acc: 0.7275\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5067 - acc: 0.7204 - val_loss: 4.8354 - val_acc: 0.7000\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4982 - acc: 0.7209 - val_loss: 3.8280 - val_acc: 0.7625\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5364 - acc: 0.7186 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6170 - acc: 0.7136 - val_loss: 4.7548 - val_acc: 0.7050\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5894 - acc: 0.7153 - val_loss: 4.4325 - val_acc: 0.7250\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6297 - acc: 0.7128 - val_loss: 4.7548 - val_acc: 0.7050\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4261 - acc: 0.7254 - val_loss: 4.3922 - val_acc: 0.7275\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6955 - acc: 0.7087 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4664 - acc: 0.7229 - val_loss: 4.7145 - val_acc: 0.7075\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5852 - acc: 0.7155 - val_loss: 5.0772 - val_acc: 0.6850\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5555 - acc: 0.7174 - val_loss: 4.9160 - val_acc: 0.6950\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5470 - acc: 0.7179 - val_loss: 4.3519 - val_acc: 0.7300\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6530 - acc: 0.7113 - val_loss: 3.7878 - val_acc: 0.7650\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.1907 - val_acc: 0.7400\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6233 - acc: 0.7132 - val_loss: 4.4325 - val_acc: 0.7250\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5746 - acc: 0.7162 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5406 - acc: 0.7183 - val_loss: 5.2384 - val_acc: 0.6750\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.7124 - acc: 0.7076 - val_loss: 4.6742 - val_acc: 0.7100\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5173 - acc: 0.7197 - val_loss: 4.4728 - val_acc: 0.7225\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6552 - acc: 0.7112 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.7442 - acc: 0.7057 - val_loss: 4.6340 - val_acc: 0.7125\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4897 - acc: 0.7214 - val_loss: 4.9563 - val_acc: 0.6925\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6764 - acc: 0.7099 - val_loss: 4.8354 - val_acc: 0.7000\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5131 - acc: 0.7200 - val_loss: 4.3922 - val_acc: 0.7275\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4728 - acc: 0.7225 - val_loss: 3.8280 - val_acc: 0.7625\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5682 - acc: 0.7166 - val_loss: 4.7548 - val_acc: 0.7050\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4282 - acc: 0.7253 - val_loss: 5.0369 - val_acc: 0.6875\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6170 - acc: 0.7136 - val_loss: 4.8354 - val_acc: 0.7000\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5703 - acc: 0.7164 - val_loss: 4.6742 - val_acc: 0.7100\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5534 - acc: 0.7175 - val_loss: 4.3519 - val_acc: 0.7300\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.7400 - acc: 0.7059 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5279 - acc: 0.7191 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6297 - acc: 0.7128 - val_loss: 4.3116 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5831 - acc: 0.7157 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.4537 - acc: 0.7237 - val_loss: 4.4325 - val_acc: 0.7250\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5788 - acc: 0.7159 - val_loss: 5.1981 - val_acc: 0.6775\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.4919 - acc: 0.7213 - val_loss: 4.6340 - val_acc: 0.7125\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5640 - acc: 0.7168 - val_loss: 4.7951 - val_acc: 0.7025\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6721 - acc: 0.7101 - val_loss: 4.8757 - val_acc: 0.6975\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5831 - acc: 0.7157 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6149 - acc: 0.7137 - val_loss: 4.7548 - val_acc: 0.7050\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6636 - acc: 0.7107 - val_loss: 3.7878 - val_acc: 0.7650\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6467 - acc: 0.7117 - val_loss: 4.5534 - val_acc: 0.7175\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.4304 - acc: 0.7251 - val_loss: 3.8683 - val_acc: 0.7600\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6021 - acc: 0.7145 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6976 - acc: 0.7086 - val_loss: 4.3922 - val_acc: 0.7275\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.3052 - acc: 0.7329 - val_loss: 4.7951 - val_acc: 0.7025\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5640 - acc: 0.7168 - val_loss: 4.3519 - val_acc: 0.7300\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.4855 - acc: 0.7217 - val_loss: 4.9966 - val_acc: 0.6900\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.4664 - acc: 0.7229 - val_loss: 4.4325 - val_acc: 0.7250\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5682 - acc: 0.7166 - val_loss: 4.1101 - val_acc: 0.7450\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6255 - acc: 0.7130 - val_loss: 4.3922 - val_acc: 0.7275\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6976 - acc: 0.7086 - val_loss: 4.3519 - val_acc: 0.7300\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5449 - acc: 0.7180 - val_loss: 4.7548 - val_acc: 0.7050\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.5449 - acc: 0.7180 - val_loss: 4.6340 - val_acc: 0.7125\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6764 - acc: 0.7099 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 3s 17ms/step - loss: 4.6361 - acc: 0.7124 - val_loss: 4.2713 - val_acc: 0.7350\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5788 - acc: 0.7159 - val_loss: 4.3116 - val_acc: 0.7325\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.4961 - acc: 0.7211 - val_loss: 4.8757 - val_acc: 0.6975\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.7612 - acc: 0.7046 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6021 - acc: 0.7145 - val_loss: 4.9563 - val_acc: 0.6925\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5449 - acc: 0.7180 - val_loss: 4.9160 - val_acc: 0.6950\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6191 - acc: 0.7134 - val_loss: 5.3190 - val_acc: 0.6700\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6361 - acc: 0.7124 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6106 - acc: 0.7139 - val_loss: 4.3116 - val_acc: 0.7325\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.7336 - acc: 0.7063 - val_loss: 4.9966 - val_acc: 0.6900\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.6636 - acc: 0.7107 - val_loss: 5.1981 - val_acc: 0.6775\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5809 - acc: 0.7158 - val_loss: 4.4728 - val_acc: 0.7225\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 3s 18ms/step - loss: 4.5300 - acc: 0.7189 - val_loss: 5.1808 - val_acc: 0.6786\n",
      "\n",
      "Training process completed in: 0 h 3 m 56 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_991.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 993 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_101 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 110\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5839 - acc: 0.7111 - val_loss: 0.5384 - val_acc: 0.7181\n",
      "Epoch 2/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4858 - acc: 0.7600 - val_loss: 0.4437 - val_acc: 0.8055\n",
      "Epoch 3/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4431 - acc: 0.8073 - val_loss: 0.4333 - val_acc: 0.8144\n",
      "Epoch 4/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4272 - acc: 0.8150 - val_loss: 0.4382 - val_acc: 0.8127\n",
      "Epoch 5/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4212 - acc: 0.8193 - val_loss: 0.4310 - val_acc: 0.8126\n",
      "Epoch 6/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4208 - acc: 0.8190 - val_loss: 0.4428 - val_acc: 0.8094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4302 - acc: 0.8192 - val_loss: 0.4240 - val_acc: 0.8191\n",
      "Epoch 8/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4237 - acc: 0.8214 - val_loss: 0.4174 - val_acc: 0.8231\n",
      "Epoch 9/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4132 - acc: 0.8223 - val_loss: 0.4033 - val_acc: 0.8227\n",
      "Epoch 10/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.4142 - acc: 0.8253 - val_loss: 0.4041 - val_acc: 0.8284\n",
      "Epoch 11/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.4159 - acc: 0.8220 - val_loss: 0.4247 - val_acc: 0.8122\n",
      "Epoch 12/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.4208 - acc: 0.8188 - val_loss: 0.4060 - val_acc: 0.8219\n",
      "Epoch 13/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3991 - acc: 0.8277 - val_loss: 0.4139 - val_acc: 0.8188\n",
      "Epoch 14/80\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.4056 - acc: 0.8223 - val_loss: 0.4056 - val_acc: 0.8229\n",
      "Epoch 15/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4091 - acc: 0.8314 - val_loss: 0.4169 - val_acc: 0.8170\n",
      "Epoch 16/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4056 - acc: 0.8240 - val_loss: 0.3983 - val_acc: 0.8288\n",
      "Epoch 17/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4122 - acc: 0.8239 - val_loss: 0.4029 - val_acc: 0.8222\n",
      "Epoch 18/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4059 - acc: 0.8228 - val_loss: 0.4094 - val_acc: 0.8295\n",
      "Epoch 19/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3943 - acc: 0.8333 - val_loss: 0.4112 - val_acc: 0.8245\n",
      "Epoch 20/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.4031 - acc: 0.8268 - val_loss: 0.3929 - val_acc: 0.8295\n",
      "Epoch 21/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3971 - acc: 0.8320 - val_loss: 0.3992 - val_acc: 0.8314\n",
      "Epoch 22/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3834 - acc: 0.8343 - val_loss: 0.3919 - val_acc: 0.8253\n",
      "Epoch 23/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.4000 - acc: 0.8256 - val_loss: 0.3972 - val_acc: 0.8338\n",
      "Epoch 24/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3886 - acc: 0.8280 - val_loss: 0.3900 - val_acc: 0.8344\n",
      "Epoch 25/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3913 - acc: 0.8317 - val_loss: 0.3980 - val_acc: 0.8261\n",
      "Epoch 26/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3946 - acc: 0.8345 - val_loss: 0.3937 - val_acc: 0.8305\n",
      "Epoch 27/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3916 - acc: 0.8314 - val_loss: 0.4030 - val_acc: 0.8251\n",
      "Epoch 28/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3900 - acc: 0.8336 - val_loss: 0.3874 - val_acc: 0.8314\n",
      "Epoch 29/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3868 - acc: 0.8325 - val_loss: 0.3920 - val_acc: 0.8266\n",
      "Epoch 30/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3889 - acc: 0.8289 - val_loss: 0.3894 - val_acc: 0.8328\n",
      "Epoch 31/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3951 - acc: 0.8346 - val_loss: 0.3838 - val_acc: 0.8328\n",
      "Epoch 32/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3808 - acc: 0.8366 - val_loss: 0.3911 - val_acc: 0.8316\n",
      "Epoch 33/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3733 - acc: 0.8397 - val_loss: 0.3782 - val_acc: 0.8442\n",
      "Epoch 34/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3862 - acc: 0.8311 - val_loss: 0.3757 - val_acc: 0.8394\n",
      "Epoch 35/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3810 - acc: 0.8381 - val_loss: 0.4096 - val_acc: 0.8196\n",
      "Epoch 36/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3896 - acc: 0.8320 - val_loss: 0.3994 - val_acc: 0.8328\n",
      "Epoch 37/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3910 - acc: 0.8320 - val_loss: 0.3814 - val_acc: 0.8314\n",
      "Epoch 38/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3728 - acc: 0.8365 - val_loss: 0.3807 - val_acc: 0.8333\n",
      "Epoch 39/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3682 - acc: 0.8414 - val_loss: 0.3852 - val_acc: 0.8369\n",
      "Epoch 40/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3867 - acc: 0.8318 - val_loss: 0.3771 - val_acc: 0.8337\n",
      "Epoch 41/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3766 - acc: 0.8366 - val_loss: 0.3786 - val_acc: 0.8388\n",
      "Epoch 42/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3824 - acc: 0.8359 - val_loss: 0.3843 - val_acc: 0.8327\n",
      "Epoch 43/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3828 - acc: 0.8337 - val_loss: 0.3911 - val_acc: 0.8303\n",
      "Epoch 44/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3791 - acc: 0.8370 - val_loss: 0.3712 - val_acc: 0.8412\n",
      "Epoch 45/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3722 - acc: 0.8409 - val_loss: 0.3715 - val_acc: 0.8394\n",
      "Epoch 46/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3724 - acc: 0.8418 - val_loss: 0.3787 - val_acc: 0.8363\n",
      "Epoch 47/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3840 - acc: 0.8353 - val_loss: 0.3817 - val_acc: 0.8427\n",
      "Epoch 48/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3751 - acc: 0.8403 - val_loss: 0.3808 - val_acc: 0.8392\n",
      "Epoch 49/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3750 - acc: 0.8395 - val_loss: 0.3704 - val_acc: 0.8380\n",
      "Epoch 50/80\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 0.3705 - acc: 0.8449 - val_loss: 0.3620 - val_acc: 0.8416\n",
      "Epoch 51/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3730 - acc: 0.8395 - val_loss: 0.3941 - val_acc: 0.8236\n",
      "Epoch 52/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3806 - acc: 0.8366 - val_loss: 0.3727 - val_acc: 0.8364\n",
      "Epoch 53/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3818 - acc: 0.8369 - val_loss: 0.3633 - val_acc: 0.8404\n",
      "Epoch 54/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3691 - acc: 0.8405 - val_loss: 0.3793 - val_acc: 0.8359\n",
      "Epoch 55/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3592 - acc: 0.8443 - val_loss: 0.3751 - val_acc: 0.8427\n",
      "Epoch 56/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3556 - acc: 0.8487 - val_loss: 0.3991 - val_acc: 0.8377\n",
      "Epoch 57/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3566 - acc: 0.8503 - val_loss: 0.3669 - val_acc: 0.8368\n",
      "Epoch 58/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3578 - acc: 0.8486 - val_loss: 0.3683 - val_acc: 0.8409\n",
      "Epoch 59/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3663 - acc: 0.8441 - val_loss: 0.3628 - val_acc: 0.8458\n",
      "Epoch 60/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3639 - acc: 0.8428 - val_loss: 0.3623 - val_acc: 0.8500\n",
      "Epoch 61/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3686 - acc: 0.8407 - val_loss: 0.3600 - val_acc: 0.8457\n",
      "Epoch 62/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3591 - acc: 0.8465 - val_loss: 0.3652 - val_acc: 0.8441\n",
      "Epoch 63/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3692 - acc: 0.8442 - val_loss: 0.3663 - val_acc: 0.8388\n",
      "Epoch 64/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3636 - acc: 0.8425 - val_loss: 0.3537 - val_acc: 0.8483\n",
      "Epoch 65/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3512 - acc: 0.8502 - val_loss: 0.3668 - val_acc: 0.8494\n",
      "Epoch 66/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3571 - acc: 0.8460 - val_loss: 0.3688 - val_acc: 0.8414\n",
      "Epoch 67/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3513 - acc: 0.8503 - val_loss: 0.3502 - val_acc: 0.8525\n",
      "Epoch 68/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3593 - acc: 0.8484 - val_loss: 0.3512 - val_acc: 0.8495\n",
      "Epoch 69/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3690 - acc: 0.8418 - val_loss: 0.3613 - val_acc: 0.8481\n",
      "Epoch 70/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3595 - acc: 0.8483 - val_loss: 0.3528 - val_acc: 0.8479\n",
      "Epoch 71/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3619 - acc: 0.8422 - val_loss: 0.3495 - val_acc: 0.8495\n",
      "Epoch 72/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3596 - acc: 0.8475 - val_loss: 0.3485 - val_acc: 0.8561\n",
      "Epoch 73/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3501 - acc: 0.8497 - val_loss: 0.3692 - val_acc: 0.8397\n",
      "Epoch 74/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3624 - acc: 0.8493 - val_loss: 0.3613 - val_acc: 0.8503\n",
      "Epoch 75/80\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.3594 - acc: 0.8465 - val_loss: 0.3669 - val_acc: 0.8441\n",
      "Epoch 76/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3472 - acc: 0.8465 - val_loss: 0.3572 - val_acc: 0.8458\n",
      "Epoch 77/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3528 - acc: 0.8501 - val_loss: 0.3430 - val_acc: 0.8541\n",
      "Epoch 78/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3484 - acc: 0.8495 - val_loss: 0.3523 - val_acc: 0.8556\n",
      "Epoch 79/80\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.3531 - acc: 0.8481 - val_loss: 0.3524 - val_acc: 0.8442\n",
      "Epoch 80/80\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3427 - acc: 0.8570 - val_loss: 0.3574 - val_acc: 0.8522\n",
      "\n",
      "Training process completed in: 0 h 7 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_992.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 994 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_105 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 0.4897 - acc: 0.7726 - val_loss: 0.4803 - val_acc: 0.8160\n",
      "Epoch 2/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.4285 - acc: 0.8134 - val_loss: 0.4076 - val_acc: 0.8231\n",
      "Epoch 3/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.4003 - acc: 0.8291 - val_loss: 0.3975 - val_acc: 0.8277\n",
      "Epoch 4/40\n",
      "140/140 [==============================] - 18s 125ms/step - loss: 0.3969 - acc: 0.8321 - val_loss: 0.4361 - val_acc: 0.8040\n",
      "Epoch 5/40\n",
      "140/140 [==============================] - 18s 126ms/step - loss: 0.3944 - acc: 0.8318 - val_loss: 0.4046 - val_acc: 0.8271\n",
      "Epoch 6/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.3833 - acc: 0.8357 - val_loss: 0.3928 - val_acc: 0.8358\n",
      "Epoch 7/40\n",
      "140/140 [==============================] - 18s 126ms/step - loss: 0.3893 - acc: 0.8327 - val_loss: 0.3921 - val_acc: 0.8328\n",
      "Epoch 8/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.3866 - acc: 0.8345 - val_loss: 0.3768 - val_acc: 0.8380\n",
      "Epoch 9/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3676 - acc: 0.8423 - val_loss: 0.3855 - val_acc: 0.8368\n",
      "Epoch 10/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3672 - acc: 0.8428 - val_loss: 0.3824 - val_acc: 0.8389\n",
      "Epoch 11/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.3773 - acc: 0.8369 - val_loss: 0.3611 - val_acc: 0.8455\n",
      "Epoch 12/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3618 - acc: 0.8451 - val_loss: 0.3645 - val_acc: 0.8394\n",
      "Epoch 13/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3659 - acc: 0.8430 - val_loss: 0.3977 - val_acc: 0.8132\n",
      "Epoch 14/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3558 - acc: 0.8456 - val_loss: 0.3534 - val_acc: 0.8509\n",
      "Epoch 15/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3584 - acc: 0.8463 - val_loss: 0.3838 - val_acc: 0.8429\n",
      "Epoch 16/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3656 - acc: 0.8440 - val_loss: 0.3589 - val_acc: 0.8420\n",
      "Epoch 17/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3546 - acc: 0.8492 - val_loss: 0.3628 - val_acc: 0.8346\n",
      "Epoch 18/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3441 - acc: 0.8560 - val_loss: 0.3616 - val_acc: 0.8504\n",
      "Epoch 19/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3492 - acc: 0.8502 - val_loss: 0.3517 - val_acc: 0.8476\n",
      "Epoch 20/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3525 - acc: 0.8511 - val_loss: 0.3432 - val_acc: 0.8566\n",
      "Epoch 21/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3467 - acc: 0.8524 - val_loss: 0.4002 - val_acc: 0.8313\n",
      "Epoch 22/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3456 - acc: 0.8515 - val_loss: 0.3551 - val_acc: 0.8497\n",
      "Epoch 23/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3455 - acc: 0.8511 - val_loss: 0.3563 - val_acc: 0.8563\n",
      "Epoch 24/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3440 - acc: 0.8527 - val_loss: 0.3409 - val_acc: 0.8617\n",
      "Epoch 25/40\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.3357 - acc: 0.8557 - val_loss: 0.3377 - val_acc: 0.8563\n",
      "Epoch 26/40\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 0.3356 - acc: 0.8586 - val_loss: 0.3423 - val_acc: 0.8606\n",
      "Epoch 27/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3428 - acc: 0.8563 - val_loss: 0.3448 - val_acc: 0.8493\n",
      "Epoch 28/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3300 - acc: 0.8579 - val_loss: 0.3496 - val_acc: 0.8445\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 18s 128ms/step - loss: 0.3386 - acc: 0.8554 - val_loss: 0.3531 - val_acc: 0.8498\n",
      "Epoch 30/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3310 - acc: 0.8615 - val_loss: 0.3698 - val_acc: 0.8455\n",
      "Epoch 31/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3308 - acc: 0.8598 - val_loss: 0.3387 - val_acc: 0.8636\n",
      "Epoch 32/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3275 - acc: 0.8626 - val_loss: 0.3349 - val_acc: 0.8600\n",
      "Epoch 33/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3158 - acc: 0.8668 - val_loss: 0.3306 - val_acc: 0.8558\n",
      "Epoch 34/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3315 - acc: 0.8613 - val_loss: 0.3351 - val_acc: 0.8581\n",
      "Epoch 35/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3249 - acc: 0.8595 - val_loss: 0.3263 - val_acc: 0.8622\n",
      "Epoch 36/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3219 - acc: 0.8655 - val_loss: 0.3204 - val_acc: 0.8670\n",
      "Epoch 37/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3254 - acc: 0.8612 - val_loss: 0.3209 - val_acc: 0.8664\n",
      "Epoch 38/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3168 - acc: 0.8640 - val_loss: 0.3454 - val_acc: 0.8567\n",
      "Epoch 39/40\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.3304 - acc: 0.8595 - val_loss: 0.3350 - val_acc: 0.8575\n",
      "Epoch 40/40\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.3197 - acc: 0.8653 - val_loss: 0.3440 - val_acc: 0.8622\n",
      "\n",
      "Training process completed in: 0 h 12 m 3 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_993.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 995 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_109 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.4839 - acc: 0.7787 - val_loss: 0.4883 - val_acc: 0.7921\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.4348 - acc: 0.8153 - val_loss: 0.4052 - val_acc: 0.8250\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.4160 - acc: 0.8224 - val_loss: 0.4611 - val_acc: 0.8259\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.4039 - acc: 0.8268 - val_loss: 0.3995 - val_acc: 0.8376\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3919 - acc: 0.8320 - val_loss: 0.4179 - val_acc: 0.8341\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3906 - acc: 0.8345 - val_loss: 0.3859 - val_acc: 0.8391\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3746 - acc: 0.8383 - val_loss: 0.3859 - val_acc: 0.8290\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3799 - acc: 0.8389 - val_loss: 0.3841 - val_acc: 0.8336\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3742 - acc: 0.8369 - val_loss: 0.3931 - val_acc: 0.8341\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3680 - acc: 0.8428 - val_loss: 0.3861 - val_acc: 0.8374\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3737 - acc: 0.8401 - val_loss: 0.3899 - val_acc: 0.8409\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3720 - acc: 0.8408 - val_loss: 0.3705 - val_acc: 0.8584\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3600 - acc: 0.8472 - val_loss: 0.3586 - val_acc: 0.8437\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3637 - acc: 0.8447 - val_loss: 0.3593 - val_acc: 0.8479\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3576 - acc: 0.8486 - val_loss: 0.3698 - val_acc: 0.8489\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3546 - acc: 0.8470 - val_loss: 0.3575 - val_acc: 0.8471\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3513 - acc: 0.8503 - val_loss: 0.3598 - val_acc: 0.8437\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3559 - acc: 0.8462 - val_loss: 0.3562 - val_acc: 0.8544\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3507 - acc: 0.8501 - val_loss: 0.3534 - val_acc: 0.8537\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3457 - acc: 0.8518 - val_loss: 0.3380 - val_acc: 0.8584\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3409 - acc: 0.8554 - val_loss: 0.3456 - val_acc: 0.8581\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3397 - acc: 0.8546 - val_loss: 0.3533 - val_acc: 0.8480\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3422 - acc: 0.8545 - val_loss: 0.3417 - val_acc: 0.8544\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3428 - acc: 0.8552 - val_loss: 0.3532 - val_acc: 0.8616\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3424 - acc: 0.8543 - val_loss: 0.3309 - val_acc: 0.8589\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3381 - acc: 0.8564 - val_loss: 0.3588 - val_acc: 0.8466\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3368 - acc: 0.8575 - val_loss: 0.3316 - val_acc: 0.8606\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 13s 70ms/step - loss: 0.3316 - acc: 0.8585 - val_loss: 0.3361 - val_acc: 0.8530\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 13s 70ms/step - loss: 0.3339 - acc: 0.8598 - val_loss: 0.3342 - val_acc: 0.8623\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 13s 70ms/step - loss: 0.3306 - acc: 0.8597 - val_loss: 0.3375 - val_acc: 0.8666\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 13s 70ms/step - loss: 0.3391 - acc: 0.8590 - val_loss: 0.3441 - val_acc: 0.8529\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 13s 70ms/step - loss: 0.3261 - acc: 0.8616 - val_loss: 0.3248 - val_acc: 0.8651\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3301 - acc: 0.8587 - val_loss: 0.3211 - val_acc: 0.8690\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3321 - acc: 0.8567 - val_loss: 0.3377 - val_acc: 0.8573\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3302 - acc: 0.8595 - val_loss: 0.3329 - val_acc: 0.8571\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3268 - acc: 0.8607 - val_loss: 0.3273 - val_acc: 0.8614\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3288 - acc: 0.8618 - val_loss: 0.3258 - val_acc: 0.8633\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3233 - acc: 0.8637 - val_loss: 0.3295 - val_acc: 0.8611\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3215 - acc: 0.8638 - val_loss: 0.3336 - val_acc: 0.8603\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3244 - acc: 0.8625 - val_loss: 0.3439 - val_acc: 0.8543\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3316 - acc: 0.8601 - val_loss: 0.3297 - val_acc: 0.8590\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3307 - acc: 0.8601 - val_loss: 0.3474 - val_acc: 0.8537\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3257 - acc: 0.8617 - val_loss: 0.3233 - val_acc: 0.8664\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3257 - acc: 0.8618 - val_loss: 0.3284 - val_acc: 0.8697\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3236 - acc: 0.8645 - val_loss: 0.3330 - val_acc: 0.8597\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3159 - acc: 0.8655 - val_loss: 0.3404 - val_acc: 0.8544\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3231 - acc: 0.8621 - val_loss: 0.3516 - val_acc: 0.8583\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3220 - acc: 0.8623 - val_loss: 0.3253 - val_acc: 0.8671\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3178 - acc: 0.8656 - val_loss: 0.3234 - val_acc: 0.8676\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3204 - acc: 0.8640 - val_loss: 0.3159 - val_acc: 0.8749\n",
      "\n",
      "Training process completed in: 0 h 10 m 14 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_994.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 996 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_113 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "170/170 [==============================] - 21s 125ms/step - loss: 0.5034 - acc: 0.7634 - val_loss: 0.4230 - val_acc: 0.8151\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.4182 - acc: 0.8229 - val_loss: 0.4064 - val_acc: 0.8234\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.4112 - acc: 0.8226 - val_loss: 0.4168 - val_acc: 0.8316\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 20s 118ms/step - loss: 0.3981 - acc: 0.8292 - val_loss: 0.4336 - val_acc: 0.8336\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 20s 117ms/step - loss: 0.3924 - acc: 0.8337 - val_loss: 0.4246 - val_acc: 0.8257\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3864 - acc: 0.8347 - val_loss: 0.4041 - val_acc: 0.8368\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3794 - acc: 0.8366 - val_loss: 0.3752 - val_acc: 0.8382\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3744 - acc: 0.8404 - val_loss: 0.3752 - val_acc: 0.8404\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.3653 - acc: 0.8456 - val_loss: 0.3805 - val_acc: 0.8509\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 19s 115ms/step - loss: 0.3736 - acc: 0.8423 - val_loss: 0.3992 - val_acc: 0.8415\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3702 - acc: 0.8401 - val_loss: 0.3635 - val_acc: 0.8434\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3575 - acc: 0.8470 - val_loss: 0.3995 - val_acc: 0.8354\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3669 - acc: 0.8440 - val_loss: 0.3649 - val_acc: 0.8421\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3523 - acc: 0.8517 - val_loss: 0.3846 - val_acc: 0.8527\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3504 - acc: 0.8496 - val_loss: 0.3741 - val_acc: 0.8499\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3532 - acc: 0.8477 - val_loss: 0.3635 - val_acc: 0.8552\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3521 - acc: 0.8478 - val_loss: 0.3734 - val_acc: 0.8462\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3447 - acc: 0.8531 - val_loss: 0.3599 - val_acc: 0.8522\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 20s 117ms/step - loss: 0.3501 - acc: 0.8517 - val_loss: 0.3432 - val_acc: 0.8584\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3487 - acc: 0.8522 - val_loss: 0.3927 - val_acc: 0.8515\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3392 - acc: 0.8576 - val_loss: 0.3557 - val_acc: 0.8569\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3444 - acc: 0.8541 - val_loss: 0.3526 - val_acc: 0.8592\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.3424 - acc: 0.8560 - val_loss: 0.3583 - val_acc: 0.8499\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3377 - acc: 0.8567 - val_loss: 0.3604 - val_acc: 0.8578\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3479 - acc: 0.8510 - val_loss: 0.3435 - val_acc: 0.8581\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.3371 - acc: 0.8564 - val_loss: 0.3584 - val_acc: 0.8531\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3292 - acc: 0.8608 - val_loss: 0.3381 - val_acc: 0.8577\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3331 - acc: 0.8582 - val_loss: 0.3497 - val_acc: 0.8595\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 19s 115ms/step - loss: 0.3291 - acc: 0.8597 - val_loss: 0.3426 - val_acc: 0.8635\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3366 - acc: 0.8579 - val_loss: 0.3405 - val_acc: 0.8605\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3320 - acc: 0.8584 - val_loss: 0.3524 - val_acc: 0.8581\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3336 - acc: 0.8578 - val_loss: 0.3688 - val_acc: 0.8527\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3268 - acc: 0.8613 - val_loss: 0.3635 - val_acc: 0.8586\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3305 - acc: 0.8590 - val_loss: 0.3327 - val_acc: 0.8650\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3226 - acc: 0.8641 - val_loss: 0.3337 - val_acc: 0.8676\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3218 - acc: 0.8636 - val_loss: 0.3638 - val_acc: 0.8643\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3338 - acc: 0.8598 - val_loss: 0.3460 - val_acc: 0.8624\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3233 - acc: 0.8622 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.3238 - acc: 0.8638 - val_loss: 0.3495 - val_acc: 0.8648\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3241 - acc: 0.8603 - val_loss: 0.3783 - val_acc: 0.8494\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 19s 115ms/step - loss: 0.3250 - acc: 0.8638 - val_loss: 0.3221 - val_acc: 0.8636\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3203 - acc: 0.8638 - val_loss: 0.3317 - val_acc: 0.8625\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 19s 112ms/step - loss: 0.3192 - acc: 0.8641 - val_loss: 0.3263 - val_acc: 0.8682\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.3158 - acc: 0.8642 - val_loss: 0.3696 - val_acc: 0.8517\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.3145 - acc: 0.8681 - val_loss: 0.3254 - val_acc: 0.8651\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3167 - acc: 0.8668 - val_loss: 0.3676 - val_acc: 0.8524\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3197 - acc: 0.8640 - val_loss: 0.3205 - val_acc: 0.8699\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 20s 116ms/step - loss: 0.3153 - acc: 0.8684 - val_loss: 0.3323 - val_acc: 0.8619\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 19s 114ms/step - loss: 0.3135 - acc: 0.8687 - val_loss: 0.3250 - val_acc: 0.8672\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 19s 115ms/step - loss: 0.3213 - acc: 0.8624 - val_loss: 0.3282 - val_acc: 0.8648\n",
      "\n",
      "Training process completed in: 0 h 16 m 18 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_995.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 997 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_117 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.5318 - acc: 0.7499 - val_loss: 0.4696 - val_acc: 0.7844\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 9s 65ms/step - loss: 0.4375 - acc: 0.8132 - val_loss: 0.4156 - val_acc: 0.8344\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.4166 - acc: 0.8246 - val_loss: 0.4300 - val_acc: 0.8106\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.4204 - acc: 0.8188 - val_loss: 0.4118 - val_acc: 0.8156\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.4011 - acc: 0.8282 - val_loss: 0.4017 - val_acc: 0.8194\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3949 - acc: 0.8304 - val_loss: 0.3773 - val_acc: 0.8450\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3913 - acc: 0.8338 - val_loss: 0.3840 - val_acc: 0.8412\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3906 - acc: 0.8338 - val_loss: 0.3899 - val_acc: 0.8394\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3807 - acc: 0.8372 - val_loss: 0.3783 - val_acc: 0.8450\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3892 - acc: 0.8342 - val_loss: 0.3753 - val_acc: 0.8469\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3837 - acc: 0.8344 - val_loss: 0.3792 - val_acc: 0.8494\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3723 - acc: 0.8405 - val_loss: 0.3749 - val_acc: 0.8363\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3746 - acc: 0.8380 - val_loss: 0.4110 - val_acc: 0.8419\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3588 - acc: 0.8496 - val_loss: 0.3967 - val_acc: 0.8300\n",
      "Epoch 15/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3629 - acc: 0.8471 - val_loss: 0.3864 - val_acc: 0.8325\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3655 - acc: 0.8449 - val_loss: 0.3776 - val_acc: 0.8406\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3615 - acc: 0.8488 - val_loss: 0.3701 - val_acc: 0.8444\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 10s 69ms/step - loss: 0.3546 - acc: 0.8494 - val_loss: 0.3867 - val_acc: 0.8366\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 9s 65ms/step - loss: 0.3584 - acc: 0.8459 - val_loss: 0.3539 - val_acc: 0.8469\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3532 - acc: 0.8478 - val_loss: 0.3325 - val_acc: 0.8569\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3473 - acc: 0.8527 - val_loss: 0.3799 - val_acc: 0.8363\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3432 - acc: 0.8546 - val_loss: 0.3479 - val_acc: 0.8519\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3372 - acc: 0.8578 - val_loss: 0.3406 - val_acc: 0.8625\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3383 - acc: 0.8561 - val_loss: 0.3524 - val_acc: 0.8550\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3378 - acc: 0.8547 - val_loss: 0.3332 - val_acc: 0.8587\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3415 - acc: 0.8557 - val_loss: 0.3485 - val_acc: 0.8538\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3475 - acc: 0.8501 - val_loss: 0.3618 - val_acc: 0.8519\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3549 - acc: 0.8515 - val_loss: 0.3752 - val_acc: 0.8450\n",
      "Epoch 29/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3408 - acc: 0.8541 - val_loss: 0.3951 - val_acc: 0.8481\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3468 - acc: 0.8533 - val_loss: 0.3830 - val_acc: 0.8631\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3436 - acc: 0.8523 - val_loss: 0.3873 - val_acc: 0.8444\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3312 - acc: 0.8604 - val_loss: 0.3428 - val_acc: 0.8619\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3344 - acc: 0.8605 - val_loss: 0.3382 - val_acc: 0.8656\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3347 - acc: 0.8581 - val_loss: 0.3230 - val_acc: 0.8644\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3328 - acc: 0.8600 - val_loss: 0.3573 - val_acc: 0.8604\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3333 - acc: 0.8589 - val_loss: 0.3361 - val_acc: 0.8600\n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3261 - acc: 0.8610 - val_loss: 0.3614 - val_acc: 0.8500\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3252 - acc: 0.8617 - val_loss: 0.3710 - val_acc: 0.8312\n",
      "Epoch 39/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3291 - acc: 0.8604 - val_loss: 0.3694 - val_acc: 0.8588\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3220 - acc: 0.8647 - val_loss: 0.3653 - val_acc: 0.8631\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3275 - acc: 0.8597 - val_loss: 0.3257 - val_acc: 0.8606\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3299 - acc: 0.8617 - val_loss: 0.3265 - val_acc: 0.8738\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3291 - acc: 0.8628 - val_loss: 0.3291 - val_acc: 0.8744\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3400 - acc: 0.8558 - val_loss: 0.3490 - val_acc: 0.8550\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3264 - acc: 0.8639 - val_loss: 0.3430 - val_acc: 0.8662\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3204 - acc: 0.8606 - val_loss: 0.3330 - val_acc: 0.8656\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3200 - acc: 0.8658 - val_loss: 0.3400 - val_acc: 0.8525\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3280 - acc: 0.8621 - val_loss: 0.3356 - val_acc: 0.8694\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3280 - acc: 0.8607 - val_loss: 0.3479 - val_acc: 0.8519\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3224 - acc: 0.8616 - val_loss: 0.3369 - val_acc: 0.8556\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3236 - acc: 0.8645 - val_loss: 0.3521 - val_acc: 0.8406\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3150 - acc: 0.8662 - val_loss: 0.3668 - val_acc: 0.8588\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 10s 70ms/step - loss: 0.3166 - acc: 0.8674 - val_loss: 0.3388 - val_acc: 0.8525\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 9s 64ms/step - loss: 0.3316 - acc: 0.8600 - val_loss: 0.3341 - val_acc: 0.8700\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3185 - acc: 0.8639 - val_loss: 0.3318 - val_acc: 0.8613\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3155 - acc: 0.8679 - val_loss: 0.3657 - val_acc: 0.8613\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3229 - acc: 0.8616 - val_loss: 0.3221 - val_acc: 0.8644\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3176 - acc: 0.8654 - val_loss: 0.3252 - val_acc: 0.8637\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3151 - acc: 0.8667 - val_loss: 0.3330 - val_acc: 0.8613\n",
      "Epoch 60/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3153 - acc: 0.8663 - val_loss: 0.3527 - val_acc: 0.8588\n",
      "Epoch 61/80\n",
      "140/140 [==============================] - 10s 68ms/step - loss: 0.3213 - acc: 0.8648 - val_loss: 0.3482 - val_acc: 0.8550\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3204 - acc: 0.8632 - val_loss: 0.3493 - val_acc: 0.8506\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3166 - acc: 0.8664 - val_loss: 0.3403 - val_acc: 0.8537\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3203 - acc: 0.8669 - val_loss: 0.3324 - val_acc: 0.8700\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3155 - acc: 0.8669 - val_loss: 0.3079 - val_acc: 0.8738\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3182 - acc: 0.8650 - val_loss: 0.3033 - val_acc: 0.8744\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3144 - acc: 0.8683 - val_loss: 0.3357 - val_acc: 0.8681\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3130 - acc: 0.8699 - val_loss: 0.3360 - val_acc: 0.8656\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 10s 68ms/step - loss: 0.3130 - acc: 0.8688 - val_loss: 0.3306 - val_acc: 0.8575\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 10s 69ms/step - loss: 0.3157 - acc: 0.8689 - val_loss: 0.3133 - val_acc: 0.8823\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 9s 65ms/step - loss: 0.3226 - acc: 0.8632 - val_loss: 0.3482 - val_acc: 0.8575\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3182 - acc: 0.8648 - val_loss: 0.3434 - val_acc: 0.8656\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3112 - acc: 0.8687 - val_loss: 0.3272 - val_acc: 0.8737\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3081 - acc: 0.8706 - val_loss: 0.3332 - val_acc: 0.8594\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3260 - acc: 0.8644 - val_loss: 0.3397 - val_acc: 0.8606\n",
      "Epoch 76/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3130 - acc: 0.8691 - val_loss: 0.3197 - val_acc: 0.8694\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3157 - acc: 0.8669 - val_loss: 0.3554 - val_acc: 0.8438\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3117 - acc: 0.8702 - val_loss: 0.3213 - val_acc: 0.8575\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3156 - acc: 0.8655 - val_loss: 0.3333 - val_acc: 0.8663\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3098 - acc: 0.8726 - val_loss: 0.3393 - val_acc: 0.8719\n",
      "\n",
      "Training process completed in: 0 h 12 m 31 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_996.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 998 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_121 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.1\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 18s 108ms/step - loss: 4.6001 - acc: 0.7122 - val_loss: 4.6229 - val_acc: 0.7132\n",
      "Epoch 2/80\n",
      "170/170 [==============================] - 17s 97ms/step - loss: 4.4876 - acc: 0.7216 - val_loss: 4.5228 - val_acc: 0.7194\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.6411 - acc: 0.7121 - val_loss: 4.5715 - val_acc: 0.7164\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5694 - acc: 0.7165 - val_loss: 4.5816 - val_acc: 0.7157\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 16s 96ms/step - loss: 4.5777 - acc: 0.7160 - val_loss: 4.6168 - val_acc: 0.7136\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 16s 96ms/step - loss: 4.5978 - acc: 0.7147 - val_loss: 4.5613 - val_acc: 0.7170\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5036 - acc: 0.7206 - val_loss: 4.5512 - val_acc: 0.7176\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 16s 96ms/step - loss: 4.6280 - acc: 0.7129 - val_loss: 4.5947 - val_acc: 0.7149\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5658 - acc: 0.7167 - val_loss: 4.5279 - val_acc: 0.7191\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5540 - acc: 0.7175 - val_loss: 4.5876 - val_acc: 0.7154\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5913 - acc: 0.7151 - val_loss: 4.6434 - val_acc: 0.7119\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5818 - acc: 0.7157 - val_loss: 4.5201 - val_acc: 0.7196\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5095 - acc: 0.7202 - val_loss: 4.6039 - val_acc: 0.7144\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5773 - acc: 0.7160 - val_loss: 4.5542 - val_acc: 0.7174\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6446 - acc: 0.7118 - val_loss: 4.5080 - val_acc: 0.7203\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5540 - acc: 0.7175 - val_loss: 4.6079 - val_acc: 0.7141\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6185 - acc: 0.7135 - val_loss: 4.6279 - val_acc: 0.7129\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6286 - acc: 0.7128 - val_loss: 4.5502 - val_acc: 0.7177\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.4988 - acc: 0.7209 - val_loss: 4.5534 - val_acc: 0.7175\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5830 - acc: 0.7157 - val_loss: 4.6201 - val_acc: 0.7134\n",
      "Epoch 21/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6102 - acc: 0.7140 - val_loss: 4.5664 - val_acc: 0.7167\n",
      "Epoch 22/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6268 - acc: 0.7129 - val_loss: 4.5534 - val_acc: 0.7175\n",
      "Epoch 23/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.4858 - acc: 0.7217 - val_loss: 4.5694 - val_acc: 0.7165\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5409 - acc: 0.7183 - val_loss: 4.5655 - val_acc: 0.7168\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5385 - acc: 0.7184 - val_loss: 4.6819 - val_acc: 0.7095\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6043 - acc: 0.7143 - val_loss: 4.5100 - val_acc: 0.7202\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5711 - acc: 0.7164 - val_loss: 4.5603 - val_acc: 0.7171\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5688 - acc: 0.7165 - val_loss: 4.5542 - val_acc: 0.7174\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6191 - acc: 0.7134 - val_loss: 4.6027 - val_acc: 0.7144\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5569 - acc: 0.7173 - val_loss: 4.5633 - val_acc: 0.7169\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5670 - acc: 0.7167 - val_loss: 4.5473 - val_acc: 0.7179\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5303 - acc: 0.7189 - val_loss: 4.6130 - val_acc: 0.7138\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6079 - acc: 0.7141 - val_loss: 4.5846 - val_acc: 0.7156\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 4.5178 - acc: 0.7197 - val_loss: 4.6008 - val_acc: 0.7146\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5368 - acc: 0.7185 - val_loss: 4.5340 - val_acc: 0.7187\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5545 - acc: 0.7174 - val_loss: 4.5201 - val_acc: 0.7196\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5600 - acc: 0.7171 - val_loss: 4.6089 - val_acc: 0.7141\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6565 - acc: 0.7111 - val_loss: 4.6601 - val_acc: 0.7109\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5842 - acc: 0.7156 - val_loss: 4.5522 - val_acc: 0.7176\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6582 - acc: 0.7110 - val_loss: 4.5483 - val_acc: 0.7178\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 4.6002 - acc: 0.7146 - val_loss: 4.5593 - val_acc: 0.7171\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6085 - acc: 0.7141 - val_loss: 4.5330 - val_acc: 0.7188\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5634 - acc: 0.7169 - val_loss: 4.5040 - val_acc: 0.7206\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5225 - acc: 0.7194 - val_loss: 4.6646 - val_acc: 0.7106\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6144 - acc: 0.7137 - val_loss: 4.6209 - val_acc: 0.7133\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5581 - acc: 0.7172 - val_loss: 4.6049 - val_acc: 0.7143\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5550 - acc: 0.7174 - val_loss: 4.5390 - val_acc: 0.7184\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5747 - acc: 0.7162 - val_loss: 4.5060 - val_acc: 0.7204\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5664 - acc: 0.7167 - val_loss: 4.6474 - val_acc: 0.7117\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6002 - acc: 0.7146 - val_loss: 4.5906 - val_acc: 0.7152\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6014 - acc: 0.7145 - val_loss: 4.5026 - val_acc: 0.7207\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5095 - acc: 0.7202 - val_loss: 4.6128 - val_acc: 0.7138\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6114 - acc: 0.7139 - val_loss: 4.5654 - val_acc: 0.7168\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5291 - acc: 0.7190 - val_loss: 4.6262 - val_acc: 0.7130\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5362 - acc: 0.7186 - val_loss: 4.5272 - val_acc: 0.7191\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.6179 - acc: 0.7135 - val_loss: 4.5816 - val_acc: 0.7157\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6215 - acc: 0.7133 - val_loss: 4.6219 - val_acc: 0.7132\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5824 - acc: 0.7157 - val_loss: 4.5775 - val_acc: 0.7160\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5617 - acc: 0.7170 - val_loss: 4.5332 - val_acc: 0.7187\n",
      "Epoch 60/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5984 - acc: 0.7147 - val_loss: 4.6201 - val_acc: 0.7134\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6014 - acc: 0.7145 - val_loss: 4.5168 - val_acc: 0.7198\n",
      "Epoch 62/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.4864 - acc: 0.7217 - val_loss: 4.6491 - val_acc: 0.7116\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5877 - acc: 0.7154 - val_loss: 4.5603 - val_acc: 0.7171\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5950 - acc: 0.7149 - val_loss: 4.5967 - val_acc: 0.7148\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5504 - acc: 0.7177 - val_loss: 4.5319 - val_acc: 0.7188\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5960 - acc: 0.7149 - val_loss: 4.5574 - val_acc: 0.7173\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.6612 - acc: 0.7108 - val_loss: 4.5654 - val_acc: 0.7168\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5510 - acc: 0.7176 - val_loss: 4.5745 - val_acc: 0.7162\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5297 - acc: 0.7190 - val_loss: 4.5322 - val_acc: 0.7188\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5822 - acc: 0.7157 - val_loss: 4.6738 - val_acc: 0.7100\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5628 - acc: 0.7169 - val_loss: 4.5312 - val_acc: 0.7189\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 4.5723 - acc: 0.7163 - val_loss: 4.5421 - val_acc: 0.7182\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.5646 - acc: 0.7168 - val_loss: 4.6098 - val_acc: 0.7140\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 4.5380 - acc: 0.7185 - val_loss: 4.6079 - val_acc: 0.7141\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 4.4685 - acc: 0.7228 - val_loss: 4.5451 - val_acc: 0.7180\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6221 - acc: 0.7132 - val_loss: 4.6269 - val_acc: 0.7129\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6049 - acc: 0.7143 - val_loss: 4.5502 - val_acc: 0.7177\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5717 - acc: 0.7164 - val_loss: 4.5876 - val_acc: 0.7154\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.5883 - acc: 0.7153 - val_loss: 4.5765 - val_acc: 0.7161\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 4.6322 - acc: 0.7126 - val_loss: 4.5443 - val_acc: 0.7181\n",
      "\n",
      "Training process completed in: 0 h 22 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_997.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 999 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_125 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 22s 116ms/step - loss: 0.4819 - acc: 0.7795 - val_loss: 0.4178 - val_acc: 0.8229\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.4235 - acc: 0.8188 - val_loss: 0.4183 - val_acc: 0.8135\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.4066 - acc: 0.8259 - val_loss: 0.3973 - val_acc: 0.8241\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.4003 - acc: 0.8289 - val_loss: 0.4113 - val_acc: 0.8244\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3928 - acc: 0.8322 - val_loss: 0.3973 - val_acc: 0.8306\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3804 - acc: 0.8358 - val_loss: 0.3803 - val_acc: 0.8372\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3775 - acc: 0.8396 - val_loss: 0.3769 - val_acc: 0.8390\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3671 - acc: 0.8418 - val_loss: 0.3633 - val_acc: 0.8424\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3609 - acc: 0.8470 - val_loss: 0.3620 - val_acc: 0.8461\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3624 - acc: 0.8441 - val_loss: 0.3859 - val_acc: 0.8460\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3565 - acc: 0.8464 - val_loss: 0.3589 - val_acc: 0.8511\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3495 - acc: 0.8509 - val_loss: 0.3583 - val_acc: 0.8494\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3452 - acc: 0.8541 - val_loss: 0.3798 - val_acc: 0.8464\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3367 - acc: 0.8562 - val_loss: 0.3877 - val_acc: 0.8413\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3481 - acc: 0.8518 - val_loss: 0.3611 - val_acc: 0.8548\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3432 - acc: 0.8553 - val_loss: 0.3594 - val_acc: 0.8414\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3384 - acc: 0.8582 - val_loss: 0.3342 - val_acc: 0.8643\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3351 - acc: 0.8592 - val_loss: 0.3564 - val_acc: 0.8569\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3310 - acc: 0.8621 - val_loss: 0.3325 - val_acc: 0.8653\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3240 - acc: 0.8622 - val_loss: 0.3395 - val_acc: 0.8605\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3305 - acc: 0.8626 - val_loss: 0.3379 - val_acc: 0.8615\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3302 - acc: 0.8608 - val_loss: 0.3764 - val_acc: 0.8476\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3307 - acc: 0.8590 - val_loss: 0.3490 - val_acc: 0.8612\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3253 - acc: 0.8634 - val_loss: 0.3576 - val_acc: 0.8630\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3289 - acc: 0.8611 - val_loss: 0.3364 - val_acc: 0.8667\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3266 - acc: 0.8618 - val_loss: 0.3654 - val_acc: 0.8582\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3215 - acc: 0.8655 - val_loss: 0.3311 - val_acc: 0.8663\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3244 - acc: 0.8640 - val_loss: 0.3281 - val_acc: 0.8626\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3235 - acc: 0.8640 - val_loss: 0.3301 - val_acc: 0.8642\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3258 - acc: 0.8612 - val_loss: 0.3326 - val_acc: 0.8649\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3152 - acc: 0.8655 - val_loss: 0.3619 - val_acc: 0.8647\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3191 - acc: 0.8686 - val_loss: 0.3601 - val_acc: 0.8578\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3233 - acc: 0.8658 - val_loss: 0.3504 - val_acc: 0.8625\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3139 - acc: 0.8688 - val_loss: 0.3690 - val_acc: 0.8541\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3184 - acc: 0.8659 - val_loss: 0.3179 - val_acc: 0.8671\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3126 - acc: 0.8683 - val_loss: 0.3444 - val_acc: 0.8583\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3156 - acc: 0.8676 - val_loss: 0.3382 - val_acc: 0.8581\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3140 - acc: 0.8694 - val_loss: 0.3247 - val_acc: 0.8689\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3206 - acc: 0.8646 - val_loss: 0.3156 - val_acc: 0.8719\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.3084 - acc: 0.8715 - val_loss: 0.3346 - val_acc: 0.8635\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.3128 - acc: 0.8674 - val_loss: 0.3405 - val_acc: 0.8630\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3173 - acc: 0.8674 - val_loss: 0.3307 - val_acc: 0.8702\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3053 - acc: 0.8705 - val_loss: 0.3250 - val_acc: 0.8639\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.3152 - acc: 0.8693 - val_loss: 0.3173 - val_acc: 0.8656\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3092 - acc: 0.8712 - val_loss: 0.3544 - val_acc: 0.8633\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.3023 - acc: 0.8746 - val_loss: 0.3084 - val_acc: 0.8722\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3034 - acc: 0.8744 - val_loss: 0.3284 - val_acc: 0.8670\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3124 - acc: 0.8689 - val_loss: 0.3308 - val_acc: 0.8631\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3057 - acc: 0.8712 - val_loss: 0.3256 - val_acc: 0.8694\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3127 - acc: 0.8700 - val_loss: 0.3926 - val_acc: 0.8508\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3056 - acc: 0.8730 - val_loss: 0.3181 - val_acc: 0.8716\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3058 - acc: 0.8699 - val_loss: 0.3483 - val_acc: 0.8675\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3095 - acc: 0.8708 - val_loss: 0.3231 - val_acc: 0.8670\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3016 - acc: 0.8737 - val_loss: 0.3254 - val_acc: 0.8689\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3002 - acc: 0.8753 - val_loss: 0.3206 - val_acc: 0.8694\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3008 - acc: 0.8747 - val_loss: 0.3246 - val_acc: 0.8672\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3068 - acc: 0.8702 - val_loss: 0.3423 - val_acc: 0.8702\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3013 - acc: 0.8720 - val_loss: 0.3301 - val_acc: 0.8745\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.3043 - acc: 0.8742 - val_loss: 0.3132 - val_acc: 0.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.2993 - acc: 0.8749 - val_loss: 0.3327 - val_acc: 0.8687\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.2983 - acc: 0.8743 - val_loss: 0.3403 - val_acc: 0.8676\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3037 - acc: 0.8730 - val_loss: 0.3154 - val_acc: 0.8727\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.2960 - acc: 0.8756 - val_loss: 0.3043 - val_acc: 0.8739\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 20s 108ms/step - loss: 0.3013 - acc: 0.8732 - val_loss: 0.3243 - val_acc: 0.8723\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.2987 - acc: 0.8746 - val_loss: 0.3117 - val_acc: 0.8747\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.2953 - acc: 0.8780 - val_loss: 0.3099 - val_acc: 0.8713\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.2991 - acc: 0.8740 - val_loss: 0.3082 - val_acc: 0.8739\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.2996 - acc: 0.8740 - val_loss: 0.3141 - val_acc: 0.8763\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.2932 - acc: 0.8775 - val_loss: 0.3301 - val_acc: 0.8699\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.2978 - acc: 0.8753 - val_loss: 0.3260 - val_acc: 0.8695\n",
      "\n",
      "Training process completed in: 0 h 23 m 21 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_998.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1000 of 1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_129 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_130 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_131 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_132 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x0000015406FC19D8>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 40\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.5940 - acc: 0.7029 - val_loss: 0.5517 - val_acc: 0.7114\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.5298 - acc: 0.7318 - val_loss: 0.5001 - val_acc: 0.7764\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4717 - acc: 0.7929 - val_loss: 0.4236 - val_acc: 0.8164\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4250 - acc: 0.8221 - val_loss: 0.4588 - val_acc: 0.8021\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4403 - acc: 0.8073 - val_loss: 0.4904 - val_acc: 0.8007\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4117 - acc: 0.8257 - val_loss: 0.4033 - val_acc: 0.8164\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4245 - acc: 0.8227 - val_loss: 0.4155 - val_acc: 0.8207\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4096 - acc: 0.8257 - val_loss: 0.4262 - val_acc: 0.8179\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4239 - acc: 0.8129 - val_loss: 0.4204 - val_acc: 0.8293\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4063 - acc: 0.8325 - val_loss: 0.4283 - val_acc: 0.8250\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4064 - acc: 0.8293 - val_loss: 0.4309 - val_acc: 0.8443\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4167 - acc: 0.8229 - val_loss: 0.4698 - val_acc: 0.8207\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4339 - acc: 0.8121 - val_loss: 0.4390 - val_acc: 0.8321\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4040 - acc: 0.8268 - val_loss: 0.4226 - val_acc: 0.8143\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.3932 - acc: 0.8345 - val_loss: 0.4063 - val_acc: 0.8329\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4027 - acc: 0.8302 - val_loss: 0.3901 - val_acc: 0.8436\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3847 - acc: 0.8323 - val_loss: 0.3831 - val_acc: 0.8500\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3901 - acc: 0.8271 - val_loss: 0.4437 - val_acc: 0.8321\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3888 - acc: 0.8355 - val_loss: 0.4273 - val_acc: 0.8521\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.3951 - acc: 0.8352 - val_loss: 0.4052 - val_acc: 0.8235\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.3945 - acc: 0.8311 - val_loss: 0.3954 - val_acc: 0.8243\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3802 - acc: 0.8339 - val_loss: 0.4150 - val_acc: 0.8364\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3935 - acc: 0.8271 - val_loss: 0.3894 - val_acc: 0.8264\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.4022 - acc: 0.8313 - val_loss: 0.5013 - val_acc: 0.8121\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3952 - acc: 0.8321 - val_loss: 0.3915 - val_acc: 0.8314\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3887 - acc: 0.8339 - val_loss: 0.4053 - val_acc: 0.8364\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3624 - acc: 0.8463 - val_loss: 0.3931 - val_acc: 0.8329\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3703 - acc: 0.8357 - val_loss: 0.3928 - val_acc: 0.8214\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.4046 - acc: 0.8254 - val_loss: 0.3784 - val_acc: 0.8414\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3845 - acc: 0.8339 - val_loss: 0.3878 - val_acc: 0.8293\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3693 - acc: 0.8434 - val_loss: 0.3786 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3712 - acc: 0.8409 - val_loss: 0.3829 - val_acc: 0.8286\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3771 - acc: 0.8343 - val_loss: 0.3773 - val_acc: 0.8364\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3826 - acc: 0.8343 - val_loss: 0.4055 - val_acc: 0.8393\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3914 - acc: 0.8314 - val_loss: 0.4042 - val_acc: 0.8414\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3859 - acc: 0.8327 - val_loss: 0.3695 - val_acc: 0.8450\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3740 - acc: 0.8404 - val_loss: 0.4014 - val_acc: 0.8464\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3642 - acc: 0.8470 - val_loss: 0.4025 - val_acc: 0.8179\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3633 - acc: 0.8446 - val_loss: 0.3726 - val_acc: 0.8364\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.3735 - acc: 0.8338 - val_loss: 0.3650 - val_acc: 0.8390\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.3810 - acc: 0.8371 - val_loss: 0.3878 - val_acc: 0.8321\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3698 - acc: 0.8371 - val_loss: 0.3627 - val_acc: 0.8421\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3632 - acc: 0.8459 - val_loss: 0.3882 - val_acc: 0.8407\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3542 - acc: 0.8459 - val_loss: 0.3759 - val_acc: 0.8450\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3647 - acc: 0.8405 - val_loss: 0.4235 - val_acc: 0.8421\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3628 - acc: 0.8443 - val_loss: 0.3582 - val_acc: 0.8521\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3637 - acc: 0.8509 - val_loss: 0.3982 - val_acc: 0.8350\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3617 - acc: 0.8411 - val_loss: 0.3915 - val_acc: 0.8293\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.3673 - acc: 0.8412 - val_loss: 0.3307 - val_acc: 0.8643\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.3605 - acc: 0.8427 - val_loss: 0.3798 - val_acc: 0.8436\n",
      "\n",
      "Training process completed in: 0 h 2 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_999.h5 \"\n",
      "######################################################################################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596284</td>\n",
       "      <td>0.717086</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.424821</td>\n",
       "      <td>0.824666</td>\n",
       "      <td>0:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.400397</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.821459</td>\n",
       "      <td>0:02:56</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.342393</td>\n",
       "      <td>0.854934</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0:03:59</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.61192</td>\n",
       "      <td>0.713867</td>\n",
       "      <td>4.51508</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0:11:35</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.57984</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>4.66014</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>0:04:34</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.414818</td>\n",
       "      <td>0.818889</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.355077</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0:11:37</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.598234</td>\n",
       "      <td>0.714492</td>\n",
       "      <td>0.587283</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0:11:21</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.415619</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.415587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0:03:26</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355923</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.340781</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0:04:54</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.386344</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>0.38406</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0:01:19</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.578921</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.572354</td>\n",
       "      <td>0.707286</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.386086</td>\n",
       "      <td>0.829286</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.406065</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.821349</td>\n",
       "      <td>0:09:57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.343212</td>\n",
       "      <td>0.854563</td>\n",
       "      <td>0.333918</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0:11:05</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.366198</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.378055</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0:02:27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.36458</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>0.842172</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.398393</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.593772</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.418344</td>\n",
       "      <td>0.815605</td>\n",
       "      <td>0:06:57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.369263</td>\n",
       "      <td>0.838594</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.846597</td>\n",
       "      <td>0:05:47</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.720147</td>\n",
       "      <td>0.593732</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0:03:39</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.481815</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.503438</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0:01:15</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.60906</td>\n",
       "      <td>0.714044</td>\n",
       "      <td>4.5453</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0:20:24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.63599</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>4.53844</td>\n",
       "      <td>0.718426</td>\n",
       "      <td>0:01:44</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.66619</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>4.60252</td>\n",
       "      <td>0.71445</td>\n",
       "      <td>0:06:20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.401561</td>\n",
       "      <td>0.824792</td>\n",
       "      <td>0.387844</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0:03:24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.602757</td>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.592917</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0:07:09</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.485893</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>0.79175</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.601346</td>\n",
       "      <td>0.711027</td>\n",
       "      <td>0.597481</td>\n",
       "      <td>0.715408</td>\n",
       "      <td>0:12:40</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.403532</td>\n",
       "      <td>0.826222</td>\n",
       "      <td>0.395664</td>\n",
       "      <td>0.830907</td>\n",
       "      <td>0:05:02</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.412687</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.418053</td>\n",
       "      <td>0.828744</td>\n",
       "      <td>0:07:50</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.405146</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.416881</td>\n",
       "      <td>0.818917</td>\n",
       "      <td>0:09:10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.50501</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>4.59366</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0:01:36</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.432218</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.413683</td>\n",
       "      <td>0.819375</td>\n",
       "      <td>0:01:30</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.600507</td>\n",
       "      <td>0.712089</td>\n",
       "      <td>0.589967</td>\n",
       "      <td>0.724124</td>\n",
       "      <td>0:06:10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.326822</td>\n",
       "      <td>0.863472</td>\n",
       "      <td>0.333745</td>\n",
       "      <td>0.860016</td>\n",
       "      <td>0:18:48</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.51307</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.58963</td>\n",
       "      <td>0.71525</td>\n",
       "      <td>0:08:48</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596477</td>\n",
       "      <td>0.717083</td>\n",
       "      <td>0.601323</td>\n",
       "      <td>0.711045</td>\n",
       "      <td>0:02:31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.310391</td>\n",
       "      <td>0.870357</td>\n",
       "      <td>0.323439</td>\n",
       "      <td>0.86698</td>\n",
       "      <td>0:14:44</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.454561</td>\n",
       "      <td>0.787917</td>\n",
       "      <td>0.466094</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>0:00:51</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.312476</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.311568</td>\n",
       "      <td>0.867812</td>\n",
       "      <td>0:13:52</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.361246</td>\n",
       "      <td>0.844902</td>\n",
       "      <td>0.375628</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0:03:42</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.34627</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>0.363982</td>\n",
       "      <td>0.859753</td>\n",
       "      <td>0:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>4.85155</td>\n",
       "      <td>0.699</td>\n",
       "      <td>5.04138</td>\n",
       "      <td>0.687222</td>\n",
       "      <td>0:01:27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.58963</td>\n",
       "      <td>0.71525</td>\n",
       "      <td>4.55157</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>0:06:46</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.56807</td>\n",
       "      <td>0.716587</td>\n",
       "      <td>4.70014</td>\n",
       "      <td>0.708394</td>\n",
       "      <td>0:03:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.600436</td>\n",
       "      <td>0.71199</td>\n",
       "      <td>0.589267</td>\n",
       "      <td>0.723945</td>\n",
       "      <td>0:13:03</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>140</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.429227</td>\n",
       "      <td>0.812041</td>\n",
       "      <td>0.445243</td>\n",
       "      <td>0.813561</td>\n",
       "      <td>0:10:47</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.592386</td>\n",
       "      <td>0.72125</td>\n",
       "      <td>0.600429</td>\n",
       "      <td>0.712083</td>\n",
       "      <td>0:02:24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.53003</td>\n",
       "      <td>0.718947</td>\n",
       "      <td>5.18082</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0:03:56</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.342689</td>\n",
       "      <td>0.857045</td>\n",
       "      <td>0.357372</td>\n",
       "      <td>0.852188</td>\n",
       "      <td>0:07:47</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>200</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.319671</td>\n",
       "      <td>0.865321</td>\n",
       "      <td>0.343955</td>\n",
       "      <td>0.86215</td>\n",
       "      <td>0:12:03</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>140</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.320372</td>\n",
       "      <td>0.864048</td>\n",
       "      <td>0.315853</td>\n",
       "      <td>0.874857</td>\n",
       "      <td>0:10:14</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>200</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.862441</td>\n",
       "      <td>0.328234</td>\n",
       "      <td>0.86475</td>\n",
       "      <td>0:16:18</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.309834</td>\n",
       "      <td>0.872634</td>\n",
       "      <td>0.339324</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0:12:31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.63217</td>\n",
       "      <td>0.71261</td>\n",
       "      <td>4.5443</td>\n",
       "      <td>0.718063</td>\n",
       "      <td>0:22:27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.297779</td>\n",
       "      <td>0.875322</td>\n",
       "      <td>0.325952</td>\n",
       "      <td>0.869482</td>\n",
       "      <td>0:23:21</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.36047</td>\n",
       "      <td>0.842679</td>\n",
       "      <td>0.37984</td>\n",
       "      <td>0.843571</td>\n",
       "      <td>0:02:08</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc  val_loss   val_acc     time  gen  alive\n",
       "0           160               60                50      30        0.01000   0.596284  0.717086  0.602438  0.710375  0:02:47    1   True\n",
       "1           140              200                20      80        0.01000   0.419026  0.819964  0.424821  0.824666  0:14:00    1   True\n",
       "2           200               30                70      30        0.00010   0.400397  0.828667  0.407492  0.821459  0:02:56    1   True\n",
       "3            80              190                30      40        0.00100   0.342393  0.854934    0.3493     0.855  0:03:59    1   True\n",
       "4           100              150                80      90        0.10000    4.61192  0.713867   4.51508  0.719875  0:11:35    1   True\n",
       "5           200               70                40      40        0.10000    4.57984  0.715857   4.66014  0.710875  0:04:34    1   True\n",
       "6            60               30                80      40        0.00010   0.414818  0.818889  0.516359  0.784375  0:01:24    1   True\n",
       "7           200              110                70      60        0.00010   0.351962  0.852273  0.355077  0.848624  0:11:37    1   True\n",
       "8           160              160                20      70        0.01000   0.598234  0.714492  0.587283  0.726542  0:11:21    1   True\n",
       "9           120              110                20      40        0.00001   0.415619  0.823788  0.415587  0.819167  0:03:26    1   True\n",
       "10           40              130               100      90        0.00100   0.355923  0.847692  0.340781     0.862  0:04:54    1   True\n",
       "11          140              120                50      10        0.00100   0.386344   0.83375   0.38406  0.837714  0:01:19    1   True\n",
       "12          140               10                50      10        0.00010   0.578921  0.707143  0.572354  0.707286  0:00:27    1   True\n",
       "13           20              130                70      30        0.00100   0.396505  0.838462  0.386086  0.829286  0:00:46    1   True\n",
       "14          140              160                90      50        0.00001   0.406065  0.825893  0.408935  0.821349  0:09:57    1   True\n",
       "15          160              100                80      70        0.00010   0.343212  0.854563  0.333918  0.855412  0:11:05    1   True\n",
       "16          140               90                10      30        0.00100   0.366198  0.840635  0.378055  0.837143  0:02:27    1   True\n",
       "17           80               80                10      70        0.00100    0.36458  0.840156   0.34817  0.842172  0:03:00    1   True\n",
       "18          120               30                20      40        0.00100   0.398393  0.832778  0.461081  0.833333  0:01:07    1   True\n",
       "19           60              120                40      40        0.01000   0.596109  0.716944  0.593772  0.719167  0:02:15    1   True\n",
       "20          160               10                70     100        0.00010   0.409997    0.8225  0.418344  0.815605  0:06:57    1   True\n",
       "21          160              120                90      30        0.00010   0.369263  0.838594  0.359941  0.846597  0:05:47    1   True\n",
       "22          120              170                90      20        0.01000   0.593047  0.720147  0.593732  0.719444  0:03:39    1   True\n",
       "23           40               70                20      60        0.01000   0.481815      0.79  0.503438    0.7525  0:01:15    1   True\n",
       "24          160              170                50     100        0.10000    4.60906  0.714044    4.5453     0.718  0:20:24    1   True\n",
       "25          180              110                60      10        0.10000    4.63599  0.712374   4.53844  0.718426  0:01:44    1   True\n",
       "26          200               20               100      50        0.10000    4.66619    0.7105   4.60252   0.71445  0:06:20    1   True\n",
       "27           60               80                30      90        0.00001   0.401561  0.824792  0.387844     0.835  0:03:24    1   True\n",
       "28           80              120                30     100        0.01000   0.602757  0.709479  0.592917  0.720833  0:07:09    1   True\n",
       "29           80               70                50      20        0.00001   0.485893  0.765714  0.457634   0.79175  0:01:06    1   True\n",
       "..          ...              ...               ...     ...            ...        ...       ...       ...       ...      ...  ...    ...\n",
       "970         140              160                70      70        0.01000   0.601346  0.711027  0.597481  0.715408  0:12:40    1   True\n",
       "971          60              150                60      70        0.00001   0.403532  0.826222  0.395664  0.830907  0:05:02    1   True\n",
       "972         180              170                90      30        0.01000   0.412687  0.825229  0.418053  0.828744  0:07:50    1   True\n",
       "973         200               40                60      90        0.00001   0.405146     0.826  0.416881  0.818917  0:09:10    1   True\n",
       "974         100               20                60      40        0.10000    4.50501    0.7205   4.59366     0.715  0:01:36    1   True\n",
       "975          40               40                40      90        0.00001   0.432218    0.8075  0.413683  0.819375  0:01:30    1   True\n",
       "976          80              130                60      70        0.01000   0.600507  0.712089  0.589967  0.724124  0:06:10    1   True\n",
       "977         180              160               100      70        0.00010   0.326822  0.863472  0.333745  0.860016  0:18:48    1   True\n",
       "978         160               30               100      80        0.10000    4.51307      0.72   4.58963   0.71525  0:08:48    1   True\n",
       "979          80               60                80      40        0.01000   0.596477  0.717083  0.601323  0.711045  0:02:31    1   True\n",
       "980         140              120                60     100        0.00100   0.310391  0.870357  0.323439   0.86698  0:14:44    1   True\n",
       "981          40               60                60      30        0.00001   0.454561  0.787917  0.466094  0.785833  0:00:51    1   True\n",
       "982         120              120                80     100        0.00100   0.312476  0.868472  0.311568  0.867812  0:13:52    1   True\n",
       "983          60              170                80      40        0.00100   0.361246  0.844902  0.375628      0.85  0:03:42    1   True\n",
       "984         100              200                70      20        0.00100    0.34627    0.8521  0.363982  0.859753  0:03:20    1   True\n",
       "985          20               50                90      80        0.01000    4.85155     0.699   5.04138  0.687222  0:01:27    1   True\n",
       "986         200               60                90      40        0.10000    4.58963   0.71525   4.55157  0.717611  0:06:46    1   True\n",
       "987         140               90                60      30        0.10000    4.56807  0.716587   4.70014  0.708394  0:03:41    1   True\n",
       "988         140              140                80      70        0.01000   0.600436   0.71199  0.589267  0.723945  0:13:03    1   True\n",
       "989         140               70                90      80        0.01000   0.429227  0.812041  0.445243  0.813561  0:10:47    1   True\n",
       "990          80              100                60      30        0.01000   0.592386   0.72125  0.600429  0.712083  0:02:24    1   True\n",
       "991          40              190                10      70        0.10000    4.53003  0.718947   5.18082  0.678571  0:03:56    1   True\n",
       "992          80              110                80      80        0.00010   0.342689  0.857045  0.357372  0.852188  0:07:47    1   True\n",
       "993         200              140               100      40        0.00100   0.319671  0.865321  0.343955   0.86215  0:12:03    1   True\n",
       "994         140              180                50      50        0.00100   0.320372  0.864048  0.315853  0.874857  0:10:14    1   True\n",
       "995         200              170                90      50        0.00100   0.321289  0.862441  0.328234   0.86475  0:16:18    1   True\n",
       "996         160              140                10      80        0.00100   0.309834  0.872634  0.339324  0.871875  0:12:31    1   True\n",
       "997         160              170               100      80        0.10000    4.63217   0.71261    4.5443  0.718063  0:22:27    1   True\n",
       "998         180              190               100      70        0.00100   0.297779  0.875322  0.325952  0.869482  0:23:21    1   True\n",
       "999         140               40                10      50        0.00100    0.36047  0.842679   0.37984  0.843571  0:02:08    1   True\n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate\n",
    "train_generation(model=model_7, image_size=(50,50), gen=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.865789</td>\n",
       "      <td>0.292571</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0:11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>140</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.320372</td>\n",
       "      <td>0.864048</td>\n",
       "      <td>0.315853</td>\n",
       "      <td>0.874857</td>\n",
       "      <td>0:10:14</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.315224</td>\n",
       "      <td>0.867411</td>\n",
       "      <td>0.319296</td>\n",
       "      <td>0.874613</td>\n",
       "      <td>0:13:23</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.326009</td>\n",
       "      <td>0.861417</td>\n",
       "      <td>0.316879</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0:19:31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.298031</td>\n",
       "      <td>0.874026</td>\n",
       "      <td>0.304660</td>\n",
       "      <td>0.873125</td>\n",
       "      <td>0:39:18</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.312412</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.306135</td>\n",
       "      <td>0.872778</td>\n",
       "      <td>0:34:51</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>80</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.313608</td>\n",
       "      <td>0.866063</td>\n",
       "      <td>0.324402</td>\n",
       "      <td>0.872083</td>\n",
       "      <td>0:21:46</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.309834</td>\n",
       "      <td>0.872634</td>\n",
       "      <td>0.339324</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0:12:31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>0.311656</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>0:24:30</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>180</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.312375</td>\n",
       "      <td>0.871169</td>\n",
       "      <td>0:37:29</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "653         100              190                10      90         0.0001    0.317655   0.865789  0.292571  0.894000  0:11:41    1   True\n",
       "994         140              180                50      50         0.0010    0.320372   0.864048  0.315853  0.874857  0:10:14    1   True\n",
       "693         140              160                10      80         0.0010    0.315224   0.867411  0.319296  0.874613  0:13:23    1   True\n",
       "605          60              200                30      80         0.0010    0.326009   0.861417  0.316879  0.873889  0:19:31    1   True\n",
       "760         200              190                40     100         0.0001    0.298031   0.874026  0.304660  0.873125  0:39:18    1   True\n",
       "963         140              200                90      90         0.0001    0.312412   0.867250  0.306135  0.872778  0:34:51    1   True\n",
       "548          80              200                30     100         0.0010    0.313608   0.866063  0.324402  0.872083  0:21:46    1   True\n",
       "996         160              140                10      80         0.0010    0.309834   0.872634  0.339324  0.871875  0:12:31    1   True\n",
       "276         100              170                50      80         0.0001    0.335177   0.857294  0.311656  0.871600  0:24:30    1   True\n",
       "215         180              130                90     100         0.0010    0.304454   0.868462  0.312375  0.871169  0:37:29    1   True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep top performing algorithms\n",
    "df_fittest = select_fittest(top_percent=10)\n",
    "df_fittest.nlargest(10, 'val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd GENERATION ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(276, 936),\n",
       " (258, 46),\n",
       " (170, 839),\n",
       " (968, 246),\n",
       " (242, 367),\n",
       " (521, 713),\n",
       " (853, 302),\n",
       " (630, 557),\n",
       " (114, 714),\n",
       " (605, 980),\n",
       " (653, 996),\n",
       " (626, 363),\n",
       " (256, 591),\n",
       " (961, 15),\n",
       " (652, 480),\n",
       " (215, 760),\n",
       " (574, 795),\n",
       " (90, 454),\n",
       " (93, 88),\n",
       " (10, 326),\n",
       " (553, 142),\n",
       " (418, 266),\n",
       " (430, 924),\n",
       " (444, 693),\n",
       " (781, 496),\n",
       " (688, 813),\n",
       " (994, 888),\n",
       " (982, 892),\n",
       " (451, 132),\n",
       " (638, 167),\n",
       " (95, 269),\n",
       " (904, 442),\n",
       " (216, 685),\n",
       " (355, 158),\n",
       " (76, 706),\n",
       " (358, 229),\n",
       " (801, 548),\n",
       " (96, 768),\n",
       " (998, 960),\n",
       " (716, 632),\n",
       " (372, 977),\n",
       " (137, 724),\n",
       " (832, 176),\n",
       " (887, 775),\n",
       " (787, 174),\n",
       " (275, 938),\n",
       " (995, 814),\n",
       " (202, 953),\n",
       " (437, 163),\n",
       " (963, 923)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = create_parents()\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read generations file\n",
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "    \n",
    "for pair in parents:\n",
    "    df_parents = df_generations.iloc[[pair[0], pair[1]]]\n",
    "    \n",
    "    # make children\n",
    "    df_child_1 = create_child(df_parents, generation=2)\n",
    "    df_child_2 = create_child(df_parents, generation=2)\n",
    "    df_child_3 = create_child(df_parents, generation=2)\n",
    "    df_child_4 = create_child(df_parents, generation=2)\n",
    "    df_child_5 = create_child(df_parents, generation=2, mutate=True)\n",
    "\n",
    "    df_children = df_child_1.append([df_child_2, df_child_3, df_child_4, df_child_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.312412</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.306135</td>\n",
       "      <td>0.872778</td>\n",
       "      <td>0:34:51</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.334619</td>\n",
       "      <td>0.858523</td>\n",
       "      <td>0.333084</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0:07:29</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "963         140              200                90      90         0.0001    0.312412   0.867250  0.306135  0.872778  0:34:51    1   True\n",
       "923          80              110                50      90         0.0001    0.334619   0.858523  0.333084  0.854750  0:07:29    1   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of parents\n",
    "df_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.1000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc val_loss val_acc time  gen  alive\n",
       "0          80              200                90      90         0.0001                                               2   True\n",
       "1         140              200                50      90         0.0001                                               2   True\n",
       "2          80              110                50      90         0.0001                                               2   True\n",
       "3          80              110                50      90         0.0001                                               2   True\n",
       "4         140              200                90      90         0.1000                                               2   True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of children\n",
    "df_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 1161 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 25s 141ms/step - loss: 0.5473 - acc: 0.7303 - val_loss: 0.4417 - val_acc: 0.8043\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 0.4308 - acc: 0.8120 - val_loss: 0.4197 - val_acc: 0.8163\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 19s 105ms/step - loss: 0.4121 - acc: 0.8210 - val_loss: 0.4115 - val_acc: 0.8212\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 18s 98ms/step - loss: 0.4184 - acc: 0.8203 - val_loss: 0.4105 - val_acc: 0.8213\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 18s 99ms/step - loss: 0.4115 - acc: 0.8227 - val_loss: 0.4025 - val_acc: 0.8242\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 19s 105ms/step - loss: 0.4094 - acc: 0.8243 - val_loss: 0.4080 - val_acc: 0.8245\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 18s 100ms/step - loss: 0.4065 - acc: 0.8235 - val_loss: 0.4050 - val_acc: 0.8246\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 18s 99ms/step - loss: 0.4053 - acc: 0.8263 - val_loss: 0.4135 - val_acc: 0.8159\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 17s 92ms/step - loss: 0.3996 - acc: 0.8289 - val_loss: 0.3937 - val_acc: 0.8309\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3995 - acc: 0.8290 - val_loss: 0.4052 - val_acc: 0.8239\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3951 - acc: 0.8309 - val_loss: 0.3942 - val_acc: 0.8272\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3908 - acc: 0.8306 - val_loss: 0.3950 - val_acc: 0.8329\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3944 - acc: 0.8304 - val_loss: 0.3986 - val_acc: 0.8289\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3929 - acc: 0.8297 - val_loss: 0.3830 - val_acc: 0.8336\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3937 - acc: 0.8306 - val_loss: 0.4018 - val_acc: 0.8199\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3840 - acc: 0.8327 - val_loss: 0.3752 - val_acc: 0.8413\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3793 - acc: 0.8366 - val_loss: 0.3798 - val_acc: 0.8340\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3858 - acc: 0.8332 - val_loss: 0.3917 - val_acc: 0.8342\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3843 - acc: 0.8331 - val_loss: 0.3785 - val_acc: 0.8323\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3762 - acc: 0.8382 - val_loss: 0.3837 - val_acc: 0.8377\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3735 - acc: 0.8405 - val_loss: 0.3749 - val_acc: 0.8385\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3770 - acc: 0.8378 - val_loss: 0.3686 - val_acc: 0.8394\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3707 - acc: 0.8395 - val_loss: 0.3683 - val_acc: 0.8372\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3645 - acc: 0.8440 - val_loss: 0.3724 - val_acc: 0.8377\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3697 - acc: 0.8398 - val_loss: 0.3771 - val_acc: 0.8343\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3686 - acc: 0.8424 - val_loss: 0.3650 - val_acc: 0.8442\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3621 - acc: 0.8448 - val_loss: 0.3593 - val_acc: 0.8483\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3616 - acc: 0.8446 - val_loss: 0.3678 - val_acc: 0.8403\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3576 - acc: 0.8470 - val_loss: 0.3639 - val_acc: 0.8453\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3589 - acc: 0.8459 - val_loss: 0.3600 - val_acc: 0.8422\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3618 - acc: 0.8444 - val_loss: 0.3507 - val_acc: 0.8531\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3541 - acc: 0.8506 - val_loss: 0.3661 - val_acc: 0.8450\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3602 - acc: 0.8455 - val_loss: 0.3593 - val_acc: 0.8501\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3589 - acc: 0.8455 - val_loss: 0.3460 - val_acc: 0.8505\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3505 - acc: 0.8523 - val_loss: 0.3518 - val_acc: 0.8472\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3479 - acc: 0.8504 - val_loss: 0.3494 - val_acc: 0.8515\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3478 - acc: 0.8527 - val_loss: 0.3466 - val_acc: 0.8564\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3428 - acc: 0.8528 - val_loss: 0.3581 - val_acc: 0.8422\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3499 - acc: 0.8494 - val_loss: 0.3397 - val_acc: 0.8585\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3468 - acc: 0.8524 - val_loss: 0.3423 - val_acc: 0.8533\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3473 - acc: 0.8530 - val_loss: 0.3331 - val_acc: 0.8544\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3446 - acc: 0.8544 - val_loss: 0.3453 - val_acc: 0.8578\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3506 - acc: 0.8481 - val_loss: 0.3538 - val_acc: 0.8463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3481 - acc: 0.8529 - val_loss: 0.3345 - val_acc: 0.8580\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 13s 71ms/step - loss: 0.3447 - acc: 0.8512 - val_loss: 0.3444 - val_acc: 0.8583\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3367 - acc: 0.8560 - val_loss: 0.3822 - val_acc: 0.8411\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3408 - acc: 0.8559 - val_loss: 0.3451 - val_acc: 0.8552\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3420 - acc: 0.8549 - val_loss: 0.3609 - val_acc: 0.8470\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3421 - acc: 0.8543 - val_loss: 0.3676 - val_acc: 0.8389\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3415 - acc: 0.8553 - val_loss: 0.3462 - val_acc: 0.8485\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3373 - acc: 0.8552 - val_loss: 0.3358 - val_acc: 0.8596\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3372 - acc: 0.8567 - val_loss: 0.3424 - val_acc: 0.8552\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3398 - acc: 0.8552 - val_loss: 0.3448 - val_acc: 0.8557\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3322 - acc: 0.8606 - val_loss: 0.3249 - val_acc: 0.8638\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3333 - acc: 0.8575 - val_loss: 0.3301 - val_acc: 0.8614\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3278 - acc: 0.8614 - val_loss: 0.3401 - val_acc: 0.8543\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3385 - acc: 0.8560 - val_loss: 0.3454 - val_acc: 0.8529\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3341 - acc: 0.8578 - val_loss: 0.3332 - val_acc: 0.8587\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3356 - acc: 0.8576 - val_loss: 0.3364 - val_acc: 0.8571\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3299 - acc: 0.8613 - val_loss: 0.3384 - val_acc: 0.8570\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3337 - acc: 0.8583 - val_loss: 0.3280 - val_acc: 0.8593\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3367 - acc: 0.8551 - val_loss: 0.3335 - val_acc: 0.8602\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3299 - acc: 0.8592 - val_loss: 0.3289 - val_acc: 0.8601\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3272 - acc: 0.8585 - val_loss: 0.3206 - val_acc: 0.8672\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3280 - acc: 0.8603 - val_loss: 0.3469 - val_acc: 0.8523\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3201 - acc: 0.8648 - val_loss: 0.3302 - val_acc: 0.8615\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3324 - acc: 0.8600 - val_loss: 0.3237 - val_acc: 0.8642\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3307 - acc: 0.8581 - val_loss: 0.3230 - val_acc: 0.8623\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3284 - acc: 0.8616 - val_loss: 0.3264 - val_acc: 0.8625\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3213 - acc: 0.8632 - val_loss: 0.3204 - val_acc: 0.8668\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3224 - acc: 0.8642 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3192 - acc: 0.8658 - val_loss: 0.3269 - val_acc: 0.8638\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3246 - acc: 0.8636 - val_loss: 0.3206 - val_acc: 0.8608\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3221 - acc: 0.8613 - val_loss: 0.3251 - val_acc: 0.8634\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3267 - acc: 0.8616 - val_loss: 0.3429 - val_acc: 0.8580\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3214 - acc: 0.8623 - val_loss: 0.3342 - val_acc: 0.8598\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3192 - acc: 0.8645 - val_loss: 0.3243 - val_acc: 0.8639\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3200 - acc: 0.8665 - val_loss: 0.3288 - val_acc: 0.8610\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3300 - acc: 0.8607 - val_loss: 0.3093 - val_acc: 0.8683\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3179 - acc: 0.8654 - val_loss: 0.3195 - val_acc: 0.8662\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3215 - acc: 0.8627 - val_loss: 0.3234 - val_acc: 0.8628\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3245 - acc: 0.8647 - val_loss: 0.3310 - val_acc: 0.8650\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3131 - acc: 0.8660 - val_loss: 0.3162 - val_acc: 0.8654\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3160 - acc: 0.8679 - val_loss: 0.3259 - val_acc: 0.8580\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3112 - acc: 0.8664 - val_loss: 0.3261 - val_acc: 0.8665\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3232 - acc: 0.8602 - val_loss: 0.3381 - val_acc: 0.8556\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3227 - acc: 0.8621 - val_loss: 0.3147 - val_acc: 0.8677\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3205 - acc: 0.8637 - val_loss: 0.3242 - val_acc: 0.8647\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3142 - acc: 0.8654 - val_loss: 0.3131 - val_acc: 0.8662\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3137 - acc: 0.8645 - val_loss: 0.3252 - val_acc: 0.8646\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 12s 67ms/step - loss: 0.3177 - acc: 0.8656 - val_loss: 0.3138 - val_acc: 0.8660\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3102 - acc: 0.8682 - val_loss: 0.3198 - val_acc: 0.8648\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3155 - acc: 0.8654 - val_loss: 0.3179 - val_acc: 0.8646\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3165 - acc: 0.8674 - val_loss: 0.3209 - val_acc: 0.8621\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3166 - acc: 0.8667 - val_loss: 0.3156 - val_acc: 0.8683\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3133 - acc: 0.8662 - val_loss: 0.3116 - val_acc: 0.8671\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3108 - acc: 0.8704 - val_loss: 0.3069 - val_acc: 0.8695\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3120 - acc: 0.8671 - val_loss: 0.3119 - val_acc: 0.8690\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3102 - acc: 0.8697 - val_loss: 0.3447 - val_acc: 0.8550\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3089 - acc: 0.8701 - val_loss: 0.3327 - val_acc: 0.8558\n",
      "\n",
      "Training process completed in: 0 h 21 m 5 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1160.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1162 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.5761 - acc: 0.7180 - val_loss: 0.5332 - val_acc: 0.7213\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.4450 - acc: 0.7981 - val_loss: 0.4178 - val_acc: 0.8153\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.4120 - acc: 0.8236 - val_loss: 0.4205 - val_acc: 0.8191\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.4120 - acc: 0.8233 - val_loss: 0.4090 - val_acc: 0.8293\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.4047 - acc: 0.8257 - val_loss: 0.3949 - val_acc: 0.8290\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4038 - acc: 0.8290 - val_loss: 0.4056 - val_acc: 0.8223\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3932 - acc: 0.8306 - val_loss: 0.3811 - val_acc: 0.8364\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3891 - acc: 0.8331 - val_loss: 0.3959 - val_acc: 0.8282\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3949 - acc: 0.8308 - val_loss: 0.4100 - val_acc: 0.8206\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3934 - acc: 0.8326 - val_loss: 0.3820 - val_acc: 0.8366\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3885 - acc: 0.8352 - val_loss: 0.3906 - val_acc: 0.8332\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3857 - acc: 0.8332 - val_loss: 0.3955 - val_acc: 0.8270\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3820 - acc: 0.8358 - val_loss: 0.3830 - val_acc: 0.8342\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 14s 80ms/step - loss: 0.3907 - acc: 0.8325 - val_loss: 0.4043 - val_acc: 0.8294\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3793 - acc: 0.8387 - val_loss: 0.3778 - val_acc: 0.8396\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3761 - acc: 0.8399 - val_loss: 0.3733 - val_acc: 0.8426\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 14s 80ms/step - loss: 0.3742 - acc: 0.8398 - val_loss: 0.4172 - val_acc: 0.8218\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3833 - acc: 0.8354 - val_loss: 0.3771 - val_acc: 0.8400\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3742 - acc: 0.8400 - val_loss: 0.3740 - val_acc: 0.8400\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3734 - acc: 0.8390 - val_loss: 0.4057 - val_acc: 0.8239\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3734 - acc: 0.8393 - val_loss: 0.3719 - val_acc: 0.8384\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3686 - acc: 0.8412 - val_loss: 0.3596 - val_acc: 0.8479\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 14s 80ms/step - loss: 0.3651 - acc: 0.8419 - val_loss: 0.3897 - val_acc: 0.8323\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3594 - acc: 0.8453 - val_loss: 0.3621 - val_acc: 0.8431\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3654 - acc: 0.8420 - val_loss: 0.3613 - val_acc: 0.8461\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3635 - acc: 0.8449 - val_loss: 0.3543 - val_acc: 0.8491\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3622 - acc: 0.8448 - val_loss: 0.3877 - val_acc: 0.8398\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3540 - acc: 0.8475 - val_loss: 0.3620 - val_acc: 0.8448\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3554 - acc: 0.8459 - val_loss: 0.3525 - val_acc: 0.8519\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3537 - acc: 0.8498 - val_loss: 0.3491 - val_acc: 0.8548\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3475 - acc: 0.8507 - val_loss: 0.3580 - val_acc: 0.8467\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3517 - acc: 0.8506 - val_loss: 0.3520 - val_acc: 0.8488\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3556 - acc: 0.8490 - val_loss: 0.3564 - val_acc: 0.8529\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3551 - acc: 0.8479 - val_loss: 0.3497 - val_acc: 0.8533\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3516 - acc: 0.8506 - val_loss: 0.3872 - val_acc: 0.8275\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3526 - acc: 0.8494 - val_loss: 0.3429 - val_acc: 0.8599\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3468 - acc: 0.8513 - val_loss: 0.3439 - val_acc: 0.8528\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3478 - acc: 0.8531 - val_loss: 0.3445 - val_acc: 0.8559\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3461 - acc: 0.8522 - val_loss: 0.3673 - val_acc: 0.8421\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3419 - acc: 0.8559 - val_loss: 0.3651 - val_acc: 0.8394\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3457 - acc: 0.8537 - val_loss: 0.3394 - val_acc: 0.8575\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3463 - acc: 0.8523 - val_loss: 0.3477 - val_acc: 0.8518\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3403 - acc: 0.8565 - val_loss: 0.3419 - val_acc: 0.8567\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3426 - acc: 0.8541 - val_loss: 0.3428 - val_acc: 0.8549\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3421 - acc: 0.8551 - val_loss: 0.3648 - val_acc: 0.8346\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 14s 80ms/step - loss: 0.3390 - acc: 0.8561 - val_loss: 0.3441 - val_acc: 0.8557\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3406 - acc: 0.8560 - val_loss: 0.3368 - val_acc: 0.8556\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3362 - acc: 0.8576 - val_loss: 0.3341 - val_acc: 0.8573\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3372 - acc: 0.8554 - val_loss: 0.3678 - val_acc: 0.8338\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3375 - acc: 0.8568 - val_loss: 0.3390 - val_acc: 0.8545\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3439 - acc: 0.8528 - val_loss: 0.3432 - val_acc: 0.8573\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3315 - acc: 0.8591 - val_loss: 0.3332 - val_acc: 0.8591\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3422 - acc: 0.8550 - val_loss: 0.3399 - val_acc: 0.8566\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3379 - acc: 0.8556 - val_loss: 0.3343 - val_acc: 0.8603\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3288 - acc: 0.8606 - val_loss: 0.3389 - val_acc: 0.8568\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3359 - acc: 0.8572 - val_loss: 0.3317 - val_acc: 0.8588\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3398 - acc: 0.8527 - val_loss: 0.3335 - val_acc: 0.8588\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3308 - acc: 0.8591 - val_loss: 0.3319 - val_acc: 0.8567\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3288 - acc: 0.8592 - val_loss: 0.3283 - val_acc: 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3271 - acc: 0.8633 - val_loss: 0.3419 - val_acc: 0.8581\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3363 - acc: 0.8584 - val_loss: 0.3213 - val_acc: 0.8652\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3322 - acc: 0.8589 - val_loss: 0.3362 - val_acc: 0.8554\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3293 - acc: 0.8588 - val_loss: 0.3515 - val_acc: 0.8468\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3334 - acc: 0.8571 - val_loss: 0.3227 - val_acc: 0.8664\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3245 - acc: 0.8633 - val_loss: 0.3187 - val_acc: 0.8659\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3273 - acc: 0.8612 - val_loss: 0.3322 - val_acc: 0.8667\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3250 - acc: 0.8606 - val_loss: 0.3246 - val_acc: 0.8636\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3282 - acc: 0.8602 - val_loss: 0.3349 - val_acc: 0.8568\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3288 - acc: 0.8605 - val_loss: 0.3514 - val_acc: 0.8478\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3251 - acc: 0.8631 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3245 - acc: 0.8603 - val_loss: 0.3177 - val_acc: 0.8617\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3228 - acc: 0.8635 - val_loss: 0.3357 - val_acc: 0.8579\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 14s 75ms/step - loss: 0.3259 - acc: 0.8595 - val_loss: 0.3276 - val_acc: 0.8632\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3219 - acc: 0.8622 - val_loss: 0.3234 - val_acc: 0.8654\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3275 - acc: 0.8604 - val_loss: 0.3319 - val_acc: 0.8598\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3207 - acc: 0.8643 - val_loss: 0.3211 - val_acc: 0.8637\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3244 - acc: 0.8627 - val_loss: 0.3192 - val_acc: 0.8651\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3181 - acc: 0.8658 - val_loss: 0.3259 - val_acc: 0.8677\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3255 - acc: 0.8616 - val_loss: 0.3190 - val_acc: 0.8642\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3172 - acc: 0.8642 - val_loss: 0.3236 - val_acc: 0.8602\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3217 - acc: 0.8616 - val_loss: 0.3134 - val_acc: 0.8644\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3198 - acc: 0.8636 - val_loss: 0.3211 - val_acc: 0.8636\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3172 - acc: 0.8656 - val_loss: 0.3150 - val_acc: 0.8670\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3221 - acc: 0.8619 - val_loss: 0.3371 - val_acc: 0.8572\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3098 - acc: 0.8675 - val_loss: 0.3176 - val_acc: 0.8642\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3146 - acc: 0.8672 - val_loss: 0.3257 - val_acc: 0.8592\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3205 - acc: 0.8639 - val_loss: 0.3248 - val_acc: 0.8610\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3170 - acc: 0.8664 - val_loss: 0.3208 - val_acc: 0.8641\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3142 - acc: 0.8663 - val_loss: 0.3273 - val_acc: 0.8581\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3135 - acc: 0.8666 - val_loss: 0.3255 - val_acc: 0.8613\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3125 - acc: 0.8673 - val_loss: 0.3205 - val_acc: 0.8637\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3135 - acc: 0.8667 - val_loss: 0.3261 - val_acc: 0.8644\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3167 - acc: 0.8666 - val_loss: 0.3406 - val_acc: 0.8487\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3146 - acc: 0.8665 - val_loss: 0.3197 - val_acc: 0.8649\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.3115 - acc: 0.8673 - val_loss: 0.3168 - val_acc: 0.8659\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.3139 - acc: 0.8663 - val_loss: 0.3166 - val_acc: 0.8604\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 14s 79ms/step - loss: 0.3106 - acc: 0.8685 - val_loss: 0.3134 - val_acc: 0.8643\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3115 - acc: 0.8672 - val_loss: 0.3166 - val_acc: 0.8657\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3112 - acc: 0.8675 - val_loss: 0.3215 - val_acc: 0.8641\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 14s 78ms/step - loss: 0.3127 - acc: 0.8682 - val_loss: 0.3160 - val_acc: 0.8650\n",
      "\n",
      "Training process completed in: 0 h 23 m 18 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1161.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1163 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.1\n",
      "Epochs: 50\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 11s 72ms/step - loss: 4.6226 - acc: 0.7105 - val_loss: 4.6858 - val_acc: 0.7093\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5653 - acc: 0.7168 - val_loss: 4.5887 - val_acc: 0.7153\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5422 - acc: 0.7182 - val_loss: 4.4403 - val_acc: 0.7245\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5215 - acc: 0.7195 - val_loss: 4.6117 - val_acc: 0.7139\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5484 - acc: 0.7178 - val_loss: 4.6150 - val_acc: 0.7137\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5714 - acc: 0.7164 - val_loss: 4.4586 - val_acc: 0.7234\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6059 - acc: 0.7142 - val_loss: 4.5229 - val_acc: 0.7194\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6059 - acc: 0.7142 - val_loss: 4.6512 - val_acc: 0.7114\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 4.5676 - acc: 0.7166 - val_loss: 4.6532 - val_acc: 0.7113\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.6044 - acc: 0.7143 - val_loss: 4.5739 - val_acc: 0.7162\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5361 - acc: 0.7186 - val_loss: 4.5904 - val_acc: 0.7152\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5430 - acc: 0.7181 - val_loss: 4.5318 - val_acc: 0.7188\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6351 - acc: 0.7124 - val_loss: 4.6578 - val_acc: 0.7110\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5645 - acc: 0.7168 - val_loss: 4.5016 - val_acc: 0.7207\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5016 - acc: 0.7207 - val_loss: 4.6232 - val_acc: 0.7132\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 10s 67ms/step - loss: 4.4655 - acc: 0.7230 - val_loss: 4.5065 - val_acc: 0.7204\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 10s 67ms/step - loss: 4.6190 - acc: 0.7134 - val_loss: 4.5673 - val_acc: 0.7166\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 4.6212 - acc: 0.7133 - val_loss: 4.6399 - val_acc: 0.7121\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 4.5814 - acc: 0.7158 - val_loss: 4.5262 - val_acc: 0.7192\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6543 - acc: 0.7112 - val_loss: 4.5384 - val_acc: 0.7184\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5929 - acc: 0.7150 - val_loss: 4.6035 - val_acc: 0.7144\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5736 - acc: 0.7162 - val_loss: 4.6331 - val_acc: 0.7126\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6482 - acc: 0.7116 - val_loss: 4.5218 - val_acc: 0.7195\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5537 - acc: 0.7175 - val_loss: 4.6150 - val_acc: 0.7137\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5200 - acc: 0.7196 - val_loss: 4.5460 - val_acc: 0.7180\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6044 - acc: 0.7143 - val_loss: 4.5933 - val_acc: 0.7150\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5745 - acc: 0.7162 - val_loss: 4.6085 - val_acc: 0.7141\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5852 - acc: 0.7155 - val_loss: 4.5081 - val_acc: 0.7203\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5737 - acc: 0.7162 - val_loss: 4.5334 - val_acc: 0.7187\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.4893 - acc: 0.7215 - val_loss: 4.6150 - val_acc: 0.7137\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6259 - acc: 0.7130 - val_loss: 4.6068 - val_acc: 0.7142\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5914 - acc: 0.7151 - val_loss: 4.4386 - val_acc: 0.7246\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5223 - acc: 0.7194 - val_loss: 4.7137 - val_acc: 0.7076\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5526 - acc: 0.7175 - val_loss: 4.5246 - val_acc: 0.7193\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6267 - acc: 0.7130 - val_loss: 4.5301 - val_acc: 0.7189\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.6190 - acc: 0.7134 - val_loss: 4.5575 - val_acc: 0.7172\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.6105 - acc: 0.7140 - val_loss: 4.6332 - val_acc: 0.7125\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5522 - acc: 0.7176 - val_loss: 4.6381 - val_acc: 0.7122\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6343 - acc: 0.7125 - val_loss: 4.5394 - val_acc: 0.7184\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5852 - acc: 0.7155 - val_loss: 4.5567 - val_acc: 0.7173\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 10s 67ms/step - loss: 4.5085 - acc: 0.7203 - val_loss: 4.5706 - val_acc: 0.7164\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 10s 67ms/step - loss: 4.5399 - acc: 0.7183 - val_loss: 4.5344 - val_acc: 0.7187\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5491 - acc: 0.7178 - val_loss: 4.6365 - val_acc: 0.7123\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6505 - acc: 0.7115 - val_loss: 4.6200 - val_acc: 0.7134\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5207 - acc: 0.7195 - val_loss: 4.5164 - val_acc: 0.7198\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.5967 - acc: 0.7148 - val_loss: 4.5817 - val_acc: 0.7157\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.5238 - acc: 0.7193 - val_loss: 4.5525 - val_acc: 0.7176\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.4762 - acc: 0.7223 - val_loss: 4.6002 - val_acc: 0.7146\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.6048 - acc: 0.7143 - val_loss: 4.5683 - val_acc: 0.7166\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 4.6128 - acc: 0.7138 - val_loss: 4.5772 - val_acc: 0.7160\n",
      "\n",
      "Training process completed in: 0 h 8 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1162.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1164 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.5017 - acc: 0.7670 - val_loss: 0.4201 - val_acc: 0.8206\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4457 - acc: 0.8114 - val_loss: 0.4152 - val_acc: 0.8289\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4184 - acc: 0.8238 - val_loss: 0.4230 - val_acc: 0.8283\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4238 - acc: 0.8189 - val_loss: 0.4310 - val_acc: 0.8006\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4061 - acc: 0.8288 - val_loss: 0.3998 - val_acc: 0.8239\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4052 - acc: 0.8284 - val_loss: 0.3888 - val_acc: 0.8361\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4092 - acc: 0.8245 - val_loss: 0.4335 - val_acc: 0.8189\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3955 - acc: 0.8312 - val_loss: 0.3973 - val_acc: 0.8178\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3951 - acc: 0.8306 - val_loss: 0.3792 - val_acc: 0.8300\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3936 - acc: 0.8288 - val_loss: 0.4115 - val_acc: 0.8372\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3993 - acc: 0.8304 - val_loss: 0.4385 - val_acc: 0.8206\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3883 - acc: 0.8351 - val_loss: 0.4199 - val_acc: 0.8056\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3855 - acc: 0.8337 - val_loss: 0.3867 - val_acc: 0.8439\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3825 - acc: 0.8380 - val_loss: 0.3627 - val_acc: 0.8450\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3844 - acc: 0.8354 - val_loss: 0.4012 - val_acc: 0.8367\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3862 - acc: 0.8338 - val_loss: 0.3895 - val_acc: 0.8442\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3793 - acc: 0.8376 - val_loss: 0.4099 - val_acc: 0.8289\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3705 - acc: 0.8400 - val_loss: 0.4153 - val_acc: 0.8344\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3809 - acc: 0.8368 - val_loss: 0.3733 - val_acc: 0.8517\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3808 - acc: 0.8380 - val_loss: 0.3590 - val_acc: 0.8517\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3667 - acc: 0.8443 - val_loss: 0.4143 - val_acc: 0.8328\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3682 - acc: 0.8447 - val_loss: 0.3733 - val_acc: 0.8411\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3799 - acc: 0.8393 - val_loss: 0.3801 - val_acc: 0.8467\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3652 - acc: 0.8431 - val_loss: 0.3927 - val_acc: 0.8356\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3655 - acc: 0.8458 - val_loss: 0.3489 - val_acc: 0.8500\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3576 - acc: 0.8494 - val_loss: 0.3819 - val_acc: 0.8528\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3582 - acc: 0.8482 - val_loss: 0.3857 - val_acc: 0.8311\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3559 - acc: 0.8490 - val_loss: 0.3470 - val_acc: 0.8511\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3612 - acc: 0.8479 - val_loss: 0.4086 - val_acc: 0.8261\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3534 - acc: 0.8513 - val_loss: 0.3897 - val_acc: 0.8456\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3625 - acc: 0.8488 - val_loss: 0.3833 - val_acc: 0.8482\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3541 - acc: 0.8510 - val_loss: 0.3473 - val_acc: 0.8639\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3563 - acc: 0.8516 - val_loss: 0.3697 - val_acc: 0.8506\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3675 - acc: 0.8428 - val_loss: 0.3700 - val_acc: 0.8572\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3482 - acc: 0.8532 - val_loss: 0.3834 - val_acc: 0.8311\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3616 - acc: 0.8426 - val_loss: 0.3683 - val_acc: 0.8411\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3437 - acc: 0.8542 - val_loss: 0.3634 - val_acc: 0.8511\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3479 - acc: 0.8536 - val_loss: 0.3504 - val_acc: 0.8578\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3517 - acc: 0.8501 - val_loss: 0.3585 - val_acc: 0.8550\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3487 - acc: 0.8532 - val_loss: 0.3630 - val_acc: 0.8472\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3507 - acc: 0.8500 - val_loss: 0.3474 - val_acc: 0.8456\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3452 - acc: 0.8523 - val_loss: 0.3607 - val_acc: 0.8539\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3356 - acc: 0.8552 - val_loss: 0.3610 - val_acc: 0.8511\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3432 - acc: 0.8538 - val_loss: 0.3546 - val_acc: 0.8583\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3405 - acc: 0.8579 - val_loss: 0.3799 - val_acc: 0.8378\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3543 - acc: 0.8553 - val_loss: 0.3796 - val_acc: 0.8456\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3361 - acc: 0.8613 - val_loss: 0.3283 - val_acc: 0.8753\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3356 - acc: 0.8573 - val_loss: 0.3338 - val_acc: 0.8600\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3365 - acc: 0.8554 - val_loss: 0.3838 - val_acc: 0.8311\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3456 - acc: 0.8548 - val_loss: 0.3799 - val_acc: 0.8494\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3454 - acc: 0.8546 - val_loss: 0.3329 - val_acc: 0.8783\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3452 - acc: 0.8521 - val_loss: 0.3321 - val_acc: 0.8583\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3289 - acc: 0.8627 - val_loss: 0.3256 - val_acc: 0.8706\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3442 - acc: 0.8513 - val_loss: 0.3522 - val_acc: 0.8606\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3424 - acc: 0.8532 - val_loss: 0.3421 - val_acc: 0.8572\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3242 - acc: 0.8594 - val_loss: 0.3250 - val_acc: 0.8656\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3414 - acc: 0.8567 - val_loss: 0.3542 - val_acc: 0.8522\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3397 - acc: 0.8554 - val_loss: 0.3461 - val_acc: 0.8539\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3403 - acc: 0.8539 - val_loss: 0.3578 - val_acc: 0.8489\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3310 - acc: 0.8603 - val_loss: 0.3391 - val_acc: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3351 - acc: 0.8563 - val_loss: 0.3461 - val_acc: 0.8678\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3353 - acc: 0.8628 - val_loss: 0.3390 - val_acc: 0.8696\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3249 - acc: 0.8640 - val_loss: 0.3448 - val_acc: 0.8611\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3399 - acc: 0.8547 - val_loss: 0.3271 - val_acc: 0.8656\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3296 - acc: 0.8614 - val_loss: 0.3315 - val_acc: 0.8700\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3260 - acc: 0.8593 - val_loss: 0.3221 - val_acc: 0.8689\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3261 - acc: 0.8632 - val_loss: 0.3767 - val_acc: 0.8528\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3336 - acc: 0.8618 - val_loss: 0.3492 - val_acc: 0.8633\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3295 - acc: 0.8605 - val_loss: 0.3608 - val_acc: 0.8489\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3367 - acc: 0.8540 - val_loss: 0.3544 - val_acc: 0.8550\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3283 - acc: 0.8587 - val_loss: 0.3385 - val_acc: 0.8561\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3269 - acc: 0.8606 - val_loss: 0.3814 - val_acc: 0.8456\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3402 - acc: 0.8559 - val_loss: 0.3298 - val_acc: 0.8733\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3302 - acc: 0.8576 - val_loss: 0.3363 - val_acc: 0.8661\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3310 - acc: 0.8603 - val_loss: 0.3619 - val_acc: 0.8550\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3282 - acc: 0.8629 - val_loss: 0.3414 - val_acc: 0.8611\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3305 - acc: 0.8598 - val_loss: 0.3473 - val_acc: 0.8556\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3282 - acc: 0.8568 - val_loss: 0.3349 - val_acc: 0.8550\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3249 - acc: 0.8634 - val_loss: 0.3343 - val_acc: 0.8667\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3309 - acc: 0.8601 - val_loss: 0.3321 - val_acc: 0.8622\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3284 - acc: 0.8608 - val_loss: 0.3796 - val_acc: 0.8411\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3277 - acc: 0.8617 - val_loss: 0.3576 - val_acc: 0.8561\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3314 - acc: 0.8607 - val_loss: 0.3445 - val_acc: 0.8633\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3226 - acc: 0.8620 - val_loss: 0.3342 - val_acc: 0.8678\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3219 - acc: 0.8647 - val_loss: 0.3363 - val_acc: 0.8656\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3316 - acc: 0.8581 - val_loss: 0.3317 - val_acc: 0.8606\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3264 - acc: 0.8608 - val_loss: 0.3220 - val_acc: 0.8694\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3255 - acc: 0.8601 - val_loss: 0.3475 - val_acc: 0.8500\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3281 - acc: 0.8613 - val_loss: 0.3477 - val_acc: 0.8606\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3207 - acc: 0.8698 - val_loss: 0.3377 - val_acc: 0.8606\n",
      "\n",
      "Training process completed in: 0 h 7 m 26 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1163.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1165 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.4883 - acc: 0.7802 - val_loss: 0.4651 - val_acc: 0.7871\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4270 - acc: 0.8176 - val_loss: 0.4236 - val_acc: 0.8079\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4241 - acc: 0.8195 - val_loss: 0.4026 - val_acc: 0.8271\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4110 - acc: 0.8241 - val_loss: 0.4362 - val_acc: 0.8200\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3952 - acc: 0.8338 - val_loss: 0.3758 - val_acc: 0.8371\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3906 - acc: 0.8362 - val_loss: 0.3894 - val_acc: 0.8354\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3899 - acc: 0.8341 - val_loss: 0.3701 - val_acc: 0.8367\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3937 - acc: 0.8327 - val_loss: 0.3675 - val_acc: 0.8413\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3856 - acc: 0.8360 - val_loss: 0.3941 - val_acc: 0.8388\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3852 - acc: 0.8353 - val_loss: 0.3721 - val_acc: 0.8379\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3746 - acc: 0.8393 - val_loss: 0.4054 - val_acc: 0.8217\n",
      "Epoch 12/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3811 - acc: 0.8377 - val_loss: 0.3871 - val_acc: 0.8319\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3745 - acc: 0.8412 - val_loss: 0.3867 - val_acc: 0.8317\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3762 - acc: 0.8389 - val_loss: 0.3704 - val_acc: 0.8425\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3707 - acc: 0.8422 - val_loss: 0.3772 - val_acc: 0.8225\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3687 - acc: 0.8438 - val_loss: 0.3665 - val_acc: 0.8492\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3625 - acc: 0.8463 - val_loss: 0.3531 - val_acc: 0.8537\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3604 - acc: 0.8476 - val_loss: 0.3584 - val_acc: 0.8483\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3618 - acc: 0.8451 - val_loss: 0.3623 - val_acc: 0.8467\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3609 - acc: 0.8482 - val_loss: 0.3651 - val_acc: 0.8350\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3567 - acc: 0.8474 - val_loss: 0.3575 - val_acc: 0.8400\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3606 - acc: 0.8442 - val_loss: 0.3706 - val_acc: 0.8629\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3555 - acc: 0.8496 - val_loss: 0.3664 - val_acc: 0.8504\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3536 - acc: 0.8496 - val_loss: 0.3491 - val_acc: 0.8436\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3523 - acc: 0.8503 - val_loss: 0.3471 - val_acc: 0.8571\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3441 - acc: 0.8533 - val_loss: 0.3373 - val_acc: 0.8600\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3535 - acc: 0.8491 - val_loss: 0.3485 - val_acc: 0.8550\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3518 - acc: 0.8505 - val_loss: 0.3552 - val_acc: 0.8483\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3507 - acc: 0.8524 - val_loss: 0.3458 - val_acc: 0.8454\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3487 - acc: 0.8524 - val_loss: 0.3433 - val_acc: 0.8542\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3401 - acc: 0.8549 - val_loss: 0.3411 - val_acc: 0.8508\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3488 - acc: 0.8501 - val_loss: 0.3619 - val_acc: 0.8417\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3459 - acc: 0.8531 - val_loss: 0.3821 - val_acc: 0.8221\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3413 - acc: 0.8538 - val_loss: 0.3506 - val_acc: 0.8437\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3394 - acc: 0.8561 - val_loss: 0.3394 - val_acc: 0.8583\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3437 - acc: 0.8532 - val_loss: 0.3291 - val_acc: 0.8554\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3387 - acc: 0.8568 - val_loss: 0.3441 - val_acc: 0.8596\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3356 - acc: 0.8564 - val_loss: 0.3589 - val_acc: 0.8563\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3423 - acc: 0.8532 - val_loss: 0.3403 - val_acc: 0.8537\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3329 - acc: 0.8602 - val_loss: 0.3498 - val_acc: 0.8500: 0.3336\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3404 - acc: 0.8537 - val_loss: 0.3770 - val_acc: 0.8454\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3417 - acc: 0.8562 - val_loss: 0.3129 - val_acc: 0.8717\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3362 - acc: 0.8569 - val_loss: 0.3735 - val_acc: 0.8496\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3307 - acc: 0.8587 - val_loss: 0.3297 - val_acc: 0.8600\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3298 - acc: 0.8623 - val_loss: 0.3227 - val_acc: 0.8667s: 0.3432 - acc: 0. - ETA: 2s - los - ETA: 1s -\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3433 - acc: 0.8566 - val_loss: 0.3359 - val_acc: 0.8579\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3377 - acc: 0.8562 - val_loss: 0.3381 - val_acc: 0.8591\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3350 - acc: 0.8589 - val_loss: 0.3432 - val_acc: 0.8567\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3275 - acc: 0.8625 - val_loss: 0.3567 - val_acc: 0.8454\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3404 - acc: 0.8564 - val_loss: 0.3230 - val_acc: 0.8646\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3250 - acc: 0.8633 - val_loss: 0.3247 - val_acc: 0.8629\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3363 - acc: 0.8572 - val_loss: 0.3401 - val_acc: 0.8525\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3315 - acc: 0.8593 - val_loss: 0.3192 - val_acc: 0.8704\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3273 - acc: 0.8631 - val_loss: 0.3077 - val_acc: 0.8667\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3296 - acc: 0.8597 - val_loss: 0.3543 - val_acc: 0.8458\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3287 - acc: 0.8608 - val_loss: 0.3477 - val_acc: 0.8567\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3223 - acc: 0.8634 - val_loss: 0.3264 - val_acc: 0.8654\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3250 - acc: 0.8602 - val_loss: 0.3375 - val_acc: 0.8558\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3210 - acc: 0.8663 - val_loss: 0.3297 - val_acc: 0.8658\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3262 - acc: 0.8619 - val_loss: 0.3161 - val_acc: 0.8613\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3333 - acc: 0.8593 - val_loss: 0.3466 - val_acc: 0.8421\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3225 - acc: 0.8644 - val_loss: 0.3472 - val_acc: 0.8492\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3268 - acc: 0.8653 - val_loss: 0.3365 - val_acc: 0.8571\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3265 - acc: 0.8589 - val_loss: 0.3347 - val_acc: 0.8471\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3342 - acc: 0.8596 - val_loss: 0.3736 - val_acc: 0.8367\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3273 - acc: 0.8634 - val_loss: 0.3256 - val_acc: 0.8650\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3281 - acc: 0.8600 - val_loss: 0.3140 - val_acc: 0.8713\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3283 - acc: 0.8588 - val_loss: 0.3388 - val_acc: 0.8542\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3227 - acc: 0.8624 - val_loss: 0.3383 - val_acc: 0.8571\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3179 - acc: 0.8659 - val_loss: 0.3127 - val_acc: 0.8691\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3163 - acc: 0.8689 - val_loss: 0.3399 - val_acc: 0.8654\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3215 - acc: 0.8643 - val_loss: 0.3318 - val_acc: 0.8546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3143 - acc: 0.8693 - val_loss: 0.3436 - val_acc: 0.8554\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3194 - acc: 0.8644 - val_loss: 0.3419 - val_acc: 0.8508\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3152 - acc: 0.8664 - val_loss: 0.3219 - val_acc: 0.8642\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3207 - acc: 0.8659 - val_loss: 0.3086 - val_acc: 0.8679\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3255 - acc: 0.8627 - val_loss: 0.3461 - val_acc: 0.8592\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3263 - acc: 0.8605 - val_loss: 0.3138 - val_acc: 0.8717\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3254 - acc: 0.8619 - val_loss: 0.3381 - val_acc: 0.8629\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3178 - acc: 0.8650 - val_loss: 0.3386 - val_acc: 0.8592\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3254 - acc: 0.8640 - val_loss: 0.3328 - val_acc: 0.8620\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3313 - acc: 0.8597 - val_loss: 0.3179 - val_acc: 0.8704\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3223 - acc: 0.8611 - val_loss: 0.3544 - val_acc: 0.8475\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3159 - acc: 0.8658 - val_loss: 0.3232 - val_acc: 0.8563\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3213 - acc: 0.8618 - val_loss: 0.3441 - val_acc: 0.8450\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3188 - acc: 0.8652 - val_loss: 0.3410 - val_acc: 0.8496\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3167 - acc: 0.8655 - val_loss: 0.3201 - val_acc: 0.8600\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3152 - acc: 0.8662 - val_loss: 0.3182 - val_acc: 0.8683\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3243 - acc: 0.8613 - val_loss: 0.3202 - val_acc: 0.8712\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3161 - acc: 0.8666 - val_loss: 0.3186 - val_acc: 0.8683\n",
      "\n",
      "Training process completed in: 0 h 9 m 45 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1164.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1166 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.5033 - acc: 0.7681 - val_loss: 0.4436 - val_acc: 0.8196\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.4375 - acc: 0.8138 - val_loss: 0.4617 - val_acc: 0.8038\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.4217 - acc: 0.8211 - val_loss: 0.3996 - val_acc: 0.8300\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.4238 - acc: 0.8149 - val_loss: 0.3995 - val_acc: 0.8279\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4052 - acc: 0.8291 - val_loss: 0.4153 - val_acc: 0.8350\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3973 - acc: 0.8314 - val_loss: 0.4154 - val_acc: 0.8317\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3932 - acc: 0.8314 - val_loss: 0.4101 - val_acc: 0.8329\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3929 - acc: 0.8315 - val_loss: 0.4244 - val_acc: 0.8317\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3875 - acc: 0.8356 - val_loss: 0.3859 - val_acc: 0.8317\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3896 - acc: 0.8319 - val_loss: 0.4136 - val_acc: 0.8383\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3887 - acc: 0.8331 - val_loss: 0.4197 - val_acc: 0.8400\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3850 - acc: 0.8320 - val_loss: 0.4057 - val_acc: 0.8403\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3860 - acc: 0.8334 - val_loss: 0.3852 - val_acc: 0.8412\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3758 - acc: 0.8385 - val_loss: 0.3876 - val_acc: 0.8471\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3694 - acc: 0.8438 - val_loss: 0.3857 - val_acc: 0.8304\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3786 - acc: 0.8386 - val_loss: 0.3754 - val_acc: 0.8454\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3677 - acc: 0.8426 - val_loss: 0.3678 - val_acc: 0.8400\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3736 - acc: 0.8446 - val_loss: 0.3776 - val_acc: 0.8438\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3691 - acc: 0.8411 - val_loss: 0.3999 - val_acc: 0.8321\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3687 - acc: 0.8434 - val_loss: 0.3976 - val_acc: 0.8254\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3620 - acc: 0.8456 - val_loss: 0.3938 - val_acc: 0.8421\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3547 - acc: 0.8491 - val_loss: 0.3731 - val_acc: 0.8533\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3614 - acc: 0.8438 - val_loss: 0.3656 - val_acc: 0.8467\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3530 - acc: 0.8492 - val_loss: 0.4081 - val_acc: 0.8344\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3470 - acc: 0.8539 - val_loss: 0.3656 - val_acc: 0.8525\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3541 - acc: 0.8492 - val_loss: 0.3793 - val_acc: 0.8392\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3484 - acc: 0.8515 - val_loss: 0.3919 - val_acc: 0.8388\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3535 - acc: 0.8515 - val_loss: 0.3552 - val_acc: 0.8575\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3564 - acc: 0.8472 - val_loss: 0.3818 - val_acc: 0.8550\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3528 - acc: 0.8518 - val_loss: 0.3509 - val_acc: 0.8496\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3485 - acc: 0.8509 - val_loss: 0.3571 - val_acc: 0.8558\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3401 - acc: 0.8546 - val_loss: 0.3825 - val_acc: 0.8450\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3364 - acc: 0.8534 - val_loss: 0.3512 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3424 - acc: 0.8532 - val_loss: 0.3289 - val_acc: 0.8671\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3520 - acc: 0.8482 - val_loss: 0.3422 - val_acc: 0.8570\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3430 - acc: 0.8555 - val_loss: 0.3587 - val_acc: 0.8483\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3357 - acc: 0.8568 - val_loss: 0.3498 - val_acc: 0.8700\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3465 - acc: 0.8536 - val_loss: 0.3652 - val_acc: 0.8667\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3374 - acc: 0.8567 - val_loss: 0.3541 - val_acc: 0.8492\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3374 - acc: 0.8577 - val_loss: 0.3643 - val_acc: 0.8529\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3397 - acc: 0.8557 - val_loss: 0.3540 - val_acc: 0.8629\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3343 - acc: 0.8576 - val_loss: 0.3502 - val_acc: 0.8542\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3387 - acc: 0.8518 - val_loss: 0.3500 - val_acc: 0.8533\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3369 - acc: 0.8547 - val_loss: 0.3567 - val_acc: 0.8600\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3434 - acc: 0.8556 - val_loss: 0.3476 - val_acc: 0.8546\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3376 - acc: 0.8558 - val_loss: 0.3430 - val_acc: 0.8604\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3379 - acc: 0.8582 - val_loss: 0.3404 - val_acc: 0.8616\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3224 - acc: 0.8639 - val_loss: 0.3473 - val_acc: 0.8521\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3294 - acc: 0.8611 - val_loss: 0.3483 - val_acc: 0.8529\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3291 - acc: 0.8601 - val_loss: 0.3430 - val_acc: 0.8792\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3328 - acc: 0.8611 - val_loss: 0.3265 - val_acc: 0.8658\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3352 - acc: 0.8569 - val_loss: 0.3436 - val_acc: 0.8567\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3344 - acc: 0.8561 - val_loss: 0.3633 - val_acc: 0.8554\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3274 - acc: 0.8612 - val_loss: 0.3368 - val_acc: 0.8554\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3368 - acc: 0.8573 - val_loss: 0.3691 - val_acc: 0.8475\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3263 - acc: 0.8618 - val_loss: 0.3589 - val_acc: 0.8533\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3286 - acc: 0.8615 - val_loss: 0.3193 - val_acc: 0.8646\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3220 - acc: 0.8661 - val_loss: 0.3229 - val_acc: 0.8750\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3337 - acc: 0.8573 - val_loss: 0.3698 - val_acc: 0.8504\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3330 - acc: 0.8573 - val_loss: 0.3690 - val_acc: 0.8596\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3275 - acc: 0.8605 - val_loss: 0.3332 - val_acc: 0.8779\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3273 - acc: 0.8629 - val_loss: 0.3481 - val_acc: 0.8663\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3163 - acc: 0.8657 - val_loss: 0.3343 - val_acc: 0.8575\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3258 - acc: 0.8627 - val_loss: 0.3360 - val_acc: 0.8583\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3184 - acc: 0.8665 - val_loss: 0.3393 - val_acc: 0.8529\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3277 - acc: 0.8611 - val_loss: 0.3348 - val_acc: 0.8583\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3272 - acc: 0.8608 - val_loss: 0.3326 - val_acc: 0.8679\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3296 - acc: 0.8595 - val_loss: 0.3461 - val_acc: 0.8662\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3286 - acc: 0.8614 - val_loss: 0.3478 - val_acc: 0.8608\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3147 - acc: 0.8673 - val_loss: 0.3280 - val_acc: 0.8662\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3264 - acc: 0.8659 - val_loss: 0.3330 - val_acc: 0.8800\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3281 - acc: 0.8601 - val_loss: 0.3275 - val_acc: 0.8737\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3113 - acc: 0.8671 - val_loss: 0.3309 - val_acc: 0.8687\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3233 - acc: 0.8660 - val_loss: 0.3486 - val_acc: 0.8712\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3120 - acc: 0.8694 - val_loss: 0.3209 - val_acc: 0.8742\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3204 - acc: 0.8662 - val_loss: 0.3500 - val_acc: 0.8512\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3138 - acc: 0.8686 - val_loss: 0.3576 - val_acc: 0.8492\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3186 - acc: 0.8634 - val_loss: 0.3865 - val_acc: 0.8413\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3200 - acc: 0.8625 - val_loss: 0.3209 - val_acc: 0.8692\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3180 - acc: 0.8679 - val_loss: 0.3408 - val_acc: 0.8550\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3261 - acc: 0.8611 - val_loss: 0.3491 - val_acc: 0.8608\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3250 - acc: 0.8622 - val_loss: 0.3245 - val_acc: 0.8687\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3219 - acc: 0.8624 - val_loss: 0.3371 - val_acc: 0.8617\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3188 - acc: 0.8641 - val_loss: 0.3312 - val_acc: 0.8662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3095 - acc: 0.8719 - val_loss: 0.3201 - val_acc: 0.8612\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3188 - acc: 0.8671 - val_loss: 0.3400 - val_acc: 0.8617\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3159 - acc: 0.8681 - val_loss: 0.3525 - val_acc: 0.8525\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3177 - acc: 0.8654 - val_loss: 0.3301 - val_acc: 0.8671\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3139 - acc: 0.8699 - val_loss: 0.3166 - val_acc: 0.8692\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3173 - acc: 0.8679 - val_loss: 0.3495 - val_acc: 0.8692\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3228 - acc: 0.8652 - val_loss: 0.3338 - val_acc: 0.8708\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3168 - acc: 0.8679 - val_loss: 0.3257 - val_acc: 0.8717\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3121 - acc: 0.8679 - val_loss: 0.3478 - val_acc: 0.8558\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3212 - acc: 0.8619 - val_loss: 0.3379 - val_acc: 0.8683\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3150 - acc: 0.8679 - val_loss: 0.3511 - val_acc: 0.8567\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3191 - acc: 0.8626 - val_loss: 0.3033 - val_acc: 0.8737\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3231 - acc: 0.8618 - val_loss: 0.3169 - val_acc: 0.8729\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3211 - acc: 0.8649 - val_loss: 0.3389 - val_acc: 0.8596\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3193 - acc: 0.8644 - val_loss: 0.3363 - val_acc: 0.8646\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3105 - acc: 0.8662 - val_loss: 0.3276 - val_acc: 0.8679\n",
      "\n",
      "Training process completed in: 0 h 10 m 51 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1165.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1167 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.4976 - acc: 0.7707 - val_loss: 0.5172 - val_acc: 0.7943\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4381 - acc: 0.8133 - val_loss: 0.4259 - val_acc: 0.8075\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4296 - acc: 0.8188 - val_loss: 0.4675 - val_acc: 0.8175\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.4197 - acc: 0.8241 - val_loss: 0.4073 - val_acc: 0.8297\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4080 - acc: 0.8228 - val_loss: 0.3999 - val_acc: 0.8275\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4055 - acc: 0.8305 - val_loss: 0.3949 - val_acc: 0.8247\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4037 - acc: 0.8270 - val_loss: 0.4039 - val_acc: 0.8323\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3981 - acc: 0.8286 - val_loss: 0.3908 - val_acc: 0.8377\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3929 - acc: 0.8335 - val_loss: 0.4032 - val_acc: 0.8150\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4038 - acc: 0.8271 - val_loss: 0.4240 - val_acc: 0.8310\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3924 - acc: 0.8297 - val_loss: 0.3829 - val_acc: 0.8408\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3919 - acc: 0.8305 - val_loss: 0.4109 - val_acc: 0.8252\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3829 - acc: 0.8341 - val_loss: 0.3879 - val_acc: 0.8447\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3844 - acc: 0.8357 - val_loss: 0.3967 - val_acc: 0.8269\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3689 - acc: 0.8403 - val_loss: 0.3743 - val_acc: 0.8398\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.3725 - acc: 0.8433 - val_loss: 0.3942 - val_acc: 0.8263\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3712 - acc: 0.8398 - val_loss: 0.3695 - val_acc: 0.8407\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3634 - acc: 0.8452 - val_loss: 0.3802 - val_acc: 0.8515\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3719 - acc: 0.8382 - val_loss: 0.3743 - val_acc: 0.8391\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3747 - acc: 0.8409 - val_loss: 0.3849 - val_acc: 0.8290\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3704 - acc: 0.8403 - val_loss: 0.3667 - val_acc: 0.8500\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3563 - acc: 0.8497 - val_loss: 0.3649 - val_acc: 0.8442\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3532 - acc: 0.8489 - val_loss: 0.3717 - val_acc: 0.8532\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3647 - acc: 0.8444 - val_loss: 0.3738 - val_acc: 0.8406\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3669 - acc: 0.8457 - val_loss: 0.3702 - val_acc: 0.8467\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 6s 31ms/step - loss: 0.3584 - acc: 0.8478 - val_loss: 0.3567 - val_acc: 0.8535\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.3617 - acc: 0.8474 - val_loss: 0.3642 - val_acc: 0.8500\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3627 - acc: 0.8430 - val_loss: 0.3612 - val_acc: 0.8583\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3549 - acc: 0.8466 - val_loss: 0.3663 - val_acc: 0.8440\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3439 - acc: 0.8521 - val_loss: 0.3440 - val_acc: 0.8567\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3518 - acc: 0.8510 - val_loss: 0.3509 - val_acc: 0.8502\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3371 - acc: 0.8572 - val_loss: 0.3393 - val_acc: 0.8588\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3575 - acc: 0.8481 - val_loss: 0.3336 - val_acc: 0.8620\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3464 - acc: 0.8544 - val_loss: 0.3638 - val_acc: 0.8475\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3413 - acc: 0.8532 - val_loss: 0.3411 - val_acc: 0.8638\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3406 - acc: 0.8580 - val_loss: 0.3667 - val_acc: 0.8472\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3417 - acc: 0.8568 - val_loss: 0.3550 - val_acc: 0.8583\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3271 - acc: 0.8628 - val_loss: 0.3529 - val_acc: 0.8543\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3328 - acc: 0.8563 - val_loss: 0.3314 - val_acc: 0.8690\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3428 - acc: 0.8531 - val_loss: 0.3428 - val_acc: 0.8607\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3373 - acc: 0.8582 - val_loss: 0.3442 - val_acc: 0.8517\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3429 - acc: 0.8527 - val_loss: 0.3717 - val_acc: 0.8480\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3505 - acc: 0.8491 - val_loss: 0.3476 - val_acc: 0.8545\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3345 - acc: 0.8623 - val_loss: 0.3388 - val_acc: 0.8565\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3395 - acc: 0.8573 - val_loss: 0.3347 - val_acc: 0.8623\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3373 - acc: 0.8579 - val_loss: 0.3592 - val_acc: 0.8423\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.3341 - acc: 0.8588 - val_loss: 0.3477 - val_acc: 0.8624\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3377 - acc: 0.8584 - val_loss: 0.3497 - val_acc: 0.8473\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3405 - acc: 0.8556 - val_loss: 0.3319 - val_acc: 0.8627\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.3404 - acc: 0.8572 - val_loss: 0.3483 - val_acc: 0.8593\n",
      "\n",
      "Training process completed in: 0 h 5 m 22 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1166.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1168 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.4729 - acc: 0.7814 - val_loss: 0.4207 - val_acc: 0.8254\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.4098 - acc: 0.8264 - val_loss: 0.4260 - val_acc: 0.8167\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.4133 - acc: 0.8227 - val_loss: 0.4175 - val_acc: 0.8302\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3912 - acc: 0.8316 - val_loss: 0.3931 - val_acc: 0.8327\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3897 - acc: 0.8345 - val_loss: 0.4461 - val_acc: 0.8249\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3815 - acc: 0.8370 - val_loss: 0.3739 - val_acc: 0.8370\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3778 - acc: 0.8368 - val_loss: 0.3686 - val_acc: 0.8421\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3746 - acc: 0.8392 - val_loss: 0.4093 - val_acc: 0.8316\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3637 - acc: 0.8441 - val_loss: 0.3697 - val_acc: 0.8430\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3619 - acc: 0.8450 - val_loss: 0.3966 - val_acc: 0.8451\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3707 - acc: 0.8417 - val_loss: 0.3814 - val_acc: 0.8386\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3613 - acc: 0.8471 - val_loss: 0.4261 - val_acc: 0.8331\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3577 - acc: 0.8463 - val_loss: 0.3776 - val_acc: 0.8515\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3420 - acc: 0.8536 - val_loss: 0.3530 - val_acc: 0.8557\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3545 - acc: 0.8501 - val_loss: 0.3831 - val_acc: 0.8494\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3483 - acc: 0.8505 - val_loss: 0.3508 - val_acc: 0.8554\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3491 - acc: 0.8519 - val_loss: 0.3852 - val_acc: 0.8527\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3446 - acc: 0.8538 - val_loss: 0.3662 - val_acc: 0.8576\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3423 - acc: 0.8557 - val_loss: 0.3650 - val_acc: 0.8492\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3389 - acc: 0.8563 - val_loss: 0.3520 - val_acc: 0.8564\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3339 - acc: 0.8580 - val_loss: 0.3409 - val_acc: 0.8598\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3364 - acc: 0.8571 - val_loss: 0.3486 - val_acc: 0.8644\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3293 - acc: 0.8608 - val_loss: 0.3534 - val_acc: 0.8509\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3412 - acc: 0.8552 - val_loss: 0.3456 - val_acc: 0.8536\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3259 - acc: 0.8612 - val_loss: 0.3773 - val_acc: 0.8439\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3279 - acc: 0.8605 - val_loss: 0.3876 - val_acc: 0.8529\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3250 - acc: 0.8619 - val_loss: 0.3286 - val_acc: 0.8634\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3310 - acc: 0.8611 - val_loss: 0.3286 - val_acc: 0.8638\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3192 - acc: 0.8648 - val_loss: 0.3222 - val_acc: 0.8610\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3303 - acc: 0.8601 - val_loss: 0.3251 - val_acc: 0.8688\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3204 - acc: 0.8639 - val_loss: 0.3499 - val_acc: 0.8489: 0.3204 - a\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3232 - acc: 0.8655 - val_loss: 0.3323 - val_acc: 0.8616\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3200 - acc: 0.8659 - val_loss: 0.3313 - val_acc: 0.8679\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3293 - acc: 0.8592 - val_loss: 0.3230 - val_acc: 0.8624\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3210 - acc: 0.8653 - val_loss: 0.3416 - val_acc: 0.8643\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3183 - acc: 0.8652 - val_loss: 0.3560 - val_acc: 0.8586\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3205 - acc: 0.8643 - val_loss: 0.3461 - val_acc: 0.8605\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3135 - acc: 0.8677 - val_loss: 0.3403 - val_acc: 0.8647\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3168 - acc: 0.8650 - val_loss: 0.3242 - val_acc: 0.8664\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3253 - acc: 0.8622 - val_loss: 0.3371 - val_acc: 0.8598\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3124 - acc: 0.8690 - val_loss: 0.3169 - val_acc: 0.8734\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3175 - acc: 0.8648 - val_loss: 0.3352 - val_acc: 0.8636\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3113 - acc: 0.8701 - val_loss: 0.3192 - val_acc: 0.8721\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3077 - acc: 0.8713 - val_loss: 0.3132 - val_acc: 0.8720\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3102 - acc: 0.8692 - val_loss: 0.3475 - val_acc: 0.8605\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3112 - acc: 0.8675 - val_loss: 0.3254 - val_acc: 0.8710\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3108 - acc: 0.8689 - val_loss: 0.3242 - val_acc: 0.8669\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3146 - acc: 0.8678 - val_loss: 0.3170 - val_acc: 0.8681\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3048 - acc: 0.8725 - val_loss: 0.3386 - val_acc: 0.8665\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3067 - acc: 0.8705 - val_loss: 0.3132 - val_acc: 0.8714\n",
      "\n",
      "Training process completed in: 0 h 11 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1167.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1169 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 30\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.5664 - acc: 0.7123 - val_loss: 0.4834 - val_acc: 0.7535\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.4333 - acc: 0.8118 - val_loss: 0.4206 - val_acc: 0.8156\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.4204 - acc: 0.8184 - val_loss: 0.4106 - val_acc: 0.8219\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.4113 - acc: 0.8226 - val_loss: 0.3969 - val_acc: 0.8291\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.3999 - acc: 0.8277 - val_loss: 0.3974 - val_acc: 0.8248\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.4022 - acc: 0.8285 - val_loss: 0.4083 - val_acc: 0.8229\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3952 - acc: 0.8299 - val_loss: 0.3899 - val_acc: 0.8316\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3911 - acc: 0.8314 - val_loss: 0.4023 - val_acc: 0.8224\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3951 - acc: 0.8299 - val_loss: 0.3998 - val_acc: 0.8245\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3910 - acc: 0.8293 - val_loss: 0.3841 - val_acc: 0.8349\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3836 - acc: 0.8348 - val_loss: 0.3829 - val_acc: 0.8387\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3830 - acc: 0.8358 - val_loss: 0.3840 - val_acc: 0.8311\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3857 - acc: 0.8336 - val_loss: 0.3851 - val_acc: 0.8315\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3820 - acc: 0.8385 - val_loss: 0.3897 - val_acc: 0.8304\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3813 - acc: 0.8364 - val_loss: 0.3761 - val_acc: 0.8401\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3792 - acc: 0.8386 - val_loss: 0.3702 - val_acc: 0.8356\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3806 - acc: 0.8369 - val_loss: 0.4039 - val_acc: 0.8276\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.3668 - acc: 0.8428 - val_loss: 0.3738 - val_acc: 0.8359\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3735 - acc: 0.8392 - val_loss: 0.3715 - val_acc: 0.8390\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3752 - acc: 0.8397 - val_loss: 0.3711 - val_acc: 0.8404\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3668 - acc: 0.8429 - val_loss: 0.3625 - val_acc: 0.8445\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3672 - acc: 0.8425 - val_loss: 0.3599 - val_acc: 0.8467\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3675 - acc: 0.8443 - val_loss: 0.3623 - val_acc: 0.8494\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3633 - acc: 0.8454 - val_loss: 0.3664 - val_acc: 0.8437\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3683 - acc: 0.8440 - val_loss: 0.3871 - val_acc: 0.8342\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3570 - acc: 0.8471 - val_loss: 0.3627 - val_acc: 0.8409\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3623 - acc: 0.8431 - val_loss: 0.3603 - val_acc: 0.8469\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3648 - acc: 0.8459 - val_loss: 0.3652 - val_acc: 0.8411\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3584 - acc: 0.8465 - val_loss: 0.3573 - val_acc: 0.8456\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3564 - acc: 0.8487 - val_loss: 0.3489 - val_acc: 0.8560\n",
      "\n",
      "Training process completed in: 0 h 6 m 58 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1168.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1170 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 80\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "80/80 [==============================] - 7s 92ms/step - loss: 0.5949 - acc: 0.7102 - val_loss: 0.5719 - val_acc: 0.7148\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.5529 - acc: 0.7127 - val_loss: 0.5033 - val_acc: 0.7275\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.4708 - acc: 0.7839 - val_loss: 0.4438 - val_acc: 0.8060\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.4458 - acc: 0.8095 - val_loss: 0.4289 - val_acc: 0.8117\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.4263 - acc: 0.8151 - val_loss: 0.4213 - val_acc: 0.8165\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.4208 - acc: 0.8203 - val_loss: 0.4150 - val_acc: 0.8221\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.4172 - acc: 0.8235 - val_loss: 0.4145 - val_acc: 0.8176\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.4167 - acc: 0.8212 - val_loss: 0.4353 - val_acc: 0.8146\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.4167 - acc: 0.8220 - val_loss: 0.4047 - val_acc: 0.8275\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.4100 - acc: 0.8236 - val_loss: 0.4084 - val_acc: 0.8261\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 7s 86ms/step - loss: 0.4053 - acc: 0.8295 - val_loss: 0.4002 - val_acc: 0.8248\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.4091 - acc: 0.8249 - val_loss: 0.4514 - val_acc: 0.8026\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.4111 - acc: 0.8258 - val_loss: 0.4044 - val_acc: 0.8294\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 0.3979 - acc: 0.8299 - val_loss: 0.3961 - val_acc: 0.8275\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.4000 - acc: 0.8286 - val_loss: 0.3960 - val_acc: 0.8332\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.4135 - acc: 0.8245 - val_loss: 0.4123 - val_acc: 0.8195\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.3975 - acc: 0.8309 - val_loss: 0.4014 - val_acc: 0.8288\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3922 - acc: 0.8339 - val_loss: 0.4113 - val_acc: 0.8215\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3983 - acc: 0.8290 - val_loss: 0.4005 - val_acc: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3952 - acc: 0.8296 - val_loss: 0.3898 - val_acc: 0.8346\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.4111 - acc: 0.8250 - val_loss: 0.4014 - val_acc: 0.8280\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.3937 - acc: 0.8291 - val_loss: 0.3958 - val_acc: 0.8291\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.3907 - acc: 0.8342 - val_loss: 0.3914 - val_acc: 0.8309\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 7s 81ms/step - loss: 0.3963 - acc: 0.8316 - val_loss: 0.3985 - val_acc: 0.8292\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 7s 81ms/step - loss: 0.3983 - acc: 0.8343 - val_loss: 0.3976 - val_acc: 0.8294\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3984 - acc: 0.8297 - val_loss: 0.3894 - val_acc: 0.8310\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3812 - acc: 0.8352 - val_loss: 0.3841 - val_acc: 0.8334\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3985 - acc: 0.8300 - val_loss: 0.4000 - val_acc: 0.8271\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.3869 - acc: 0.8321 - val_loss: 0.3827 - val_acc: 0.8366\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.3870 - acc: 0.8357 - val_loss: 0.3878 - val_acc: 0.8318\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.3860 - acc: 0.8345 - val_loss: 0.3943 - val_acc: 0.8341\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 7s 81ms/step - loss: 0.3806 - acc: 0.8399 - val_loss: 0.3902 - val_acc: 0.8306\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3860 - acc: 0.8338 - val_loss: 0.3876 - val_acc: 0.8349\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3876 - acc: 0.8325 - val_loss: 0.3828 - val_acc: 0.8391\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 7s 86ms/step - loss: 0.3796 - acc: 0.8370 - val_loss: 0.3847 - val_acc: 0.8306\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3768 - acc: 0.8387 - val_loss: 0.3859 - val_acc: 0.8334\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3794 - acc: 0.8367 - val_loss: 0.3783 - val_acc: 0.8378\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3793 - acc: 0.8405 - val_loss: 0.3812 - val_acc: 0.8389\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.3779 - acc: 0.8378 - val_loss: 0.3749 - val_acc: 0.8418\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.3774 - acc: 0.8387 - val_loss: 0.3690 - val_acc: 0.8401\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.3723 - acc: 0.8423 - val_loss: 0.3865 - val_acc: 0.8350\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 0.3789 - acc: 0.8384 - val_loss: 0.3855 - val_acc: 0.8284\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3772 - acc: 0.8391 - val_loss: 0.3996 - val_acc: 0.8362\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3733 - acc: 0.8393 - val_loss: 0.3646 - val_acc: 0.8440\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 0.3783 - acc: 0.8348 - val_loss: 0.3739 - val_acc: 0.8431\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 0.3693 - acc: 0.8442 - val_loss: 0.3815 - val_acc: 0.8361\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 0.3779 - acc: 0.8380 - val_loss: 0.3708 - val_acc: 0.8417\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 0.3675 - acc: 0.8433 - val_loss: 0.3858 - val_acc: 0.8401\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 0.3702 - acc: 0.8429 - val_loss: 0.3823 - val_acc: 0.8351\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 0.3711 - acc: 0.8430 - val_loss: 0.3818 - val_acc: 0.8382\n",
      "\n",
      "Training process completed in: 0 h 5 m 32 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1169.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1171 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 40\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.5740 - acc: 0.7167 - val_loss: 0.5233 - val_acc: 0.7154\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.5032 - acc: 0.7797 - val_loss: 0.5096 - val_acc: 0.7328\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.4567 - acc: 0.7937 - val_loss: 0.4161 - val_acc: 0.8235\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.4372 - acc: 0.8156 - val_loss: 0.4336 - val_acc: 0.8205\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.4491 - acc: 0.8059 - val_loss: 0.4492 - val_acc: 0.8182\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.4207 - acc: 0.8225 - val_loss: 0.4594 - val_acc: 0.8217\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.4290 - acc: 0.8150 - val_loss: 0.4713 - val_acc: 0.8119\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.4074 - acc: 0.8309 - val_loss: 0.5028 - val_acc: 0.7919\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.4217 - acc: 0.8189 - val_loss: 0.4414 - val_acc: 0.8153\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.4189 - acc: 0.8153 - val_loss: 0.4318 - val_acc: 0.8214\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 4s 112ms/step - loss: 0.4116 - acc: 0.8233 - val_loss: 0.3999 - val_acc: 0.8285\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 104ms/step - loss: 0.4342 - acc: 0.8150 - val_loss: 0.4169 - val_acc: 0.8271\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 0.3946 - acc: 0.8323 - val_loss: 0.4351 - val_acc: 0.8273\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.3863 - acc: 0.8383 - val_loss: 0.4399 - val_acc: 0.8256\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3881 - acc: 0.8336 - val_loss: 0.3997 - val_acc: 0.8339\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3948 - acc: 0.8273 - val_loss: 0.4316 - val_acc: 0.8227\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3966 - acc: 0.8267 - val_loss: 0.4853 - val_acc: 0.8181\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.3737 - acc: 0.8450 - val_loss: 0.4017 - val_acc: 0.8291\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3988 - acc: 0.8292 - val_loss: 0.4103 - val_acc: 0.8377\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 0.4025 - acc: 0.8239 - val_loss: 0.4023 - val_acc: 0.8342\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 0.3994 - acc: 0.8236 - val_loss: 0.4089 - val_acc: 0.8231\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3731 - acc: 0.8433 - val_loss: 0.3988 - val_acc: 0.8334\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3933 - acc: 0.8289 - val_loss: 0.4149 - val_acc: 0.8315\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3927 - acc: 0.8344 - val_loss: 0.4767 - val_acc: 0.8181\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.3943 - acc: 0.8297 - val_loss: 0.4023 - val_acc: 0.8247\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3875 - acc: 0.8312 - val_loss: 0.4592 - val_acc: 0.8093\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3777 - acc: 0.8388 - val_loss: 0.3947 - val_acc: 0.8363\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.4173 - acc: 0.8239 - val_loss: 0.3959 - val_acc: 0.8327\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3816 - acc: 0.8384 - val_loss: 0.4024 - val_acc: 0.8374\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3783 - acc: 0.8373 - val_loss: 0.3956 - val_acc: 0.8456\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3825 - acc: 0.8369 - val_loss: 0.4220 - val_acc: 0.8372\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3862 - acc: 0.8319 - val_loss: 0.4171 - val_acc: 0.8353\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3733 - acc: 0.8417 - val_loss: 0.3749 - val_acc: 0.8353\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3783 - acc: 0.8359 - val_loss: 0.3820 - val_acc: 0.8377\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.3634 - acc: 0.8409 - val_loss: 0.3659 - val_acc: 0.8531\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3686 - acc: 0.8406 - val_loss: 0.4116 - val_acc: 0.8392\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3613 - acc: 0.8436 - val_loss: 0.3823 - val_acc: 0.8446\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3622 - acc: 0.8461 - val_loss: 0.3761 - val_acc: 0.8429\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.3756 - acc: 0.8408 - val_loss: 0.4172 - val_acc: 0.8284\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.3726 - acc: 0.8416 - val_loss: 0.3865 - val_acc: 0.8530\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.3680 - acc: 0.8463 - val_loss: 0.3664 - val_acc: 0.8444\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.3662 - acc: 0.8441 - val_loss: 0.3673 - val_acc: 0.8414\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3717 - acc: 0.8425 - val_loss: 0.3737 - val_acc: 0.8315\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3735 - acc: 0.8384 - val_loss: 0.4131 - val_acc: 0.8293\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.3620 - acc: 0.8458 - val_loss: 0.3612 - val_acc: 0.8406\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.3606 - acc: 0.8427 - val_loss: 0.3749 - val_acc: 0.8524\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 0.3450 - acc: 0.8516 - val_loss: 0.3713 - val_acc: 0.8479\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.3533 - acc: 0.8480 - val_loss: 0.3790 - val_acc: 0.8395\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.3709 - acc: 0.8447 - val_loss: 0.3720 - val_acc: 0.8406\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.3698 - acc: 0.8427 - val_loss: 0.3685 - val_acc: 0.8404\n",
      "\n",
      "Training process completed in: 0 h 3 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1170.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1172 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 21s 110ms/step - loss: 0.4683 - acc: 0.7888 - val_loss: 0.4352 - val_acc: 0.8166\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.4201 - acc: 0.8191 - val_loss: 0.4118 - val_acc: 0.8164\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.4087 - acc: 0.8230 - val_loss: 0.4035 - val_acc: 0.8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.4045 - acc: 0.8277 - val_loss: 0.4187 - val_acc: 0.8278\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3892 - acc: 0.8346 - val_loss: 0.4114 - val_acc: 0.8314\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.3816 - acc: 0.8364 - val_loss: 0.4088 - val_acc: 0.8383\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3839 - acc: 0.8336 - val_loss: 0.3734 - val_acc: 0.8352\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3778 - acc: 0.8357 - val_loss: 0.3735 - val_acc: 0.8414\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3753 - acc: 0.8391 - val_loss: 0.3737 - val_acc: 0.8427\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3619 - acc: 0.8469 - val_loss: 0.3739 - val_acc: 0.8353\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3668 - acc: 0.8426 - val_loss: 0.3887 - val_acc: 0.8508\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3621 - acc: 0.8439 - val_loss: 0.3594 - val_acc: 0.8501\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3598 - acc: 0.8458 - val_loss: 0.3629 - val_acc: 0.8481\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3530 - acc: 0.8481 - val_loss: 0.3715 - val_acc: 0.8515\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3532 - acc: 0.8497 - val_loss: 0.3630 - val_acc: 0.8471\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3529 - acc: 0.8501 - val_loss: 0.3748 - val_acc: 0.8451\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3520 - acc: 0.8508 - val_loss: 0.3490 - val_acc: 0.8588\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3430 - acc: 0.8534 - val_loss: 0.3543 - val_acc: 0.8556\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3350 - acc: 0.8571 - val_loss: 0.3759 - val_acc: 0.8482\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3417 - acc: 0.8548 - val_loss: 0.3656 - val_acc: 0.8556\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3399 - acc: 0.8543 - val_loss: 0.3418 - val_acc: 0.8606\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3382 - acc: 0.8582 - val_loss: 0.3435 - val_acc: 0.8596\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3372 - acc: 0.8578 - val_loss: 0.3421 - val_acc: 0.8616\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3370 - acc: 0.8573 - val_loss: 0.3427 - val_acc: 0.8573\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3294 - acc: 0.8569 - val_loss: 0.3356 - val_acc: 0.8533\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3322 - acc: 0.8588 - val_loss: 0.3745 - val_acc: 0.8567\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3252 - acc: 0.8620 - val_loss: 0.3519 - val_acc: 0.8572\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3322 - acc: 0.8582 - val_loss: 0.3429 - val_acc: 0.8601\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3288 - acc: 0.8618 - val_loss: 0.3278 - val_acc: 0.8628\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3242 - acc: 0.8627 - val_loss: 0.3733 - val_acc: 0.8419\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3237 - acc: 0.8615 - val_loss: 0.4194 - val_acc: 0.8208\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3276 - acc: 0.8616 - val_loss: 0.3390 - val_acc: 0.8640\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3225 - acc: 0.8632 - val_loss: 0.3506 - val_acc: 0.8639\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3195 - acc: 0.8639 - val_loss: 0.3311 - val_acc: 0.8620\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3215 - acc: 0.8656 - val_loss: 0.3320 - val_acc: 0.8679\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3197 - acc: 0.8628 - val_loss: 0.3254 - val_acc: 0.8677\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3138 - acc: 0.8671 - val_loss: 0.3286 - val_acc: 0.8656\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3187 - acc: 0.8638 - val_loss: 0.3399 - val_acc: 0.8673\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3197 - acc: 0.8649 - val_loss: 0.3393 - val_acc: 0.8644\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3189 - acc: 0.8649 - val_loss: 0.3328 - val_acc: 0.8638\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3198 - acc: 0.8637 - val_loss: 0.3191 - val_acc: 0.8689\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3104 - acc: 0.8678 - val_loss: 0.3377 - val_acc: 0.8623\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 19s 103ms/step - loss: 0.3110 - acc: 0.8688 - val_loss: 0.3338 - val_acc: 0.8632\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3145 - acc: 0.8666 - val_loss: 0.3269 - val_acc: 0.8652\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3127 - acc: 0.8669 - val_loss: 0.3233 - val_acc: 0.8587\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3156 - acc: 0.8669 - val_loss: 0.3234 - val_acc: 0.8585\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3079 - acc: 0.8702 - val_loss: 0.3192 - val_acc: 0.8649\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3088 - acc: 0.8684 - val_loss: 0.3136 - val_acc: 0.8670\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3138 - acc: 0.8677 - val_loss: 0.3192 - val_acc: 0.8636\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3084 - acc: 0.8694 - val_loss: 0.3179 - val_acc: 0.8671\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3088 - acc: 0.8704 - val_loss: 0.3104 - val_acc: 0.8715\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 20s 105ms/step - loss: 0.3040 - acc: 0.8723 - val_loss: 0.3224 - val_acc: 0.8667\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3113 - acc: 0.8665 - val_loss: 0.3280 - val_acc: 0.8684\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3044 - acc: 0.8720 - val_loss: 0.3278 - val_acc: 0.8655\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.3077 - acc: 0.8698 - val_loss: 0.3181 - val_acc: 0.8695\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3044 - acc: 0.8709 - val_loss: 0.3067 - val_acc: 0.8706\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3109 - acc: 0.8696 - val_loss: 0.3367 - val_acc: 0.8563\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3044 - acc: 0.8726 - val_loss: 0.3173 - val_acc: 0.8636\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3044 - acc: 0.8721 - val_loss: 0.3503 - val_acc: 0.8575\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3013 - acc: 0.8714 - val_loss: 0.3137 - val_acc: 0.8696\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.2975 - acc: 0.8759 - val_loss: 0.3149 - val_acc: 0.8694\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 19s 103ms/step - loss: 0.3009 - acc: 0.8723 - val_loss: 0.3359 - val_acc: 0.8693\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3033 - acc: 0.8723 - val_loss: 0.3113 - val_acc: 0.8726\n",
      "Epoch 64/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 19s 102ms/step - loss: 0.2952 - acc: 0.8758 - val_loss: 0.3230 - val_acc: 0.8676\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.2955 - acc: 0.8757 - val_loss: 0.3201 - val_acc: 0.8714\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.2957 - acc: 0.8765 - val_loss: 0.3490 - val_acc: 0.8575\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3013 - acc: 0.8733 - val_loss: 0.3170 - val_acc: 0.8713\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.2999 - acc: 0.8731 - val_loss: 0.3178 - val_acc: 0.8701\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3052 - acc: 0.8702 - val_loss: 0.3168 - val_acc: 0.8727\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.2997 - acc: 0.8722 - val_loss: 0.3101 - val_acc: 0.8724\n",
      "\n",
      "Training process completed in: 0 h 22 m 52 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1171.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1173 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 14s 76ms/step - loss: 0.4735 - acc: 0.7854 - val_loss: 0.4266 - val_acc: 0.8120\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.4110 - acc: 0.8263 - val_loss: 0.4117 - val_acc: 0.8335\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.4131 - acc: 0.8244 - val_loss: 0.4354 - val_acc: 0.8217\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3892 - acc: 0.8318 - val_loss: 0.3826 - val_acc: 0.8367\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3871 - acc: 0.8354 - val_loss: 0.4160 - val_acc: 0.8311\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3889 - acc: 0.8346 - val_loss: 0.3853 - val_acc: 0.8311\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3795 - acc: 0.8357 - val_loss: 0.3910 - val_acc: 0.8419\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3671 - acc: 0.8450 - val_loss: 0.3840 - val_acc: 0.8443\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3728 - acc: 0.8414 - val_loss: 0.3777 - val_acc: 0.8411\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3671 - acc: 0.8439 - val_loss: 0.3761 - val_acc: 0.8428\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3604 - acc: 0.8451 - val_loss: 0.3635 - val_acc: 0.8507\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3572 - acc: 0.8483 - val_loss: 0.3618 - val_acc: 0.8437\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3619 - acc: 0.8443 - val_loss: 0.3677 - val_acc: 0.8433\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3506 - acc: 0.8510 - val_loss: 0.3757 - val_acc: 0.8393\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3523 - acc: 0.8511 - val_loss: 0.3808 - val_acc: 0.8506\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3420 - acc: 0.8559 - val_loss: 0.3737 - val_acc: 0.8513\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3499 - acc: 0.8532 - val_loss: 0.3669 - val_acc: 0.8526\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3485 - acc: 0.8507 - val_loss: 0.3612 - val_acc: 0.8494\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3545 - acc: 0.8482 - val_loss: 0.3764 - val_acc: 0.8487\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3417 - acc: 0.8558 - val_loss: 0.3510 - val_acc: 0.8530\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3357 - acc: 0.8569 - val_loss: 0.3730 - val_acc: 0.8604\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3453 - acc: 0.8532 - val_loss: 0.3482 - val_acc: 0.8494\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3368 - acc: 0.8567 - val_loss: 0.3480 - val_acc: 0.8585\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3301 - acc: 0.8595 - val_loss: 0.3433 - val_acc: 0.8574\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3283 - acc: 0.8618 - val_loss: 0.3859 - val_acc: 0.8465\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3372 - acc: 0.8564 - val_loss: 0.3565 - val_acc: 0.8612\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3321 - acc: 0.8592 - val_loss: 0.3445 - val_acc: 0.8600\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3343 - acc: 0.8586 - val_loss: 0.3303 - val_acc: 0.8683\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3160 - acc: 0.8666 - val_loss: 0.3417 - val_acc: 0.8594\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3297 - acc: 0.8622 - val_loss: 0.3412 - val_acc: 0.8654\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3229 - acc: 0.8619 - val_loss: 0.3330 - val_acc: 0.8637\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3287 - acc: 0.8622 - val_loss: 0.3418 - val_acc: 0.8530\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3214 - acc: 0.8667 - val_loss: 0.3656 - val_acc: 0.8422\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3260 - acc: 0.8635 - val_loss: 0.3526 - val_acc: 0.8648\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3145 - acc: 0.8670 - val_loss: 0.3266 - val_acc: 0.8706\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3194 - acc: 0.8627 - val_loss: 0.3179 - val_acc: 0.8726\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3236 - acc: 0.8629 - val_loss: 0.3482 - val_acc: 0.8612\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3207 - acc: 0.8638 - val_loss: 0.3393 - val_acc: 0.8604\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3201 - acc: 0.8649 - val_loss: 0.3514 - val_acc: 0.8676\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 14s 73ms/step - loss: 0.3145 - acc: 0.8665 - val_loss: 0.3291 - val_acc: 0.8680\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3183 - acc: 0.8665 - val_loss: 0.3387 - val_acc: 0.8613\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3110 - acc: 0.8709 - val_loss: 0.3440 - val_acc: 0.8656\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3181 - acc: 0.8661 - val_loss: 0.3287 - val_acc: 0.8596\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3146 - acc: 0.8671 - val_loss: 0.3172 - val_acc: 0.8713\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3087 - acc: 0.8704 - val_loss: 0.3366 - val_acc: 0.8589\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3146 - acc: 0.8668 - val_loss: 0.3301 - val_acc: 0.8580\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3154 - acc: 0.8670 - val_loss: 0.3446 - val_acc: 0.8631\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3078 - acc: 0.8709 - val_loss: 0.3266 - val_acc: 0.8665\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3075 - acc: 0.8698 - val_loss: 0.3232 - val_acc: 0.8622\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3121 - acc: 0.8691 - val_loss: 0.3327 - val_acc: 0.8678\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3154 - acc: 0.8673 - val_loss: 0.3174 - val_acc: 0.8698\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3063 - acc: 0.8713 - val_loss: 0.3291 - val_acc: 0.8677\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3008 - acc: 0.8745 - val_loss: 0.3303 - val_acc: 0.8598\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3099 - acc: 0.8709 - val_loss: 0.3248 - val_acc: 0.8752\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3104 - acc: 0.8725 - val_loss: 0.3239 - val_acc: 0.8689\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3153 - acc: 0.8668 - val_loss: 0.3345 - val_acc: 0.8615\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3092 - acc: 0.8684 - val_loss: 0.3427 - val_acc: 0.8635\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3044 - acc: 0.8726 - val_loss: 0.3098 - val_acc: 0.8696\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3088 - acc: 0.8681 - val_loss: 0.3261 - val_acc: 0.8733\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3043 - acc: 0.8721 - val_loss: 0.3176 - val_acc: 0.8787\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.2980 - acc: 0.8765 - val_loss: 0.3190 - val_acc: 0.8663\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3017 - acc: 0.8735 - val_loss: 0.3059 - val_acc: 0.8762\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3073 - acc: 0.8704 - val_loss: 0.3144 - val_acc: 0.8676\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3063 - acc: 0.8720 - val_loss: 0.3118 - val_acc: 0.8720\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3040 - acc: 0.8725 - val_loss: 0.3159 - val_acc: 0.8665\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3078 - acc: 0.8701 - val_loss: 0.3136 - val_acc: 0.8737\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2989 - acc: 0.8736 - val_loss: 0.3187 - val_acc: 0.8681\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 14s 73ms/step - loss: 0.3022 - acc: 0.8730 - val_loss: 0.3161 - val_acc: 0.8684\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2932 - acc: 0.8778 - val_loss: 0.3180 - val_acc: 0.8633\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2961 - acc: 0.8765 - val_loss: 0.3167 - val_acc: 0.8763\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3007 - acc: 0.8741 - val_loss: 0.3123 - val_acc: 0.8711\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2919 - acc: 0.8769 - val_loss: 0.3130 - val_acc: 0.8728\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2898 - acc: 0.8777 - val_loss: 0.2878 - val_acc: 0.8764\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.2999 - acc: 0.8741 - val_loss: 0.3111 - val_acc: 0.8693\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3003 - acc: 0.8737 - val_loss: 0.3162 - val_acc: 0.8715\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3027 - acc: 0.8745 - val_loss: 0.3113 - val_acc: 0.8730\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2971 - acc: 0.8768 - val_loss: 0.3307 - val_acc: 0.8648\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2973 - acc: 0.8752 - val_loss: 0.3210 - val_acc: 0.8688\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.2883 - acc: 0.8797 - val_loss: 0.3116 - val_acc: 0.8704\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.2910 - acc: 0.8792 - val_loss: 0.3225 - val_acc: 0.8694\n",
      "\n",
      "Training process completed in: 0 h 18 m 5 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1172.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1174 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 110\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.5192 - acc: 0.7496 - val_loss: 0.4220 - val_acc: 0.8161\n",
      "Epoch 2/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.4294 - acc: 0.8188 - val_loss: 0.4145 - val_acc: 0.8196\n",
      "Epoch 3/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.4140 - acc: 0.8255 - val_loss: 0.4005 - val_acc: 0.8265\n",
      "Epoch 4/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.4041 - acc: 0.8263 - val_loss: 0.4052 - val_acc: 0.8181\n",
      "Epoch 5/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.4019 - acc: 0.8250 - val_loss: 0.4186 - val_acc: 0.8253\n",
      "Epoch 6/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3961 - acc: 0.8288 - val_loss: 0.3909 - val_acc: 0.8277\n",
      "Epoch 7/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3891 - acc: 0.8323 - val_loss: 0.3868 - val_acc: 0.8315\n",
      "Epoch 8/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3872 - acc: 0.8343 - val_loss: 0.3800 - val_acc: 0.8340\n",
      "Epoch 9/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3870 - acc: 0.8351 - val_loss: 0.3920 - val_acc: 0.8366\n",
      "Epoch 10/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3728 - acc: 0.8404 - val_loss: 0.3830 - val_acc: 0.8377\n",
      "Epoch 11/70\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3741 - acc: 0.8397 - val_loss: 0.3849 - val_acc: 0.8404\n",
      "Epoch 12/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3726 - acc: 0.8396 - val_loss: 0.3669 - val_acc: 0.8401\n",
      "Epoch 13/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3730 - acc: 0.8422 - val_loss: 0.3918 - val_acc: 0.8383\n",
      "Epoch 14/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3642 - acc: 0.8439 - val_loss: 0.4136 - val_acc: 0.8454\n",
      "Epoch 15/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3702 - acc: 0.8413 - val_loss: 0.3797 - val_acc: 0.8412\n",
      "Epoch 16/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3620 - acc: 0.8463 - val_loss: 0.3639 - val_acc: 0.8418\n",
      "Epoch 17/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3594 - acc: 0.8478 - val_loss: 0.3722 - val_acc: 0.8456\n",
      "Epoch 18/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3701 - acc: 0.8429 - val_loss: 0.3708 - val_acc: 0.8459\n",
      "Epoch 19/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3668 - acc: 0.8411 - val_loss: 0.3877 - val_acc: 0.8428\n",
      "Epoch 20/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3584 - acc: 0.8480 - val_loss: 0.3642 - val_acc: 0.8468\n",
      "Epoch 21/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3597 - acc: 0.8474 - val_loss: 0.3598 - val_acc: 0.8470\n",
      "Epoch 22/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3580 - acc: 0.8471 - val_loss: 0.3620 - val_acc: 0.8506\n",
      "Epoch 23/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3471 - acc: 0.8522 - val_loss: 0.3580 - val_acc: 0.8536\n",
      "Epoch 24/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3439 - acc: 0.8535 - val_loss: 0.4068 - val_acc: 0.8447\n",
      "Epoch 25/70\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3481 - acc: 0.8521 - val_loss: 0.4045 - val_acc: 0.8471\n",
      "Epoch 26/70\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3478 - acc: 0.8513 - val_loss: 0.3507 - val_acc: 0.8559\n",
      "Epoch 27/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3480 - acc: 0.8527 - val_loss: 0.3606 - val_acc: 0.8568\n",
      "Epoch 28/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3480 - acc: 0.8525 - val_loss: 0.3570 - val_acc: 0.8510\n",
      "Epoch 29/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3388 - acc: 0.8579 - val_loss: 0.3874 - val_acc: 0.8494\n",
      "Epoch 30/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3499 - acc: 0.8497 - val_loss: 0.3617 - val_acc: 0.8576\n",
      "Epoch 31/70\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3422 - acc: 0.8563 - val_loss: 0.3692 - val_acc: 0.8552\n",
      "Epoch 32/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3370 - acc: 0.8549 - val_loss: 0.3462 - val_acc: 0.8555\n",
      "Epoch 33/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3388 - acc: 0.8571 - val_loss: 0.3773 - val_acc: 0.8511\n",
      "Epoch 34/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3401 - acc: 0.8570 - val_loss: 0.3796 - val_acc: 0.8495\n",
      "Epoch 35/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3409 - acc: 0.8541 - val_loss: 0.3878 - val_acc: 0.8489\n",
      "Epoch 36/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3427 - acc: 0.8534 - val_loss: 0.3514 - val_acc: 0.8609\n",
      "Epoch 37/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3347 - acc: 0.8565 - val_loss: 0.3475 - val_acc: 0.8573\n",
      "Epoch 38/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3447 - acc: 0.8537 - val_loss: 0.3439 - val_acc: 0.8515\n",
      "Epoch 39/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3339 - acc: 0.8592 - val_loss: 0.3613 - val_acc: 0.8544\n",
      "Epoch 40/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3281 - acc: 0.8616 - val_loss: 0.3688 - val_acc: 0.8525\n",
      "Epoch 41/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3378 - acc: 0.8564 - val_loss: 0.3369 - val_acc: 0.8633\n",
      "Epoch 42/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3325 - acc: 0.8608 - val_loss: 0.3529 - val_acc: 0.8592\n",
      "Epoch 43/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3313 - acc: 0.8595 - val_loss: 0.3470 - val_acc: 0.8535\n",
      "Epoch 44/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3232 - acc: 0.8637 - val_loss: 0.3258 - val_acc: 0.8643\n",
      "Epoch 45/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3279 - acc: 0.8587 - val_loss: 0.3589 - val_acc: 0.8567\n",
      "Epoch 46/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3347 - acc: 0.8594 - val_loss: 0.3369 - val_acc: 0.8614\n",
      "Epoch 47/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3205 - acc: 0.8630 - val_loss: 0.3435 - val_acc: 0.8586\n",
      "Epoch 48/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3323 - acc: 0.8606 - val_loss: 0.3486 - val_acc: 0.8574\n",
      "Epoch 49/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3282 - acc: 0.8589 - val_loss: 0.3459 - val_acc: 0.8605\n",
      "Epoch 50/70\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3192 - acc: 0.8633 - val_loss: 0.3388 - val_acc: 0.8627\n",
      "Epoch 51/70\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3263 - acc: 0.8604 - val_loss: 0.3328 - val_acc: 0.8586\n",
      "Epoch 52/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3214 - acc: 0.8632 - val_loss: 0.3306 - val_acc: 0.8641\n",
      "Epoch 53/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3280 - acc: 0.8616 - val_loss: 0.3441 - val_acc: 0.8632\n",
      "Epoch 54/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3139 - acc: 0.8671 - val_loss: 0.3432 - val_acc: 0.8540\n",
      "Epoch 55/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3223 - acc: 0.8637 - val_loss: 0.3354 - val_acc: 0.8668\n",
      "Epoch 56/70\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3266 - acc: 0.8629 - val_loss: 0.3303 - val_acc: 0.8657\n",
      "Epoch 57/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3233 - acc: 0.8620 - val_loss: 0.3438 - val_acc: 0.8612\n",
      "Epoch 58/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3181 - acc: 0.8620 - val_loss: 0.3263 - val_acc: 0.8632\n",
      "Epoch 59/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3256 - acc: 0.8618 - val_loss: 0.3394 - val_acc: 0.8662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3184 - acc: 0.8678 - val_loss: 0.3512 - val_acc: 0.8629\n",
      "Epoch 61/70\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3172 - acc: 0.8671 - val_loss: 0.3336 - val_acc: 0.8594\n",
      "Epoch 62/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3248 - acc: 0.8626 - val_loss: 0.3383 - val_acc: 0.8574\n",
      "Epoch 63/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3180 - acc: 0.8662 - val_loss: 0.3277 - val_acc: 0.8648\n",
      "Epoch 64/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3274 - acc: 0.8587 - val_loss: 0.3430 - val_acc: 0.8654\n",
      "Epoch 65/70\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3185 - acc: 0.8651 - val_loss: 0.3535 - val_acc: 0.8628\n",
      "Epoch 66/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3176 - acc: 0.8664 - val_loss: 0.3268 - val_acc: 0.8647\n",
      "Epoch 67/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3189 - acc: 0.8661 - val_loss: 0.3255 - val_acc: 0.8607\n",
      "Epoch 68/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3121 - acc: 0.8680 - val_loss: 0.3216 - val_acc: 0.8675\n",
      "Epoch 69/70\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3145 - acc: 0.8651 - val_loss: 0.3540 - val_acc: 0.8627\n",
      "Epoch 70/70\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3111 - acc: 0.8693 - val_loss: 0.3228 - val_acc: 0.8651\n",
      "\n",
      "Training process completed in: 0 h 16 m 7 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1173.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1175 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 110\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.5531 - acc: 0.7278 - val_loss: 0.5547 - val_acc: 0.7969\n",
      "Epoch 2/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.4610 - acc: 0.8068 - val_loss: 0.4333 - val_acc: 0.8086\n",
      "Epoch 3/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.4210 - acc: 0.8212 - val_loss: 0.4541 - val_acc: 0.8094\n",
      "Epoch 4/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.4165 - acc: 0.8226 - val_loss: 0.4301 - val_acc: 0.8233\n",
      "Epoch 5/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.4009 - acc: 0.8300 - val_loss: 0.4053 - val_acc: 0.8267\n",
      "Epoch 6/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3980 - acc: 0.8295 - val_loss: 0.3905 - val_acc: 0.8309\n",
      "Epoch 7/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3899 - acc: 0.8342 - val_loss: 0.3947 - val_acc: 0.8284\n",
      "Epoch 8/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3930 - acc: 0.8350 - val_loss: 0.3849 - val_acc: 0.8314\n",
      "Epoch 9/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3796 - acc: 0.8372 - val_loss: 0.3852 - val_acc: 0.8341\n",
      "Epoch 10/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3858 - acc: 0.8358 - val_loss: 0.4268 - val_acc: 0.8298\n",
      "Epoch 11/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3837 - acc: 0.8362 - val_loss: 0.3918 - val_acc: 0.8332\n",
      "Epoch 12/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3786 - acc: 0.8406 - val_loss: 0.3818 - val_acc: 0.8415\n",
      "Epoch 13/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3717 - acc: 0.8425 - val_loss: 0.3803 - val_acc: 0.8339\n",
      "Epoch 14/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3702 - acc: 0.8430 - val_loss: 0.3625 - val_acc: 0.8435\n",
      "Epoch 15/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3695 - acc: 0.8432 - val_loss: 0.3765 - val_acc: 0.8489\n",
      "Epoch 16/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3691 - acc: 0.8454 - val_loss: 0.3655 - val_acc: 0.8459\n",
      "Epoch 17/80\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3562 - acc: 0.8510 - val_loss: 0.3613 - val_acc: 0.8515\n",
      "Epoch 18/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3675 - acc: 0.8442 - val_loss: 0.4256 - val_acc: 0.8347\n",
      "Epoch 19/80\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3597 - acc: 0.8465 - val_loss: 0.3578 - val_acc: 0.8471\n",
      "Epoch 20/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3575 - acc: 0.8483 - val_loss: 0.3680 - val_acc: 0.8450\n",
      "Epoch 21/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3554 - acc: 0.8480 - val_loss: 0.3665 - val_acc: 0.8569\n",
      "Epoch 22/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3578 - acc: 0.8488 - val_loss: 0.3609 - val_acc: 0.8504\n",
      "Epoch 23/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3619 - acc: 0.8454 - val_loss: 0.3876 - val_acc: 0.8413\n",
      "Epoch 24/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3504 - acc: 0.8515 - val_loss: 0.3804 - val_acc: 0.8431\n",
      "Epoch 25/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3522 - acc: 0.8517 - val_loss: 0.3686 - val_acc: 0.8471\n",
      "Epoch 26/80\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3493 - acc: 0.8517 - val_loss: 0.3585 - val_acc: 0.8490\n",
      "Epoch 27/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3435 - acc: 0.8547 - val_loss: 0.3544 - val_acc: 0.8481\n",
      "Epoch 28/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3355 - acc: 0.8587 - val_loss: 0.3547 - val_acc: 0.8589\n",
      "Epoch 29/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3504 - acc: 0.8535 - val_loss: 0.3593 - val_acc: 0.8523\n",
      "Epoch 30/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3409 - acc: 0.8571 - val_loss: 0.3596 - val_acc: 0.8569\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3461 - acc: 0.8512 - val_loss: 0.3573 - val_acc: 0.8516\n",
      "Epoch 32/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3457 - acc: 0.8535 - val_loss: 0.3757 - val_acc: 0.8505\n",
      "Epoch 33/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3400 - acc: 0.8565 - val_loss: 0.3403 - val_acc: 0.8563\n",
      "Epoch 34/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3401 - acc: 0.8552 - val_loss: 0.3532 - val_acc: 0.8532\n",
      "Epoch 35/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3360 - acc: 0.8572 - val_loss: 0.3349 - val_acc: 0.8606\n",
      "Epoch 36/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3418 - acc: 0.8538 - val_loss: 0.3391 - val_acc: 0.8589\n",
      "Epoch 37/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3359 - acc: 0.8589 - val_loss: 0.3501 - val_acc: 0.8587\n",
      "Epoch 38/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3376 - acc: 0.8593 - val_loss: 0.4208 - val_acc: 0.8241\n",
      "Epoch 39/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3337 - acc: 0.8580 - val_loss: 0.3405 - val_acc: 0.8604\n",
      "Epoch 40/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3389 - acc: 0.8580 - val_loss: 0.3611 - val_acc: 0.8548\n",
      "Epoch 41/80\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 0.3362 - acc: 0.8582 - val_loss: 0.3583 - val_acc: 0.8520\n",
      "Epoch 42/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3271 - acc: 0.8601 - val_loss: 0.3447 - val_acc: 0.8615\n",
      "Epoch 43/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3442 - acc: 0.8548 - val_loss: 0.3784 - val_acc: 0.8521\n",
      "Epoch 44/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3392 - acc: 0.8566 - val_loss: 0.3488 - val_acc: 0.8598\n",
      "Epoch 45/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3293 - acc: 0.8600 - val_loss: 0.3645 - val_acc: 0.8477\n",
      "Epoch 46/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3202 - acc: 0.8661 - val_loss: 0.3718 - val_acc: 0.8497\n",
      "Epoch 47/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3282 - acc: 0.8614 - val_loss: 0.3434 - val_acc: 0.8619\n",
      "Epoch 48/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3237 - acc: 0.8648 - val_loss: 0.3517 - val_acc: 0.8566\n",
      "Epoch 49/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3304 - acc: 0.8635 - val_loss: 0.3578 - val_acc: 0.8613\n",
      "Epoch 50/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3360 - acc: 0.8583 - val_loss: 0.3391 - val_acc: 0.8607\n",
      "Epoch 51/80\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.3257 - acc: 0.8629 - val_loss: 0.3708 - val_acc: 0.8473\n",
      "Epoch 52/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3258 - acc: 0.8622 - val_loss: 0.3371 - val_acc: 0.8630\n",
      "Epoch 53/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3200 - acc: 0.8638 - val_loss: 0.3980 - val_acc: 0.8315\n",
      "Epoch 54/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3238 - acc: 0.8635 - val_loss: 0.3509 - val_acc: 0.8567\n",
      "Epoch 55/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3255 - acc: 0.8639 - val_loss: 0.3314 - val_acc: 0.8657\n",
      "Epoch 56/80\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3276 - acc: 0.8622 - val_loss: 0.3671 - val_acc: 0.8489\n",
      "Epoch 57/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3319 - acc: 0.8598 - val_loss: 0.3601 - val_acc: 0.8586\n",
      "Epoch 58/80\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 0.3292 - acc: 0.8610 - val_loss: 0.3476 - val_acc: 0.8592\n",
      "Epoch 59/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3198 - acc: 0.8650 - val_loss: 0.3635 - val_acc: 0.8474\n",
      "Epoch 60/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3223 - acc: 0.8645 - val_loss: 0.3570 - val_acc: 0.8606\n",
      "Epoch 61/80\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3293 - acc: 0.8614 - val_loss: 0.3724 - val_acc: 0.8533\n",
      "Epoch 62/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3167 - acc: 0.8673 - val_loss: 0.3456 - val_acc: 0.8571\n",
      "Epoch 63/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3236 - acc: 0.8629 - val_loss: 0.3507 - val_acc: 0.8605\n",
      "Epoch 64/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3171 - acc: 0.8635 - val_loss: 0.3344 - val_acc: 0.8617\n",
      "Epoch 65/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3211 - acc: 0.8641 - val_loss: 0.3552 - val_acc: 0.8524\n",
      "Epoch 66/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3174 - acc: 0.8657 - val_loss: 0.3623 - val_acc: 0.8492\n",
      "Epoch 67/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3203 - acc: 0.8645 - val_loss: 0.4153 - val_acc: 0.8264\n",
      "Epoch 68/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3246 - acc: 0.8638 - val_loss: 0.3476 - val_acc: 0.8600\n",
      "Epoch 69/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3257 - acc: 0.8621 - val_loss: 0.3457 - val_acc: 0.8604\n",
      "Epoch 70/80\n",
      "110/110 [==============================] - 14s 123ms/step - loss: 0.3132 - acc: 0.8697 - val_loss: 0.3477 - val_acc: 0.8552\n",
      "Epoch 71/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3239 - acc: 0.8660 - val_loss: 0.3324 - val_acc: 0.8602\n",
      "Epoch 72/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3318 - acc: 0.8560 - val_loss: 0.3398 - val_acc: 0.8640\n",
      "Epoch 73/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3156 - acc: 0.8641 - val_loss: 0.3443 - val_acc: 0.8537\n",
      "Epoch 74/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3138 - acc: 0.8671 - val_loss: 0.3537 - val_acc: 0.8594\n",
      "Epoch 75/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3168 - acc: 0.8684 - val_loss: 0.3328 - val_acc: 0.8613\n",
      "Epoch 76/80\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 0.3157 - acc: 0.8680 - val_loss: 0.3181 - val_acc: 0.8707\n",
      "Epoch 77/80\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3155 - acc: 0.8667 - val_loss: 0.3334 - val_acc: 0.8625\n",
      "Epoch 78/80\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.3169 - acc: 0.8648 - val_loss: 0.3233 - val_acc: 0.8627\n",
      "Epoch 79/80\n",
      "110/110 [==============================] - 14s 124ms/step - loss: 0.3090 - acc: 0.8673 - val_loss: 0.3212 - val_acc: 0.8637\n",
      "Epoch 80/80\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.3135 - acc: 0.8699 - val_loss: 0.3418 - val_acc: 0.8619\n",
      "\n",
      "Training process completed in: 0 h 18 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1174.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1176 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 10\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 14s 76ms/step - loss: 0.4872 - acc: 0.7736 - val_loss: 0.4581 - val_acc: 0.8152\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.4200 - acc: 0.8196 - val_loss: 0.4495 - val_acc: 0.8159\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.4161 - acc: 0.8233 - val_loss: 0.4101 - val_acc: 0.8250\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.4001 - acc: 0.8270 - val_loss: 0.3857 - val_acc: 0.8304\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3857 - acc: 0.8319 - val_loss: 0.3802 - val_acc: 0.8365\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3789 - acc: 0.8373 - val_loss: 0.3727 - val_acc: 0.8410\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3776 - acc: 0.8357 - val_loss: 0.4581 - val_acc: 0.8272\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3726 - acc: 0.8403 - val_loss: 0.3473 - val_acc: 0.8433\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3602 - acc: 0.8446 - val_loss: 0.3744 - val_acc: 0.8326\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3681 - acc: 0.8408 - val_loss: 0.3752 - val_acc: 0.8443\n",
      "\n",
      "Training process completed in: 0 h 2 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1175.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1177 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.4758 - acc: 0.7847 - val_loss: 0.4469 - val_acc: 0.8005\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4128 - acc: 0.8226 - val_loss: 0.3983 - val_acc: 0.8299\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.4019 - acc: 0.8285 - val_loss: 0.4325 - val_acc: 0.8254\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.4089 - acc: 0.8241 - val_loss: 0.3934 - val_acc: 0.8285\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3912 - acc: 0.8316 - val_loss: 0.4091 - val_acc: 0.8299\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3860 - acc: 0.8364 - val_loss: 0.4106 - val_acc: 0.8333\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3792 - acc: 0.8383 - val_loss: 0.3964 - val_acc: 0.8383\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 13s 67ms/step - loss: 0.3838 - acc: 0.8377 - val_loss: 0.3968 - val_acc: 0.8412\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3705 - acc: 0.8418 - val_loss: 0.4018 - val_acc: 0.8246\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3626 - acc: 0.8451 - val_loss: 0.3595 - val_acc: 0.8487\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3665 - acc: 0.8418 - val_loss: 0.3787 - val_acc: 0.8321\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3659 - acc: 0.8464 - val_loss: 0.3801 - val_acc: 0.8468\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3649 - acc: 0.8427 - val_loss: 0.3580 - val_acc: 0.8503\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3548 - acc: 0.8488 - val_loss: 0.3606 - val_acc: 0.8538\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3567 - acc: 0.8504 - val_loss: 0.4006 - val_acc: 0.8368\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3552 - acc: 0.8477 - val_loss: 0.3554 - val_acc: 0.8565\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3538 - acc: 0.8515 - val_loss: 0.3509 - val_acc: 0.8537\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3527 - acc: 0.8501 - val_loss: 0.3532 - val_acc: 0.8461\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3364 - acc: 0.8588 - val_loss: 0.3396 - val_acc: 0.8572\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3506 - acc: 0.8517 - val_loss: 0.3512 - val_acc: 0.8597\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3379 - acc: 0.8568 - val_loss: 0.3316 - val_acc: 0.8621\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3370 - acc: 0.8577 - val_loss: 0.3357 - val_acc: 0.8571\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3332 - acc: 0.8583 - val_loss: 0.3367 - val_acc: 0.8589\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3356 - acc: 0.8595 - val_loss: 0.3426 - val_acc: 0.8607\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3388 - acc: 0.8555 - val_loss: 0.3362 - val_acc: 0.8561\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3379 - acc: 0.8568 - val_loss: 0.3373 - val_acc: 0.8583\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3291 - acc: 0.8630 - val_loss: 0.3338 - val_acc: 0.8555\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3346 - acc: 0.8568 - val_loss: 0.3321 - val_acc: 0.8581\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3269 - acc: 0.8625 - val_loss: 0.3322 - val_acc: 0.8588\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3265 - acc: 0.8628 - val_loss: 0.3261 - val_acc: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3287 - acc: 0.8612 - val_loss: 0.3435 - val_acc: 0.8548\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3288 - acc: 0.8631 - val_loss: 0.3260 - val_acc: 0.8628\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3315 - acc: 0.8598 - val_loss: 0.3341 - val_acc: 0.8606\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3247 - acc: 0.8630 - val_loss: 0.3251 - val_acc: 0.8674\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3274 - acc: 0.8616 - val_loss: 0.3258 - val_acc: 0.8617\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3231 - acc: 0.8614 - val_loss: 0.3380 - val_acc: 0.8599\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3255 - acc: 0.8637 - val_loss: 0.3473 - val_acc: 0.8496\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3237 - acc: 0.8652 - val_loss: 0.3219 - val_acc: 0.8651\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3208 - acc: 0.8650 - val_loss: 0.3442 - val_acc: 0.8538\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3225 - acc: 0.8656 - val_loss: 0.3206 - val_acc: 0.8669\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3192 - acc: 0.8649 - val_loss: 0.3277 - val_acc: 0.8634\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3191 - acc: 0.8633 - val_loss: 0.3238 - val_acc: 0.8628\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3140 - acc: 0.8670 - val_loss: 0.3456 - val_acc: 0.8534\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3215 - acc: 0.8626 - val_loss: 0.3378 - val_acc: 0.8637\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3072 - acc: 0.8715 - val_loss: 0.3064 - val_acc: 0.8727\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3121 - acc: 0.8699 - val_loss: 0.3211 - val_acc: 0.8643\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3172 - acc: 0.8680 - val_loss: 0.3344 - val_acc: 0.8574\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3203 - acc: 0.8621 - val_loss: 0.3223 - val_acc: 0.8682\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3180 - acc: 0.8675 - val_loss: 0.3130 - val_acc: 0.8687\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3156 - acc: 0.8668 - val_loss: 0.3122 - val_acc: 0.8713\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3144 - acc: 0.8671 - val_loss: 0.3406 - val_acc: 0.8502\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3151 - acc: 0.8658 - val_loss: 0.3260 - val_acc: 0.8619\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3020 - acc: 0.8762 - val_loss: 0.3281 - val_acc: 0.8582\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3200 - acc: 0.8648 - val_loss: 0.3437 - val_acc: 0.8533\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3091 - acc: 0.8706 - val_loss: 0.3086 - val_acc: 0.8746\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3134 - acc: 0.8667 - val_loss: 0.3335 - val_acc: 0.8615\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3174 - acc: 0.8647 - val_loss: 0.3317 - val_acc: 0.8617\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3116 - acc: 0.8699 - val_loss: 0.3097 - val_acc: 0.8742\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3114 - acc: 0.8691 - val_loss: 0.3266 - val_acc: 0.8604\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3062 - acc: 0.8693 - val_loss: 0.3113 - val_acc: 0.8695\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3055 - acc: 0.8712 - val_loss: 0.3326 - val_acc: 0.8586\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3067 - acc: 0.8708 - val_loss: 0.3329 - val_acc: 0.8630\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3039 - acc: 0.8729 - val_loss: 0.3234 - val_acc: 0.8591\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3144 - acc: 0.8670 - val_loss: 0.3193 - val_acc: 0.8676\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3078 - acc: 0.8718 - val_loss: 0.3145 - val_acc: 0.8688\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2988 - acc: 0.8747 - val_loss: 0.3158 - val_acc: 0.8705\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3091 - acc: 0.8704 - val_loss: 0.3116 - val_acc: 0.8685\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3052 - acc: 0.8708 - val_loss: 0.3165 - val_acc: 0.8674\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3023 - acc: 0.8744 - val_loss: 0.3184 - val_acc: 0.8666\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3075 - acc: 0.8711 - val_loss: 0.3419 - val_acc: 0.8478\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3022 - acc: 0.8747 - val_loss: 0.3145 - val_acc: 0.8649\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3093 - acc: 0.8691 - val_loss: 0.3174 - val_acc: 0.8676\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3024 - acc: 0.8721 - val_loss: 0.3231 - val_acc: 0.8659\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3066 - acc: 0.8705 - val_loss: 0.3126 - val_acc: 0.8686\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.2950 - acc: 0.8772 - val_loss: 0.3072 - val_acc: 0.8736\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 14s 73ms/step - loss: 0.3026 - acc: 0.8716 - val_loss: 0.3200 - val_acc: 0.8633\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.2973 - acc: 0.8764 - val_loss: 0.3077 - val_acc: 0.8729\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 14s 73ms/step - loss: 0.3071 - acc: 0.8713 - val_loss: 0.3292 - val_acc: 0.8589\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.2991 - acc: 0.8751 - val_loss: 0.3157 - val_acc: 0.8682\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3010 - acc: 0.8735 - val_loss: 0.3389 - val_acc: 0.8516\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.3070 - acc: 0.8697 - val_loss: 0.3211 - val_acc: 0.8629\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.2945 - acc: 0.8770 - val_loss: 0.3066 - val_acc: 0.8754\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3011 - acc: 0.8738 - val_loss: 0.3172 - val_acc: 0.8695\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.3020 - acc: 0.8717 - val_loss: 0.3091 - val_acc: 0.8704\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 14s 71ms/step - loss: 0.2983 - acc: 0.8740 - val_loss: 0.3199 - val_acc: 0.8652\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.2949 - acc: 0.8774 - val_loss: 0.3154 - val_acc: 0.8656\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3016 - acc: 0.8731 - val_loss: 0.3079 - val_acc: 0.8722\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 14s 76ms/step - loss: 0.2889 - acc: 0.8824 - val_loss: 0.3153 - val_acc: 0.8679\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.2990 - acc: 0.8752 - val_loss: 0.3153 - val_acc: 0.8693\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3036 - acc: 0.8716 - val_loss: 0.3061 - val_acc: 0.8745\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2981 - acc: 0.8762 - val_loss: 0.3244 - val_acc: 0.8585\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2928 - acc: 0.8785 - val_loss: 0.3130 - val_acc: 0.8691\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.2959 - acc: 0.8750 - val_loss: 0.3176 - val_acc: 0.8693\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2948 - acc: 0.8753 - val_loss: 0.3178 - val_acc: 0.8682\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2947 - acc: 0.8762 - val_loss: 0.2998 - val_acc: 0.8760\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2914 - acc: 0.8788 - val_loss: 0.3113 - val_acc: 0.8682\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2974 - acc: 0.8762 - val_loss: 0.3223 - val_acc: 0.8688\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.2998 - acc: 0.8726 - val_loss: 0.3109 - val_acc: 0.8715\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2960 - acc: 0.8742 - val_loss: 0.3135 - val_acc: 0.8731\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.2911 - acc: 0.8786 - val_loss: 0.3079 - val_acc: 0.8741\n",
      "\n",
      "Training process completed in: 0 h 22 m 1 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1176.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1178 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.5290 - acc: 0.7486 - val_loss: 0.5311 - val_acc: 0.7503\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.4490 - acc: 0.8086 - val_loss: 0.4385 - val_acc: 0.8033\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.4209 - acc: 0.8195 - val_loss: 0.4416 - val_acc: 0.8233\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.4242 - acc: 0.8180 - val_loss: 0.4209 - val_acc: 0.8123\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.4129 - acc: 0.8266 - val_loss: 0.4007 - val_acc: 0.8284\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.4019 - acc: 0.8279 - val_loss: 0.4216 - val_acc: 0.8302\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.4024 - acc: 0.8279 - val_loss: 0.3931 - val_acc: 0.8295\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3947 - acc: 0.8316 - val_loss: 0.4063 - val_acc: 0.8297\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.4048 - acc: 0.8197 - val_loss: 0.3985 - val_acc: 0.8378\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.4005 - acc: 0.8264 - val_loss: 0.4163 - val_acc: 0.8259\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3927 - acc: 0.8307 - val_loss: 0.4058 - val_acc: 0.8270\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3890 - acc: 0.8338 - val_loss: 0.4085 - val_acc: 0.8403\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3834 - acc: 0.8369 - val_loss: 0.3740 - val_acc: 0.8342\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3805 - acc: 0.8406 - val_loss: 0.3850 - val_acc: 0.8282\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.3854 - acc: 0.8368 - val_loss: 0.3974 - val_acc: 0.8356\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.3948 - acc: 0.8300 - val_loss: 0.4122 - val_acc: 0.8373\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.3732 - acc: 0.8399 - val_loss: 0.3868 - val_acc: 0.8408\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3819 - acc: 0.8373 - val_loss: 0.4346 - val_acc: 0.8307\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3736 - acc: 0.8391 - val_loss: 0.4190 - val_acc: 0.8405\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3798 - acc: 0.8397 - val_loss: 0.3704 - val_acc: 0.8453\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3767 - acc: 0.8351 - val_loss: 0.3905 - val_acc: 0.8402\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 0.3755 - acc: 0.8364 - val_loss: 0.3821 - val_acc: 0.8378\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3660 - acc: 0.8428 - val_loss: 0.3860 - val_acc: 0.8423\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3573 - acc: 0.8450 - val_loss: 0.3596 - val_acc: 0.8489\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3609 - acc: 0.8458 - val_loss: 0.4160 - val_acc: 0.8431\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3670 - acc: 0.8413 - val_loss: 0.3703 - val_acc: 0.8512\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 0.3557 - acc: 0.8502 - val_loss: 0.3719 - val_acc: 0.8539\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3505 - acc: 0.8518 - val_loss: 0.3648 - val_acc: 0.8444\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3556 - acc: 0.8488 - val_loss: 0.3841 - val_acc: 0.8450\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3656 - acc: 0.8431 - val_loss: 0.3623 - val_acc: 0.8503\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3526 - acc: 0.8495 - val_loss: 0.3481 - val_acc: 0.8553\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3523 - acc: 0.8516 - val_loss: 0.4116 - val_acc: 0.8231\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3458 - acc: 0.8559 - val_loss: 0.3500 - val_acc: 0.8491\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3476 - acc: 0.8521 - val_loss: 0.3680 - val_acc: 0.8345\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3567 - acc: 0.8475 - val_loss: 0.3562 - val_acc: 0.8454\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3468 - acc: 0.8522 - val_loss: 0.3646 - val_acc: 0.8547\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3535 - acc: 0.8477 - val_loss: 0.3595 - val_acc: 0.8467\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3462 - acc: 0.8553 - val_loss: 0.3352 - val_acc: 0.8634\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3479 - acc: 0.8537 - val_loss: 0.3499 - val_acc: 0.8570\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 0.3494 - acc: 0.8498 - val_loss: 0.3394 - val_acc: 0.8601\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3575 - acc: 0.8492 - val_loss: 0.3612 - val_acc: 0.8381\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3382 - acc: 0.8544 - val_loss: 0.3571 - val_acc: 0.8517\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3409 - acc: 0.8544 - val_loss: 0.3414 - val_acc: 0.8547\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.3420 - acc: 0.8523 - val_loss: 0.3532 - val_acc: 0.8525\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3375 - acc: 0.8552 - val_loss: 0.3480 - val_acc: 0.8559\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3453 - acc: 0.8515 - val_loss: 0.3552 - val_acc: 0.8505\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3394 - acc: 0.8549 - val_loss: 0.4145 - val_acc: 0.8303\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3445 - acc: 0.8559 - val_loss: 0.3440 - val_acc: 0.8559\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3446 - acc: 0.8562 - val_loss: 0.3642 - val_acc: 0.8573\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3424 - acc: 0.8555 - val_loss: 0.3488 - val_acc: 0.8608\n",
      "\n",
      "Training process completed in: 0 h 4 m 55 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1177.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1179 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "190/190 [==============================] - 8s 41ms/step - loss: 0.5049 - acc: 0.7641 - val_loss: 0.4327 - val_acc: 0.8079\n",
      "Epoch 2/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4345 - acc: 0.8142 - val_loss: 0.4154 - val_acc: 0.8229\n",
      "Epoch 3/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4124 - acc: 0.8259 - val_loss: 0.4327 - val_acc: 0.8188\n",
      "Epoch 4/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4171 - acc: 0.8186 - val_loss: 0.4233 - val_acc: 0.8142\n",
      "Epoch 5/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4021 - acc: 0.8307 - val_loss: 0.3947 - val_acc: 0.8263\n",
      "Epoch 6/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3988 - acc: 0.8293 - val_loss: 0.4071 - val_acc: 0.8137\n",
      "Epoch 7/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3986 - acc: 0.8271 - val_loss: 0.3942 - val_acc: 0.8254\n",
      "Epoch 8/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4017 - acc: 0.8264 - val_loss: 0.3842 - val_acc: 0.8275\n",
      "Epoch 9/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3860 - acc: 0.8341 - val_loss: 0.3803 - val_acc: 0.8421\n",
      "Epoch 10/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4005 - acc: 0.8274 - val_loss: 0.4172 - val_acc: 0.8221\n",
      "Epoch 11/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3811 - acc: 0.8359 - val_loss: 0.4267 - val_acc: 0.8225\n",
      "Epoch 12/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3841 - acc: 0.8338 - val_loss: 0.4033 - val_acc: 0.8307\n",
      "Epoch 13/50\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3694 - acc: 0.8401 - val_loss: 0.3983 - val_acc: 0.8288\n",
      "Epoch 14/50\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3727 - acc: 0.8430 - val_loss: 0.3521 - val_acc: 0.8479\n",
      "Epoch 15/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3740 - acc: 0.8445 - val_loss: 0.3898 - val_acc: 0.8250\n",
      "Epoch 16/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3725 - acc: 0.8408 - val_loss: 0.3832 - val_acc: 0.8358\n",
      "Epoch 17/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3727 - acc: 0.8411 - val_loss: 0.3812 - val_acc: 0.8379\n",
      "Epoch 18/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3723 - acc: 0.8427 - val_loss: 0.3816 - val_acc: 0.8392\n",
      "Epoch 19/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3618 - acc: 0.8439 - val_loss: 0.3407 - val_acc: 0.8612\n",
      "Epoch 20/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3666 - acc: 0.8440 - val_loss: 0.3650 - val_acc: 0.8538\n",
      "Epoch 21/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3614 - acc: 0.8435 - val_loss: 0.3868 - val_acc: 0.8329\n",
      "Epoch 22/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3625 - acc: 0.8463 - val_loss: 0.3465 - val_acc: 0.8550\n",
      "Epoch 23/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3610 - acc: 0.8460 - val_loss: 0.3592 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3547 - acc: 0.8477 - val_loss: 0.3487 - val_acc: 0.8579\n",
      "Epoch 25/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3541 - acc: 0.8472 - val_loss: 0.3726 - val_acc: 0.8358\n",
      "Epoch 26/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3489 - acc: 0.8484 - val_loss: 0.3637 - val_acc: 0.8400\n",
      "Epoch 27/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3418 - acc: 0.8542 - val_loss: 0.3403 - val_acc: 0.8546\n",
      "Epoch 28/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3586 - acc: 0.8509 - val_loss: 0.3733 - val_acc: 0.8463\n",
      "Epoch 29/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3399 - acc: 0.8536 - val_loss: 0.3620 - val_acc: 0.8421\n",
      "Epoch 30/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3482 - acc: 0.8509 - val_loss: 0.3486 - val_acc: 0.8508\n",
      "Epoch 31/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3478 - acc: 0.8552 - val_loss: 0.3389 - val_acc: 0.8679\n",
      "Epoch 32/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3417 - acc: 0.8552 - val_loss: 0.3518 - val_acc: 0.8483\n",
      "Epoch 33/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3435 - acc: 0.8534 - val_loss: 0.3383 - val_acc: 0.8558\n",
      "Epoch 34/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3479 - acc: 0.8505 - val_loss: 0.3395 - val_acc: 0.8596\n",
      "Epoch 35/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3371 - acc: 0.8588 - val_loss: 0.3476 - val_acc: 0.8591\n",
      "Epoch 36/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3469 - acc: 0.8522 - val_loss: 0.3518 - val_acc: 0.8500\n",
      "Epoch 37/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3363 - acc: 0.8557 - val_loss: 0.3803 - val_acc: 0.8496\n",
      "Epoch 38/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3431 - acc: 0.8542 - val_loss: 0.3276 - val_acc: 0.8704\n",
      "Epoch 39/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3451 - acc: 0.8513 - val_loss: 0.3528 - val_acc: 0.8579\n",
      "Epoch 40/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3452 - acc: 0.8527 - val_loss: 0.3488 - val_acc: 0.8521\n",
      "Epoch 41/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3424 - acc: 0.8551 - val_loss: 0.3369 - val_acc: 0.8617\n",
      "Epoch 42/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3337 - acc: 0.8581 - val_loss: 0.3555 - val_acc: 0.8546\n",
      "Epoch 43/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3333 - acc: 0.8599 - val_loss: 0.3848 - val_acc: 0.8371\n",
      "Epoch 44/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3331 - acc: 0.8569 - val_loss: 0.3464 - val_acc: 0.8512\n",
      "Epoch 45/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3322 - acc: 0.8584 - val_loss: 0.3270 - val_acc: 0.8604\n",
      "Epoch 46/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3265 - acc: 0.8629 - val_loss: 0.3396 - val_acc: 0.8583\n",
      "Epoch 47/50\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3389 - acc: 0.8568 - val_loss: 0.3229 - val_acc: 0.8704\n",
      "Epoch 48/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3398 - acc: 0.8541 - val_loss: 0.3370 - val_acc: 0.8646\n",
      "Epoch 49/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3380 - acc: 0.8568 - val_loss: 0.3449 - val_acc: 0.8629\n",
      "Epoch 50/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3335 - acc: 0.8588 - val_loss: 0.2930 - val_acc: 0.8846\n",
      "\n",
      "Training process completed in: 0 h 5 m 13 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1178.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1180 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.5092 - acc: 0.7620 - val_loss: 0.4200 - val_acc: 0.8261\n",
      "Epoch 2/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.4110 - acc: 0.8253 - val_loss: 0.3975 - val_acc: 0.8296\n",
      "Epoch 3/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.4077 - acc: 0.8245 - val_loss: 0.3963 - val_acc: 0.8274\n",
      "Epoch 4/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.4020 - acc: 0.8286 - val_loss: 0.3911 - val_acc: 0.8246\n",
      "Epoch 5/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3856 - acc: 0.8352 - val_loss: 0.4012 - val_acc: 0.8354\n",
      "Epoch 6/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3863 - acc: 0.8348 - val_loss: 0.4108 - val_acc: 0.8363\n",
      "Epoch 7/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3810 - acc: 0.8384 - val_loss: 0.3761 - val_acc: 0.8406\n",
      "Epoch 8/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3812 - acc: 0.8373 - val_loss: 0.3716 - val_acc: 0.8384\n",
      "Epoch 9/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3750 - acc: 0.8382 - val_loss: 0.3706 - val_acc: 0.8416\n",
      "Epoch 10/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3682 - acc: 0.8444 - val_loss: 0.3586 - val_acc: 0.8439\n",
      "Epoch 11/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3666 - acc: 0.8435 - val_loss: 0.3786 - val_acc: 0.8270\n",
      "Epoch 12/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3667 - acc: 0.8456 - val_loss: 0.3708 - val_acc: 0.8459\n",
      "Epoch 13/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3608 - acc: 0.8475 - val_loss: 0.3563 - val_acc: 0.8520\n",
      "Epoch 14/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3598 - acc: 0.8472 - val_loss: 0.3849 - val_acc: 0.8403\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3580 - acc: 0.8470 - val_loss: 0.3537 - val_acc: 0.8539\n",
      "Epoch 16/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3500 - acc: 0.8511 - val_loss: 0.3438 - val_acc: 0.8578\n",
      "Epoch 17/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3489 - acc: 0.8517 - val_loss: 0.3426 - val_acc: 0.8576\n",
      "Epoch 18/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3492 - acc: 0.8501 - val_loss: 0.3581 - val_acc: 0.8496\n",
      "Epoch 19/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3404 - acc: 0.8539 - val_loss: 0.3443 - val_acc: 0.8554\n",
      "Epoch 20/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3423 - acc: 0.8546 - val_loss: 0.3717 - val_acc: 0.8468\n",
      "Epoch 21/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3446 - acc: 0.8515 - val_loss: 0.3729 - val_acc: 0.8340\n",
      "Epoch 22/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3395 - acc: 0.8559 - val_loss: 0.3350 - val_acc: 0.8583\n",
      "Epoch 23/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3384 - acc: 0.8560 - val_loss: 0.3570 - val_acc: 0.8537\n",
      "Epoch 24/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3400 - acc: 0.8562 - val_loss: 0.3433 - val_acc: 0.8553\n",
      "Epoch 25/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3428 - acc: 0.8567 - val_loss: 0.3431 - val_acc: 0.8554\n",
      "Epoch 26/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3253 - acc: 0.8600 - val_loss: 0.3363 - val_acc: 0.8571\n",
      "Epoch 27/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3290 - acc: 0.8640 - val_loss: 0.3671 - val_acc: 0.8396\n",
      "Epoch 28/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3361 - acc: 0.8583 - val_loss: 0.3330 - val_acc: 0.8609\n",
      "Epoch 29/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3298 - acc: 0.8607 - val_loss: 0.3424 - val_acc: 0.8581\n",
      "Epoch 30/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3342 - acc: 0.8594 - val_loss: 0.3513 - val_acc: 0.8526\n",
      "Epoch 31/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3326 - acc: 0.8592 - val_loss: 0.3446 - val_acc: 0.8584\n",
      "Epoch 32/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3304 - acc: 0.8599 - val_loss: 0.3345 - val_acc: 0.8585\n",
      "Epoch 33/50\n",
      "190/190 [==============================] - 11s 60ms/step - loss: 0.3288 - acc: 0.8613 - val_loss: 0.3464 - val_acc: 0.8649\n",
      "Epoch 34/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3251 - acc: 0.8618 - val_loss: 0.3337 - val_acc: 0.8641\n",
      "Epoch 35/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3302 - acc: 0.8587 - val_loss: 0.3298 - val_acc: 0.8649\n",
      "Epoch 36/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3282 - acc: 0.8611 - val_loss: 0.3461 - val_acc: 0.8514\n",
      "Epoch 37/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3270 - acc: 0.8608 - val_loss: 0.3231 - val_acc: 0.8661\n",
      "Epoch 38/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3306 - acc: 0.8593 - val_loss: 0.3414 - val_acc: 0.8474\n",
      "Epoch 39/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3253 - acc: 0.8627 - val_loss: 0.3182 - val_acc: 0.8680\n",
      "Epoch 40/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3179 - acc: 0.8659 - val_loss: 0.3290 - val_acc: 0.8633\n",
      "Epoch 41/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3244 - acc: 0.8635 - val_loss: 0.3383 - val_acc: 0.8619\n",
      "Epoch 42/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.3198 - acc: 0.8648 - val_loss: 0.3165 - val_acc: 0.8686\n",
      "Epoch 43/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3225 - acc: 0.8659 - val_loss: 0.3252 - val_acc: 0.8616\n",
      "Epoch 44/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3216 - acc: 0.8650 - val_loss: 0.3513 - val_acc: 0.8519\n",
      "Epoch 45/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3290 - acc: 0.8610 - val_loss: 0.3346 - val_acc: 0.8621\n",
      "Epoch 46/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3200 - acc: 0.8655 - val_loss: 0.3306 - val_acc: 0.8593\n",
      "Epoch 47/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3164 - acc: 0.8671 - val_loss: 0.3177 - val_acc: 0.8674\n",
      "Epoch 48/50\n",
      "190/190 [==============================] - 12s 61ms/step - loss: 0.3195 - acc: 0.8630 - val_loss: 0.3415 - val_acc: 0.8508\n",
      "Epoch 49/50\n",
      "190/190 [==============================] - 11s 60ms/step - loss: 0.3145 - acc: 0.8664 - val_loss: 0.3292 - val_acc: 0.8564\n",
      "Epoch 50/50\n",
      "190/190 [==============================] - 11s 60ms/step - loss: 0.3092 - acc: 0.8698 - val_loss: 0.3128 - val_acc: 0.8707\n",
      "\n",
      "Training process completed in: 0 h 9 m 43 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1179.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1181 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 100\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5873 - acc: 0.7073 - val_loss: 0.5500 - val_acc: 0.7200\n",
      "Epoch 2/70\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.4909 - acc: 0.7614 - val_loss: 0.4415 - val_acc: 0.8075\n",
      "Epoch 3/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.4224 - acc: 0.8163 - val_loss: 0.4196 - val_acc: 0.8163\n",
      "Epoch 4/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4220 - acc: 0.8204 - val_loss: 0.4113 - val_acc: 0.8200\n",
      "Epoch 5/70\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.4272 - acc: 0.8171 - val_loss: 0.4247 - val_acc: 0.8145\n",
      "Epoch 6/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4165 - acc: 0.8212 - val_loss: 0.4114 - val_acc: 0.8174\n",
      "Epoch 7/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4168 - acc: 0.8185 - val_loss: 0.4062 - val_acc: 0.8238\n",
      "Epoch 8/70\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.4081 - acc: 0.8212 - val_loss: 0.4049 - val_acc: 0.8243\n",
      "Epoch 9/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4071 - acc: 0.8243 - val_loss: 0.4106 - val_acc: 0.8226\n",
      "Epoch 10/70\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.4183 - acc: 0.8176 - val_loss: 0.4069 - val_acc: 0.8214\n",
      "Epoch 11/70\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.4035 - acc: 0.8274 - val_loss: 0.3989 - val_acc: 0.8288\n",
      "Epoch 12/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3929 - acc: 0.8332 - val_loss: 0.4097 - val_acc: 0.8256\n",
      "Epoch 13/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.4007 - acc: 0.8251 - val_loss: 0.4075 - val_acc: 0.8240\n",
      "Epoch 14/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4087 - acc: 0.8246 - val_loss: 0.4035 - val_acc: 0.8264\n",
      "Epoch 15/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3945 - acc: 0.8282 - val_loss: 0.3990 - val_acc: 0.8271\n",
      "Epoch 16/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3890 - acc: 0.8319 - val_loss: 0.3895 - val_acc: 0.8307\n",
      "Epoch 17/70\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3844 - acc: 0.8370 - val_loss: 0.4000 - val_acc: 0.8247\n",
      "Epoch 18/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3897 - acc: 0.8319 - val_loss: 0.3917 - val_acc: 0.8285\n",
      "Epoch 19/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.4066 - acc: 0.8265 - val_loss: 0.3985 - val_acc: 0.8250\n",
      "Epoch 20/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3912 - acc: 0.8302 - val_loss: 0.3894 - val_acc: 0.8312\n",
      "Epoch 21/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3860 - acc: 0.8311 - val_loss: 0.4133 - val_acc: 0.8272\n",
      "Epoch 22/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3955 - acc: 0.8288 - val_loss: 0.3927 - val_acc: 0.8287\n",
      "Epoch 23/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3905 - acc: 0.8326 - val_loss: 0.3894 - val_acc: 0.8278\n",
      "Epoch 24/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3871 - acc: 0.8363 - val_loss: 0.3777 - val_acc: 0.8354\n",
      "Epoch 25/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3838 - acc: 0.8341 - val_loss: 0.4084 - val_acc: 0.8286\n",
      "Epoch 26/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3841 - acc: 0.8338 - val_loss: 0.3780 - val_acc: 0.8381\n",
      "Epoch 27/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3741 - acc: 0.8408 - val_loss: 0.4011 - val_acc: 0.8271\n",
      "Epoch 28/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3834 - acc: 0.8334 - val_loss: 0.3855 - val_acc: 0.8338\n",
      "Epoch 29/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3796 - acc: 0.8347 - val_loss: 0.3800 - val_acc: 0.8393\n",
      "Epoch 30/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3748 - acc: 0.8362 - val_loss: 0.3679 - val_acc: 0.8389\n",
      "Epoch 31/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3737 - acc: 0.8397 - val_loss: 0.3874 - val_acc: 0.8238\n",
      "Epoch 32/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3720 - acc: 0.8374 - val_loss: 0.3722 - val_acc: 0.8367\n",
      "Epoch 33/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3787 - acc: 0.8364 - val_loss: 0.3731 - val_acc: 0.8355\n",
      "Epoch 34/70\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.3680 - acc: 0.8403 - val_loss: 0.3778 - val_acc: 0.8398\n",
      "Epoch 35/70\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.3702 - acc: 0.8404 - val_loss: 0.3839 - val_acc: 0.8370\n",
      "Epoch 36/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3689 - acc: 0.8404 - val_loss: 0.3696 - val_acc: 0.8387\n",
      "Epoch 37/70\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3734 - acc: 0.8367 - val_loss: 0.3815 - val_acc: 0.8386\n",
      "Epoch 38/70\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.3697 - acc: 0.8406 - val_loss: 0.3716 - val_acc: 0.8397\n",
      "Epoch 39/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3635 - acc: 0.8463 - val_loss: 0.3597 - val_acc: 0.8447\n",
      "Epoch 40/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3655 - acc: 0.8406 - val_loss: 0.3750 - val_acc: 0.8359\n",
      "Epoch 41/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3673 - acc: 0.8418 - val_loss: 0.3611 - val_acc: 0.8400\n",
      "Epoch 42/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3646 - acc: 0.8420 - val_loss: 0.3656 - val_acc: 0.8394\n",
      "Epoch 43/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3663 - acc: 0.8440 - val_loss: 0.3647 - val_acc: 0.8413\n",
      "Epoch 44/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3613 - acc: 0.8432 - val_loss: 0.3574 - val_acc: 0.8447\n",
      "Epoch 45/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3643 - acc: 0.8401 - val_loss: 0.3661 - val_acc: 0.8359\n",
      "Epoch 46/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3641 - acc: 0.8421 - val_loss: 0.3693 - val_acc: 0.8438\n",
      "Epoch 47/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3590 - acc: 0.8447 - val_loss: 0.3628 - val_acc: 0.8383\n",
      "Epoch 48/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3653 - acc: 0.8391 - val_loss: 0.3601 - val_acc: 0.8477\n",
      "Epoch 49/70\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.3525 - acc: 0.8504 - val_loss: 0.3578 - val_acc: 0.8461\n",
      "Epoch 50/70\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.3495 - acc: 0.8494 - val_loss: 0.3552 - val_acc: 0.8453\n",
      "Epoch 51/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3613 - acc: 0.8438 - val_loss: 0.3567 - val_acc: 0.8421\n",
      "Epoch 52/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3533 - acc: 0.8484 - val_loss: 0.3538 - val_acc: 0.8453\n",
      "Epoch 53/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3672 - acc: 0.8424 - val_loss: 0.3567 - val_acc: 0.8470\n",
      "Epoch 54/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3618 - acc: 0.8434 - val_loss: 0.3562 - val_acc: 0.8459\n",
      "Epoch 55/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3567 - acc: 0.8459 - val_loss: 0.3532 - val_acc: 0.8512\n",
      "Epoch 56/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3524 - acc: 0.8503 - val_loss: 0.3653 - val_acc: 0.8474\n",
      "Epoch 57/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3507 - acc: 0.8517 - val_loss: 0.3548 - val_acc: 0.8488\n",
      "Epoch 58/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3395 - acc: 0.8534 - val_loss: 0.3479 - val_acc: 0.8499\n",
      "Epoch 59/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3537 - acc: 0.8471 - val_loss: 0.3593 - val_acc: 0.8474\n",
      "Epoch 60/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3530 - acc: 0.8487 - val_loss: 0.3516 - val_acc: 0.8461\n",
      "Epoch 61/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3534 - acc: 0.8487 - val_loss: 0.3576 - val_acc: 0.8508\n",
      "Epoch 62/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3421 - acc: 0.8542 - val_loss: 0.3479 - val_acc: 0.8509\n",
      "Epoch 63/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3575 - acc: 0.8481 - val_loss: 0.3460 - val_acc: 0.8515\n",
      "Epoch 64/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3539 - acc: 0.8474 - val_loss: 0.3617 - val_acc: 0.8406\n",
      "Epoch 65/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3469 - acc: 0.8509 - val_loss: 0.3441 - val_acc: 0.8527\n",
      "Epoch 66/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3463 - acc: 0.8544 - val_loss: 0.3559 - val_acc: 0.8527\n",
      "Epoch 67/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3510 - acc: 0.8502 - val_loss: 0.3546 - val_acc: 0.8444\n",
      "Epoch 68/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3438 - acc: 0.8531 - val_loss: 0.3594 - val_acc: 0.8501\n",
      "Epoch 69/70\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.3408 - acc: 0.8514 - val_loss: 0.3438 - val_acc: 0.8552\n",
      "Epoch 70/70\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3457 - acc: 0.8516 - val_loss: 0.3486 - val_acc: 0.8462\n",
      "\n",
      "Training process completed in: 0 h 14 m 11 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1180.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1182 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.5877 - acc: 0.7091 - val_loss: 0.5557 - val_acc: 0.7188\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4885 - acc: 0.7647 - val_loss: 0.4360 - val_acc: 0.8121\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.4255 - acc: 0.8180 - val_loss: 0.4156 - val_acc: 0.8205\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4102 - acc: 0.8255 - val_loss: 0.4124 - val_acc: 0.8213\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.4033 - acc: 0.8278 - val_loss: 0.4117 - val_acc: 0.8204\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4087 - acc: 0.8232 - val_loss: 0.4075 - val_acc: 0.8281\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.4074 - acc: 0.8237 - val_loss: 0.4009 - val_acc: 0.8213\n",
      "Epoch 8/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4058 - acc: 0.8251 - val_loss: 0.4009 - val_acc: 0.8282\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3986 - acc: 0.8283 - val_loss: 0.3966 - val_acc: 0.8275\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3988 - acc: 0.8299 - val_loss: 0.3987 - val_acc: 0.8254\n",
      "Epoch 11/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3958 - acc: 0.8299 - val_loss: 0.4098 - val_acc: 0.8203\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.4011 - acc: 0.8270 - val_loss: 0.3867 - val_acc: 0.8334\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3967 - acc: 0.8290 - val_loss: 0.4054 - val_acc: 0.8225\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3915 - acc: 0.8315 - val_loss: 0.3922 - val_acc: 0.8294\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3887 - acc: 0.8328 - val_loss: 0.3890 - val_acc: 0.8312\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3886 - acc: 0.8336 - val_loss: 0.3827 - val_acc: 0.8356\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3887 - acc: 0.8324 - val_loss: 0.3892 - val_acc: 0.8278\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3854 - acc: 0.8341 - val_loss: 0.3882 - val_acc: 0.8305\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3846 - acc: 0.8335 - val_loss: 0.3812 - val_acc: 0.8338\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3793 - acc: 0.8387 - val_loss: 0.3778 - val_acc: 0.8347\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3784 - acc: 0.8379 - val_loss: 0.3796 - val_acc: 0.8360\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3822 - acc: 0.8360 - val_loss: 0.3787 - val_acc: 0.8368\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3755 - acc: 0.8373 - val_loss: 0.3797 - val_acc: 0.8362\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3788 - acc: 0.8351 - val_loss: 0.3898 - val_acc: 0.8329\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3714 - acc: 0.8407 - val_loss: 0.3781 - val_acc: 0.8366\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3751 - acc: 0.8414 - val_loss: 0.3746 - val_acc: 0.8371\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3664 - acc: 0.8425 - val_loss: 0.3726 - val_acc: 0.8413\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3777 - acc: 0.8358 - val_loss: 0.3749 - val_acc: 0.8401\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3667 - acc: 0.8402 - val_loss: 0.3707 - val_acc: 0.8403\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3685 - acc: 0.8405 - val_loss: 0.3684 - val_acc: 0.8409\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3725 - acc: 0.8406 - val_loss: 0.3630 - val_acc: 0.8438\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3609 - acc: 0.8459 - val_loss: 0.3594 - val_acc: 0.8451\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3599 - acc: 0.8461 - val_loss: 0.3829 - val_acc: 0.8382\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3622 - acc: 0.8428 - val_loss: 0.3531 - val_acc: 0.8501\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3613 - acc: 0.8436 - val_loss: 0.3689 - val_acc: 0.8448\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3569 - acc: 0.8464 - val_loss: 0.3561 - val_acc: 0.8476\n",
      "Epoch 37/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3569 - acc: 0.8469 - val_loss: 0.3539 - val_acc: 0.8484\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3625 - acc: 0.8430 - val_loss: 0.3557 - val_acc: 0.8480\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3531 - acc: 0.8510 - val_loss: 0.3625 - val_acc: 0.8428\n",
      "Epoch 40/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3520 - acc: 0.8491 - val_loss: 0.3505 - val_acc: 0.8468\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3602 - acc: 0.8453 - val_loss: 0.3462 - val_acc: 0.8509\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3535 - acc: 0.8495 - val_loss: 0.3481 - val_acc: 0.8506\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3541 - acc: 0.8471 - val_loss: 0.3578 - val_acc: 0.8456\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3571 - acc: 0.8461 - val_loss: 0.3482 - val_acc: 0.8525\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 14s 91ms/step - loss: 0.3458 - acc: 0.8531 - val_loss: 0.3566 - val_acc: 0.8520\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3491 - acc: 0.8521 - val_loss: 0.3502 - val_acc: 0.8507\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3464 - acc: 0.8535 - val_loss: 0.3535 - val_acc: 0.8511\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3461 - acc: 0.8524 - val_loss: 0.3462 - val_acc: 0.8509\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3558 - acc: 0.8463 - val_loss: 0.3347 - val_acc: 0.8631\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3451 - acc: 0.8519 - val_loss: 0.3439 - val_acc: 0.8556\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3444 - acc: 0.8525 - val_loss: 0.3340 - val_acc: 0.8594\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3432 - acc: 0.8549 - val_loss: 0.3469 - val_acc: 0.8511\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3462 - acc: 0.8519 - val_loss: 0.3436 - val_acc: 0.8601\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3419 - acc: 0.8529 - val_loss: 0.3477 - val_acc: 0.8535\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3389 - acc: 0.8559 - val_loss: 0.3312 - val_acc: 0.8619\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3440 - acc: 0.8529 - val_loss: 0.3408 - val_acc: 0.8565\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3375 - acc: 0.8557 - val_loss: 0.3407 - val_acc: 0.8556\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3399 - acc: 0.8527 - val_loss: 0.3400 - val_acc: 0.8548\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 14s 87ms/step - loss: 0.3371 - acc: 0.8559 - val_loss: 0.3326 - val_acc: 0.8593\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3393 - acc: 0.8569 - val_loss: 0.3373 - val_acc: 0.8593\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3387 - acc: 0.8559 - val_loss: 0.3301 - val_acc: 0.8595\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3366 - acc: 0.8550 - val_loss: 0.3478 - val_acc: 0.8551\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3458 - acc: 0.8523 - val_loss: 0.3326 - val_acc: 0.8593\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3312 - acc: 0.8596 - val_loss: 0.3307 - val_acc: 0.8620\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3383 - acc: 0.8582 - val_loss: 0.3360 - val_acc: 0.8608\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3344 - acc: 0.8587 - val_loss: 0.3353 - val_acc: 0.8583\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3336 - acc: 0.8572 - val_loss: 0.3335 - val_acc: 0.8600\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3333 - acc: 0.8576 - val_loss: 0.3311 - val_acc: 0.8593\n",
      "Epoch 69/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3356 - acc: 0.8588 - val_loss: 0.3413 - val_acc: 0.8549\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3362 - acc: 0.8586 - val_loss: 0.3307 - val_acc: 0.8633\n",
      "\n",
      "Training process completed in: 0 h 16 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1181.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1183 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_89 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.4874 - acc: 0.7750 - val_loss: 0.4348 - val_acc: 0.8135\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4137 - acc: 0.8243 - val_loss: 0.4066 - val_acc: 0.8266\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4030 - acc: 0.8282 - val_loss: 0.3874 - val_acc: 0.8348\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3923 - acc: 0.8299 - val_loss: 0.3857 - val_acc: 0.8324\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3851 - acc: 0.8343 - val_loss: 0.3763 - val_acc: 0.8356\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3806 - acc: 0.8357 - val_loss: 0.4077 - val_acc: 0.8219\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3843 - acc: 0.8367 - val_loss: 0.3760 - val_acc: 0.8315\n",
      "Epoch 8/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3787 - acc: 0.8380 - val_loss: 0.3695 - val_acc: 0.8422\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3666 - acc: 0.8409 - val_loss: 0.3621 - val_acc: 0.8493\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3634 - acc: 0.8463 - val_loss: 0.3766 - val_acc: 0.8474\n",
      "Epoch 11/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3593 - acc: 0.8466 - val_loss: 0.3501 - val_acc: 0.8494\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3528 - acc: 0.8493 - val_loss: 0.3563 - val_acc: 0.8416\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3574 - acc: 0.8475 - val_loss: 0.3663 - val_acc: 0.8438\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3447 - acc: 0.8530 - val_loss: 0.3498 - val_acc: 0.8504\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.3593 - acc: 0.8465 - val_loss: 0.3546 - val_acc: 0.8555\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3477 - acc: 0.8507 - val_loss: 0.3343 - val_acc: 0.8603\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3377 - acc: 0.8548 - val_loss: 0.3517 - val_acc: 0.8456\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3433 - acc: 0.8517 - val_loss: 0.3520 - val_acc: 0.8554\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3400 - acc: 0.8542 - val_loss: 0.3415 - val_acc: 0.8526\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3440 - acc: 0.8556 - val_loss: 0.3490 - val_acc: 0.8527\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3361 - acc: 0.8553 - val_loss: 0.3700 - val_acc: 0.8566\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3381 - acc: 0.8570 - val_loss: 0.3253 - val_acc: 0.8611\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3300 - acc: 0.8601 - val_loss: 0.3308 - val_acc: 0.8588\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3245 - acc: 0.8636 - val_loss: 0.3288 - val_acc: 0.8641\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3309 - acc: 0.8603 - val_loss: 0.3526 - val_acc: 0.8506\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.3286 - acc: 0.8602 - val_loss: 0.3315 - val_acc: 0.8632\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3199 - acc: 0.8634 - val_loss: 0.3243 - val_acc: 0.8616\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3245 - acc: 0.8610 - val_loss: 0.3455 - val_acc: 0.8568\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3365 - acc: 0.8563 - val_loss: 0.3260 - val_acc: 0.8661\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3292 - acc: 0.8612 - val_loss: 0.3317 - val_acc: 0.8605\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3248 - acc: 0.8613 - val_loss: 0.3450 - val_acc: 0.8569\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3240 - acc: 0.8628 - val_loss: 0.3358 - val_acc: 0.8643\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3213 - acc: 0.8661 - val_loss: 0.3276 - val_acc: 0.8587\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3175 - acc: 0.8666 - val_loss: 0.3198 - val_acc: 0.8592\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3203 - acc: 0.8645 - val_loss: 0.3416 - val_acc: 0.8585\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3267 - acc: 0.8614 - val_loss: 0.3279 - val_acc: 0.8659\n",
      "Epoch 37/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3206 - acc: 0.8648 - val_loss: 0.3219 - val_acc: 0.8690\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3283 - acc: 0.8605 - val_loss: 0.3231 - val_acc: 0.8593\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3198 - acc: 0.8645 - val_loss: 0.3212 - val_acc: 0.8649\n",
      "Epoch 40/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3210 - acc: 0.8650 - val_loss: 0.3430 - val_acc: 0.8648\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3200 - acc: 0.8649 - val_loss: 0.3446 - val_acc: 0.8614\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3163 - acc: 0.8677 - val_loss: 0.3146 - val_acc: 0.8674\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3222 - acc: 0.8621 - val_loss: 0.3186 - val_acc: 0.8706\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3200 - acc: 0.8653 - val_loss: 0.3189 - val_acc: 0.8637\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3123 - acc: 0.8670 - val_loss: 0.3149 - val_acc: 0.8672\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3141 - acc: 0.8691 - val_loss: 0.3193 - val_acc: 0.8708\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3118 - acc: 0.8657 - val_loss: 0.3157 - val_acc: 0.8671\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3093 - acc: 0.8719 - val_loss: 0.3271 - val_acc: 0.8648\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3095 - acc: 0.8676 - val_loss: 0.3194 - val_acc: 0.8644\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3138 - acc: 0.8676 - val_loss: 0.3142 - val_acc: 0.8661\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3085 - acc: 0.8697 - val_loss: 0.3278 - val_acc: 0.8654\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3137 - acc: 0.8696 - val_loss: 0.3199 - val_acc: 0.8649\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3128 - acc: 0.8683 - val_loss: 0.3475 - val_acc: 0.8537\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3036 - acc: 0.8725 - val_loss: 0.3302 - val_acc: 0.8622\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3068 - acc: 0.8682 - val_loss: 0.3113 - val_acc: 0.8716\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3190 - acc: 0.8647 - val_loss: 0.3236 - val_acc: 0.8658\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3080 - acc: 0.8714 - val_loss: 0.3274 - val_acc: 0.8630\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3012 - acc: 0.8736 - val_loss: 0.3107 - val_acc: 0.8709\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3092 - acc: 0.8692 - val_loss: 0.3150 - val_acc: 0.8682\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3091 - acc: 0.8691 - val_loss: 0.3113 - val_acc: 0.8680\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3099 - acc: 0.8699 - val_loss: 0.3239 - val_acc: 0.8683\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3048 - acc: 0.8718 - val_loss: 0.3128 - val_acc: 0.8676\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3057 - acc: 0.8709 - val_loss: 0.3208 - val_acc: 0.8681\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3041 - acc: 0.8727 - val_loss: 0.3210 - val_acc: 0.8720\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.3069 - acc: 0.8711 - val_loss: 0.3198 - val_acc: 0.8659\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3090 - acc: 0.8720 - val_loss: 0.3215 - val_acc: 0.8682\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3006 - acc: 0.8745 - val_loss: 0.3105 - val_acc: 0.8709\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3005 - acc: 0.8718 - val_loss: 0.3066 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3046 - acc: 0.8718 - val_loss: 0.3418 - val_acc: 0.8580\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3078 - acc: 0.8696 - val_loss: 0.3150 - val_acc: 0.8685\n",
      "\n",
      "Training process completed in: 0 h 15 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1182.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1184 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_93 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.4957 - acc: 0.7673 - val_loss: 0.4150 - val_acc: 0.8211\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4357 - acc: 0.8124 - val_loss: 0.4483 - val_acc: 0.8166\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.4082 - acc: 0.8274 - val_loss: 0.4354 - val_acc: 0.8066\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.4013 - acc: 0.8311 - val_loss: 0.3976 - val_acc: 0.8314\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3954 - acc: 0.8311 - val_loss: 0.3883 - val_acc: 0.8319\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3836 - acc: 0.8354 - val_loss: 0.4568 - val_acc: 0.8212\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3810 - acc: 0.8362 - val_loss: 0.3867 - val_acc: 0.8383\n",
      "Epoch 8/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3964 - acc: 0.8287 - val_loss: 0.3946 - val_acc: 0.8439\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3754 - acc: 0.8401 - val_loss: 0.3737 - val_acc: 0.8371\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3757 - acc: 0.8389 - val_loss: 0.3928 - val_acc: 0.8328\n",
      "Epoch 11/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3705 - acc: 0.8447 - val_loss: 0.4413 - val_acc: 0.8144\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3666 - acc: 0.8468 - val_loss: 0.3829 - val_acc: 0.8467\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3641 - acc: 0.8477 - val_loss: 0.4006 - val_acc: 0.8413\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3656 - acc: 0.8462 - val_loss: 0.3934 - val_acc: 0.8453\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3670 - acc: 0.8418 - val_loss: 0.3747 - val_acc: 0.8477\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3625 - acc: 0.8451 - val_loss: 0.3762 - val_acc: 0.8315\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3646 - acc: 0.8456 - val_loss: 0.3707 - val_acc: 0.8493\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3517 - acc: 0.8501 - val_loss: 0.3611 - val_acc: 0.8520\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3553 - acc: 0.8523 - val_loss: 0.3716 - val_acc: 0.8532\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3460 - acc: 0.8550 - val_loss: 0.3612 - val_acc: 0.8545\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3548 - acc: 0.8485 - val_loss: 0.3749 - val_acc: 0.8568\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3500 - acc: 0.8508 - val_loss: 0.3561 - val_acc: 0.8541\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3462 - acc: 0.8536 - val_loss: 0.3563 - val_acc: 0.8533\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3438 - acc: 0.8546 - val_loss: 0.3753 - val_acc: 0.8440\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3448 - acc: 0.8525 - val_loss: 0.3507 - val_acc: 0.8501\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3464 - acc: 0.8523 - val_loss: 0.3579 - val_acc: 0.8563\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3436 - acc: 0.8531 - val_loss: 0.3784 - val_acc: 0.8516\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3247 - acc: 0.8627 - val_loss: 0.3458 - val_acc: 0.8512\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3384 - acc: 0.8564 - val_loss: 0.3541 - val_acc: 0.8562\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3412 - acc: 0.8548 - val_loss: 0.3647 - val_acc: 0.8577\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3386 - acc: 0.8552 - val_loss: 0.3737 - val_acc: 0.8562\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3348 - acc: 0.8591 - val_loss: 0.3926 - val_acc: 0.8506\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3305 - acc: 0.8575 - val_loss: 0.3609 - val_acc: 0.8583\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3435 - acc: 0.8555 - val_loss: 0.3700 - val_acc: 0.8578\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3320 - acc: 0.8593 - val_loss: 0.3508 - val_acc: 0.8575\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3296 - acc: 0.8616 - val_loss: 0.3613 - val_acc: 0.8579\n",
      "Epoch 37/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3407 - acc: 0.8544 - val_loss: 0.3910 - val_acc: 0.8488\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3297 - acc: 0.8612 - val_loss: 0.3630 - val_acc: 0.8556\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3266 - acc: 0.8609 - val_loss: 0.3830 - val_acc: 0.8551\n",
      "Epoch 40/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3347 - acc: 0.8573 - val_loss: 0.3277 - val_acc: 0.8667\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3279 - acc: 0.8617 - val_loss: 0.3640 - val_acc: 0.8632\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3289 - acc: 0.8595 - val_loss: 0.3480 - val_acc: 0.8635\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3176 - acc: 0.8668 - val_loss: 0.3356 - val_acc: 0.8669\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3245 - acc: 0.8620 - val_loss: 0.3342 - val_acc: 0.8610\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3260 - acc: 0.8629 - val_loss: 0.3368 - val_acc: 0.8646\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3163 - acc: 0.8650 - val_loss: 0.3375 - val_acc: 0.8587\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3244 - acc: 0.8634 - val_loss: 0.3422 - val_acc: 0.8673\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3200 - acc: 0.8660 - val_loss: 0.3307 - val_acc: 0.8677\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3243 - acc: 0.8620 - val_loss: 0.3412 - val_acc: 0.8580\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3231 - acc: 0.8630 - val_loss: 0.3845 - val_acc: 0.8472\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3240 - acc: 0.8625 - val_loss: 0.3530 - val_acc: 0.8618\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3272 - acc: 0.8616 - val_loss: 0.3639 - val_acc: 0.8607\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3242 - acc: 0.8630 - val_loss: 0.3519 - val_acc: 0.8626\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3156 - acc: 0.8658 - val_loss: 0.3397 - val_acc: 0.8604\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3258 - acc: 0.8613 - val_loss: 0.4097 - val_acc: 0.8514\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3106 - acc: 0.8700 - val_loss: 0.3223 - val_acc: 0.8705\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3232 - acc: 0.8641 - val_loss: 0.3375 - val_acc: 0.8604\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3172 - acc: 0.8659 - val_loss: 0.3362 - val_acc: 0.8671\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3201 - acc: 0.8655 - val_loss: 0.3251 - val_acc: 0.8671\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3105 - acc: 0.8724 - val_loss: 0.3402 - val_acc: 0.8638\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3142 - acc: 0.8670 - val_loss: 0.3886 - val_acc: 0.8442\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3125 - acc: 0.8672 - val_loss: 0.3455 - val_acc: 0.8621\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3203 - acc: 0.8653 - val_loss: 0.3294 - val_acc: 0.8671\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3134 - acc: 0.8693 - val_loss: 0.3468 - val_acc: 0.8614\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3128 - acc: 0.8683 - val_loss: 0.3215 - val_acc: 0.8686\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.3151 - acc: 0.8678 - val_loss: 0.3463 - val_acc: 0.8662\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3098 - acc: 0.8681 - val_loss: 0.3630 - val_acc: 0.8492\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3048 - acc: 0.8726 - val_loss: 0.3074 - val_acc: 0.8736\n",
      "Epoch 69/70\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.3237 - acc: 0.8650 - val_loss: 0.3362 - val_acc: 0.8652\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 14s 90ms/step - loss: 0.3158 - acc: 0.8648 - val_loss: 0.3397 - val_acc: 0.8698\n",
      "\n",
      "Training process completed in: 0 h 16 m 39 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1183.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1185 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.5835 - acc: 0.7009 - val_loss: 0.5023 - val_acc: 0.7426\n",
      "Epoch 2/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.4475 - acc: 0.8003 - val_loss: 0.4282 - val_acc: 0.8145\n",
      "Epoch 3/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.4192 - acc: 0.8211 - val_loss: 0.4070 - val_acc: 0.8219\n",
      "Epoch 4/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.4165 - acc: 0.8223 - val_loss: 0.4110 - val_acc: 0.8233\n",
      "Epoch 5/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.4073 - acc: 0.8253 - val_loss: 0.4100 - val_acc: 0.8173\n",
      "Epoch 6/70\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.4058 - acc: 0.8237 - val_loss: 0.4233 - val_acc: 0.8197\n",
      "Epoch 7/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3971 - acc: 0.8305 - val_loss: 0.4096 - val_acc: 0.8233\n",
      "Epoch 8/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.4009 - acc: 0.8286 - val_loss: 0.3916 - val_acc: 0.8319\n",
      "Epoch 9/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3967 - acc: 0.8283 - val_loss: 0.4057 - val_acc: 0.8191\n",
      "Epoch 10/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3952 - acc: 0.8296 - val_loss: 0.3982 - val_acc: 0.8240\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3957 - acc: 0.8274 - val_loss: 0.3872 - val_acc: 0.8299\n",
      "Epoch 12/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3954 - acc: 0.8286 - val_loss: 0.3855 - val_acc: 0.8358\n",
      "Epoch 13/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3827 - acc: 0.8365 - val_loss: 0.3970 - val_acc: 0.8269\n",
      "Epoch 14/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3865 - acc: 0.8322 - val_loss: 0.3816 - val_acc: 0.8367\n",
      "Epoch 15/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3806 - acc: 0.8368 - val_loss: 0.3939 - val_acc: 0.8225\n",
      "Epoch 16/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3875 - acc: 0.8328 - val_loss: 0.3799 - val_acc: 0.8374\n",
      "Epoch 17/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3770 - acc: 0.8391 - val_loss: 0.3742 - val_acc: 0.8405\n",
      "Epoch 18/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3766 - acc: 0.8358 - val_loss: 0.3825 - val_acc: 0.8336\n",
      "Epoch 19/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3811 - acc: 0.8353 - val_loss: 0.3803 - val_acc: 0.8333\n",
      "Epoch 20/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3741 - acc: 0.8367 - val_loss: 0.3763 - val_acc: 0.8363\n",
      "Epoch 21/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3685 - acc: 0.8415 - val_loss: 0.3680 - val_acc: 0.8386\n",
      "Epoch 22/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3774 - acc: 0.8382 - val_loss: 0.3722 - val_acc: 0.8411\n",
      "Epoch 23/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3639 - acc: 0.8450 - val_loss: 0.3834 - val_acc: 0.8420\n",
      "Epoch 24/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3683 - acc: 0.8397 - val_loss: 0.3695 - val_acc: 0.8401\n",
      "Epoch 25/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3675 - acc: 0.8411 - val_loss: 0.3789 - val_acc: 0.8409\n",
      "Epoch 26/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3679 - acc: 0.8406 - val_loss: 0.3611 - val_acc: 0.8435\n",
      "Epoch 27/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3619 - acc: 0.8446 - val_loss: 0.3696 - val_acc: 0.8327\n",
      "Epoch 28/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3606 - acc: 0.8445 - val_loss: 0.3650 - val_acc: 0.8419\n",
      "Epoch 29/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3571 - acc: 0.8469 - val_loss: 0.3810 - val_acc: 0.8404\n",
      "Epoch 30/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3552 - acc: 0.8473 - val_loss: 0.3533 - val_acc: 0.8477\n",
      "Epoch 31/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3557 - acc: 0.8483 - val_loss: 0.3598 - val_acc: 0.8469\n",
      "Epoch 32/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3619 - acc: 0.8443 - val_loss: 0.3567 - val_acc: 0.8438\n",
      "Epoch 33/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3549 - acc: 0.8506 - val_loss: 0.3549 - val_acc: 0.8486\n",
      "Epoch 34/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3559 - acc: 0.8446 - val_loss: 0.3443 - val_acc: 0.8529\n",
      "Epoch 35/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3510 - acc: 0.8491 - val_loss: 0.3618 - val_acc: 0.8426\n",
      "Epoch 36/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3520 - acc: 0.8476 - val_loss: 0.3540 - val_acc: 0.8493\n",
      "Epoch 37/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3519 - acc: 0.8496 - val_loss: 0.3602 - val_acc: 0.8408\n",
      "Epoch 38/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3446 - acc: 0.8537 - val_loss: 0.3496 - val_acc: 0.8526\n",
      "Epoch 39/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3490 - acc: 0.8515 - val_loss: 0.3557 - val_acc: 0.8501\n",
      "Epoch 40/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3479 - acc: 0.8521 - val_loss: 0.3431 - val_acc: 0.8539\n",
      "Epoch 41/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3416 - acc: 0.8549 - val_loss: 0.3426 - val_acc: 0.8544\n",
      "Epoch 42/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3468 - acc: 0.8522 - val_loss: 0.3461 - val_acc: 0.8543\n",
      "Epoch 43/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3443 - acc: 0.8537 - val_loss: 0.3407 - val_acc: 0.8559\n",
      "Epoch 44/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3393 - acc: 0.8567 - val_loss: 0.3407 - val_acc: 0.8576\n",
      "Epoch 45/70\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.3445 - acc: 0.8513 - val_loss: 0.3571 - val_acc: 0.8489\n",
      "Epoch 46/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3403 - acc: 0.8543 - val_loss: 0.3438 - val_acc: 0.8510\n",
      "Epoch 47/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3386 - acc: 0.8546 - val_loss: 0.3215 - val_acc: 0.8660\n",
      "Epoch 48/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3423 - acc: 0.8540 - val_loss: 0.3505 - val_acc: 0.8539\n",
      "Epoch 49/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3480 - acc: 0.8521 - val_loss: 0.3498 - val_acc: 0.8517\n",
      "Epoch 50/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3419 - acc: 0.8546 - val_loss: 0.3490 - val_acc: 0.8538\n",
      "Epoch 51/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3292 - acc: 0.8598 - val_loss: 0.3387 - val_acc: 0.8548\n",
      "Epoch 52/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3354 - acc: 0.8567 - val_loss: 0.3389 - val_acc: 0.8544\n",
      "Epoch 53/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3322 - acc: 0.8582 - val_loss: 0.3358 - val_acc: 0.8590\n",
      "Epoch 54/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3390 - acc: 0.8548 - val_loss: 0.3306 - val_acc: 0.8621\n",
      "Epoch 55/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3370 - acc: 0.8557 - val_loss: 0.3435 - val_acc: 0.8547\n",
      "Epoch 56/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3278 - acc: 0.8600 - val_loss: 0.3284 - val_acc: 0.8605\n",
      "Epoch 57/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3303 - acc: 0.8591 - val_loss: 0.3368 - val_acc: 0.8561\n",
      "Epoch 58/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3310 - acc: 0.8608 - val_loss: 0.3307 - val_acc: 0.8614\n",
      "Epoch 59/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3367 - acc: 0.8582 - val_loss: 0.3350 - val_acc: 0.8579\n",
      "Epoch 60/70\n",
      "160/160 [==============================] - 15s 97ms/step - loss: 0.3369 - acc: 0.8563 - val_loss: 0.3263 - val_acc: 0.8625\n",
      "Epoch 61/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3369 - acc: 0.8572 - val_loss: 0.3352 - val_acc: 0.8555\n",
      "Epoch 62/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3329 - acc: 0.8577 - val_loss: 0.3313 - val_acc: 0.8613\n",
      "Epoch 63/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3311 - acc: 0.8594 - val_loss: 0.3326 - val_acc: 0.8590\n",
      "Epoch 64/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3370 - acc: 0.8572 - val_loss: 0.3283 - val_acc: 0.8628\n",
      "Epoch 65/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3237 - acc: 0.8612 - val_loss: 0.3389 - val_acc: 0.8562\n",
      "Epoch 66/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3285 - acc: 0.8597 - val_loss: 0.3282 - val_acc: 0.8620\n",
      "Epoch 67/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3245 - acc: 0.8623 - val_loss: 0.3264 - val_acc: 0.8611\n",
      "Epoch 68/70\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3332 - acc: 0.8566 - val_loss: 0.3242 - val_acc: 0.8637\n",
      "Epoch 69/70\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3257 - acc: 0.8611 - val_loss: 0.3320 - val_acc: 0.8606\n",
      "Epoch 70/70\n",
      "160/160 [==============================] - 15s 96ms/step - loss: 0.3230 - acc: 0.8614 - val_loss: 0.3239 - val_acc: 0.8632\n",
      "\n",
      "Training process completed in: 0 h 17 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1184.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1186 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_101 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "170/170 [==============================] - 19s 111ms/step - loss: 0.5479 - acc: 0.7280 - val_loss: 0.4557 - val_acc: 0.7919\n",
      "Epoch 2/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.4302 - acc: 0.8168 - val_loss: 0.4250 - val_acc: 0.8165\n",
      "Epoch 3/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.4190 - acc: 0.8204 - val_loss: 0.4170 - val_acc: 0.8164\n",
      "Epoch 4/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.4083 - acc: 0.8253 - val_loss: 0.4239 - val_acc: 0.8172\n",
      "Epoch 5/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.4142 - acc: 0.8204 - val_loss: 0.4050 - val_acc: 0.8243\n",
      "Epoch 6/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.4074 - acc: 0.8242 - val_loss: 0.4130 - val_acc: 0.8206\n",
      "Epoch 7/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.4089 - acc: 0.8228 - val_loss: 0.3980 - val_acc: 0.8252\n",
      "Epoch 8/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.4008 - acc: 0.8276 - val_loss: 0.4010 - val_acc: 0.8266\n",
      "Epoch 9/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3987 - acc: 0.8269 - val_loss: 0.4065 - val_acc: 0.8233\n",
      "Epoch 10/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3880 - acc: 0.8336 - val_loss: 0.3907 - val_acc: 0.8292\n",
      "Epoch 11/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3915 - acc: 0.8331 - val_loss: 0.3810 - val_acc: 0.8351\n",
      "Epoch 12/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3886 - acc: 0.8338 - val_loss: 0.3875 - val_acc: 0.8296\n",
      "Epoch 13/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3858 - acc: 0.8347 - val_loss: 0.3773 - val_acc: 0.8363\n",
      "Epoch 14/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3807 - acc: 0.8352 - val_loss: 0.3864 - val_acc: 0.8314\n",
      "Epoch 15/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3791 - acc: 0.8376 - val_loss: 0.3897 - val_acc: 0.8333\n",
      "Epoch 16/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3787 - acc: 0.8373 - val_loss: 0.3752 - val_acc: 0.8354\n",
      "Epoch 17/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3735 - acc: 0.8416 - val_loss: 0.3695 - val_acc: 0.8409\n",
      "Epoch 18/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3768 - acc: 0.8374 - val_loss: 0.3742 - val_acc: 0.8376\n",
      "Epoch 19/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3723 - acc: 0.8390 - val_loss: 0.3706 - val_acc: 0.8399\n",
      "Epoch 20/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3664 - acc: 0.8440 - val_loss: 0.3661 - val_acc: 0.8399\n",
      "Epoch 21/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3642 - acc: 0.8439 - val_loss: 0.3684 - val_acc: 0.8401\n",
      "Epoch 22/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3669 - acc: 0.8431 - val_loss: 0.3726 - val_acc: 0.8345\n",
      "Epoch 23/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3634 - acc: 0.8435 - val_loss: 0.3706 - val_acc: 0.8421\n",
      "Epoch 24/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3584 - acc: 0.8454 - val_loss: 0.3611 - val_acc: 0.8437\n",
      "Epoch 25/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3556 - acc: 0.8479 - val_loss: 0.3576 - val_acc: 0.8517\n",
      "Epoch 26/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3589 - acc: 0.8455 - val_loss: 0.3538 - val_acc: 0.8479\n",
      "Epoch 27/60\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3551 - acc: 0.8489 - val_loss: 0.3516 - val_acc: 0.8499\n",
      "Epoch 28/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3546 - acc: 0.8494 - val_loss: 0.3632 - val_acc: 0.8474\n",
      "Epoch 29/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3488 - acc: 0.8509 - val_loss: 0.3575 - val_acc: 0.8521\n",
      "Epoch 30/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3562 - acc: 0.8478 - val_loss: 0.3414 - val_acc: 0.8551\n",
      "Epoch 31/60\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3497 - acc: 0.8499 - val_loss: 0.3536 - val_acc: 0.8521\n",
      "Epoch 32/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3474 - acc: 0.8522 - val_loss: 0.3492 - val_acc: 0.8556\n",
      "Epoch 33/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3427 - acc: 0.8538 - val_loss: 0.3435 - val_acc: 0.8526\n",
      "Epoch 34/60\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3459 - acc: 0.8536 - val_loss: 0.3497 - val_acc: 0.8519\n",
      "Epoch 35/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3454 - acc: 0.8532 - val_loss: 0.3316 - val_acc: 0.8586\n",
      "Epoch 36/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3408 - acc: 0.8557 - val_loss: 0.3597 - val_acc: 0.8498\n",
      "Epoch 37/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3398 - acc: 0.8555 - val_loss: 0.3442 - val_acc: 0.8556\n",
      "Epoch 38/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3482 - acc: 0.8531 - val_loss: 0.3514 - val_acc: 0.8481\n",
      "Epoch 39/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3423 - acc: 0.8536 - val_loss: 0.3416 - val_acc: 0.8551\n",
      "Epoch 40/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3345 - acc: 0.8598 - val_loss: 0.3378 - val_acc: 0.8568\n",
      "Epoch 41/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3376 - acc: 0.8568 - val_loss: 0.3574 - val_acc: 0.8529\n",
      "Epoch 42/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3392 - acc: 0.8552 - val_loss: 0.3518 - val_acc: 0.8504\n",
      "Epoch 43/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3405 - acc: 0.8544 - val_loss: 0.3478 - val_acc: 0.8559\n",
      "Epoch 44/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3370 - acc: 0.8580 - val_loss: 0.3387 - val_acc: 0.8550\n",
      "Epoch 45/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3371 - acc: 0.8578 - val_loss: 0.3273 - val_acc: 0.8627\n",
      "Epoch 46/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3383 - acc: 0.8562 - val_loss: 0.3383 - val_acc: 0.8583\n",
      "Epoch 47/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3312 - acc: 0.8591 - val_loss: 0.3299 - val_acc: 0.8613\n",
      "Epoch 48/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3418 - acc: 0.8538 - val_loss: 0.3374 - val_acc: 0.8593\n",
      "Epoch 49/60\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3341 - acc: 0.8593 - val_loss: 0.3321 - val_acc: 0.8588\n",
      "Epoch 50/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3317 - acc: 0.8593 - val_loss: 0.3577 - val_acc: 0.8485\n",
      "Epoch 51/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3278 - acc: 0.8641 - val_loss: 0.3524 - val_acc: 0.8479\n",
      "Epoch 52/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3331 - acc: 0.8588 - val_loss: 0.3285 - val_acc: 0.8619\n",
      "Epoch 53/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3269 - acc: 0.8622 - val_loss: 0.3264 - val_acc: 0.8624\n",
      "Epoch 54/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3256 - acc: 0.8606 - val_loss: 0.3292 - val_acc: 0.8616\n",
      "Epoch 55/60\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.3280 - acc: 0.8603 - val_loss: 0.3339 - val_acc: 0.8622\n",
      "Epoch 56/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3281 - acc: 0.8605 - val_loss: 0.3221 - val_acc: 0.8650\n",
      "Epoch 57/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3330 - acc: 0.8588 - val_loss: 0.3419 - val_acc: 0.8562\n",
      "Epoch 58/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3282 - acc: 0.8605 - val_loss: 0.3333 - val_acc: 0.8595\n",
      "Epoch 59/60\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3286 - acc: 0.8598 - val_loss: 0.3248 - val_acc: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3251 - acc: 0.8621 - val_loss: 0.3315 - val_acc: 0.8620\n",
      "\n",
      "Training process completed in: 0 h 17 m 12 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1185.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1187 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_105 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.5507 - acc: 0.7255 - val_loss: 0.4547 - val_acc: 0.7991\n",
      "Epoch 2/60\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.4332 - acc: 0.8153 - val_loss: 0.4207 - val_acc: 0.8184\n",
      "Epoch 3/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4223 - acc: 0.8183 - val_loss: 0.4154 - val_acc: 0.8196\n",
      "Epoch 4/60\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.4109 - acc: 0.8254 - val_loss: 0.4127 - val_acc: 0.8203\n",
      "Epoch 5/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.4081 - acc: 0.8251 - val_loss: 0.4127 - val_acc: 0.8203\n",
      "Epoch 6/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.4005 - acc: 0.8280 - val_loss: 0.4032 - val_acc: 0.8256\n",
      "Epoch 7/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.4100 - acc: 0.8244 - val_loss: 0.3985 - val_acc: 0.8290\n",
      "Epoch 8/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.4060 - acc: 0.8243 - val_loss: 0.3996 - val_acc: 0.8280\n",
      "Epoch 9/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3996 - acc: 0.8273 - val_loss: 0.4047 - val_acc: 0.8244\n",
      "Epoch 10/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3957 - acc: 0.8316 - val_loss: 0.4030 - val_acc: 0.8244\n",
      "Epoch 11/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3979 - acc: 0.8276 - val_loss: 0.3872 - val_acc: 0.8317\n",
      "Epoch 12/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3910 - acc: 0.8347 - val_loss: 0.4097 - val_acc: 0.8209\n",
      "Epoch 13/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3900 - acc: 0.8334 - val_loss: 0.3962 - val_acc: 0.8294\n",
      "Epoch 14/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3892 - acc: 0.8337 - val_loss: 0.3813 - val_acc: 0.8354\n",
      "Epoch 15/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3818 - acc: 0.8366 - val_loss: 0.3793 - val_acc: 0.8358\n",
      "Epoch 16/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3853 - acc: 0.8359 - val_loss: 0.4066 - val_acc: 0.8276\n",
      "Epoch 17/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3814 - acc: 0.8359 - val_loss: 0.3857 - val_acc: 0.8344\n",
      "Epoch 18/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3806 - acc: 0.8375 - val_loss: 0.3740 - val_acc: 0.8404\n",
      "Epoch 19/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3806 - acc: 0.8380 - val_loss: 0.3765 - val_acc: 0.8402\n",
      "Epoch 20/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3661 - acc: 0.8432 - val_loss: 0.3714 - val_acc: 0.8404\n",
      "Epoch 21/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3772 - acc: 0.8380 - val_loss: 0.3687 - val_acc: 0.8425\n",
      "Epoch 22/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3701 - acc: 0.8424 - val_loss: 0.3776 - val_acc: 0.8383\n",
      "Epoch 23/60\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.3634 - acc: 0.8449 - val_loss: 0.3730 - val_acc: 0.8451\n",
      "Epoch 24/60\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.3683 - acc: 0.8435 - val_loss: 0.3909 - val_acc: 0.8363\n",
      "Epoch 25/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3669 - acc: 0.8431 - val_loss: 0.3663 - val_acc: 0.8393\n",
      "Epoch 26/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3651 - acc: 0.8458 - val_loss: 0.3649 - val_acc: 0.8481\n",
      "Epoch 27/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3627 - acc: 0.8461 - val_loss: 0.3572 - val_acc: 0.8499\n",
      "Epoch 28/60\n",
      "170/170 [==============================] - 16s 91ms/step - loss: 0.3607 - acc: 0.8473 - val_loss: 0.3606 - val_acc: 0.8468\n",
      "Epoch 29/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3638 - acc: 0.8437 - val_loss: 0.3645 - val_acc: 0.8427\n",
      "Epoch 30/60\n",
      "170/170 [==============================] - 16s 96ms/step - loss: 0.3525 - acc: 0.8517 - val_loss: 0.3454 - val_acc: 0.8518\n",
      "Epoch 31/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3559 - acc: 0.8491 - val_loss: 0.3551 - val_acc: 0.8501\n",
      "Epoch 32/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3532 - acc: 0.8501 - val_loss: 0.3547 - val_acc: 0.8488\n",
      "Epoch 33/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3556 - acc: 0.8469 - val_loss: 0.3445 - val_acc: 0.8550\n",
      "Epoch 34/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3511 - acc: 0.8530 - val_loss: 0.3497 - val_acc: 0.8557\n",
      "Epoch 35/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3548 - acc: 0.8519 - val_loss: 0.3548 - val_acc: 0.8522\n",
      "Epoch 36/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3527 - acc: 0.8519 - val_loss: 0.3486 - val_acc: 0.8501\n",
      "Epoch 37/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3424 - acc: 0.8551 - val_loss: 0.3449 - val_acc: 0.8549\n",
      "Epoch 38/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3448 - acc: 0.8542 - val_loss: 0.3501 - val_acc: 0.8474\n",
      "Epoch 39/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3434 - acc: 0.8553 - val_loss: 0.3552 - val_acc: 0.8495\n",
      "Epoch 40/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3411 - acc: 0.8533 - val_loss: 0.3509 - val_acc: 0.8544\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3539 - acc: 0.8494 - val_loss: 0.3558 - val_acc: 0.8529\n",
      "Epoch 42/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3445 - acc: 0.8536 - val_loss: 0.3385 - val_acc: 0.8567\n",
      "Epoch 43/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3416 - acc: 0.8542 - val_loss: 0.3359 - val_acc: 0.8595\n",
      "Epoch 44/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3372 - acc: 0.8559 - val_loss: 0.3350 - val_acc: 0.8559\n",
      "Epoch 45/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3410 - acc: 0.8548 - val_loss: 0.3375 - val_acc: 0.8545\n",
      "Epoch 46/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3390 - acc: 0.8552 - val_loss: 0.3493 - val_acc: 0.8514\n",
      "Epoch 47/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3352 - acc: 0.8569 - val_loss: 0.3363 - val_acc: 0.8569\n",
      "Epoch 48/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3399 - acc: 0.8551 - val_loss: 0.3422 - val_acc: 0.8552\n",
      "Epoch 49/60\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3361 - acc: 0.8587 - val_loss: 0.3431 - val_acc: 0.8531\n",
      "Epoch 50/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3368 - acc: 0.8570 - val_loss: 0.3544 - val_acc: 0.8513\n",
      "Epoch 51/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3308 - acc: 0.8591 - val_loss: 0.3409 - val_acc: 0.8573\n",
      "Epoch 52/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3324 - acc: 0.8595 - val_loss: 0.3436 - val_acc: 0.8529\n",
      "Epoch 53/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3340 - acc: 0.8579 - val_loss: 0.3318 - val_acc: 0.8609\n",
      "Epoch 54/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3313 - acc: 0.8605 - val_loss: 0.3274 - val_acc: 0.8604\n",
      "Epoch 55/60\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3292 - acc: 0.8606 - val_loss: 0.3413 - val_acc: 0.8576\n",
      "Epoch 56/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3322 - acc: 0.8581 - val_loss: 0.3298 - val_acc: 0.8605\n",
      "Epoch 57/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3305 - acc: 0.8598 - val_loss: 0.3282 - val_acc: 0.8567\n",
      "Epoch 58/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3255 - acc: 0.8624 - val_loss: 0.3287 - val_acc: 0.8623\n",
      "Epoch 59/60\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.3297 - acc: 0.8613 - val_loss: 0.3243 - val_acc: 0.8646\n",
      "Epoch 60/60\n",
      "170/170 [==============================] - 16s 92ms/step - loss: 0.3285 - acc: 0.8618 - val_loss: 0.3260 - val_acc: 0.8632\n",
      "\n",
      "Training process completed in: 0 h 15 m 38 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1186.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1188 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_109 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.4894 - acc: 0.7730 - val_loss: 0.4420 - val_acc: 0.8078\n",
      "Epoch 2/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.4323 - acc: 0.8155 - val_loss: 0.4276 - val_acc: 0.8123\n",
      "Epoch 3/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.4123 - acc: 0.8247 - val_loss: 0.4227 - val_acc: 0.8236\n",
      "Epoch 4/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.4122 - acc: 0.8223 - val_loss: 0.4094 - val_acc: 0.8192\n",
      "Epoch 5/60\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 0.4022 - acc: 0.8278 - val_loss: 0.3916 - val_acc: 0.8303\n",
      "Epoch 6/60\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.3980 - acc: 0.8285 - val_loss: 0.3879 - val_acc: 0.8294\n",
      "Epoch 7/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3978 - acc: 0.8283 - val_loss: 0.4214 - val_acc: 0.8301\n",
      "Epoch 8/60\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.3901 - acc: 0.8330 - val_loss: 0.4342 - val_acc: 0.8229\n",
      "Epoch 9/60\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.3862 - acc: 0.8341 - val_loss: 0.3798 - val_acc: 0.8385\n",
      "Epoch 10/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3834 - acc: 0.8358 - val_loss: 0.3898 - val_acc: 0.8376\n",
      "Epoch 11/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3763 - acc: 0.8378 - val_loss: 0.3821 - val_acc: 0.8337\n",
      "Epoch 12/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3835 - acc: 0.8358 - val_loss: 0.3858 - val_acc: 0.8266\n",
      "Epoch 13/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3694 - acc: 0.8413 - val_loss: 0.3798 - val_acc: 0.8353\n",
      "Epoch 14/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3819 - acc: 0.8330 - val_loss: 0.3671 - val_acc: 0.8443\n",
      "Epoch 15/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3734 - acc: 0.8403 - val_loss: 0.3592 - val_acc: 0.8456\n",
      "Epoch 16/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3707 - acc: 0.8387 - val_loss: 0.3811 - val_acc: 0.8388\n",
      "Epoch 17/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3632 - acc: 0.8451 - val_loss: 0.4004 - val_acc: 0.8439\n",
      "Epoch 18/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3716 - acc: 0.8426 - val_loss: 0.3644 - val_acc: 0.8430\n",
      "Epoch 19/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3655 - acc: 0.8448 - val_loss: 0.3737 - val_acc: 0.8488\n",
      "Epoch 20/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3655 - acc: 0.8411 - val_loss: 0.3832 - val_acc: 0.8339\n",
      "Epoch 21/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3583 - acc: 0.8481 - val_loss: 0.3590 - val_acc: 0.8490\n",
      "Epoch 22/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3609 - acc: 0.8435 - val_loss: 0.3571 - val_acc: 0.8425\n",
      "Epoch 23/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3510 - acc: 0.8505 - val_loss: 0.3577 - val_acc: 0.8517\n",
      "Epoch 24/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3598 - acc: 0.8452 - val_loss: 0.3601 - val_acc: 0.8494\n",
      "Epoch 25/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3533 - acc: 0.8500 - val_loss: 0.3499 - val_acc: 0.8500\n",
      "Epoch 26/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3489 - acc: 0.8517 - val_loss: 0.3400 - val_acc: 0.8558\n",
      "Epoch 27/60\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.3459 - acc: 0.8516 - val_loss: 0.3516 - val_acc: 0.8529\n",
      "Epoch 28/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3462 - acc: 0.8514 - val_loss: 0.3558 - val_acc: 0.8462\n",
      "Epoch 29/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3497 - acc: 0.8516 - val_loss: 0.3493 - val_acc: 0.8597\n",
      "Epoch 30/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3420 - acc: 0.8545 - val_loss: 0.3643 - val_acc: 0.8533\n",
      "Epoch 31/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3396 - acc: 0.8549 - val_loss: 0.3348 - val_acc: 0.8584\n",
      "Epoch 32/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3444 - acc: 0.8541 - val_loss: 0.3375 - val_acc: 0.8566\n",
      "Epoch 33/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3460 - acc: 0.8531 - val_loss: 0.3365 - val_acc: 0.8581\n",
      "Epoch 34/60\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 0.3409 - acc: 0.8561 - val_loss: 0.3421 - val_acc: 0.8564\n",
      "Epoch 35/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3426 - acc: 0.8533 - val_loss: 0.3383 - val_acc: 0.8574\n",
      "Epoch 36/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3353 - acc: 0.8568 - val_loss: 0.3386 - val_acc: 0.8592\n",
      "Epoch 37/60\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.3347 - acc: 0.8567 - val_loss: 0.3437 - val_acc: 0.8532\n",
      "Epoch 38/60\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 0.3340 - acc: 0.8613 - val_loss: 0.3459 - val_acc: 0.8503\n",
      "Epoch 39/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3319 - acc: 0.8607 - val_loss: 0.3445 - val_acc: 0.8603\n",
      "Epoch 40/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3405 - acc: 0.8545 - val_loss: 0.3302 - val_acc: 0.8609\n",
      "Epoch 41/60\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.3337 - acc: 0.8586 - val_loss: 0.3258 - val_acc: 0.8614\n",
      "Epoch 42/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3393 - acc: 0.8557 - val_loss: 0.3470 - val_acc: 0.8541\n",
      "Epoch 43/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3351 - acc: 0.8550 - val_loss: 0.3626 - val_acc: 0.8432\n",
      "Epoch 44/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3295 - acc: 0.8597 - val_loss: 0.3598 - val_acc: 0.8440\n",
      "Epoch 45/60\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.3409 - acc: 0.8546 - val_loss: 0.3280 - val_acc: 0.8607\n",
      "Epoch 46/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3321 - acc: 0.8607 - val_loss: 0.3367 - val_acc: 0.8593\n",
      "Epoch 47/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3283 - acc: 0.8617 - val_loss: 0.3397 - val_acc: 0.8549\n",
      "Epoch 48/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3341 - acc: 0.8582 - val_loss: 0.3335 - val_acc: 0.8583\n",
      "Epoch 49/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3279 - acc: 0.8614 - val_loss: 0.3301 - val_acc: 0.8632\n",
      "Epoch 50/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3265 - acc: 0.8603 - val_loss: 0.3358 - val_acc: 0.8614\n",
      "Epoch 51/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3286 - acc: 0.8590 - val_loss: 0.3352 - val_acc: 0.8610\n",
      "Epoch 52/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3243 - acc: 0.8637 - val_loss: 0.3210 - val_acc: 0.8659\n",
      "Epoch 53/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3277 - acc: 0.8607 - val_loss: 0.3390 - val_acc: 0.8621\n",
      "Epoch 54/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3272 - acc: 0.8601 - val_loss: 0.3139 - val_acc: 0.8675\n",
      "Epoch 55/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3233 - acc: 0.8646 - val_loss: 0.3481 - val_acc: 0.8532\n",
      "Epoch 56/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3286 - acc: 0.8620 - val_loss: 0.3408 - val_acc: 0.8534\n",
      "Epoch 57/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3195 - acc: 0.8662 - val_loss: 0.3293 - val_acc: 0.8561\n",
      "Epoch 58/60\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 0.3240 - acc: 0.8630 - val_loss: 0.3315 - val_acc: 0.8615\n",
      "Epoch 59/60\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.3284 - acc: 0.8598 - val_loss: 0.3340 - val_acc: 0.8641\n",
      "Epoch 60/60\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3193 - acc: 0.8642 - val_loss: 0.3248 - val_acc: 0.8640\n",
      "\n",
      "Training process completed in: 0 h 13 m 33 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1187.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1189 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_113 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "170/170 [==============================] - 14s 83ms/step - loss: 0.5593 - acc: 0.7235 - val_loss: 0.4696 - val_acc: 0.7881\n",
      "Epoch 2/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.4313 - acc: 0.8123 - val_loss: 0.4557 - val_acc: 0.8100\n",
      "Epoch 3/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 13s 74ms/step - loss: 0.4174 - acc: 0.8177 - val_loss: 0.4241 - val_acc: 0.8133\n",
      "Epoch 4/90\n",
      "170/170 [==============================] - 12s 73ms/step - loss: 0.4109 - acc: 0.8209 - val_loss: 0.4034 - val_acc: 0.8287\n",
      "Epoch 5/90\n",
      "170/170 [==============================] - 12s 73ms/step - loss: 0.4048 - acc: 0.8255 - val_loss: 0.3980 - val_acc: 0.8233\n",
      "Epoch 6/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.4025 - acc: 0.8265 - val_loss: 0.3965 - val_acc: 0.8305\n",
      "Epoch 7/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.4029 - acc: 0.8266 - val_loss: 0.3950 - val_acc: 0.8298\n",
      "Epoch 8/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3994 - acc: 0.8290 - val_loss: 0.3940 - val_acc: 0.8291\n",
      "Epoch 9/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3968 - acc: 0.8282 - val_loss: 0.3879 - val_acc: 0.8313\n",
      "Epoch 10/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3950 - acc: 0.8280 - val_loss: 0.3976 - val_acc: 0.8263\n",
      "Epoch 11/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3864 - acc: 0.8350 - val_loss: 0.3790 - val_acc: 0.8311\n",
      "Epoch 12/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3830 - acc: 0.8379 - val_loss: 0.4078 - val_acc: 0.8244\n",
      "Epoch 13/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3853 - acc: 0.8333 - val_loss: 0.3866 - val_acc: 0.8289\n",
      "Epoch 14/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3835 - acc: 0.8342 - val_loss: 0.3771 - val_acc: 0.8369\n",
      "Epoch 15/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3759 - acc: 0.8380 - val_loss: 0.3834 - val_acc: 0.8361\n",
      "Epoch 16/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3707 - acc: 0.8418 - val_loss: 0.3804 - val_acc: 0.8383\n",
      "Epoch 17/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3745 - acc: 0.8382 - val_loss: 0.3698 - val_acc: 0.8387\n",
      "Epoch 18/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3732 - acc: 0.8382 - val_loss: 0.3666 - val_acc: 0.8420\n",
      "Epoch 19/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3750 - acc: 0.8379 - val_loss: 0.3678 - val_acc: 0.8387\n",
      "Epoch 20/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3734 - acc: 0.8400 - val_loss: 0.3664 - val_acc: 0.8439\n",
      "Epoch 21/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3698 - acc: 0.8408 - val_loss: 0.3746 - val_acc: 0.8302\n",
      "Epoch 22/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3721 - acc: 0.8391 - val_loss: 0.3687 - val_acc: 0.8433\n",
      "Epoch 23/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3644 - acc: 0.8425 - val_loss: 0.3771 - val_acc: 0.8380\n",
      "Epoch 24/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3636 - acc: 0.8430 - val_loss: 0.3807 - val_acc: 0.8389\n",
      "Epoch 25/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3663 - acc: 0.8428 - val_loss: 0.3540 - val_acc: 0.8485\n",
      "Epoch 26/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3610 - acc: 0.8443 - val_loss: 0.3639 - val_acc: 0.8524\n",
      "Epoch 27/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3510 - acc: 0.8491 - val_loss: 0.3605 - val_acc: 0.8443\n",
      "Epoch 28/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3553 - acc: 0.8482 - val_loss: 0.3545 - val_acc: 0.8456\n",
      "Epoch 29/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3530 - acc: 0.8480 - val_loss: 0.3453 - val_acc: 0.8513\n",
      "Epoch 30/90\n",
      "170/170 [==============================] - 13s 77ms/step - loss: 0.3495 - acc: 0.8479 - val_loss: 0.3573 - val_acc: 0.8444\n",
      "Epoch 31/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3547 - acc: 0.8473 - val_loss: 0.3455 - val_acc: 0.8543\n",
      "Epoch 32/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3437 - acc: 0.8526 - val_loss: 0.3526 - val_acc: 0.8533\n",
      "Epoch 33/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3497 - acc: 0.8488 - val_loss: 0.3472 - val_acc: 0.8524\n",
      "Epoch 34/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3478 - acc: 0.8514 - val_loss: 0.3425 - val_acc: 0.8544\n",
      "Epoch 35/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3450 - acc: 0.8527 - val_loss: 0.3405 - val_acc: 0.8569\n",
      "Epoch 36/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3452 - acc: 0.8526 - val_loss: 0.3579 - val_acc: 0.8426\n",
      "Epoch 37/90\n",
      "170/170 [==============================] - 13s 76ms/step - loss: 0.3429 - acc: 0.8539 - val_loss: 0.3446 - val_acc: 0.8507\n",
      "Epoch 38/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3351 - acc: 0.8559 - val_loss: 0.3430 - val_acc: 0.8546\n",
      "Epoch 39/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3392 - acc: 0.8542 - val_loss: 0.3534 - val_acc: 0.8437\n",
      "Epoch 40/90\n",
      "170/170 [==============================] - 12s 73ms/step - loss: 0.3450 - acc: 0.8514 - val_loss: 0.3436 - val_acc: 0.8585\n",
      "Epoch 41/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3397 - acc: 0.8547 - val_loss: 0.3341 - val_acc: 0.8602\n",
      "Epoch 42/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3378 - acc: 0.8554 - val_loss: 0.3617 - val_acc: 0.8496\n",
      "Epoch 43/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3295 - acc: 0.8599 - val_loss: 0.3285 - val_acc: 0.8581\n",
      "Epoch 44/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3412 - acc: 0.8530 - val_loss: 0.3418 - val_acc: 0.8567\n",
      "Epoch 45/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3380 - acc: 0.8562 - val_loss: 0.3436 - val_acc: 0.8520\n",
      "Epoch 46/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3400 - acc: 0.8566 - val_loss: 0.3307 - val_acc: 0.8602\n",
      "Epoch 47/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3314 - acc: 0.8609 - val_loss: 0.3242 - val_acc: 0.8639\n",
      "Epoch 48/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3347 - acc: 0.8575 - val_loss: 0.3335 - val_acc: 0.8591\n",
      "Epoch 49/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3348 - acc: 0.8581 - val_loss: 0.3399 - val_acc: 0.8565\n",
      "Epoch 50/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3345 - acc: 0.8568 - val_loss: 0.3302 - val_acc: 0.8567\n",
      "Epoch 51/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3292 - acc: 0.8614 - val_loss: 0.3321 - val_acc: 0.8604\n",
      "Epoch 52/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3357 - acc: 0.8580 - val_loss: 0.3299 - val_acc: 0.8581\n",
      "Epoch 53/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3342 - acc: 0.8583 - val_loss: 0.3269 - val_acc: 0.8580\n",
      "Epoch 54/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3303 - acc: 0.8589 - val_loss: 0.3334 - val_acc: 0.8624\n",
      "Epoch 55/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3203 - acc: 0.8630 - val_loss: 0.3362 - val_acc: 0.8581\n",
      "Epoch 56/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3323 - acc: 0.8584 - val_loss: 0.3369 - val_acc: 0.8596\n",
      "Epoch 57/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3271 - acc: 0.8614 - val_loss: 0.3252 - val_acc: 0.8601\n",
      "Epoch 58/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3242 - acc: 0.8626 - val_loss: 0.3319 - val_acc: 0.8613\n",
      "Epoch 59/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3275 - acc: 0.8626 - val_loss: 0.3224 - val_acc: 0.8667\n",
      "Epoch 60/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3276 - acc: 0.8602 - val_loss: 0.3398 - val_acc: 0.8546\n",
      "Epoch 61/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3216 - acc: 0.8621 - val_loss: 0.3051 - val_acc: 0.8646\n",
      "Epoch 62/90\n",
      "170/170 [==============================] - 12s 74ms/step - loss: 0.3230 - acc: 0.8625 - val_loss: 0.3312 - val_acc: 0.8561\n",
      "Epoch 63/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3255 - acc: 0.8630 - val_loss: 0.3369 - val_acc: 0.8596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3246 - acc: 0.8613 - val_loss: 0.3219 - val_acc: 0.8639\n",
      "Epoch 65/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3220 - acc: 0.8650 - val_loss: 0.3365 - val_acc: 0.8543\n",
      "Epoch 66/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3215 - acc: 0.8636 - val_loss: 0.3388 - val_acc: 0.8609\n",
      "Epoch 67/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3213 - acc: 0.8634 - val_loss: 0.3191 - val_acc: 0.8631\n",
      "Epoch 68/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3184 - acc: 0.8650 - val_loss: 0.3303 - val_acc: 0.8549\n",
      "Epoch 69/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3246 - acc: 0.8615 - val_loss: 0.3144 - val_acc: 0.8678\n",
      "Epoch 70/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3175 - acc: 0.8651 - val_loss: 0.3227 - val_acc: 0.8609\n",
      "Epoch 71/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3200 - acc: 0.8642 - val_loss: 0.3139 - val_acc: 0.8659\n",
      "Epoch 72/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3162 - acc: 0.8676 - val_loss: 0.3449 - val_acc: 0.8539\n",
      "Epoch 73/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3102 - acc: 0.8685 - val_loss: 0.3277 - val_acc: 0.8616\n",
      "Epoch 74/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3172 - acc: 0.8673 - val_loss: 0.3249 - val_acc: 0.8607\n",
      "Epoch 75/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3114 - acc: 0.8672 - val_loss: 0.3215 - val_acc: 0.8630\n",
      "Epoch 76/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3201 - acc: 0.8640 - val_loss: 0.3117 - val_acc: 0.8693\n",
      "Epoch 77/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3144 - acc: 0.8692 - val_loss: 0.3192 - val_acc: 0.8633\n",
      "Epoch 78/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3147 - acc: 0.8681 - val_loss: 0.3330 - val_acc: 0.8561\n",
      "Epoch 79/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3135 - acc: 0.8661 - val_loss: 0.3181 - val_acc: 0.8667\n",
      "Epoch 80/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3128 - acc: 0.8671 - val_loss: 0.3230 - val_acc: 0.8630\n",
      "Epoch 81/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3094 - acc: 0.8689 - val_loss: 0.3200 - val_acc: 0.8628\n",
      "Epoch 82/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3142 - acc: 0.8677 - val_loss: 0.3052 - val_acc: 0.8722\n",
      "Epoch 83/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3072 - acc: 0.8698 - val_loss: 0.3227 - val_acc: 0.8602\n",
      "Epoch 84/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3127 - acc: 0.8681 - val_loss: 0.3050 - val_acc: 0.8720\n",
      "Epoch 85/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3101 - acc: 0.8671 - val_loss: 0.3105 - val_acc: 0.8661\n",
      "Epoch 86/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3118 - acc: 0.8687 - val_loss: 0.3314 - val_acc: 0.8569\n",
      "Epoch 87/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3088 - acc: 0.8706 - val_loss: 0.3090 - val_acc: 0.8663\n",
      "Epoch 88/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3120 - acc: 0.8692 - val_loss: 0.3207 - val_acc: 0.8627\n",
      "Epoch 89/90\n",
      "170/170 [==============================] - 13s 74ms/step - loss: 0.3094 - acc: 0.8687 - val_loss: 0.3096 - val_acc: 0.8704\n",
      "Epoch 90/90\n",
      "170/170 [==============================] - 13s 75ms/step - loss: 0.3083 - acc: 0.8697 - val_loss: 0.3094 - val_acc: 0.8641\n",
      "\n",
      "Training process completed in: 0 h 18 m 57 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1188.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1190 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_117 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.1\n",
      "Epochs: 60\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 4.4889 - acc: 0.7194 - val_loss: 4.6116 - val_acc: 0.7139\n",
      "Epoch 2/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5511 - acc: 0.7176 - val_loss: 4.5317 - val_acc: 0.7188\n",
      "Epoch 3/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5743 - acc: 0.7162 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 4/60\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 4.6563 - acc: 0.7111 - val_loss: 4.6233 - val_acc: 0.7132\n",
      "Epoch 5/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5780 - acc: 0.7160 - val_loss: 4.6104 - val_acc: 0.7140\n",
      "Epoch 6/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5332 - acc: 0.7187 - val_loss: 4.4842 - val_acc: 0.7218\n",
      "Epoch 7/60\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 4.6272 - acc: 0.7129 - val_loss: 4.5858 - val_acc: 0.7155\n",
      "Epoch 8/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5944 - acc: 0.7150 - val_loss: 4.5565 - val_acc: 0.7173\n",
      "Epoch 9/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.6032 - acc: 0.7144 - val_loss: 4.5724 - val_acc: 0.7163\n",
      "Epoch 10/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5161 - acc: 0.7198 - val_loss: 4.5871 - val_acc: 0.7154\n",
      "Epoch 11/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5832 - acc: 0.7156 - val_loss: 4.6183 - val_acc: 0.7135\n",
      "Epoch 12/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5021 - acc: 0.7207 - val_loss: 4.5531 - val_acc: 0.7175\n",
      "Epoch 13/60\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 4.5974 - acc: 0.7148 - val_loss: 4.6384 - val_acc: 0.7122\n",
      "Epoch 14/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5011 - acc: 0.7207 - val_loss: 4.5418 - val_acc: 0.7182\n",
      "Epoch 15/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5698 - acc: 0.7165 - val_loss: 4.5500 - val_acc: 0.7177\n",
      "Epoch 16/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5802 - acc: 0.7158 - val_loss: 4.5430 - val_acc: 0.7181\n",
      "Epoch 17/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.6168 - acc: 0.7136 - val_loss: 4.6373 - val_acc: 0.7123\n",
      "Epoch 18/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.6153 - acc: 0.7137 - val_loss: 4.5079 - val_acc: 0.7203\n",
      "Epoch 19/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5847 - acc: 0.7156 - val_loss: 4.5567 - val_acc: 0.7173\n",
      "Epoch 20/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.6280 - acc: 0.7129 - val_loss: 4.6470 - val_acc: 0.7117\n",
      "Epoch 21/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5519 - acc: 0.7176 - val_loss: 4.5556 - val_acc: 0.7174\n",
      "Epoch 22/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5302 - acc: 0.7189 - val_loss: 4.5373 - val_acc: 0.7185\n",
      "Epoch 23/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5780 - acc: 0.7160 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 24/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5675 - acc: 0.7166 - val_loss: 4.6233 - val_acc: 0.7132\n",
      "Epoch 25/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5213 - acc: 0.7195 - val_loss: 4.5377 - val_acc: 0.7185\n",
      "Epoch 26/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.6123 - acc: 0.7138 - val_loss: 4.5271 - val_acc: 0.7191\n",
      "Epoch 27/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.6556 - acc: 0.7112 - val_loss: 4.6351 - val_acc: 0.7124\n",
      "Epoch 28/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5153 - acc: 0.7199 - val_loss: 4.5464 - val_acc: 0.7179\n",
      "Epoch 29/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5877 - acc: 0.7154 - val_loss: 4.6015 - val_acc: 0.7145\n",
      "Epoch 30/60\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 4.5799 - acc: 0.7159 - val_loss: 4.6063 - val_acc: 0.7142\n",
      "Epoch 31/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.6190 - acc: 0.7134 - val_loss: 4.5498 - val_acc: 0.7177\n",
      "Epoch 32/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5623 - acc: 0.7169 - val_loss: 4.5175 - val_acc: 0.7197\n",
      "Epoch 33/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5405 - acc: 0.7183 - val_loss: 4.6357 - val_acc: 0.7124\n",
      "Epoch 34/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5757 - acc: 0.7161 - val_loss: 4.5925 - val_acc: 0.7151\n",
      "Epoch 35/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5026 - acc: 0.7206 - val_loss: 4.5418 - val_acc: 0.7182\n",
      "Epoch 36/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.6078 - acc: 0.7141 - val_loss: 4.5377 - val_acc: 0.7185\n",
      "Epoch 37/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.6474 - acc: 0.7117 - val_loss: 4.6278 - val_acc: 0.7129\n",
      "Epoch 38/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.6302 - acc: 0.7127 - val_loss: 4.5556 - val_acc: 0.7174\n",
      "Epoch 39/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5452 - acc: 0.7180 - val_loss: 4.6233 - val_acc: 0.7132\n",
      "Epoch 40/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5362 - acc: 0.7186 - val_loss: 4.5276 - val_acc: 0.7191\n",
      "Epoch 41/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5787 - acc: 0.7159 - val_loss: 4.5984 - val_acc: 0.7147\n",
      "Epoch 42/60\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 4.6287 - acc: 0.7128 - val_loss: 4.5254 - val_acc: 0.7192\n",
      "Epoch 43/60\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 4.5504 - acc: 0.7177 - val_loss: 4.6052 - val_acc: 0.7143\n",
      "Epoch 44/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5981 - acc: 0.7147 - val_loss: 4.6127 - val_acc: 0.7138\n",
      "Epoch 45/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5772 - acc: 0.7160 - val_loss: 4.5498 - val_acc: 0.7177\n",
      "Epoch 46/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.5832 - acc: 0.7156 - val_loss: 4.6127 - val_acc: 0.7138\n",
      "Epoch 47/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.6235 - acc: 0.7131 - val_loss: 4.5226 - val_acc: 0.7194\n",
      "Epoch 48/60\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 4.5295 - acc: 0.7190 - val_loss: 4.5892 - val_acc: 0.7153\n",
      "Epoch 49/60\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 4.4847 - acc: 0.7218 - val_loss: 4.6606 - val_acc: 0.7108\n",
      "Epoch 50/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.5489 - acc: 0.7178 - val_loss: 4.4963 - val_acc: 0.7210\n",
      "Epoch 51/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.6071 - acc: 0.7142 - val_loss: 4.6719 - val_acc: 0.7101\n",
      "Epoch 52/60\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 4.6093 - acc: 0.7140 - val_loss: 4.5108 - val_acc: 0.7201\n",
      "Epoch 53/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5646 - acc: 0.7168 - val_loss: 4.5011 - val_acc: 0.7207\n",
      "Epoch 54/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5243 - acc: 0.7193 - val_loss: 4.5948 - val_acc: 0.7149\n",
      "Epoch 55/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5340 - acc: 0.7187 - val_loss: 4.6640 - val_acc: 0.7106\n",
      "Epoch 56/60\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 4.5675 - acc: 0.7166 - val_loss: 4.5422 - val_acc: 0.7182\n",
      "Epoch 57/60\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 4.6442 - acc: 0.7119 - val_loss: 4.4819 - val_acc: 0.7219\n",
      "Epoch 58/60\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 4.5832 - acc: 0.7156 - val_loss: 4.6093 - val_acc: 0.7140\n",
      "Epoch 59/60\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 4.5743 - acc: 0.7162 - val_loss: 4.5611 - val_acc: 0.7170\n",
      "Epoch 60/60\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 4.5683 - acc: 0.7166 - val_loss: 4.6474 - val_acc: 0.7117\n",
      "\n",
      "Training process completed in: 0 h 12 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1189.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1191 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_121 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.5630 - acc: 0.7190 - val_loss: 0.4974 - val_acc: 0.7438\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4537 - acc: 0.7976 - val_loss: 0.4451 - val_acc: 0.8012\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4318 - acc: 0.8165 - val_loss: 0.4520 - val_acc: 0.7975\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4260 - acc: 0.8171 - val_loss: 0.4076 - val_acc: 0.8284\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4269 - acc: 0.8192 - val_loss: 0.4278 - val_acc: 0.8225\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4098 - acc: 0.8265 - val_loss: 0.4129 - val_acc: 0.8247\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4108 - acc: 0.8258 - val_loss: 0.4235 - val_acc: 0.8128\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4160 - acc: 0.8211 - val_loss: 0.3980 - val_acc: 0.8281\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4176 - acc: 0.8204 - val_loss: 0.3919 - val_acc: 0.8296\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4083 - acc: 0.8263 - val_loss: 0.4147 - val_acc: 0.8219\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3988 - acc: 0.8274 - val_loss: 0.4011 - val_acc: 0.8287\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4028 - acc: 0.8258 - val_loss: 0.3909 - val_acc: 0.8250\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4013 - acc: 0.8267 - val_loss: 0.4024 - val_acc: 0.8247\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3997 - acc: 0.8287 - val_loss: 0.3904 - val_acc: 0.8319\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3993 - acc: 0.8279 - val_loss: 0.4185 - val_acc: 0.8141\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3940 - acc: 0.8303 - val_loss: 0.3914 - val_acc: 0.8303\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3988 - acc: 0.8269 - val_loss: 0.4122 - val_acc: 0.8281\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3836 - acc: 0.8383 - val_loss: 0.3989 - val_acc: 0.8330\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3853 - acc: 0.8363 - val_loss: 0.3731 - val_acc: 0.8409\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3914 - acc: 0.8336 - val_loss: 0.3899 - val_acc: 0.8281\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3968 - acc: 0.8276 - val_loss: 0.4019 - val_acc: 0.8237\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3889 - acc: 0.8332 - val_loss: 0.3723 - val_acc: 0.8406\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3855 - acc: 0.8307 - val_loss: 0.4097 - val_acc: 0.8169\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3808 - acc: 0.8362 - val_loss: 0.3853 - val_acc: 0.8328\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3752 - acc: 0.8386 - val_loss: 0.3862 - val_acc: 0.8347\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3834 - acc: 0.8376 - val_loss: 0.3817 - val_acc: 0.8331\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3721 - acc: 0.8387 - val_loss: 0.3982 - val_acc: 0.8264\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3818 - acc: 0.8339 - val_loss: 0.3934 - val_acc: 0.8325\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3773 - acc: 0.8361 - val_loss: 0.3728 - val_acc: 0.8419\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3764 - acc: 0.8388 - val_loss: 0.3770 - val_acc: 0.8341\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3688 - acc: 0.8434 - val_loss: 0.4032 - val_acc: 0.8222\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3701 - acc: 0.8407 - val_loss: 0.3817 - val_acc: 0.8350\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3762 - acc: 0.8384 - val_loss: 0.3624 - val_acc: 0.8431\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3734 - acc: 0.8409 - val_loss: 0.3783 - val_acc: 0.8375\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3706 - acc: 0.8422 - val_loss: 0.3652 - val_acc: 0.8402\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3634 - acc: 0.8411 - val_loss: 0.3584 - val_acc: 0.8416\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3642 - acc: 0.8444 - val_loss: 0.3624 - val_acc: 0.8456\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3698 - acc: 0.8422 - val_loss: 0.3895 - val_acc: 0.8209\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3645 - acc: 0.8421 - val_loss: 0.3569 - val_acc: 0.8472\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3733 - acc: 0.8386 - val_loss: 0.3876 - val_acc: 0.8441\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3622 - acc: 0.8465 - val_loss: 0.3584 - val_acc: 0.8522\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3559 - acc: 0.8464 - val_loss: 0.3543 - val_acc: 0.8425\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3569 - acc: 0.8477 - val_loss: 0.3593 - val_acc: 0.8441\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3595 - acc: 0.8481 - val_loss: 0.3814 - val_acc: 0.8355\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3655 - acc: 0.8443 - val_loss: 0.3636 - val_acc: 0.8438\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3571 - acc: 0.8485 - val_loss: 0.3964 - val_acc: 0.8269\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3483 - acc: 0.8503 - val_loss: 0.3308 - val_acc: 0.8653\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.3637 - acc: 0.8459 - val_loss: 0.3662 - val_acc: 0.8497\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3566 - acc: 0.8465 - val_loss: 0.3543 - val_acc: 0.8484\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3528 - acc: 0.8504 - val_loss: 0.3460 - val_acc: 0.8506\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3446 - acc: 0.8559 - val_loss: 0.3639 - val_acc: 0.8431\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3575 - acc: 0.8441 - val_loss: 0.3718 - val_acc: 0.8459\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.3527 - acc: 0.8525 - val_loss: 0.3461 - val_acc: 0.8503\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3495 - acc: 0.8519 - val_loss: 0.3669 - val_acc: 0.8431\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3520 - acc: 0.8510 - val_loss: 0.3453 - val_acc: 0.8488\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3498 - acc: 0.8528 - val_loss: 0.3658 - val_acc: 0.8422\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3584 - acc: 0.8431 - val_loss: 0.3504 - val_acc: 0.8534\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3533 - acc: 0.8472 - val_loss: 0.3668 - val_acc: 0.8487\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3487 - acc: 0.8510 - val_loss: 0.3372 - val_acc: 0.8600\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3457 - acc: 0.8522 - val_loss: 0.3372 - val_acc: 0.8591\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3502 - acc: 0.8501 - val_loss: 0.3465 - val_acc: 0.8615\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3429 - acc: 0.8549 - val_loss: 0.3281 - val_acc: 0.8616\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3470 - acc: 0.8520 - val_loss: 0.3659 - val_acc: 0.8425\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3320 - acc: 0.8564 - val_loss: 0.3411 - val_acc: 0.8531\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3466 - acc: 0.8513 - val_loss: 0.3366 - val_acc: 0.8613\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3515 - acc: 0.8522 - val_loss: 0.3617 - val_acc: 0.8531\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3390 - acc: 0.8613 - val_loss: 0.3427 - val_acc: 0.8553\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3460 - acc: 0.8517 - val_loss: 0.3505 - val_acc: 0.8459\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3560 - acc: 0.8464 - val_loss: 0.3426 - val_acc: 0.8534\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3448 - acc: 0.8546 - val_loss: 0.3529 - val_acc: 0.8515\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3386 - acc: 0.8590 - val_loss: 0.3336 - val_acc: 0.8562\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3453 - acc: 0.8526 - val_loss: 0.3415 - val_acc: 0.8569\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3385 - acc: 0.8560 - val_loss: 0.3402 - val_acc: 0.8597\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3338 - acc: 0.8583 - val_loss: 0.3348 - val_acc: 0.8547\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3463 - acc: 0.8535 - val_loss: 0.3353 - val_acc: 0.8619\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3266 - acc: 0.8638 - val_loss: 0.3325 - val_acc: 0.8600\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3383 - acc: 0.8580 - val_loss: 0.3319 - val_acc: 0.8600\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3368 - acc: 0.8557 - val_loss: 0.3412 - val_acc: 0.8513\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3318 - acc: 0.8608 - val_loss: 0.3299 - val_acc: 0.8631\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3452 - acc: 0.8549 - val_loss: 0.3178 - val_acc: 0.8675\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3291 - acc: 0.8613 - val_loss: 0.3252 - val_acc: 0.8619\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3369 - acc: 0.8582 - val_loss: 0.3459 - val_acc: 0.8587\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3294 - acc: 0.8613 - val_loss: 0.3322 - val_acc: 0.8606\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3377 - acc: 0.8576 - val_loss: 0.3408 - val_acc: 0.8541\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3319 - acc: 0.8582 - val_loss: 0.3317 - val_acc: 0.8609\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3329 - acc: 0.8584 - val_loss: 0.3466 - val_acc: 0.8572\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3349 - acc: 0.8576 - val_loss: 0.3297 - val_acc: 0.8675\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3283 - acc: 0.8653 - val_loss: 0.3444 - val_acc: 0.8538\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3286 - acc: 0.8615 - val_loss: 0.3194 - val_acc: 0.8716\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3348 - acc: 0.8563 - val_loss: 0.3435 - val_acc: 0.8528\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3350 - acc: 0.8580 - val_loss: 0.3467 - val_acc: 0.8506\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3320 - acc: 0.8592 - val_loss: 0.3195 - val_acc: 0.8672\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3312 - acc: 0.8589 - val_loss: 0.3310 - val_acc: 0.8581\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3288 - acc: 0.8613 - val_loss: 0.3351 - val_acc: 0.8594\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3279 - acc: 0.8628 - val_loss: 0.3282 - val_acc: 0.8647\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3238 - acc: 0.8615 - val_loss: 0.3287 - val_acc: 0.8628\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3242 - acc: 0.8629 - val_loss: 0.3449 - val_acc: 0.8541\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3232 - acc: 0.8613 - val_loss: 0.3395 - val_acc: 0.8459\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3314 - acc: 0.8612 - val_loss: 0.3433 - val_acc: 0.8531\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3284 - acc: 0.8605 - val_loss: 0.3315 - val_acc: 0.8613\n",
      "\n",
      "Training process completed in: 0 h 10 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1190.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1192 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_125 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 46ms/step - loss: 0.5958 - acc: 0.7056 - val_loss: 0.5724 - val_acc: 0.7125\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.5420 - acc: 0.7158 - val_loss: 0.4899 - val_acc: 0.7421\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4736 - acc: 0.7896 - val_loss: 0.4222 - val_acc: 0.8183\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4364 - acc: 0.8132 - val_loss: 0.4132 - val_acc: 0.8154\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4205 - acc: 0.8183 - val_loss: 0.4394 - val_acc: 0.8121\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4258 - acc: 0.8186 - val_loss: 0.4148 - val_acc: 0.8229\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4160 - acc: 0.8213 - val_loss: 0.4233 - val_acc: 0.8096\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4087 - acc: 0.8275 - val_loss: 0.4095 - val_acc: 0.8179\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4092 - acc: 0.8256 - val_loss: 0.4154 - val_acc: 0.8167\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4056 - acc: 0.8253 - val_loss: 0.4051 - val_acc: 0.8246\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4175 - acc: 0.8200 - val_loss: 0.4107 - val_acc: 0.8196\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.3991 - acc: 0.8275 - val_loss: 0.4244 - val_acc: 0.8170\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3991 - acc: 0.8269 - val_loss: 0.4156 - val_acc: 0.8192\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4013 - acc: 0.8254 - val_loss: 0.4148 - val_acc: 0.8171\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4163 - acc: 0.8188 - val_loss: 0.4137 - val_acc: 0.8150\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4025 - acc: 0.8289 - val_loss: 0.3960 - val_acc: 0.8321\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4166 - acc: 0.8233 - val_loss: 0.4016 - val_acc: 0.8313\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4092 - acc: 0.8256 - val_loss: 0.4146 - val_acc: 0.8158\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3882 - acc: 0.8358 - val_loss: 0.3885 - val_acc: 0.8338\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.4038 - acc: 0.8296 - val_loss: 0.4239 - val_acc: 0.8167\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.3944 - val_acc: 0.8292\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3993 - acc: 0.8272 - val_loss: 0.3898 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.4097 - acc: 0.8189 - val_loss: 0.4118 - val_acc: 0.8317\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.4008 - acc: 0.8264 - val_loss: 0.4161 - val_acc: 0.8221\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3881 - acc: 0.8315 - val_loss: 0.3981 - val_acc: 0.8250\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3976 - acc: 0.8257 - val_loss: 0.4174 - val_acc: 0.8171\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.4020 - acc: 0.8246 - val_loss: 0.3928 - val_acc: 0.8225\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.4003 - acc: 0.8237 - val_loss: 0.3788 - val_acc: 0.8346\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3905 - acc: 0.8275 - val_loss: 0.3837 - val_acc: 0.8271\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3929 - acc: 0.8286 - val_loss: 0.3794 - val_acc: 0.8383\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3820 - acc: 0.8335 - val_loss: 0.3746 - val_acc: 0.8379\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3777 - acc: 0.8415 - val_loss: 0.3797 - val_acc: 0.8354\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3860 - acc: 0.8319 - val_loss: 0.3872 - val_acc: 0.8333\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3907 - acc: 0.8311 - val_loss: 0.3569 - val_acc: 0.8513\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3846 - acc: 0.8319 - val_loss: 0.3822 - val_acc: 0.8322\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3689 - acc: 0.8442 - val_loss: 0.4155 - val_acc: 0.8171\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3908 - acc: 0.8286 - val_loss: 0.4030 - val_acc: 0.8233\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3815 - acc: 0.8367 - val_loss: 0.3739 - val_acc: 0.8383\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3822 - acc: 0.8335 - val_loss: 0.3776 - val_acc: 0.8371\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3731 - acc: 0.8400 - val_loss: 0.3666 - val_acc: 0.8417\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3787 - acc: 0.8408 - val_loss: 0.4004 - val_acc: 0.8271\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3779 - acc: 0.8376 - val_loss: 0.3846 - val_acc: 0.8308\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3789 - acc: 0.8342 - val_loss: 0.3838 - val_acc: 0.8417\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3787 - acc: 0.8318 - val_loss: 0.3709 - val_acc: 0.8371\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3850 - acc: 0.8321 - val_loss: 0.3929 - val_acc: 0.8363\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3880 - acc: 0.8300 - val_loss: 0.3784 - val_acc: 0.8388\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3914 - acc: 0.8328 - val_loss: 0.4047 - val_acc: 0.8191\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3760 - acc: 0.8375 - val_loss: 0.3810 - val_acc: 0.8354\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3638 - acc: 0.8390 - val_loss: 0.3581 - val_acc: 0.8525\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3706 - acc: 0.8392 - val_loss: 0.3720 - val_acc: 0.8392\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3742 - acc: 0.8369 - val_loss: 0.3638 - val_acc: 0.8438\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3679 - acc: 0.8442 - val_loss: 0.3761 - val_acc: 0.8408\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3853 - acc: 0.8322 - val_loss: 0.3748 - val_acc: 0.8392\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3748 - acc: 0.8329 - val_loss: 0.3670 - val_acc: 0.8404\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3770 - acc: 0.8406 - val_loss: 0.3805 - val_acc: 0.8350\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3699 - acc: 0.8403 - val_loss: 0.3622 - val_acc: 0.8471\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3587 - acc: 0.8469 - val_loss: 0.3781 - val_acc: 0.8371\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3712 - acc: 0.8393 - val_loss: 0.3714 - val_acc: 0.8583\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3672 - acc: 0.8393 - val_loss: 0.3919 - val_acc: 0.8325\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3676 - acc: 0.8415 - val_loss: 0.3705 - val_acc: 0.8421\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3632 - acc: 0.8460 - val_loss: 0.3662 - val_acc: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3647 - acc: 0.8450 - val_loss: 0.3610 - val_acc: 0.8500\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3568 - acc: 0.8503 - val_loss: 0.3859 - val_acc: 0.8321\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3690 - acc: 0.8436 - val_loss: 0.3659 - val_acc: 0.8413\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3701 - acc: 0.8388 - val_loss: 0.3463 - val_acc: 0.8563\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3715 - acc: 0.8392 - val_loss: 0.3642 - val_acc: 0.8471\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3633 - acc: 0.8497 - val_loss: 0.3890 - val_acc: 0.8346\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3634 - acc: 0.8461 - val_loss: 0.3488 - val_acc: 0.8488\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3599 - acc: 0.8463 - val_loss: 0.3758 - val_acc: 0.83381s - loss: 0.3422 - acc: - ETA: 1s - loss:\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3592 - acc: 0.8481 - val_loss: 0.3557 - val_acc: 0.8470\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3573 - acc: 0.8458 - val_loss: 0.3751 - val_acc: 0.8333\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3635 - acc: 0.8461 - val_loss: 0.3643 - val_acc: 0.8450\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3563 - acc: 0.8471 - val_loss: 0.3500 - val_acc: 0.8483\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3554 - acc: 0.8471 - val_loss: 0.3745 - val_acc: 0.8404\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3501 - acc: 0.8571 - val_loss: 0.3376 - val_acc: 0.8608\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3649 - acc: 0.8440 - val_loss: 0.3493 - val_acc: 0.8467\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3635 - acc: 0.8421 - val_loss: 0.3595 - val_acc: 0.8479\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3486 - acc: 0.8544 - val_loss: 0.3426 - val_acc: 0.8550\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3556 - acc: 0.8488 - val_loss: 0.3611 - val_acc: 0.8488\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3564 - acc: 0.8500 - val_loss: 0.3732 - val_acc: 0.8379\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3570 - acc: 0.8461 - val_loss: 0.3484 - val_acc: 0.8558\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.3484 - acc: 0.8458 - val_loss: 0.3799 - val_acc: 0.8394\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3680 - acc: 0.8422 - val_loss: 0.3494 - val_acc: 0.8433\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3401 - acc: 0.8561 - val_loss: 0.3714 - val_acc: 0.8342\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3501 - acc: 0.8504 - val_loss: 0.3665 - val_acc: 0.8396\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3525 - acc: 0.8486 - val_loss: 0.3273 - val_acc: 0.8613\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3482 - acc: 0.8522 - val_loss: 0.3632 - val_acc: 0.8479\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.3574 - acc: 0.8446 - val_loss: 0.3542 - val_acc: 0.8521\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3567 - acc: 0.8486 - val_loss: 0.3402 - val_acc: 0.8513\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3520 - acc: 0.8475 - val_loss: 0.3444 - val_acc: 0.8479\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3567 - acc: 0.8447 - val_loss: 0.3550 - val_acc: 0.8521\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3486 - acc: 0.8544 - val_loss: 0.3559 - val_acc: 0.8537\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3512 - acc: 0.8547 - val_loss: 0.3628 - val_acc: 0.8411\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3427 - acc: 0.8504 - val_loss: 0.3454 - val_acc: 0.8554\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3541 - acc: 0.8500 - val_loss: 0.3480 - val_acc: 0.8517\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3649 - acc: 0.8463 - val_loss: 0.3472 - val_acc: 0.8433\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3432 - acc: 0.8526 - val_loss: 0.3389 - val_acc: 0.8663\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3350 - acc: 0.8604 - val_loss: 0.3514 - val_acc: 0.8583\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3449 - acc: 0.8540 - val_loss: 0.3296 - val_acc: 0.8658\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3512 - acc: 0.8478 - val_loss: 0.3514 - val_acc: 0.8500\n",
      "\n",
      "Training process completed in: 0 h 5 m 50 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1191.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1193 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_129 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_130 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_131 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_132 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4958 - acc: 0.7731 - val_loss: 0.4857 - val_acc: 0.7700\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4494 - acc: 0.8096 - val_loss: 0.4454 - val_acc: 0.8038\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4426 - acc: 0.8067 - val_loss: 0.4234 - val_acc: 0.8212\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4132 - acc: 0.8243 - val_loss: 0.5138 - val_acc: 0.7819\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4157 - acc: 0.8255 - val_loss: 0.4277 - val_acc: 0.8219\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4218 - acc: 0.8184 - val_loss: 0.3866 - val_acc: 0.8325\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4127 - acc: 0.8247 - val_loss: 0.4316 - val_acc: 0.8356\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4193 - acc: 0.8210 - val_loss: 0.4458 - val_acc: 0.8294\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4026 - acc: 0.8287 - val_loss: 0.4352 - val_acc: 0.7987\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3944 - acc: 0.8308 - val_loss: 0.4050 - val_acc: 0.8356\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3810 - acc: 0.8355 - val_loss: 0.3720 - val_acc: 0.8394\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3924 - acc: 0.8301 - val_loss: 0.4209 - val_acc: 0.8263\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3929 - acc: 0.8368 - val_loss: 0.4092 - val_acc: 0.8269\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3951 - acc: 0.8305 - val_loss: 0.4522 - val_acc: 0.8425\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3849 - acc: 0.8377 - val_loss: 0.4095 - val_acc: 0.8300\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3886 - acc: 0.8315 - val_loss: 0.3721 - val_acc: 0.8412\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3783 - acc: 0.8391 - val_loss: 0.3803 - val_acc: 0.8556\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3714 - acc: 0.8442 - val_loss: 0.3930 - val_acc: 0.8536\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3837 - acc: 0.8331 - val_loss: 0.4131 - val_acc: 0.8287\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3740 - acc: 0.8378 - val_loss: 0.3903 - val_acc: 0.8375\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3877 - acc: 0.8365 - val_loss: 0.3992 - val_acc: 0.8456\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3842 - acc: 0.8364 - val_loss: 0.3894 - val_acc: 0.8344\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3680 - acc: 0.8418 - val_loss: 0.4400 - val_acc: 0.8144\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3626 - acc: 0.8481 - val_loss: 0.3922 - val_acc: 0.8300\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3838 - acc: 0.8355 - val_loss: 0.4066 - val_acc: 0.8331\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3683 - acc: 0.8433 - val_loss: 0.3587 - val_acc: 0.8500\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3690 - acc: 0.8429 - val_loss: 0.3532 - val_acc: 0.8588\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3623 - acc: 0.8452 - val_loss: 0.3710 - val_acc: 0.8444\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3567 - acc: 0.8474 - val_loss: 0.4125 - val_acc: 0.8250\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3613 - acc: 0.8454 - val_loss: 0.3812 - val_acc: 0.8438\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3635 - acc: 0.8463 - val_loss: 0.4377 - val_acc: 0.8200\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3624 - acc: 0.8505 - val_loss: 0.3821 - val_acc: 0.8325\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3670 - acc: 0.8415 - val_loss: 0.3810 - val_acc: 0.8650\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3605 - acc: 0.8450 - val_loss: 0.3888 - val_acc: 0.8494\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3700 - acc: 0.8433 - val_loss: 0.4157 - val_acc: 0.8411\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3616 - acc: 0.8472 - val_loss: 0.3656 - val_acc: 0.8412\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3620 - acc: 0.8457 - val_loss: 0.3538 - val_acc: 0.8544\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3532 - acc: 0.8545 - val_loss: 0.3758 - val_acc: 0.8406\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3562 - acc: 0.8492 - val_loss: 0.3737 - val_acc: 0.8512\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3606 - acc: 0.8442 - val_loss: 0.3844 - val_acc: 0.8269\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3566 - acc: 0.8526 - val_loss: 0.3721 - val_acc: 0.8550\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3561 - acc: 0.8519 - val_loss: 0.3692 - val_acc: 0.8475\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3556 - acc: 0.8517 - val_loss: 0.3699 - val_acc: 0.8519\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3567 - acc: 0.8494 - val_loss: 0.3633 - val_acc: 0.8562\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3490 - acc: 0.8497 - val_loss: 0.3606 - val_acc: 0.8544\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3506 - acc: 0.8508 - val_loss: 0.4011 - val_acc: 0.8450\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3561 - acc: 0.8453 - val_loss: 0.3701 - val_acc: 0.8419\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3496 - acc: 0.8517 - val_loss: 0.3628 - val_acc: 0.8475\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3562 - acc: 0.8464 - val_loss: 0.3580 - val_acc: 0.8463\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3397 - acc: 0.8559 - val_loss: 0.3950 - val_acc: 0.8469\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3579 - acc: 0.8528 - val_loss: 0.4010 - val_acc: 0.8375\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3511 - acc: 0.8518 - val_loss: 0.3652 - val_acc: 0.8519\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3558 - acc: 0.8470 - val_loss: 0.3716 - val_acc: 0.8518\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3530 - acc: 0.8505 - val_loss: 0.3769 - val_acc: 0.8356\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3461 - acc: 0.8522 - val_loss: 0.3229 - val_acc: 0.8650\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3345 - acc: 0.8554 - val_loss: 0.3753 - val_acc: 0.8281\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3451 - acc: 0.8552 - val_loss: 0.4093 - val_acc: 0.8325\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3547 - acc: 0.8474 - val_loss: 0.3466 - val_acc: 0.8575\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3442 - acc: 0.8552 - val_loss: 0.3596 - val_acc: 0.8763\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3522 - acc: 0.8493 - val_loss: 0.3695 - val_acc: 0.8519\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3337 - acc: 0.8554 - val_loss: 0.3694 - val_acc: 0.8487\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3423 - acc: 0.8577 - val_loss: 0.3724 - val_acc: 0.8519\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3426 - acc: 0.8563 - val_loss: 0.3758 - val_acc: 0.8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3408 - acc: 0.8576 - val_loss: 0.3632 - val_acc: 0.8681\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3393 - acc: 0.8515 - val_loss: 0.3634 - val_acc: 0.8488\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3358 - acc: 0.8636 - val_loss: 0.3274 - val_acc: 0.8744\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3321 - acc: 0.8591 - val_loss: 0.3596 - val_acc: 0.8463\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3426 - acc: 0.8510 - val_loss: 0.3849 - val_acc: 0.8481\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3416 - acc: 0.8581 - val_loss: 0.3816 - val_acc: 0.8331\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3442 - acc: 0.8518 - val_loss: 0.3319 - val_acc: 0.8618\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3343 - acc: 0.8571 - val_loss: 0.3520 - val_acc: 0.8556\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3276 - acc: 0.8667 - val_loss: 0.3238 - val_acc: 0.8656\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3421 - acc: 0.8540 - val_loss: 0.3600 - val_acc: 0.8519\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3487 - acc: 0.8533 - val_loss: 0.3538 - val_acc: 0.8550\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3412 - acc: 0.8543 - val_loss: 0.3590 - val_acc: 0.8413\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3367 - acc: 0.8566 - val_loss: 0.3596 - val_acc: 0.8594\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3453 - acc: 0.8544 - val_loss: 0.3391 - val_acc: 0.8575\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3285 - acc: 0.8617 - val_loss: 0.3767 - val_acc: 0.8569\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3397 - acc: 0.8569 - val_loss: 0.3399 - val_acc: 0.8556\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3324 - acc: 0.8587 - val_loss: 0.3506 - val_acc: 0.8625\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3342 - acc: 0.8605 - val_loss: 0.3556 - val_acc: 0.8619\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3347 - acc: 0.8564 - val_loss: 0.3567 - val_acc: 0.8575\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3322 - acc: 0.8542 - val_loss: 0.3191 - val_acc: 0.8738\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3415 - acc: 0.8533 - val_loss: 0.3693 - val_acc: 0.8419\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3409 - acc: 0.8551 - val_loss: 0.3613 - val_acc: 0.8531\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3283 - acc: 0.8628 - val_loss: 0.3369 - val_acc: 0.8669\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3428 - acc: 0.8533 - val_loss: 0.3469 - val_acc: 0.8536\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3372 - acc: 0.8531 - val_loss: 0.3313 - val_acc: 0.8694\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3471 - acc: 0.8523 - val_loss: 0.3515 - val_acc: 0.8606\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3318 - acc: 0.8560 - val_loss: 0.3645 - val_acc: 0.8494\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3428 - acc: 0.8566 - val_loss: 0.3467 - val_acc: 0.8637\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3311 - acc: 0.8581 - val_loss: 0.3455 - val_acc: 0.8556\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3248 - acc: 0.8620 - val_loss: 0.3458 - val_acc: 0.8513\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3220 - acc: 0.8657 - val_loss: 0.3255 - val_acc: 0.8625\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3244 - acc: 0.8665 - val_loss: 0.3275 - val_acc: 0.8681\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3375 - acc: 0.8564 - val_loss: 0.3436 - val_acc: 0.8612\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3318 - acc: 0.8589 - val_loss: 0.3135 - val_acc: 0.8738\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3167 - acc: 0.8682 - val_loss: 0.3673 - val_acc: 0.8425\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3271 - acc: 0.8639 - val_loss: 0.3525 - val_acc: 0.8563\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3267 - acc: 0.8646 - val_loss: 0.3403 - val_acc: 0.8613\n",
      "\n",
      "Training process completed in: 0 h 6 m 45 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1192.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1194 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_133 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.5768 - acc: 0.7171 - val_loss: 0.5443 - val_acc: 0.7050\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4843 - acc: 0.7706 - val_loss: 0.4395 - val_acc: 0.8125\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4180 - acc: 0.8211 - val_loss: 0.4466 - val_acc: 0.8225\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4102 - acc: 0.8217 - val_loss: 0.4175 - val_acc: 0.8137\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4254 - acc: 0.8183 - val_loss: 0.4389 - val_acc: 0.8025\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4202 - acc: 0.8204 - val_loss: 0.4372 - val_acc: 0.8031\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4136 - acc: 0.8232 - val_loss: 0.4111 - val_acc: 0.8156\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4270 - acc: 0.8175 - val_loss: 0.4027 - val_acc: 0.8325\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4260 - acc: 0.8170 - val_loss: 0.3978 - val_acc: 0.8287\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4153 - acc: 0.8182 - val_loss: 0.4388 - val_acc: 0.8088\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4029 - acc: 0.8267 - val_loss: 0.4300 - val_acc: 0.8044\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4084 - acc: 0.8242 - val_loss: 0.4224 - val_acc: 0.8100\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4038 - acc: 0.8255 - val_loss: 0.3876 - val_acc: 0.8287\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4023 - acc: 0.8294 - val_loss: 0.4196 - val_acc: 0.8119\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4031 - acc: 0.8296 - val_loss: 0.4310 - val_acc: 0.8113\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4052 - acc: 0.8244 - val_loss: 0.4154 - val_acc: 0.8162\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.4150 - acc: 0.8194 - val_loss: 0.3925 - val_acc: 0.8275\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.4050 - acc: 0.8241 - val_loss: 0.4055 - val_acc: 0.8273\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3996 - acc: 0.8297 - val_loss: 0.3909 - val_acc: 0.8325\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3959 - acc: 0.8291 - val_loss: 0.4014 - val_acc: 0.8294\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3990 - acc: 0.8295 - val_loss: 0.4064 - val_acc: 0.8269\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.4036 - acc: 0.8235 - val_loss: 0.4118 - val_acc: 0.8181\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3963 - acc: 0.8296 - val_loss: 0.3975 - val_acc: 0.8281\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3991 - acc: 0.8298 - val_loss: 0.4148 - val_acc: 0.8219\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3924 - acc: 0.8282 - val_loss: 0.3801 - val_acc: 0.8338\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3969 - acc: 0.8282 - val_loss: 0.3906 - val_acc: 0.8338\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3807 - acc: 0.8382 - val_loss: 0.4019 - val_acc: 0.8250\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3941 - acc: 0.8289 - val_loss: 0.3706 - val_acc: 0.8363\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3896 - acc: 0.8332 - val_loss: 0.4224 - val_acc: 0.8056\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3822 - acc: 0.8355 - val_loss: 0.3779 - val_acc: 0.8350\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3839 - acc: 0.8322 - val_loss: 0.4001 - val_acc: 0.8219\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3766 - acc: 0.8419 - val_loss: 0.3738 - val_acc: 0.8319\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3890 - acc: 0.8321 - val_loss: 0.3817 - val_acc: 0.8419\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3876 - acc: 0.8354 - val_loss: 0.3988 - val_acc: 0.8294\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3797 - acc: 0.8361 - val_loss: 0.3819 - val_acc: 0.8298\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3807 - acc: 0.8371 - val_loss: 0.3808 - val_acc: 0.8462\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3800 - acc: 0.8361 - val_loss: 0.3526 - val_acc: 0.8531\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3828 - acc: 0.8356 - val_loss: 0.3834 - val_acc: 0.8338\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3783 - acc: 0.8389 - val_loss: 0.3942 - val_acc: 0.8331\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3787 - acc: 0.8363 - val_loss: 0.3853 - val_acc: 0.8363\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3757 - acc: 0.8383 - val_loss: 0.3721 - val_acc: 0.8275\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3788 - acc: 0.8355 - val_loss: 0.3809 - val_acc: 0.8375\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3757 - acc: 0.8370 - val_loss: 0.3766 - val_acc: 0.8425\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3812 - acc: 0.8354 - val_loss: 0.3539 - val_acc: 0.8406\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3782 - acc: 0.8384 - val_loss: 0.3784 - val_acc: 0.8400\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3809 - acc: 0.8319 - val_loss: 0.3815 - val_acc: 0.8394\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3703 - acc: 0.8422 - val_loss: 0.3642 - val_acc: 0.8413\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3720 - acc: 0.8378 - val_loss: 0.3664 - val_acc: 0.8488\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3753 - acc: 0.8393 - val_loss: 0.3698 - val_acc: 0.8406\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3713 - acc: 0.8384 - val_loss: 0.4039 - val_acc: 0.8162\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3658 - acc: 0.8486 - val_loss: 0.4041 - val_acc: 0.8281\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3680 - acc: 0.8443 - val_loss: 0.3694 - val_acc: 0.8350\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3633 - acc: 0.8455 - val_loss: 0.3695 - val_acc: 0.8448\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3564 - acc: 0.8458 - val_loss: 0.3675 - val_acc: 0.8325\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3677 - acc: 0.8451 - val_loss: 0.3663 - val_acc: 0.8581\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3743 - acc: 0.8395 - val_loss: 0.3760 - val_acc: 0.8400\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3598 - acc: 0.8466 - val_loss: 0.3685 - val_acc: 0.8463\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3552 - acc: 0.8503 - val_loss: 0.3717 - val_acc: 0.8369\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3662 - acc: 0.8423 - val_loss: 0.3588 - val_acc: 0.8394\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3638 - acc: 0.8443 - val_loss: 0.3929 - val_acc: 0.8450\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3593 - acc: 0.8475 - val_loss: 0.3950 - val_acc: 0.8325\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3707 - acc: 0.8371 - val_loss: 0.3564 - val_acc: 0.8550\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3578 - acc: 0.8472 - val_loss: 0.3596 - val_acc: 0.8500\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3621 - acc: 0.8461 - val_loss: 0.3627 - val_acc: 0.8406\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3544 - acc: 0.8511 - val_loss: 0.3562 - val_acc: 0.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3631 - acc: 0.8458 - val_loss: 0.3423 - val_acc: 0.8538\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3624 - acc: 0.8447 - val_loss: 0.3249 - val_acc: 0.8631\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3545 - acc: 0.8477 - val_loss: 0.3530 - val_acc: 0.8575\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3460 - acc: 0.8544 - val_loss: 0.3467 - val_acc: 0.8475\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3515 - acc: 0.8501 - val_loss: 0.3552 - val_acc: 0.8524\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3539 - acc: 0.8517 - val_loss: 0.3785 - val_acc: 0.8387\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3678 - acc: 0.8444 - val_loss: 0.3580 - val_acc: 0.8450\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3571 - acc: 0.8457 - val_loss: 0.3496 - val_acc: 0.8525\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3491 - acc: 0.8520 - val_loss: 0.3257 - val_acc: 0.8687\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3541 - acc: 0.8507 - val_loss: 0.3573 - val_acc: 0.8481\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3437 - acc: 0.8539 - val_loss: 0.3699 - val_acc: 0.8463\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3484 - acc: 0.8517 - val_loss: 0.3285 - val_acc: 0.8681\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3520 - acc: 0.8499 - val_loss: 0.3537 - val_acc: 0.8513\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3446 - acc: 0.8545 - val_loss: 0.3690 - val_acc: 0.8400\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3454 - acc: 0.8524 - val_loss: 0.3653 - val_acc: 0.8469\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3460 - acc: 0.8497 - val_loss: 0.3408 - val_acc: 0.8656\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3405 - acc: 0.8596 - val_loss: 0.3291 - val_acc: 0.8538\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3497 - acc: 0.8515 - val_loss: 0.3447 - val_acc: 0.8562\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3397 - acc: 0.8568 - val_loss: 0.3519 - val_acc: 0.8569\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3565 - acc: 0.8472 - val_loss: 0.3521 - val_acc: 0.8462\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3429 - acc: 0.8546 - val_loss: 0.3424 - val_acc: 0.8550\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3437 - acc: 0.8509 - val_loss: 0.3447 - val_acc: 0.8599\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3463 - acc: 0.8510 - val_loss: 0.3617 - val_acc: 0.8487\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3491 - acc: 0.8551 - val_loss: 0.3563 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3433 - acc: 0.8535 - val_loss: 0.3464 - val_acc: 0.8544\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3386 - acc: 0.8592 - val_loss: 0.3410 - val_acc: 0.8594\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3425 - acc: 0.8558 - val_loss: 0.3624 - val_acc: 0.8519\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3405 - acc: 0.8543 - val_loss: 0.3349 - val_acc: 0.8500\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3467 - acc: 0.8536 - val_loss: 0.3546 - val_acc: 0.8487\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3415 - acc: 0.8543 - val_loss: 0.3312 - val_acc: 0.8587\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3274 - acc: 0.8641 - val_loss: 0.3545 - val_acc: 0.8500\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3345 - acc: 0.8588 - val_loss: 0.3774 - val_acc: 0.8394\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3394 - acc: 0.8533 - val_loss: 0.3456 - val_acc: 0.8506\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3428 - acc: 0.8563 - val_loss: 0.3437 - val_acc: 0.8531\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3420 - acc: 0.8508 - val_loss: 0.3430 - val_acc: 0.8481\n",
      "\n",
      "Training process completed in: 0 h 6 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1193.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1195 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_137 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_137 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_138 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_139 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_140 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 10s 82ms/step - loss: 0.5824 - acc: 0.7149 - val_loss: 0.5594 - val_acc: 0.7127\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.5026 - acc: 0.7488 - val_loss: 0.4373 - val_acc: 0.8130\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4259 - acc: 0.8173 - val_loss: 0.4268 - val_acc: 0.8073\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4142 - acc: 0.8246 - val_loss: 0.4111 - val_acc: 0.8245\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4209 - acc: 0.8188 - val_loss: 0.4223 - val_acc: 0.8181\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4210 - acc: 0.8205 - val_loss: 0.4129 - val_acc: 0.8211\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4133 - acc: 0.8219 - val_loss: 0.4082 - val_acc: 0.8225\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4134 - acc: 0.8217 - val_loss: 0.4290 - val_acc: 0.8123\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4043 - acc: 0.8263 - val_loss: 0.4091 - val_acc: 0.8182\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4049 - acc: 0.8302 - val_loss: 0.3881 - val_acc: 0.8352\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.4052 - acc: 0.8268 - val_loss: 0.4137 - val_acc: 0.8173\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.4023 - acc: 0.8265 - val_loss: 0.4052 - val_acc: 0.8225\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.4000 - acc: 0.8280 - val_loss: 0.4117 - val_acc: 0.8329\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.4045 - acc: 0.8271 - val_loss: 0.4115 - val_acc: 0.8279\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3964 - acc: 0.8299 - val_loss: 0.3990 - val_acc: 0.8265\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.4019 - acc: 0.8261 - val_loss: 0.4084 - val_acc: 0.8225\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3986 - acc: 0.8292 - val_loss: 0.4028 - val_acc: 0.8245\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3927 - acc: 0.8309 - val_loss: 0.4008 - val_acc: 0.8279\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3945 - acc: 0.8329 - val_loss: 0.3854 - val_acc: 0.8373\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3912 - acc: 0.8327 - val_loss: 0.3896 - val_acc: 0.8298\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3920 - acc: 0.8342 - val_loss: 0.3868 - val_acc: 0.8323\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3888 - acc: 0.8350 - val_loss: 0.3763 - val_acc: 0.8391\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3844 - acc: 0.8375 - val_loss: 0.4031 - val_acc: 0.8275\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3863 - acc: 0.8335 - val_loss: 0.3933 - val_acc: 0.8302\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3804 - acc: 0.8360 - val_loss: 0.3933 - val_acc: 0.8261\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3795 - acc: 0.8389 - val_loss: 0.3988 - val_acc: 0.8300\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3884 - acc: 0.8347 - val_loss: 0.3958 - val_acc: 0.8289\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3790 - acc: 0.8394 - val_loss: 0.3882 - val_acc: 0.8343\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3779 - acc: 0.8376 - val_loss: 0.3688 - val_acc: 0.8438\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3794 - acc: 0.8370 - val_loss: 0.3669 - val_acc: 0.8467\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3744 - acc: 0.8396 - val_loss: 0.3792 - val_acc: 0.8400\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3692 - acc: 0.8434 - val_loss: 0.3600 - val_acc: 0.8425\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3772 - acc: 0.8385 - val_loss: 0.3710 - val_acc: 0.8411\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3846 - acc: 0.8332 - val_loss: 0.3803 - val_acc: 0.8346\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3719 - acc: 0.8398 - val_loss: 0.3938 - val_acc: 0.8369\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3776 - acc: 0.8396 - val_loss: 0.3688 - val_acc: 0.8446\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3695 - acc: 0.8417 - val_loss: 0.3720 - val_acc: 0.8377\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3693 - acc: 0.8434 - val_loss: 0.3853 - val_acc: 0.8346\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3730 - acc: 0.8428 - val_loss: 0.3652 - val_acc: 0.8450\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3647 - acc: 0.8455 - val_loss: 0.3795 - val_acc: 0.8367\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3696 - acc: 0.8439 - val_loss: 0.4142 - val_acc: 0.8191\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3679 - acc: 0.8440 - val_loss: 0.3674 - val_acc: 0.8396\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3693 - acc: 0.8436 - val_loss: 0.3634 - val_acc: 0.8496\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3653 - acc: 0.8429 - val_loss: 0.3539 - val_acc: 0.8484\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3611 - acc: 0.8477 - val_loss: 0.3713 - val_acc: 0.8421\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3720 - acc: 0.8418 - val_loss: 0.3748 - val_acc: 0.8329\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3690 - acc: 0.8434 - val_loss: 0.3671 - val_acc: 0.8409\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3549 - acc: 0.8486 - val_loss: 0.3569 - val_acc: 0.8521\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3650 - acc: 0.8473 - val_loss: 0.3726 - val_acc: 0.8416\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3701 - acc: 0.8429 - val_loss: 0.3495 - val_acc: 0.8512\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3664 - acc: 0.8440 - val_loss: 0.3584 - val_acc: 0.8457\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3515 - acc: 0.8505 - val_loss: 0.3488 - val_acc: 0.8498\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3626 - acc: 0.8465 - val_loss: 0.3643 - val_acc: 0.8404\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3584 - acc: 0.8472 - val_loss: 0.3525 - val_acc: 0.8521\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3593 - acc: 0.8475 - val_loss: 0.3761 - val_acc: 0.8409\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3595 - acc: 0.8488 - val_loss: 0.3572 - val_acc: 0.8470\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3567 - acc: 0.8490 - val_loss: 0.3450 - val_acc: 0.8521\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3639 - acc: 0.8470 - val_loss: 0.3612 - val_acc: 0.8523\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3622 - acc: 0.8470 - val_loss: 0.3576 - val_acc: 0.8445\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3494 - acc: 0.8518 - val_loss: 0.3606 - val_acc: 0.8447\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3559 - acc: 0.8482 - val_loss: 0.3416 - val_acc: 0.8609\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3530 - acc: 0.8520 - val_loss: 0.3496 - val_acc: 0.8518\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3577 - acc: 0.8490 - val_loss: 0.3498 - val_acc: 0.8489\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3515 - acc: 0.8515 - val_loss: 0.3658 - val_acc: 0.8398\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3491 - acc: 0.8518 - val_loss: 0.3880 - val_acc: 0.8288\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3508 - acc: 0.8522 - val_loss: 0.3904 - val_acc: 0.8307\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3463 - acc: 0.8512 - val_loss: 0.3594 - val_acc: 0.8473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3587 - acc: 0.8492 - val_loss: 0.3463 - val_acc: 0.8602\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3512 - acc: 0.8477 - val_loss: 0.3665 - val_acc: 0.8429\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3524 - acc: 0.8495 - val_loss: 0.3411 - val_acc: 0.8567\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3376 - acc: 0.8588 - val_loss: 0.3396 - val_acc: 0.8589\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3459 - acc: 0.8551 - val_loss: 0.3406 - val_acc: 0.8555\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3521 - acc: 0.8524 - val_loss: 0.3468 - val_acc: 0.8488\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3518 - acc: 0.8521 - val_loss: 0.3492 - val_acc: 0.8541\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3429 - acc: 0.8557 - val_loss: 0.3402 - val_acc: 0.8547\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3442 - acc: 0.8532 - val_loss: 0.3521 - val_acc: 0.8486\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3414 - acc: 0.8511 - val_loss: 0.3490 - val_acc: 0.8561\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3356 - acc: 0.8610 - val_loss: 0.3409 - val_acc: 0.8516\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3468 - acc: 0.8532 - val_loss: 0.3457 - val_acc: 0.8584\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3451 - acc: 0.8530 - val_loss: 0.3398 - val_acc: 0.8551\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3466 - acc: 0.8516 - val_loss: 0.3486 - val_acc: 0.8523\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3431 - acc: 0.8547 - val_loss: 0.3468 - val_acc: 0.8566\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3472 - acc: 0.8521 - val_loss: 0.3382 - val_acc: 0.8523\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3366 - acc: 0.8578 - val_loss: 0.3396 - val_acc: 0.8580\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3360 - acc: 0.8580 - val_loss: 0.3402 - val_acc: 0.8558\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3375 - acc: 0.8592 - val_loss: 0.3489 - val_acc: 0.8504\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3337 - acc: 0.8603 - val_loss: 0.3447 - val_acc: 0.8488\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3418 - acc: 0.8541 - val_loss: 0.3319 - val_acc: 0.8577\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3330 - acc: 0.8582 - val_loss: 0.3472 - val_acc: 0.8541\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3429 - acc: 0.8552 - val_loss: 0.3316 - val_acc: 0.8583\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3320 - acc: 0.8622 - val_loss: 0.3382 - val_acc: 0.8627\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3347 - acc: 0.8596 - val_loss: 0.3702 - val_acc: 0.8500\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3432 - acc: 0.8537 - val_loss: 0.3582 - val_acc: 0.8459\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3415 - acc: 0.8539 - val_loss: 0.3312 - val_acc: 0.8609\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3348 - acc: 0.8609 - val_loss: 0.3473 - val_acc: 0.8527\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3347 - acc: 0.8582 - val_loss: 0.3432 - val_acc: 0.8573\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3335 - acc: 0.8581 - val_loss: 0.3454 - val_acc: 0.8568\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3330 - acc: 0.8571 - val_loss: 0.3215 - val_acc: 0.8695\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3352 - acc: 0.8598 - val_loss: 0.3397 - val_acc: 0.8550\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3342 - acc: 0.8612 - val_loss: 0.3333 - val_acc: 0.8620\n",
      "\n",
      "Training process completed in: 0 h 12 m 52 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1194.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1196 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_141 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_141 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_142 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_143 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_144 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 14s 76ms/step - loss: 0.5028 - acc: 0.7636 - val_loss: 0.4426 - val_acc: 0.8133\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.4254 - acc: 0.8195 - val_loss: 0.4485 - val_acc: 0.8296\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.4176 - acc: 0.8220 - val_loss: 0.4165 - val_acc: 0.8197\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3997 - acc: 0.8271 - val_loss: 0.3980 - val_acc: 0.8212\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.4007 - acc: 0.8265 - val_loss: 0.4131 - val_acc: 0.8170\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3917 - acc: 0.8308 - val_loss: 0.3944 - val_acc: 0.8217\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3874 - acc: 0.8326 - val_loss: 0.4279 - val_acc: 0.8254\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3786 - acc: 0.8353 - val_loss: 0.3661 - val_acc: 0.8420\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3779 - acc: 0.8365 - val_loss: 0.3782 - val_acc: 0.8350\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3807 - acc: 0.8368 - val_loss: 0.3898 - val_acc: 0.8443\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3800 - acc: 0.8381 - val_loss: 0.3715 - val_acc: 0.8390\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3654 - acc: 0.8435 - val_loss: 0.3714 - val_acc: 0.8440\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3635 - acc: 0.8468 - val_loss: 0.3730 - val_acc: 0.8381\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3669 - acc: 0.8425 - val_loss: 0.3784 - val_acc: 0.8327\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3695 - acc: 0.8412 - val_loss: 0.3796 - val_acc: 0.8444\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3667 - acc: 0.8440 - val_loss: 0.3666 - val_acc: 0.8511\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3577 - acc: 0.8481 - val_loss: 0.3693 - val_acc: 0.8434\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3511 - acc: 0.8504 - val_loss: 0.3464 - val_acc: 0.8534\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3474 - acc: 0.8515 - val_loss: 0.3507 - val_acc: 0.8520\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3565 - acc: 0.8483 - val_loss: 0.3571 - val_acc: 0.8540\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3573 - acc: 0.8483 - val_loss: 0.3750 - val_acc: 0.8520\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3567 - acc: 0.8462 - val_loss: 0.3573 - val_acc: 0.8494\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3495 - acc: 0.8527 - val_loss: 0.3565 - val_acc: 0.8526\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3457 - acc: 0.8540 - val_loss: 0.3526 - val_acc: 0.8575\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3425 - acc: 0.8565 - val_loss: 0.3726 - val_acc: 0.8547\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3407 - acc: 0.8547 - val_loss: 0.3533 - val_acc: 0.8557\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3425 - acc: 0.8534 - val_loss: 0.3375 - val_acc: 0.8583\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3432 - acc: 0.8547 - val_loss: 0.3757 - val_acc: 0.8523\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3357 - acc: 0.8582 - val_loss: 0.3276 - val_acc: 0.8637\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3318 - acc: 0.8589 - val_loss: 0.3404 - val_acc: 0.8621\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3360 - acc: 0.8573 - val_loss: 0.3573 - val_acc: 0.8446\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3312 - acc: 0.8615 - val_loss: 0.3470 - val_acc: 0.8517\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3390 - acc: 0.8565 - val_loss: 0.3367 - val_acc: 0.8584\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3335 - acc: 0.8591 - val_loss: 0.3403 - val_acc: 0.8573\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3375 - acc: 0.8569 - val_loss: 0.3401 - val_acc: 0.8629\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3284 - acc: 0.8596 - val_loss: 0.3274 - val_acc: 0.8651\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3275 - acc: 0.8612 - val_loss: 0.3583 - val_acc: 0.8520\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3315 - acc: 0.8606 - val_loss: 0.3311 - val_acc: 0.8577\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3332 - acc: 0.8584 - val_loss: 0.3290 - val_acc: 0.8653\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3337 - acc: 0.8580 - val_loss: 0.3537 - val_acc: 0.8490\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3374 - acc: 0.8544 - val_loss: 0.3457 - val_acc: 0.8480\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3283 - acc: 0.8601 - val_loss: 0.3261 - val_acc: 0.8647\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3249 - acc: 0.8634 - val_loss: 0.3303 - val_acc: 0.8620\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3204 - acc: 0.8660 - val_loss: 0.3480 - val_acc: 0.8649\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3226 - acc: 0.8633 - val_loss: 0.3497 - val_acc: 0.8559\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3278 - acc: 0.8597 - val_loss: 0.3448 - val_acc: 0.8544\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3239 - acc: 0.8645 - val_loss: 0.3411 - val_acc: 0.8599\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3267 - acc: 0.8614 - val_loss: 0.3227 - val_acc: 0.8594\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3242 - acc: 0.8629 - val_loss: 0.3389 - val_acc: 0.8560\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3206 - acc: 0.8650 - val_loss: 0.3414 - val_acc: 0.8633\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3242 - acc: 0.8606 - val_loss: 0.3512 - val_acc: 0.8611\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3220 - acc: 0.8661 - val_loss: 0.3347 - val_acc: 0.8659\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3231 - acc: 0.8631 - val_loss: 0.3693 - val_acc: 0.8557\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3190 - acc: 0.8649 - val_loss: 0.3472 - val_acc: 0.8551\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3189 - acc: 0.8653 - val_loss: 0.3104 - val_acc: 0.8749\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3216 - acc: 0.8642 - val_loss: 0.3447 - val_acc: 0.8569\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3238 - acc: 0.8624 - val_loss: 0.3472 - val_acc: 0.8609\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3129 - acc: 0.8659 - val_loss: 0.3346 - val_acc: 0.8607\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3104 - acc: 0.8681 - val_loss: 0.3284 - val_acc: 0.8643\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3227 - acc: 0.8621 - val_loss: 0.3352 - val_acc: 0.8729\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3212 - acc: 0.8665 - val_loss: 0.3269 - val_acc: 0.8676\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3219 - acc: 0.8652 - val_loss: 0.3287 - val_acc: 0.8606\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3118 - acc: 0.8699 - val_loss: 0.3526 - val_acc: 0.8560\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3204 - acc: 0.8645 - val_loss: 0.3180 - val_acc: 0.8712\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3182 - acc: 0.8644 - val_loss: 0.3257 - val_acc: 0.8667\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3134 - acc: 0.8692 - val_loss: 0.3404 - val_acc: 0.8620\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3179 - acc: 0.8662 - val_loss: 0.3348 - val_acc: 0.8586\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3110 - acc: 0.8681 - val_loss: 0.3228 - val_acc: 0.8635\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3156 - acc: 0.8675 - val_loss: 0.3241 - val_acc: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3119 - acc: 0.8691 - val_loss: 0.3359 - val_acc: 0.8511\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3055 - acc: 0.8694 - val_loss: 0.3199 - val_acc: 0.8690\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3145 - acc: 0.8677 - val_loss: 0.3442 - val_acc: 0.8590\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3121 - acc: 0.8696 - val_loss: 0.3226 - val_acc: 0.8686\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3147 - acc: 0.8678 - val_loss: 0.3219 - val_acc: 0.8677\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3150 - acc: 0.8675 - val_loss: 0.3524 - val_acc: 0.8513\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3145 - acc: 0.8670 - val_loss: 0.3358 - val_acc: 0.8575\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3107 - acc: 0.8686 - val_loss: 0.3349 - val_acc: 0.8643\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3126 - acc: 0.8679 - val_loss: 0.3202 - val_acc: 0.8710\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3124 - acc: 0.8681 - val_loss: 0.3234 - val_acc: 0.8717\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3117 - acc: 0.8709 - val_loss: 0.3478 - val_acc: 0.8580\n",
      "\n",
      "Training process completed in: 0 h 15 m 19 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1195.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1197 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_145 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_145 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_146 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_147 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_148 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "160/160 [==============================] - 13s 79ms/step - loss: 0.5600 - acc: 0.7171 - val_loss: 0.4619 - val_acc: 0.7897\n",
      "Epoch 2/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4322 - acc: 0.8145 - val_loss: 0.4250 - val_acc: 0.8166\n",
      "Epoch 3/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4169 - acc: 0.8229 - val_loss: 0.4148 - val_acc: 0.8197\n",
      "Epoch 4/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4150 - acc: 0.8217 - val_loss: 0.4227 - val_acc: 0.8153\n",
      "Epoch 5/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4022 - acc: 0.8268 - val_loss: 0.4048 - val_acc: 0.8233\n",
      "Epoch 6/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4064 - acc: 0.8227 - val_loss: 0.4021 - val_acc: 0.8293\n",
      "Epoch 7/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4048 - acc: 0.8259 - val_loss: 0.4048 - val_acc: 0.8247\n",
      "Epoch 8/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4021 - acc: 0.8296 - val_loss: 0.4178 - val_acc: 0.8198\n",
      "Epoch 9/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3988 - acc: 0.8297 - val_loss: 0.4203 - val_acc: 0.8230\n",
      "Epoch 10/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4056 - acc: 0.8253 - val_loss: 0.4144 - val_acc: 0.8184\n",
      "Epoch 11/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3980 - acc: 0.8289 - val_loss: 0.4023 - val_acc: 0.8280\n",
      "Epoch 12/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3944 - acc: 0.8288 - val_loss: 0.3831 - val_acc: 0.8378\n",
      "Epoch 13/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3874 - acc: 0.8325 - val_loss: 0.3902 - val_acc: 0.8307\n",
      "Epoch 14/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3918 - acc: 0.8295 - val_loss: 0.3867 - val_acc: 0.8343\n",
      "Epoch 15/80\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.3870 - acc: 0.8360 - val_loss: 0.3856 - val_acc: 0.8306\n",
      "Epoch 16/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3837 - acc: 0.8330 - val_loss: 0.4027 - val_acc: 0.8210\n",
      "Epoch 17/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3879 - acc: 0.8356 - val_loss: 0.3918 - val_acc: 0.8314\n",
      "Epoch 18/80\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.3772 - acc: 0.8371 - val_loss: 0.3873 - val_acc: 0.8329\n",
      "Epoch 19/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3854 - acc: 0.8332 - val_loss: 0.3680 - val_acc: 0.8414\n",
      "Epoch 20/80\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.3773 - acc: 0.8341 - val_loss: 0.3739 - val_acc: 0.8362\n",
      "Epoch 21/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3754 - acc: 0.8383 - val_loss: 0.3688 - val_acc: 0.8411\n",
      "Epoch 22/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3655 - acc: 0.8409 - val_loss: 0.3706 - val_acc: 0.8417\n",
      "Epoch 23/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3671 - acc: 0.8414 - val_loss: 0.3753 - val_acc: 0.8360\n",
      "Epoch 24/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3754 - acc: 0.8381 - val_loss: 0.3667 - val_acc: 0.8373\n",
      "Epoch 25/80\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.3729 - acc: 0.8388 - val_loss: 0.3650 - val_acc: 0.8440\n",
      "Epoch 26/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3729 - acc: 0.8392 - val_loss: 0.3709 - val_acc: 0.8407\n",
      "Epoch 27/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3637 - acc: 0.8446 - val_loss: 0.3618 - val_acc: 0.8444\n",
      "Epoch 28/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3660 - acc: 0.8433 - val_loss: 0.3581 - val_acc: 0.8443\n",
      "Epoch 29/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3617 - acc: 0.8445 - val_loss: 0.3586 - val_acc: 0.8480\n",
      "Epoch 30/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3652 - acc: 0.8424 - val_loss: 0.3752 - val_acc: 0.8353\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3682 - acc: 0.8401 - val_loss: 0.3612 - val_acc: 0.8494\n",
      "Epoch 32/80\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.3604 - acc: 0.8466 - val_loss: 0.3472 - val_acc: 0.8532\n",
      "Epoch 33/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3573 - acc: 0.8470 - val_loss: 0.3507 - val_acc: 0.8557\n",
      "Epoch 34/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3627 - acc: 0.8457 - val_loss: 0.3599 - val_acc: 0.8451\n",
      "Epoch 35/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3503 - acc: 0.8523 - val_loss: 0.3659 - val_acc: 0.8437\n",
      "Epoch 36/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3540 - acc: 0.8508 - val_loss: 0.3613 - val_acc: 0.8421\n",
      "Epoch 37/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3552 - acc: 0.8478 - val_loss: 0.3579 - val_acc: 0.8453\n",
      "Epoch 38/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3453 - acc: 0.8531 - val_loss: 0.3511 - val_acc: 0.8530\n",
      "Epoch 39/80\n",
      "160/160 [==============================] - 10s 66ms/step - loss: 0.3547 - acc: 0.8490 - val_loss: 0.3603 - val_acc: 0.8451\n",
      "Epoch 40/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3495 - acc: 0.8486 - val_loss: 0.3495 - val_acc: 0.8532\n",
      "Epoch 41/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3497 - acc: 0.8508 - val_loss: 0.3496 - val_acc: 0.8499\n",
      "Epoch 42/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3498 - acc: 0.8508 - val_loss: 0.3444 - val_acc: 0.8553\n",
      "Epoch 43/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3429 - acc: 0.8561 - val_loss: 0.3546 - val_acc: 0.8520\n",
      "Epoch 44/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3565 - acc: 0.8473 - val_loss: 0.3376 - val_acc: 0.8571\n",
      "Epoch 45/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3463 - acc: 0.8517 - val_loss: 0.3411 - val_acc: 0.8524\n",
      "Epoch 46/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3431 - acc: 0.8554 - val_loss: 0.3479 - val_acc: 0.8527\n",
      "Epoch 47/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3449 - acc: 0.8530 - val_loss: 0.3444 - val_acc: 0.8543\n",
      "Epoch 48/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3404 - acc: 0.8539 - val_loss: 0.3493 - val_acc: 0.8536\n",
      "Epoch 49/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3386 - acc: 0.8571 - val_loss: 0.3428 - val_acc: 0.8563\n",
      "Epoch 50/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3449 - acc: 0.8519 - val_loss: 0.3614 - val_acc: 0.8470\n",
      "Epoch 51/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3461 - acc: 0.8530 - val_loss: 0.3424 - val_acc: 0.8530\n",
      "Epoch 52/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3456 - acc: 0.8508 - val_loss: 0.3398 - val_acc: 0.8578\n",
      "Epoch 53/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3385 - acc: 0.8529 - val_loss: 0.3452 - val_acc: 0.8536\n",
      "Epoch 54/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3481 - acc: 0.8490 - val_loss: 0.3397 - val_acc: 0.8561\n",
      "Epoch 55/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3417 - acc: 0.8551 - val_loss: 0.3364 - val_acc: 0.8591\n",
      "Epoch 56/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3346 - acc: 0.8588 - val_loss: 0.3468 - val_acc: 0.8549\n",
      "Epoch 57/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3313 - acc: 0.8593 - val_loss: 0.3327 - val_acc: 0.8581\n",
      "Epoch 58/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3331 - acc: 0.8582 - val_loss: 0.3434 - val_acc: 0.8601\n",
      "Epoch 59/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3314 - acc: 0.8586 - val_loss: 0.3375 - val_acc: 0.8603\n",
      "Epoch 60/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3421 - acc: 0.8521 - val_loss: 0.3383 - val_acc: 0.8550\n",
      "Epoch 61/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3303 - acc: 0.8605 - val_loss: 0.3350 - val_acc: 0.8576\n",
      "Epoch 62/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3394 - acc: 0.8535 - val_loss: 0.3559 - val_acc: 0.8454\n",
      "Epoch 63/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3369 - acc: 0.8553 - val_loss: 0.3394 - val_acc: 0.8566\n",
      "Epoch 64/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3371 - acc: 0.8565 - val_loss: 0.3386 - val_acc: 0.8581\n",
      "Epoch 65/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3327 - acc: 0.8546 - val_loss: 0.3330 - val_acc: 0.8586\n",
      "Epoch 66/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3309 - acc: 0.8613 - val_loss: 0.3246 - val_acc: 0.8683\n",
      "Epoch 67/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3317 - acc: 0.8594 - val_loss: 0.3314 - val_acc: 0.8590\n",
      "Epoch 68/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3293 - acc: 0.8619 - val_loss: 0.3335 - val_acc: 0.8550\n",
      "Epoch 69/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3273 - acc: 0.8592 - val_loss: 0.3357 - val_acc: 0.8589\n",
      "Epoch 70/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3259 - acc: 0.8618 - val_loss: 0.3439 - val_acc: 0.8500\n",
      "Epoch 71/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3273 - acc: 0.8605 - val_loss: 0.3239 - val_acc: 0.8634\n",
      "Epoch 72/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3252 - acc: 0.8628 - val_loss: 0.3237 - val_acc: 0.8633\n",
      "Epoch 73/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3309 - acc: 0.8596 - val_loss: 0.3383 - val_acc: 0.8564\n",
      "Epoch 74/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3286 - acc: 0.8571 - val_loss: 0.3279 - val_acc: 0.8617\n",
      "Epoch 75/80\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.3211 - acc: 0.8638 - val_loss: 0.3330 - val_acc: 0.8617\n",
      "Epoch 76/80\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.3263 - acc: 0.8617 - val_loss: 0.3343 - val_acc: 0.8594\n",
      "Epoch 77/80\n",
      "160/160 [==============================] - 11s 67ms/step - loss: 0.3229 - acc: 0.8631 - val_loss: 0.3252 - val_acc: 0.8643\n",
      "Epoch 78/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3263 - acc: 0.8604 - val_loss: 0.3277 - val_acc: 0.8641\n",
      "Epoch 79/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3281 - acc: 0.8582 - val_loss: 0.3297 - val_acc: 0.8593\n",
      "Epoch 80/80\n",
      "160/160 [==============================] - 11s 66ms/step - loss: 0.3303 - acc: 0.8573 - val_loss: 0.3444 - val_acc: 0.8490\n",
      "\n",
      "Training process completed in: 0 h 14 m 4 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1196.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1198 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_149 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_149 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_150 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_151 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_152 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "160/160 [==============================] - 14s 89ms/step - loss: 0.4695 - acc: 0.7861 - val_loss: 0.4121 - val_acc: 0.8246\n",
      "Epoch 2/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.4176 - acc: 0.8204 - val_loss: 0.4034 - val_acc: 0.8240\n",
      "Epoch 3/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.4072 - acc: 0.8243 - val_loss: 0.3949 - val_acc: 0.8323\n",
      "Epoch 4/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3973 - acc: 0.8291 - val_loss: 0.4147 - val_acc: 0.8296\n",
      "Epoch 5/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3923 - acc: 0.8332 - val_loss: 0.3927 - val_acc: 0.8346\n",
      "Epoch 6/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3868 - acc: 0.8348 - val_loss: 0.4271 - val_acc: 0.8260\n",
      "Epoch 7/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3801 - acc: 0.8375 - val_loss: 0.3673 - val_acc: 0.8439\n",
      "Epoch 8/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3793 - acc: 0.8392 - val_loss: 0.3756 - val_acc: 0.8490\n",
      "Epoch 9/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3795 - acc: 0.8389 - val_loss: 0.3716 - val_acc: 0.8428\n",
      "Epoch 10/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3762 - acc: 0.8404 - val_loss: 0.4081 - val_acc: 0.8290\n",
      "Epoch 11/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3644 - acc: 0.8443 - val_loss: 0.3710 - val_acc: 0.8514\n",
      "Epoch 12/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3644 - acc: 0.8427 - val_loss: 0.3750 - val_acc: 0.8440\n",
      "Epoch 13/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3626 - acc: 0.8472 - val_loss: 0.3644 - val_acc: 0.8429\n",
      "Epoch 14/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3555 - acc: 0.8486 - val_loss: 0.3670 - val_acc: 0.8461\n",
      "Epoch 15/90\n",
      "160/160 [==============================] - 11s 72ms/step - loss: 0.3568 - acc: 0.8472 - val_loss: 0.3564 - val_acc: 0.8514\n",
      "Epoch 16/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3506 - acc: 0.8512 - val_loss: 0.3488 - val_acc: 0.8613\n",
      "Epoch 17/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3490 - acc: 0.8521 - val_loss: 0.3545 - val_acc: 0.8537\n",
      "Epoch 18/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3541 - acc: 0.8499 - val_loss: 0.3717 - val_acc: 0.8415\n",
      "Epoch 19/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3401 - acc: 0.8578 - val_loss: 0.3520 - val_acc: 0.8542\n",
      "Epoch 20/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3534 - acc: 0.8521 - val_loss: 0.3441 - val_acc: 0.8535\n",
      "Epoch 21/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3554 - acc: 0.8475 - val_loss: 0.3533 - val_acc: 0.8567\n",
      "Epoch 22/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3457 - acc: 0.8535 - val_loss: 0.3452 - val_acc: 0.8551\n",
      "Epoch 23/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3376 - acc: 0.8550 - val_loss: 0.3457 - val_acc: 0.8527\n",
      "Epoch 24/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3398 - acc: 0.8580 - val_loss: 0.3520 - val_acc: 0.8560\n",
      "Epoch 25/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3471 - acc: 0.8521 - val_loss: 0.3292 - val_acc: 0.8643\n",
      "Epoch 26/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3428 - acc: 0.8532 - val_loss: 0.3560 - val_acc: 0.8521\n",
      "Epoch 27/90\n",
      "160/160 [==============================] - 12s 78ms/step - loss: 0.3277 - acc: 0.8598 - val_loss: 0.3526 - val_acc: 0.8576\n",
      "Epoch 28/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3315 - acc: 0.8605 - val_loss: 0.3438 - val_acc: 0.8530\n",
      "Epoch 29/90\n",
      "160/160 [==============================] - 12s 76ms/step - loss: 0.3316 - acc: 0.8614 - val_loss: 0.3453 - val_acc: 0.8495\n",
      "Epoch 30/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3350 - acc: 0.8577 - val_loss: 0.3288 - val_acc: 0.8562\n",
      "Epoch 31/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3348 - acc: 0.8598 - val_loss: 0.3437 - val_acc: 0.8600\n",
      "Epoch 32/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3346 - acc: 0.8586 - val_loss: 0.3377 - val_acc: 0.8608\n",
      "Epoch 33/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3235 - acc: 0.8636 - val_loss: 0.3399 - val_acc: 0.8593\n",
      "Epoch 34/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3349 - acc: 0.8561 - val_loss: 0.3249 - val_acc: 0.8654\n",
      "Epoch 35/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3219 - acc: 0.8640 - val_loss: 0.3167 - val_acc: 0.8686\n",
      "Epoch 36/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3304 - acc: 0.8584 - val_loss: 0.3241 - val_acc: 0.8692\n",
      "Epoch 37/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3251 - acc: 0.8641 - val_loss: 0.3196 - val_acc: 0.8701\n",
      "Epoch 38/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3304 - acc: 0.8610 - val_loss: 0.3360 - val_acc: 0.8625\n",
      "Epoch 39/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3259 - acc: 0.8611 - val_loss: 0.3404 - val_acc: 0.8531\n",
      "Epoch 40/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3184 - acc: 0.8652 - val_loss: 0.3311 - val_acc: 0.8653\n",
      "Epoch 41/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3182 - acc: 0.8646 - val_loss: 0.3505 - val_acc: 0.8535\n",
      "Epoch 42/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3169 - acc: 0.8658 - val_loss: 0.3161 - val_acc: 0.8659\n",
      "Epoch 43/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3172 - acc: 0.8689 - val_loss: 0.3503 - val_acc: 0.8581\n",
      "Epoch 44/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3180 - acc: 0.8640 - val_loss: 0.3220 - val_acc: 0.8628\n",
      "Epoch 45/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3256 - acc: 0.8625 - val_loss: 0.3186 - val_acc: 0.8648\n",
      "Epoch 46/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3190 - acc: 0.8657 - val_loss: 0.3265 - val_acc: 0.8687\n",
      "Epoch 47/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3149 - acc: 0.8666 - val_loss: 0.3356 - val_acc: 0.8549\n",
      "Epoch 48/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3102 - acc: 0.8708 - val_loss: 0.3114 - val_acc: 0.8692\n",
      "Epoch 49/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3198 - acc: 0.8648 - val_loss: 0.3223 - val_acc: 0.8644\n",
      "Epoch 50/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3082 - acc: 0.8705 - val_loss: 0.3185 - val_acc: 0.8676\n",
      "Epoch 51/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3168 - acc: 0.8655 - val_loss: 0.3206 - val_acc: 0.8664\n",
      "Epoch 52/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3146 - acc: 0.8671 - val_loss: 0.3204 - val_acc: 0.8705\n",
      "Epoch 53/90\n",
      "160/160 [==============================] - 12s 76ms/step - loss: 0.3101 - acc: 0.8692 - val_loss: 0.3155 - val_acc: 0.8654\n",
      "Epoch 54/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3098 - acc: 0.8706 - val_loss: 0.3228 - val_acc: 0.8611\n",
      "Epoch 55/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3145 - acc: 0.8683 - val_loss: 0.3360 - val_acc: 0.8640\n",
      "Epoch 56/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3081 - acc: 0.8694 - val_loss: 0.3189 - val_acc: 0.8640\n",
      "Epoch 57/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3098 - acc: 0.8683 - val_loss: 0.3558 - val_acc: 0.8518\n",
      "Epoch 58/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3157 - acc: 0.8659 - val_loss: 0.3171 - val_acc: 0.8684\n",
      "Epoch 59/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3104 - acc: 0.8697 - val_loss: 0.3081 - val_acc: 0.8733\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3135 - acc: 0.8678 - val_loss: 0.3142 - val_acc: 0.8689\n",
      "Epoch 61/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3201 - acc: 0.8657 - val_loss: 0.3201 - val_acc: 0.8725\n",
      "Epoch 62/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3022 - acc: 0.8744 - val_loss: 0.3077 - val_acc: 0.8711\n",
      "Epoch 63/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3003 - acc: 0.8757 - val_loss: 0.3263 - val_acc: 0.8636\n",
      "Epoch 64/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3062 - acc: 0.8690 - val_loss: 0.3443 - val_acc: 0.8611\n",
      "Epoch 65/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3128 - acc: 0.8690 - val_loss: 0.3442 - val_acc: 0.8590\n",
      "Epoch 66/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3060 - acc: 0.8720 - val_loss: 0.3034 - val_acc: 0.8739\n",
      "Epoch 67/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3161 - acc: 0.8671 - val_loss: 0.3184 - val_acc: 0.8708\n",
      "Epoch 68/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3066 - acc: 0.8688 - val_loss: 0.3181 - val_acc: 0.8709\n",
      "Epoch 69/90\n",
      "160/160 [==============================] - 12s 72ms/step - loss: 0.3020 - acc: 0.8745 - val_loss: 0.3162 - val_acc: 0.8698\n",
      "Epoch 70/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3063 - acc: 0.8683 - val_loss: 0.3291 - val_acc: 0.8595\n",
      "Epoch 71/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3054 - acc: 0.8703 - val_loss: 0.3103 - val_acc: 0.8723\n",
      "Epoch 72/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3054 - acc: 0.8716 - val_loss: 0.3167 - val_acc: 0.8645\n",
      "Epoch 73/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3113 - acc: 0.8691 - val_loss: 0.3151 - val_acc: 0.8634\n",
      "Epoch 74/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.2971 - acc: 0.8750 - val_loss: 0.3051 - val_acc: 0.8667\n",
      "Epoch 75/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3065 - acc: 0.8701 - val_loss: 0.3105 - val_acc: 0.8738\n",
      "Epoch 76/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3040 - acc: 0.8743 - val_loss: 0.3181 - val_acc: 0.8667\n",
      "Epoch 77/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3046 - acc: 0.8710 - val_loss: 0.3149 - val_acc: 0.8696\n",
      "Epoch 78/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3054 - acc: 0.8696 - val_loss: 0.3149 - val_acc: 0.8701\n",
      "Epoch 79/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.2955 - acc: 0.8758 - val_loss: 0.3208 - val_acc: 0.8684\n",
      "Epoch 80/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.3063 - acc: 0.8703 - val_loss: 0.3080 - val_acc: 0.8754\n",
      "Epoch 81/90\n",
      "160/160 [==============================] - 12s 76ms/step - loss: 0.3038 - acc: 0.8725 - val_loss: 0.3086 - val_acc: 0.8696\n",
      "Epoch 82/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3003 - acc: 0.8749 - val_loss: 0.3143 - val_acc: 0.8673\n",
      "Epoch 83/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3040 - acc: 0.8735 - val_loss: 0.3083 - val_acc: 0.8725\n",
      "Epoch 84/90\n",
      "160/160 [==============================] - 12s 74ms/step - loss: 0.3001 - acc: 0.8755 - val_loss: 0.3008 - val_acc: 0.8785\n",
      "Epoch 85/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.2989 - acc: 0.8736 - val_loss: 0.3119 - val_acc: 0.8699\n",
      "Epoch 86/90\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.3003 - acc: 0.8729 - val_loss: 0.3043 - val_acc: 0.8751\n",
      "Epoch 87/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.2993 - acc: 0.8746 - val_loss: 0.3167 - val_acc: 0.8658\n",
      "Epoch 88/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.2998 - acc: 0.8747 - val_loss: 0.3094 - val_acc: 0.8781\n",
      "Epoch 89/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.2995 - acc: 0.8720 - val_loss: 0.3170 - val_acc: 0.8669\n",
      "Epoch 90/90\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.2927 - acc: 0.8773 - val_loss: 0.3148 - val_acc: 0.8662\n",
      "\n",
      "Training process completed in: 0 h 17 m 49 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1197.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1199 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_153 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_153 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_154 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_155 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "180/180 [==============================] - 14s 77ms/step - loss: 0.4874 - acc: 0.7771 - val_loss: 0.4178 - val_acc: 0.8173\n",
      "Epoch 2/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.4193 - acc: 0.8231 - val_loss: 0.4168 - val_acc: 0.8159\n",
      "Epoch 3/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.4178 - acc: 0.8213 - val_loss: 0.4156 - val_acc: 0.8190\n",
      "Epoch 4/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3927 - acc: 0.8346 - val_loss: 0.4096 - val_acc: 0.8178\n",
      "Epoch 5/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3954 - acc: 0.8295 - val_loss: 0.4705 - val_acc: 0.8059\n",
      "Epoch 6/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3868 - acc: 0.8327 - val_loss: 0.3937 - val_acc: 0.8370\n",
      "Epoch 7/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3838 - acc: 0.8332 - val_loss: 0.3966 - val_acc: 0.8351\n",
      "Epoch 8/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3681 - acc: 0.8398 - val_loss: 0.3784 - val_acc: 0.8394\n",
      "Epoch 9/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3773 - acc: 0.8380 - val_loss: 0.3810 - val_acc: 0.8470\n",
      "Epoch 10/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3710 - acc: 0.8411 - val_loss: 0.3786 - val_acc: 0.8450\n",
      "Epoch 11/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3647 - acc: 0.8435 - val_loss: 0.3937 - val_acc: 0.8371\n",
      "Epoch 12/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3656 - acc: 0.8433 - val_loss: 0.3764 - val_acc: 0.8495\n",
      "Epoch 13/60\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.3683 - acc: 0.8423 - val_loss: 0.3800 - val_acc: 0.8433\n",
      "Epoch 14/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3583 - acc: 0.8472 - val_loss: 0.3522 - val_acc: 0.8506\n",
      "Epoch 15/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3591 - acc: 0.8468 - val_loss: 0.3621 - val_acc: 0.8464\n",
      "Epoch 16/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3516 - acc: 0.8501 - val_loss: 0.3652 - val_acc: 0.8459\n",
      "Epoch 17/60\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3446 - acc: 0.8544 - val_loss: 0.3589 - val_acc: 0.8536\n",
      "Epoch 18/60\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3552 - acc: 0.8494 - val_loss: 0.3698 - val_acc: 0.8410\n",
      "Epoch 19/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3447 - acc: 0.8550 - val_loss: 0.3564 - val_acc: 0.8561\n",
      "Epoch 20/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3412 - acc: 0.8563 - val_loss: 0.3463 - val_acc: 0.8550\n",
      "Epoch 21/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3475 - acc: 0.8519 - val_loss: 0.3405 - val_acc: 0.8540\n",
      "Epoch 22/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3436 - acc: 0.8546 - val_loss: 0.3605 - val_acc: 0.8497\n",
      "Epoch 23/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3474 - acc: 0.8502 - val_loss: 0.3867 - val_acc: 0.8461\n",
      "Epoch 24/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3432 - acc: 0.8549 - val_loss: 0.3394 - val_acc: 0.8606\n",
      "Epoch 25/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3365 - acc: 0.8577 - val_loss: 0.3332 - val_acc: 0.8633\n",
      "Epoch 26/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3256 - acc: 0.8611 - val_loss: 0.3304 - val_acc: 0.8617\n",
      "Epoch 27/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3328 - acc: 0.8584 - val_loss: 0.3530 - val_acc: 0.8476\n",
      "Epoch 28/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3379 - acc: 0.8593 - val_loss: 0.3284 - val_acc: 0.8569\n",
      "Epoch 29/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3315 - acc: 0.8616 - val_loss: 0.3288 - val_acc: 0.8614\n",
      "Epoch 30/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3393 - acc: 0.8544 - val_loss: 0.3535 - val_acc: 0.8631\n",
      "Epoch 31/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3286 - acc: 0.8604 - val_loss: 0.3229 - val_acc: 0.8649\n",
      "Epoch 32/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3312 - acc: 0.8599 - val_loss: 0.3363 - val_acc: 0.8640\n",
      "Epoch 33/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3256 - acc: 0.8622 - val_loss: 0.3276 - val_acc: 0.8683\n",
      "Epoch 34/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3262 - acc: 0.8640 - val_loss: 0.3385 - val_acc: 0.8610\n",
      "Epoch 35/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3241 - acc: 0.8633 - val_loss: 0.3311 - val_acc: 0.8607\n",
      "Epoch 36/60\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.3190 - acc: 0.8663 - val_loss: 0.3157 - val_acc: 0.8738\n",
      "Epoch 37/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3194 - acc: 0.8644 - val_loss: 0.3559 - val_acc: 0.8537\n",
      "Epoch 38/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3232 - acc: 0.8631 - val_loss: 0.3283 - val_acc: 0.8654\n",
      "Epoch 39/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3205 - acc: 0.8655 - val_loss: 0.3411 - val_acc: 0.8563\n",
      "Epoch 40/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3217 - acc: 0.8644 - val_loss: 0.3772 - val_acc: 0.8394\n",
      "Epoch 41/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3189 - acc: 0.8667 - val_loss: 0.3216 - val_acc: 0.8691\n",
      "Epoch 42/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3129 - acc: 0.8666 - val_loss: 0.3271 - val_acc: 0.8554\n",
      "Epoch 43/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3245 - acc: 0.8616 - val_loss: 0.3166 - val_acc: 0.8690\n",
      "Epoch 44/60\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.3165 - acc: 0.8669 - val_loss: 0.3348 - val_acc: 0.8671\n",
      "Epoch 45/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3237 - acc: 0.8640 - val_loss: 0.3419 - val_acc: 0.8719\n",
      "Epoch 46/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3121 - acc: 0.8701 - val_loss: 0.3212 - val_acc: 0.8664\n",
      "Epoch 47/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3176 - acc: 0.8655 - val_loss: 0.3226 - val_acc: 0.8657\n",
      "Epoch 48/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3107 - acc: 0.8705 - val_loss: 0.3072 - val_acc: 0.8765\n",
      "Epoch 49/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3166 - acc: 0.8657 - val_loss: 0.3186 - val_acc: 0.8677\n",
      "Epoch 50/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3145 - acc: 0.8656 - val_loss: 0.3092 - val_acc: 0.8669\n",
      "Epoch 51/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3147 - acc: 0.8657 - val_loss: 0.3230 - val_acc: 0.8657\n",
      "Epoch 52/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3066 - acc: 0.8724 - val_loss: 0.3303 - val_acc: 0.8691\n",
      "Epoch 53/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3128 - acc: 0.8690 - val_loss: 0.3214 - val_acc: 0.8659\n",
      "Epoch 54/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3014 - acc: 0.8699 - val_loss: 0.3151 - val_acc: 0.8676\n",
      "Epoch 55/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3060 - acc: 0.8730 - val_loss: 0.3202 - val_acc: 0.8693\n",
      "Epoch 56/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3101 - acc: 0.8700 - val_loss: 0.3394 - val_acc: 0.8610\n",
      "Epoch 57/60\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.3163 - acc: 0.8666 - val_loss: 0.3154 - val_acc: 0.8726\n",
      "Epoch 58/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3051 - acc: 0.8706 - val_loss: 0.3065 - val_acc: 0.8753\n",
      "Epoch 59/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3081 - acc: 0.8716 - val_loss: 0.3200 - val_acc: 0.8643\n",
      "Epoch 60/60\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.3108 - acc: 0.8685 - val_loss: 0.3251 - val_acc: 0.8691\n",
      "\n",
      "Training process completed in: 0 h 11 m 33 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1198.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1200 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_157 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_158 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_159 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_160 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "90/90 [==============================] - 12s 136ms/step - loss: 0.5925 - acc: 0.7127 - val_loss: 0.5611 - val_acc: 0.7144\n",
      "Epoch 2/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.5015 - acc: 0.7533 - val_loss: 0.4357 - val_acc: 0.8077\n",
      "Epoch 3/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4312 - acc: 0.8163 - val_loss: 0.4199 - val_acc: 0.8188\n",
      "Epoch 4/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4171 - acc: 0.8241 - val_loss: 0.4165 - val_acc: 0.8186\n",
      "Epoch 5/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4127 - acc: 0.8214 - val_loss: 0.4147 - val_acc: 0.8195\n",
      "Epoch 6/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.4071 - acc: 0.8240 - val_loss: 0.4190 - val_acc: 0.8206\n",
      "Epoch 7/90\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 0.4127 - acc: 0.8190 - val_loss: 0.4195 - val_acc: 0.8195\n",
      "Epoch 8/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4046 - acc: 0.8301 - val_loss: 0.4166 - val_acc: 0.8183\n",
      "Epoch 9/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4062 - acc: 0.8280 - val_loss: 0.4092 - val_acc: 0.8213\n",
      "Epoch 10/90\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 0.4126 - acc: 0.8206 - val_loss: 0.4042 - val_acc: 0.8275\n",
      "Epoch 11/90\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 0.3996 - acc: 0.8310 - val_loss: 0.4004 - val_acc: 0.8277\n",
      "Epoch 12/90\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.4011 - acc: 0.8299 - val_loss: 0.3986 - val_acc: 0.8281\n",
      "Epoch 13/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4037 - acc: 0.8275 - val_loss: 0.4112 - val_acc: 0.8228\n",
      "Epoch 14/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4023 - acc: 0.8266 - val_loss: 0.4072 - val_acc: 0.8209\n",
      "Epoch 15/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.4047 - acc: 0.8246 - val_loss: 0.3916 - val_acc: 0.8302\n",
      "Epoch 16/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3982 - acc: 0.8307 - val_loss: 0.3875 - val_acc: 0.8373\n",
      "Epoch 17/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3907 - acc: 0.8329 - val_loss: 0.4024 - val_acc: 0.8277\n",
      "Epoch 18/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3966 - acc: 0.8289 - val_loss: 0.4000 - val_acc: 0.8286\n",
      "Epoch 19/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3910 - acc: 0.8306 - val_loss: 0.4003 - val_acc: 0.8248\n",
      "Epoch 20/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3902 - acc: 0.8335 - val_loss: 0.3852 - val_acc: 0.8334\n",
      "Epoch 21/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3962 - acc: 0.8291 - val_loss: 0.3894 - val_acc: 0.8306\n",
      "Epoch 22/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3821 - acc: 0.8338 - val_loss: 0.3832 - val_acc: 0.8346\n",
      "Epoch 23/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3892 - acc: 0.8346 - val_loss: 0.3907 - val_acc: 0.8320\n",
      "Epoch 24/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3892 - acc: 0.8341 - val_loss: 0.3969 - val_acc: 0.8274\n",
      "Epoch 25/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3888 - acc: 0.8309 - val_loss: 0.3763 - val_acc: 0.8391\n",
      "Epoch 26/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3883 - acc: 0.8351 - val_loss: 0.3865 - val_acc: 0.8310\n",
      "Epoch 27/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3802 - acc: 0.8381 - val_loss: 0.3864 - val_acc: 0.8303\n",
      "Epoch 28/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3800 - acc: 0.8386 - val_loss: 0.3795 - val_acc: 0.8343\n",
      "Epoch 29/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3838 - acc: 0.8348 - val_loss: 0.3792 - val_acc: 0.8349\n",
      "Epoch 30/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3782 - acc: 0.8357 - val_loss: 0.3735 - val_acc: 0.8411\n",
      "Epoch 31/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3683 - acc: 0.8448 - val_loss: 0.3789 - val_acc: 0.8336\n",
      "Epoch 32/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3728 - acc: 0.8402 - val_loss: 0.3671 - val_acc: 0.8414\n",
      "Epoch 33/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3872 - acc: 0.8349 - val_loss: 0.3857 - val_acc: 0.8310\n",
      "Epoch 34/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3766 - acc: 0.8375 - val_loss: 0.3720 - val_acc: 0.8391\n",
      "Epoch 35/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3690 - acc: 0.8412 - val_loss: 0.3759 - val_acc: 0.8401\n",
      "Epoch 36/90\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.3779 - acc: 0.8372 - val_loss: 0.3822 - val_acc: 0.8342\n",
      "Epoch 37/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3832 - acc: 0.8365 - val_loss: 0.3798 - val_acc: 0.8295\n",
      "Epoch 38/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3741 - acc: 0.8389 - val_loss: 0.3632 - val_acc: 0.8472\n",
      "Epoch 39/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3665 - acc: 0.8393 - val_loss: 0.3686 - val_acc: 0.8392\n",
      "Epoch 40/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3688 - acc: 0.8422 - val_loss: 0.3718 - val_acc: 0.8393\n",
      "Epoch 41/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3645 - acc: 0.8436 - val_loss: 0.3686 - val_acc: 0.8416\n",
      "Epoch 42/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3680 - acc: 0.8427 - val_loss: 0.3616 - val_acc: 0.8393\n",
      "Epoch 43/90\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.3671 - acc: 0.8416 - val_loss: 0.3658 - val_acc: 0.8371\n",
      "Epoch 44/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3668 - acc: 0.8422 - val_loss: 0.3736 - val_acc: 0.8459\n",
      "Epoch 45/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3624 - acc: 0.8451 - val_loss: 0.3622 - val_acc: 0.8434\n",
      "Epoch 46/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3628 - acc: 0.8435 - val_loss: 0.3650 - val_acc: 0.8411\n",
      "Epoch 47/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3641 - acc: 0.8449 - val_loss: 0.3768 - val_acc: 0.8455\n",
      "Epoch 48/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3551 - acc: 0.8509 - val_loss: 0.3578 - val_acc: 0.8455\n",
      "Epoch 49/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3705 - acc: 0.8402 - val_loss: 0.3631 - val_acc: 0.8424\n",
      "Epoch 50/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3558 - acc: 0.8464 - val_loss: 0.3574 - val_acc: 0.8465\n",
      "Epoch 51/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3515 - acc: 0.8468 - val_loss: 0.3516 - val_acc: 0.8503\n",
      "Epoch 52/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3522 - acc: 0.8479 - val_loss: 0.3550 - val_acc: 0.8490\n",
      "Epoch 53/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3627 - acc: 0.8467 - val_loss: 0.3682 - val_acc: 0.8356\n",
      "Epoch 54/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3493 - acc: 0.8500 - val_loss: 0.3508 - val_acc: 0.8497\n",
      "Epoch 55/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3551 - acc: 0.8489 - val_loss: 0.3565 - val_acc: 0.8414\n",
      "Epoch 56/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3466 - acc: 0.8522 - val_loss: 0.3536 - val_acc: 0.8525\n",
      "Epoch 57/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3550 - acc: 0.8474 - val_loss: 0.3553 - val_acc: 0.8511\n",
      "Epoch 58/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3460 - acc: 0.8499 - val_loss: 0.3469 - val_acc: 0.8506\n",
      "Epoch 59/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3546 - acc: 0.8464 - val_loss: 0.3492 - val_acc: 0.8484\n",
      "Epoch 60/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3476 - acc: 0.8528 - val_loss: 0.3494 - val_acc: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3517 - acc: 0.8480 - val_loss: 0.3458 - val_acc: 0.8531\n",
      "Epoch 62/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3410 - acc: 0.8562 - val_loss: 0.3534 - val_acc: 0.8513\n",
      "Epoch 63/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3444 - acc: 0.8516 - val_loss: 0.3463 - val_acc: 0.8516\n",
      "Epoch 64/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3487 - acc: 0.8535 - val_loss: 0.3481 - val_acc: 0.8514\n",
      "Epoch 65/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3427 - acc: 0.8532 - val_loss: 0.3456 - val_acc: 0.8516\n",
      "Epoch 66/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3484 - acc: 0.8524 - val_loss: 0.3514 - val_acc: 0.8521\n",
      "Epoch 67/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3494 - acc: 0.8489 - val_loss: 0.3395 - val_acc: 0.8558\n",
      "Epoch 68/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3393 - acc: 0.8562 - val_loss: 0.3406 - val_acc: 0.8561\n",
      "Epoch 69/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3467 - acc: 0.8525 - val_loss: 0.3435 - val_acc: 0.8510\n",
      "Epoch 70/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3405 - acc: 0.8551 - val_loss: 0.3651 - val_acc: 0.8490\n",
      "Epoch 71/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3465 - acc: 0.8525 - val_loss: 0.3391 - val_acc: 0.8542\n",
      "Epoch 72/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3418 - acc: 0.8547 - val_loss: 0.3374 - val_acc: 0.8537\n",
      "Epoch 73/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3404 - acc: 0.8534 - val_loss: 0.3608 - val_acc: 0.8501\n",
      "Epoch 74/90\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.3421 - acc: 0.8544 - val_loss: 0.3492 - val_acc: 0.8536\n",
      "Epoch 75/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3338 - acc: 0.8580 - val_loss: 0.3354 - val_acc: 0.8567\n",
      "Epoch 76/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3367 - acc: 0.8549 - val_loss: 0.3329 - val_acc: 0.8573\n",
      "Epoch 77/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3368 - acc: 0.8575 - val_loss: 0.3474 - val_acc: 0.8562\n",
      "Epoch 78/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3415 - acc: 0.8502 - val_loss: 0.3492 - val_acc: 0.8563\n",
      "Epoch 79/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3350 - acc: 0.8576 - val_loss: 0.3319 - val_acc: 0.8573\n",
      "Epoch 80/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3350 - acc: 0.8577 - val_loss: 0.3376 - val_acc: 0.8534\n",
      "Epoch 81/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3315 - acc: 0.8587 - val_loss: 0.3304 - val_acc: 0.8625\n",
      "Epoch 82/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3420 - acc: 0.8546 - val_loss: 0.3406 - val_acc: 0.8544\n",
      "Epoch 83/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3353 - acc: 0.8561 - val_loss: 0.3435 - val_acc: 0.8544\n",
      "Epoch 84/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3415 - acc: 0.8549 - val_loss: 0.3334 - val_acc: 0.8610\n",
      "Epoch 85/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3310 - acc: 0.8559 - val_loss: 0.3344 - val_acc: 0.8562\n",
      "Epoch 86/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3356 - acc: 0.8568 - val_loss: 0.3355 - val_acc: 0.8577\n",
      "Epoch 87/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3383 - acc: 0.8573 - val_loss: 0.3402 - val_acc: 0.8591\n",
      "Epoch 88/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3382 - acc: 0.8571 - val_loss: 0.3262 - val_acc: 0.8609\n",
      "Epoch 89/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3331 - acc: 0.8589 - val_loss: 0.3325 - val_acc: 0.8597\n",
      "Epoch 90/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3311 - acc: 0.8586 - val_loss: 0.3265 - val_acc: 0.8588\n",
      "\n",
      "Training process completed in: 0 h 14 m 50 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1199.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1201 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_161 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_161 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_162 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_163 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_164 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "160/160 [==============================] - 17s 107ms/step - loss: 0.5541 - acc: 0.7254 - val_loss: 0.4621 - val_acc: 0.8009\n",
      "Epoch 2/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.4317 - acc: 0.8151 - val_loss: 0.4343 - val_acc: 0.8103\n",
      "Epoch 3/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.4185 - acc: 0.8214 - val_loss: 0.4270 - val_acc: 0.8210\n",
      "Epoch 4/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.4139 - acc: 0.8211 - val_loss: 0.4101 - val_acc: 0.8174\n",
      "Epoch 5/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.4092 - acc: 0.8229 - val_loss: 0.4106 - val_acc: 0.8199\n",
      "Epoch 6/60\n",
      "160/160 [==============================] - 15s 91ms/step - loss: 0.3994 - acc: 0.8274 - val_loss: 0.4026 - val_acc: 0.8229\n",
      "Epoch 7/60\n",
      "160/160 [==============================] - 14s 91ms/step - loss: 0.4087 - acc: 0.8238 - val_loss: 0.3998 - val_acc: 0.8232\n",
      "Epoch 8/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3896 - acc: 0.8329 - val_loss: 0.3946 - val_acc: 0.8264\n",
      "Epoch 9/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3954 - acc: 0.8293 - val_loss: 0.4044 - val_acc: 0.8262\n",
      "Epoch 10/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3968 - acc: 0.8305 - val_loss: 0.3962 - val_acc: 0.8250\n",
      "Epoch 11/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3915 - acc: 0.8299 - val_loss: 0.3871 - val_acc: 0.8285\n",
      "Epoch 12/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3992 - acc: 0.8298 - val_loss: 0.3917 - val_acc: 0.8322\n",
      "Epoch 13/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3872 - acc: 0.8336 - val_loss: 0.3844 - val_acc: 0.8320\n",
      "Epoch 14/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3807 - acc: 0.8343 - val_loss: 0.3926 - val_acc: 0.8288\n",
      "Epoch 15/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3834 - acc: 0.8345 - val_loss: 0.3797 - val_acc: 0.8333\n",
      "Epoch 16/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3841 - acc: 0.8321 - val_loss: 0.4089 - val_acc: 0.8237\n",
      "Epoch 17/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3856 - acc: 0.8327 - val_loss: 0.3791 - val_acc: 0.8367\n",
      "Epoch 18/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3776 - acc: 0.8374 - val_loss: 0.3840 - val_acc: 0.8355\n",
      "Epoch 19/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3759 - acc: 0.8380 - val_loss: 0.3689 - val_acc: 0.8405\n",
      "Epoch 20/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3693 - acc: 0.8402 - val_loss: 0.3949 - val_acc: 0.8221\n",
      "Epoch 21/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3732 - acc: 0.8387 - val_loss: 0.3758 - val_acc: 0.8375\n",
      "Epoch 22/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3693 - acc: 0.8428 - val_loss: 0.3607 - val_acc: 0.8448\n",
      "Epoch 23/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3658 - acc: 0.8443 - val_loss: 0.3588 - val_acc: 0.8483\n",
      "Epoch 24/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3698 - acc: 0.8406 - val_loss: 0.3668 - val_acc: 0.8404\n",
      "Epoch 25/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3625 - acc: 0.8453 - val_loss: 0.3732 - val_acc: 0.8387\n",
      "Epoch 26/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3624 - acc: 0.8440 - val_loss: 0.3733 - val_acc: 0.8371\n",
      "Epoch 27/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3651 - acc: 0.8446 - val_loss: 0.3568 - val_acc: 0.8478\n",
      "Epoch 28/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3565 - acc: 0.8462 - val_loss: 0.3574 - val_acc: 0.8483\n",
      "Epoch 29/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3647 - acc: 0.8441 - val_loss: 0.3655 - val_acc: 0.8463\n",
      "Epoch 30/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3616 - acc: 0.8433 - val_loss: 0.3630 - val_acc: 0.8447\n",
      "Epoch 31/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3600 - acc: 0.8440 - val_loss: 0.3526 - val_acc: 0.8510\n",
      "Epoch 32/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3523 - acc: 0.8488 - val_loss: 0.3537 - val_acc: 0.8493\n",
      "Epoch 33/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3544 - acc: 0.8498 - val_loss: 0.3572 - val_acc: 0.8466\n",
      "Epoch 34/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3534 - acc: 0.8473 - val_loss: 0.3603 - val_acc: 0.8471\n",
      "Epoch 35/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3561 - acc: 0.8484 - val_loss: 0.3579 - val_acc: 0.8481\n",
      "Epoch 36/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3528 - acc: 0.8498 - val_loss: 0.3573 - val_acc: 0.8462\n",
      "Epoch 37/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3504 - acc: 0.8509 - val_loss: 0.3573 - val_acc: 0.8498\n",
      "Epoch 38/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3486 - acc: 0.8492 - val_loss: 0.3854 - val_acc: 0.8297\n",
      "Epoch 39/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3470 - acc: 0.8526 - val_loss: 0.3501 - val_acc: 0.8525\n",
      "Epoch 40/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3516 - acc: 0.8497 - val_loss: 0.3440 - val_acc: 0.8549\n",
      "Epoch 41/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3450 - acc: 0.8544 - val_loss: 0.3551 - val_acc: 0.8475\n",
      "Epoch 42/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3525 - acc: 0.8507 - val_loss: 0.3437 - val_acc: 0.8546\n",
      "Epoch 43/60\n",
      "160/160 [==============================] - 15s 95ms/step - loss: 0.3465 - acc: 0.8514 - val_loss: 0.3423 - val_acc: 0.8529\n",
      "Epoch 44/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3521 - acc: 0.8491 - val_loss: 0.3551 - val_acc: 0.8518\n",
      "Epoch 45/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3426 - acc: 0.8543 - val_loss: 0.3549 - val_acc: 0.8526\n",
      "Epoch 46/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3447 - acc: 0.8517 - val_loss: 0.3407 - val_acc: 0.8563\n",
      "Epoch 47/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3427 - acc: 0.8537 - val_loss: 0.3345 - val_acc: 0.8572\n",
      "Epoch 48/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3388 - acc: 0.8570 - val_loss: 0.3442 - val_acc: 0.8534\n",
      "Epoch 49/60\n",
      "160/160 [==============================] - 15s 92ms/step - loss: 0.3450 - acc: 0.8528 - val_loss: 0.3397 - val_acc: 0.8590\n",
      "Epoch 50/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3402 - acc: 0.8548 - val_loss: 0.3390 - val_acc: 0.8547\n",
      "Epoch 51/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3429 - acc: 0.8539 - val_loss: 0.3462 - val_acc: 0.8538\n",
      "Epoch 52/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3425 - acc: 0.8527 - val_loss: 0.3389 - val_acc: 0.8604\n",
      "Epoch 53/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3388 - acc: 0.8573 - val_loss: 0.3520 - val_acc: 0.8532\n",
      "Epoch 54/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3369 - acc: 0.8576 - val_loss: 0.3469 - val_acc: 0.8527\n",
      "Epoch 55/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3381 - acc: 0.8552 - val_loss: 0.3470 - val_acc: 0.8537\n",
      "Epoch 56/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3409 - acc: 0.8523 - val_loss: 0.3319 - val_acc: 0.8637\n",
      "Epoch 57/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3322 - acc: 0.8587 - val_loss: 0.3381 - val_acc: 0.8560\n",
      "Epoch 58/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3287 - acc: 0.8619 - val_loss: 0.3384 - val_acc: 0.8538\n",
      "Epoch 59/60\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.3288 - acc: 0.8610 - val_loss: 0.3387 - val_acc: 0.8587\n",
      "Epoch 60/60\n",
      "160/160 [==============================] - 15s 94ms/step - loss: 0.3344 - acc: 0.8580 - val_loss: 0.3271 - val_acc: 0.8625\n",
      "\n",
      "Training process completed in: 0 h 14 m 54 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1200.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1202 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_165 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_167 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.5805 - acc: 0.7049 - val_loss: 0.5238 - val_acc: 0.7131\n",
      "Epoch 2/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4448 - acc: 0.7967 - val_loss: 0.4198 - val_acc: 0.8159\n",
      "Epoch 3/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4178 - acc: 0.8198 - val_loss: 0.4169 - val_acc: 0.8192\n",
      "Epoch 4/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4014 - acc: 0.8285 - val_loss: 0.3953 - val_acc: 0.8302\n",
      "Epoch 5/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.4042 - acc: 0.8259 - val_loss: 0.4058 - val_acc: 0.8224\n",
      "Epoch 6/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.4042 - acc: 0.8227 - val_loss: 0.4116 - val_acc: 0.8239\n",
      "Epoch 7/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3964 - acc: 0.8314 - val_loss: 0.4108 - val_acc: 0.8207\n",
      "Epoch 8/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3913 - acc: 0.8303 - val_loss: 0.3876 - val_acc: 0.8322\n",
      "Epoch 9/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3875 - acc: 0.8350 - val_loss: 0.3945 - val_acc: 0.8273\n",
      "Epoch 10/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3876 - acc: 0.8345 - val_loss: 0.3925 - val_acc: 0.8302\n",
      "Epoch 11/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3902 - acc: 0.8303 - val_loss: 0.3802 - val_acc: 0.8320\n",
      "Epoch 12/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3828 - acc: 0.8348 - val_loss: 0.4086 - val_acc: 0.8279\n",
      "Epoch 13/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3825 - acc: 0.8364 - val_loss: 0.3853 - val_acc: 0.8378\n",
      "Epoch 14/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3841 - acc: 0.8376 - val_loss: 0.3808 - val_acc: 0.8326\n",
      "Epoch 15/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3830 - acc: 0.8352 - val_loss: 0.3961 - val_acc: 0.8308\n",
      "Epoch 16/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3794 - acc: 0.8360 - val_loss: 0.3748 - val_acc: 0.8371\n",
      "Epoch 17/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3750 - acc: 0.8398 - val_loss: 0.3710 - val_acc: 0.8408\n",
      "Epoch 18/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3684 - acc: 0.8457 - val_loss: 0.3740 - val_acc: 0.8380\n",
      "Epoch 19/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3688 - acc: 0.8417 - val_loss: 0.3688 - val_acc: 0.8382\n",
      "Epoch 20/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3719 - acc: 0.8425 - val_loss: 0.3781 - val_acc: 0.8368\n",
      "Epoch 21/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3699 - acc: 0.8412 - val_loss: 0.3652 - val_acc: 0.8464\n",
      "Epoch 22/90\n",
      "160/160 [==============================] - 13s 81ms/step - loss: 0.3678 - acc: 0.8418 - val_loss: 0.3671 - val_acc: 0.8380\n",
      "Epoch 23/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3675 - acc: 0.8420 - val_loss: 0.3707 - val_acc: 0.8400\n",
      "Epoch 24/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3611 - acc: 0.8461 - val_loss: 0.3621 - val_acc: 0.8482\n",
      "Epoch 25/90\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.3624 - acc: 0.8451 - val_loss: 0.3579 - val_acc: 0.8455\n",
      "Epoch 26/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3546 - acc: 0.8504 - val_loss: 0.3647 - val_acc: 0.8442\n",
      "Epoch 27/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3580 - acc: 0.8459 - val_loss: 0.3594 - val_acc: 0.8526\n",
      "Epoch 28/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3641 - acc: 0.8448 - val_loss: 0.3448 - val_acc: 0.8520\n",
      "Epoch 29/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3534 - acc: 0.8499 - val_loss: 0.3559 - val_acc: 0.8509\n",
      "Epoch 30/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3628 - acc: 0.8468 - val_loss: 0.3613 - val_acc: 0.8456\n",
      "Epoch 31/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3568 - acc: 0.8481 - val_loss: 0.3521 - val_acc: 0.8493\n",
      "Epoch 32/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3541 - acc: 0.8486 - val_loss: 0.3700 - val_acc: 0.8436\n",
      "Epoch 33/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3504 - acc: 0.8519 - val_loss: 0.3508 - val_acc: 0.8511\n",
      "Epoch 34/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3487 - acc: 0.8505 - val_loss: 0.3526 - val_acc: 0.8520\n",
      "Epoch 35/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3512 - acc: 0.8512 - val_loss: 0.3543 - val_acc: 0.8503\n",
      "Epoch 36/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3447 - acc: 0.8530 - val_loss: 0.3730 - val_acc: 0.8428\n",
      "Epoch 37/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3554 - acc: 0.8469 - val_loss: 0.3483 - val_acc: 0.8582\n",
      "Epoch 38/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3501 - acc: 0.8501 - val_loss: 0.3455 - val_acc: 0.8557\n",
      "Epoch 39/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3545 - acc: 0.8507 - val_loss: 0.3540 - val_acc: 0.8500\n",
      "Epoch 40/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3457 - acc: 0.8525 - val_loss: 0.3516 - val_acc: 0.8528\n",
      "Epoch 41/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3406 - acc: 0.8571 - val_loss: 0.3429 - val_acc: 0.8556\n",
      "Epoch 42/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3437 - acc: 0.8544 - val_loss: 0.3541 - val_acc: 0.8506\n",
      "Epoch 43/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3377 - acc: 0.8559 - val_loss: 0.3419 - val_acc: 0.8592\n",
      "Epoch 44/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3470 - acc: 0.8515 - val_loss: 0.3390 - val_acc: 0.8562\n",
      "Epoch 45/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3466 - acc: 0.8519 - val_loss: 0.3373 - val_acc: 0.8588\n",
      "Epoch 46/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3374 - acc: 0.8576 - val_loss: 0.3460 - val_acc: 0.8534\n",
      "Epoch 47/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3370 - acc: 0.8588 - val_loss: 0.3359 - val_acc: 0.8595\n",
      "Epoch 48/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3432 - acc: 0.8539 - val_loss: 0.3353 - val_acc: 0.8604\n",
      "Epoch 49/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3395 - acc: 0.8551 - val_loss: 0.3328 - val_acc: 0.8589\n",
      "Epoch 50/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3369 - acc: 0.8574 - val_loss: 0.3395 - val_acc: 0.8563\n",
      "Epoch 51/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3363 - acc: 0.8574 - val_loss: 0.3413 - val_acc: 0.8573\n",
      "Epoch 52/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3393 - acc: 0.8560 - val_loss: 0.3359 - val_acc: 0.8592\n",
      "Epoch 53/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3376 - acc: 0.8575 - val_loss: 0.3399 - val_acc: 0.8572\n",
      "Epoch 54/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3345 - acc: 0.8579 - val_loss: 0.3412 - val_acc: 0.8553\n",
      "Epoch 55/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3299 - acc: 0.8602 - val_loss: 0.3264 - val_acc: 0.8639\n",
      "Epoch 56/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3316 - acc: 0.8588 - val_loss: 0.3465 - val_acc: 0.8546\n",
      "Epoch 57/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3368 - acc: 0.8558 - val_loss: 0.3390 - val_acc: 0.8556\n",
      "Epoch 58/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3373 - acc: 0.8536 - val_loss: 0.3294 - val_acc: 0.8594\n",
      "Epoch 59/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3199 - acc: 0.8664 - val_loss: 0.3205 - val_acc: 0.8671\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3305 - acc: 0.8611 - val_loss: 0.3340 - val_acc: 0.8572\n",
      "Epoch 61/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3356 - acc: 0.8582 - val_loss: 0.3247 - val_acc: 0.8617\n",
      "Epoch 62/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3270 - acc: 0.8630 - val_loss: 0.3332 - val_acc: 0.8586\n",
      "Epoch 63/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3302 - acc: 0.8605 - val_loss: 0.3406 - val_acc: 0.8519\n",
      "Epoch 64/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3356 - acc: 0.8586 - val_loss: 0.3405 - val_acc: 0.8547\n",
      "Epoch 65/90\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.3277 - acc: 0.8622 - val_loss: 0.3329 - val_acc: 0.8577\n",
      "Epoch 66/90\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3251 - acc: 0.8634 - val_loss: 0.3394 - val_acc: 0.8579\n",
      "Epoch 67/90\n",
      "160/160 [==============================] - 13s 81ms/step - loss: 0.3278 - acc: 0.8591 - val_loss: 0.3421 - val_acc: 0.8526\n",
      "Epoch 68/90\n",
      "160/160 [==============================] - 13s 81ms/step - loss: 0.3218 - acc: 0.8644 - val_loss: 0.3172 - val_acc: 0.8634\n",
      "Epoch 69/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3195 - acc: 0.8648 - val_loss: 0.3241 - val_acc: 0.8627\n",
      "Epoch 70/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3239 - acc: 0.8623 - val_loss: 0.3166 - val_acc: 0.8687\n",
      "Epoch 71/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3232 - acc: 0.8647 - val_loss: 0.3281 - val_acc: 0.8603\n",
      "Epoch 72/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3221 - acc: 0.8627 - val_loss: 0.3378 - val_acc: 0.8618\n",
      "Epoch 73/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3271 - acc: 0.8607 - val_loss: 0.3353 - val_acc: 0.8573\n",
      "Epoch 74/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3211 - acc: 0.8652 - val_loss: 0.3317 - val_acc: 0.8569\n",
      "Epoch 75/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3164 - acc: 0.8679 - val_loss: 0.3215 - val_acc: 0.8624\n",
      "Epoch 76/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3172 - acc: 0.8653 - val_loss: 0.3233 - val_acc: 0.8636\n",
      "Epoch 77/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3254 - acc: 0.8628 - val_loss: 0.3348 - val_acc: 0.8587\n",
      "Epoch 78/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3177 - acc: 0.8655 - val_loss: 0.3350 - val_acc: 0.8582\n",
      "Epoch 79/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3268 - acc: 0.8627 - val_loss: 0.3246 - val_acc: 0.8620\n",
      "Epoch 80/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3208 - acc: 0.8617 - val_loss: 0.3152 - val_acc: 0.8704\n",
      "Epoch 81/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3154 - acc: 0.8653 - val_loss: 0.3251 - val_acc: 0.8636\n",
      "Epoch 82/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3216 - acc: 0.8655 - val_loss: 0.3199 - val_acc: 0.8651\n",
      "Epoch 83/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3182 - acc: 0.8656 - val_loss: 0.3207 - val_acc: 0.8646\n",
      "Epoch 84/90\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.3155 - acc: 0.8655 - val_loss: 0.3217 - val_acc: 0.8639\n",
      "Epoch 85/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3103 - acc: 0.8699 - val_loss: 0.3246 - val_acc: 0.8640\n",
      "Epoch 86/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3123 - acc: 0.8651 - val_loss: 0.3231 - val_acc: 0.8621\n",
      "Epoch 87/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3126 - acc: 0.8687 - val_loss: 0.3043 - val_acc: 0.8727\n",
      "Epoch 88/90\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3167 - acc: 0.8674 - val_loss: 0.3169 - val_acc: 0.8614\n",
      "Epoch 89/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3115 - acc: 0.8706 - val_loss: 0.3208 - val_acc: 0.8674\n",
      "Epoch 90/90\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3188 - acc: 0.8646 - val_loss: 0.3230 - val_acc: 0.8635\n",
      "\n",
      "Training process completed in: 0 h 20 m 4 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1201.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1203 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_169 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_171 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_172 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 120\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "160/160 [==============================] - 12s 75ms/step - loss: 0.5677 - acc: 0.7207 - val_loss: 0.5258 - val_acc: 0.7162\n",
      "Epoch 2/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.4636 - acc: 0.7866 - val_loss: 0.4389 - val_acc: 0.8142\n",
      "Epoch 3/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4219 - acc: 0.8189 - val_loss: 0.4261 - val_acc: 0.8212\n",
      "Epoch 4/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4178 - acc: 0.8210 - val_loss: 0.4156 - val_acc: 0.8163\n",
      "Epoch 5/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4226 - acc: 0.8181 - val_loss: 0.4029 - val_acc: 0.8237\n",
      "Epoch 6/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4159 - acc: 0.8217 - val_loss: 0.3938 - val_acc: 0.8335\n",
      "Epoch 7/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4089 - acc: 0.8239 - val_loss: 0.3976 - val_acc: 0.8270\n",
      "Epoch 8/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4037 - acc: 0.8268 - val_loss: 0.4097 - val_acc: 0.8222\n",
      "Epoch 9/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3975 - acc: 0.8294 - val_loss: 0.4202 - val_acc: 0.8148\n",
      "Epoch 10/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.4003 - acc: 0.8306 - val_loss: 0.4037 - val_acc: 0.8244\n",
      "Epoch 11/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 9s 58ms/step - loss: 0.4006 - acc: 0.8294 - val_loss: 0.4110 - val_acc: 0.8272\n",
      "Epoch 12/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3960 - acc: 0.8283 - val_loss: 0.3993 - val_acc: 0.8272\n",
      "Epoch 13/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3918 - acc: 0.8337 - val_loss: 0.4052 - val_acc: 0.8232\n",
      "Epoch 14/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3998 - acc: 0.8297 - val_loss: 0.3946 - val_acc: 0.8261\n",
      "Epoch 15/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3905 - acc: 0.8328 - val_loss: 0.3944 - val_acc: 0.8312\n",
      "Epoch 16/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3956 - acc: 0.8306 - val_loss: 0.3876 - val_acc: 0.8308\n",
      "Epoch 17/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3913 - acc: 0.8326 - val_loss: 0.4013 - val_acc: 0.8313\n",
      "Epoch 18/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3775 - acc: 0.8374 - val_loss: 0.3878 - val_acc: 0.8317\n",
      "Epoch 19/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3826 - acc: 0.8344 - val_loss: 0.3805 - val_acc: 0.8310\n",
      "Epoch 20/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3928 - acc: 0.8311 - val_loss: 0.3863 - val_acc: 0.8328\n",
      "Epoch 21/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3926 - acc: 0.8317 - val_loss: 0.3944 - val_acc: 0.8342\n",
      "Epoch 22/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3852 - acc: 0.8361 - val_loss: 0.3809 - val_acc: 0.8313\n",
      "Epoch 23/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3840 - acc: 0.8340 - val_loss: 0.3762 - val_acc: 0.8415\n",
      "Epoch 24/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3759 - acc: 0.8393 - val_loss: 0.3920 - val_acc: 0.8317\n",
      "Epoch 25/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3783 - acc: 0.8371 - val_loss: 0.3792 - val_acc: 0.8353\n",
      "Epoch 26/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3742 - acc: 0.8419 - val_loss: 0.3742 - val_acc: 0.8333\n",
      "Epoch 27/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3661 - acc: 0.8431 - val_loss: 0.3720 - val_acc: 0.8420\n",
      "Epoch 28/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3707 - acc: 0.8420 - val_loss: 0.3730 - val_acc: 0.8354\n",
      "Epoch 29/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3796 - acc: 0.8349 - val_loss: 0.3664 - val_acc: 0.8443\n",
      "Epoch 30/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3695 - acc: 0.8421 - val_loss: 0.3728 - val_acc: 0.8375\n",
      "Epoch 31/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3716 - acc: 0.8382 - val_loss: 0.3743 - val_acc: 0.8400\n",
      "Epoch 32/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3701 - acc: 0.8398 - val_loss: 0.3755 - val_acc: 0.8372\n",
      "Epoch 33/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3732 - acc: 0.8367 - val_loss: 0.3885 - val_acc: 0.8386\n",
      "Epoch 34/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3780 - acc: 0.8375 - val_loss: 0.3771 - val_acc: 0.8393\n",
      "Epoch 35/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3676 - acc: 0.8427 - val_loss: 0.3632 - val_acc: 0.8400\n",
      "Epoch 36/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3660 - acc: 0.8426 - val_loss: 0.3921 - val_acc: 0.8353\n",
      "Epoch 37/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3671 - acc: 0.8420 - val_loss: 0.3626 - val_acc: 0.8453\n",
      "Epoch 38/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3626 - acc: 0.8441 - val_loss: 0.3657 - val_acc: 0.8378\n",
      "Epoch 39/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3667 - acc: 0.8421 - val_loss: 0.3740 - val_acc: 0.8443\n",
      "Epoch 40/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3587 - acc: 0.8469 - val_loss: 0.3711 - val_acc: 0.8410\n",
      "Epoch 41/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3623 - acc: 0.8432 - val_loss: 0.3556 - val_acc: 0.8537\n",
      "Epoch 42/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3592 - acc: 0.8480 - val_loss: 0.3538 - val_acc: 0.8495\n",
      "Epoch 43/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3551 - acc: 0.8479 - val_loss: 0.3642 - val_acc: 0.8468\n",
      "Epoch 44/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3658 - acc: 0.8408 - val_loss: 0.3742 - val_acc: 0.8472\n",
      "Epoch 45/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3497 - acc: 0.8518 - val_loss: 0.3579 - val_acc: 0.8410\n",
      "Epoch 46/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3556 - acc: 0.8470 - val_loss: 0.3637 - val_acc: 0.8477\n",
      "Epoch 47/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3621 - acc: 0.8464 - val_loss: 0.3851 - val_acc: 0.8424\n",
      "Epoch 48/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3501 - acc: 0.8521 - val_loss: 0.3507 - val_acc: 0.8510\n",
      "Epoch 49/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3510 - acc: 0.8517 - val_loss: 0.3525 - val_acc: 0.8488\n",
      "Epoch 50/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3428 - acc: 0.8556 - val_loss: 0.3617 - val_acc: 0.8483\n",
      "Epoch 51/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3547 - acc: 0.8458 - val_loss: 0.3383 - val_acc: 0.8563\n",
      "Epoch 52/60\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3492 - acc: 0.8502 - val_loss: 0.3418 - val_acc: 0.8528\n",
      "Epoch 53/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3470 - acc: 0.8517 - val_loss: 0.3538 - val_acc: 0.8523\n",
      "Epoch 54/60\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3538 - acc: 0.8481 - val_loss: 0.3517 - val_acc: 0.8500\n",
      "Epoch 55/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3453 - acc: 0.8528 - val_loss: 0.3630 - val_acc: 0.8475\n",
      "Epoch 56/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3558 - acc: 0.8470 - val_loss: 0.3418 - val_acc: 0.8567\n",
      "Epoch 57/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3477 - acc: 0.8507 - val_loss: 0.3454 - val_acc: 0.8477\n",
      "Epoch 58/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3430 - acc: 0.8541 - val_loss: 0.3405 - val_acc: 0.8553\n",
      "Epoch 59/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3386 - acc: 0.8561 - val_loss: 0.3471 - val_acc: 0.8512\n",
      "Epoch 60/60\n",
      "160/160 [==============================] - 9s 57ms/step - loss: 0.3538 - acc: 0.8504 - val_loss: 0.3439 - val_acc: 0.8563\n",
      "\n",
      "Training process completed in: 0 h 9 m 9 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1202.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1204 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_173 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_173 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_174 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_175 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_176 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "90/90 [==============================] - 12s 136ms/step - loss: 0.5933 - acc: 0.7118 - val_loss: 0.5664 - val_acc: 0.7193\n",
      "Epoch 2/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.5126 - acc: 0.7447 - val_loss: 0.4514 - val_acc: 0.7975\n",
      "Epoch 3/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.4379 - acc: 0.8079 - val_loss: 0.4270 - val_acc: 0.8155\n",
      "Epoch 4/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4243 - acc: 0.8184 - val_loss: 0.4299 - val_acc: 0.8077\n",
      "Epoch 5/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4259 - acc: 0.8153 - val_loss: 0.4118 - val_acc: 0.8231\n",
      "Epoch 6/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4130 - acc: 0.8223 - val_loss: 0.4156 - val_acc: 0.8153\n",
      "Epoch 7/90\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.4273 - acc: 0.8137 - val_loss: 0.4157 - val_acc: 0.8182\n",
      "Epoch 8/90\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.4174 - acc: 0.8201 - val_loss: 0.4132 - val_acc: 0.8214\n",
      "Epoch 9/90\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 0.4195 - acc: 0.8162 - val_loss: 0.4293 - val_acc: 0.8149\n",
      "Epoch 10/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4084 - acc: 0.8243 - val_loss: 0.4208 - val_acc: 0.8203\n",
      "Epoch 11/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.4041 - acc: 0.8288 - val_loss: 0.4188 - val_acc: 0.8214\n",
      "Epoch 12/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.4121 - acc: 0.8218 - val_loss: 0.4536 - val_acc: 0.8056\n",
      "Epoch 13/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.4135 - acc: 0.8226 - val_loss: 0.4011 - val_acc: 0.8265\n",
      "Epoch 14/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4006 - acc: 0.8302 - val_loss: 0.4193 - val_acc: 0.8151\n",
      "Epoch 15/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3957 - acc: 0.8310 - val_loss: 0.4023 - val_acc: 0.8270\n",
      "Epoch 16/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3986 - acc: 0.8289 - val_loss: 0.4252 - val_acc: 0.8084\n",
      "Epoch 17/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4003 - acc: 0.8284 - val_loss: 0.4010 - val_acc: 0.8269\n",
      "Epoch 18/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3992 - acc: 0.8275 - val_loss: 0.4039 - val_acc: 0.8263\n",
      "Epoch 19/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3968 - acc: 0.8306 - val_loss: 0.4284 - val_acc: 0.8168\n",
      "Epoch 20/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3954 - acc: 0.8304 - val_loss: 0.3927 - val_acc: 0.8261\n",
      "Epoch 21/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3987 - acc: 0.8267 - val_loss: 0.4292 - val_acc: 0.8204\n",
      "Epoch 22/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4012 - acc: 0.8283 - val_loss: 0.3944 - val_acc: 0.8300\n",
      "Epoch 23/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3909 - acc: 0.8328 - val_loss: 0.3950 - val_acc: 0.8294\n",
      "Epoch 24/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3988 - acc: 0.8299 - val_loss: 0.3908 - val_acc: 0.8294\n",
      "Epoch 25/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3867 - acc: 0.8355 - val_loss: 0.3826 - val_acc: 0.8341\n",
      "Epoch 26/90\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.3846 - acc: 0.8339 - val_loss: 0.3974 - val_acc: 0.8299\n",
      "Epoch 27/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3859 - acc: 0.8320 - val_loss: 0.4039 - val_acc: 0.8302\n",
      "Epoch 28/90\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3860 - acc: 0.8338 - val_loss: 0.3860 - val_acc: 0.8325\n",
      "Epoch 29/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3825 - acc: 0.8369 - val_loss: 0.3739 - val_acc: 0.8387\n",
      "Epoch 30/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3765 - acc: 0.8389 - val_loss: 0.3922 - val_acc: 0.8340\n",
      "Epoch 31/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3882 - acc: 0.8348 - val_loss: 0.3782 - val_acc: 0.8366\n",
      "Epoch 32/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3800 - acc: 0.8373 - val_loss: 0.3947 - val_acc: 0.8338\n",
      "Epoch 33/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3809 - acc: 0.8386 - val_loss: 0.3870 - val_acc: 0.8358\n",
      "Epoch 34/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3776 - acc: 0.8394 - val_loss: 0.3789 - val_acc: 0.8355\n",
      "Epoch 35/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3832 - acc: 0.8328 - val_loss: 0.3762 - val_acc: 0.8408\n",
      "Epoch 36/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3861 - acc: 0.8350 - val_loss: 0.3875 - val_acc: 0.8372\n",
      "Epoch 37/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3759 - acc: 0.8398 - val_loss: 0.3815 - val_acc: 0.8356\n",
      "Epoch 38/90\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.3657 - acc: 0.8414 - val_loss: 0.3705 - val_acc: 0.8400\n",
      "Epoch 39/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3811 - acc: 0.8359 - val_loss: 0.3821 - val_acc: 0.8403\n",
      "Epoch 40/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3686 - acc: 0.8438 - val_loss: 0.3714 - val_acc: 0.8365\n",
      "Epoch 41/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3753 - acc: 0.8369 - val_loss: 0.3749 - val_acc: 0.8361\n",
      "Epoch 42/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3669 - acc: 0.8454 - val_loss: 0.3644 - val_acc: 0.8456\n",
      "Epoch 43/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3692 - acc: 0.8438 - val_loss: 0.3668 - val_acc: 0.8386\n",
      "Epoch 44/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3722 - acc: 0.8393 - val_loss: 0.3715 - val_acc: 0.8429\n",
      "Epoch 45/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3714 - acc: 0.8399 - val_loss: 0.3658 - val_acc: 0.8424\n",
      "Epoch 46/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3687 - acc: 0.8396 - val_loss: 0.3650 - val_acc: 0.8421\n",
      "Epoch 47/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3642 - acc: 0.8451 - val_loss: 0.3680 - val_acc: 0.8362\n",
      "Epoch 48/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3633 - acc: 0.8431 - val_loss: 0.3648 - val_acc: 0.8421\n",
      "Epoch 49/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3684 - acc: 0.8394 - val_loss: 0.3523 - val_acc: 0.8502\n",
      "Epoch 50/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3639 - acc: 0.8443 - val_loss: 0.3665 - val_acc: 0.8447\n",
      "Epoch 51/90\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.3699 - acc: 0.8416 - val_loss: 0.3764 - val_acc: 0.8463\n",
      "Epoch 52/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3625 - acc: 0.8434 - val_loss: 0.3596 - val_acc: 0.8484\n",
      "Epoch 53/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3602 - acc: 0.8480 - val_loss: 0.3727 - val_acc: 0.8412\n",
      "Epoch 54/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3659 - acc: 0.8452 - val_loss: 0.3705 - val_acc: 0.8457\n",
      "Epoch 55/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3587 - acc: 0.8454 - val_loss: 0.3726 - val_acc: 0.8429\n",
      "Epoch 56/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3594 - acc: 0.8468 - val_loss: 0.4007 - val_acc: 0.8262\n",
      "Epoch 57/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3550 - acc: 0.8477 - val_loss: 0.3555 - val_acc: 0.8498\n",
      "Epoch 58/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3573 - acc: 0.8456 - val_loss: 0.3564 - val_acc: 0.8509\n",
      "Epoch 59/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3509 - acc: 0.8485 - val_loss: 0.3566 - val_acc: 0.8459\n",
      "Epoch 60/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3481 - acc: 0.8523 - val_loss: 0.3529 - val_acc: 0.8537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3547 - acc: 0.8468 - val_loss: 0.3526 - val_acc: 0.8510\n",
      "Epoch 62/90\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.3562 - acc: 0.8489 - val_loss: 0.3584 - val_acc: 0.8456\n",
      "Epoch 63/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3503 - acc: 0.8523 - val_loss: 0.3519 - val_acc: 0.8503\n",
      "Epoch 64/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3544 - acc: 0.8473 - val_loss: 0.3852 - val_acc: 0.8404\n",
      "Epoch 65/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3590 - acc: 0.8457 - val_loss: 0.3524 - val_acc: 0.8489\n",
      "Epoch 66/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3502 - acc: 0.8524 - val_loss: 0.3518 - val_acc: 0.8482\n",
      "Epoch 67/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3478 - acc: 0.8501 - val_loss: 0.3445 - val_acc: 0.8561\n",
      "Epoch 68/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3491 - acc: 0.8522 - val_loss: 0.3540 - val_acc: 0.8511\n",
      "Epoch 69/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3552 - acc: 0.8473 - val_loss: 0.3455 - val_acc: 0.8501\n",
      "Epoch 70/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3442 - acc: 0.8519 - val_loss: 0.3638 - val_acc: 0.8380\n",
      "Epoch 71/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3478 - acc: 0.8553 - val_loss: 0.3536 - val_acc: 0.8486\n",
      "Epoch 72/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3466 - acc: 0.8512 - val_loss: 0.3464 - val_acc: 0.8508\n",
      "Epoch 73/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3434 - acc: 0.8527 - val_loss: 0.3406 - val_acc: 0.8544\n",
      "Epoch 74/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3433 - acc: 0.8527 - val_loss: 0.3422 - val_acc: 0.8563\n",
      "Epoch 75/90\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.3450 - acc: 0.8524 - val_loss: 0.3550 - val_acc: 0.8434\n",
      "Epoch 76/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3447 - acc: 0.8544 - val_loss: 0.3424 - val_acc: 0.8528\n",
      "Epoch 77/90\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 0.3444 - acc: 0.8532 - val_loss: 0.3452 - val_acc: 0.8522\n",
      "Epoch 78/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3539 - acc: 0.8503 - val_loss: 0.3473 - val_acc: 0.8555\n",
      "Epoch 79/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3333 - acc: 0.8598 - val_loss: 0.3342 - val_acc: 0.8546\n",
      "Epoch 80/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3304 - acc: 0.8594 - val_loss: 0.3515 - val_acc: 0.8513\n",
      "Epoch 81/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3467 - acc: 0.8523 - val_loss: 0.3597 - val_acc: 0.8478\n",
      "Epoch 82/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3536 - acc: 0.8482 - val_loss: 0.3530 - val_acc: 0.8496\n",
      "Epoch 83/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3423 - acc: 0.8523 - val_loss: 0.3366 - val_acc: 0.8569\n",
      "Epoch 84/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3366 - acc: 0.8548 - val_loss: 0.3408 - val_acc: 0.8555\n",
      "Epoch 85/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3393 - acc: 0.8562 - val_loss: 0.3484 - val_acc: 0.8498\n",
      "Epoch 86/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3469 - acc: 0.8531 - val_loss: 0.3576 - val_acc: 0.8508\n",
      "Epoch 87/90\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3529 - acc: 0.8493 - val_loss: 0.3434 - val_acc: 0.8604\n",
      "Epoch 88/90\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3429 - acc: 0.8560 - val_loss: 0.3450 - val_acc: 0.8522\n",
      "Epoch 89/90\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.3331 - acc: 0.8565 - val_loss: 0.3385 - val_acc: 0.8572\n",
      "Epoch 90/90\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3423 - acc: 0.8549 - val_loss: 0.3344 - val_acc: 0.8612\n",
      "\n",
      "Training process completed in: 0 h 14 m 39 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1203.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1205 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_177 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_180 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 0.5703 - acc: 0.7151 - val_loss: 0.4872 - val_acc: 0.7764\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.4395 - acc: 0.8066 - val_loss: 0.4267 - val_acc: 0.8132\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.4101 - acc: 0.8256 - val_loss: 0.4171 - val_acc: 0.8240\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.4088 - acc: 0.8251 - val_loss: 0.4061 - val_acc: 0.8204\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.4131 - acc: 0.8237 - val_loss: 0.4086 - val_acc: 0.8239\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.4086 - acc: 0.8252 - val_loss: 0.4390 - val_acc: 0.8121\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.4080 - acc: 0.8242 - val_loss: 0.4020 - val_acc: 0.8296\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.4039 - acc: 0.8301 - val_loss: 0.4156 - val_acc: 0.8230\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3946 - acc: 0.8314 - val_loss: 0.3918 - val_acc: 0.8328\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3983 - acc: 0.8289 - val_loss: 0.3953 - val_acc: 0.8278\n",
      "Epoch 11/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3913 - acc: 0.8313 - val_loss: 0.3907 - val_acc: 0.8331\n",
      "Epoch 12/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3870 - acc: 0.8340 - val_loss: 0.3898 - val_acc: 0.8293\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3860 - acc: 0.8355 - val_loss: 0.4126 - val_acc: 0.8249\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3901 - acc: 0.8345 - val_loss: 0.3887 - val_acc: 0.8387\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3843 - acc: 0.8361 - val_loss: 0.3883 - val_acc: 0.8352\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 16s 103ms/step - loss: 0.3825 - acc: 0.8367 - val_loss: 0.3948 - val_acc: 0.8345\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3842 - acc: 0.8370 - val_loss: 0.3947 - val_acc: 0.8323\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3758 - acc: 0.8379 - val_loss: 0.3749 - val_acc: 0.8410\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3771 - acc: 0.8378 - val_loss: 0.3717 - val_acc: 0.8394\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3733 - acc: 0.8397 - val_loss: 0.3819 - val_acc: 0.8360\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3736 - acc: 0.8396 - val_loss: 0.3687 - val_acc: 0.8426\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3735 - acc: 0.8405 - val_loss: 0.3795 - val_acc: 0.8342\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3713 - acc: 0.8412 - val_loss: 0.3681 - val_acc: 0.8424\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3697 - acc: 0.8413 - val_loss: 0.3631 - val_acc: 0.8412\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.3664 - acc: 0.8428 - val_loss: 0.3687 - val_acc: 0.8432\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3650 - acc: 0.8421 - val_loss: 0.3607 - val_acc: 0.8441\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3650 - acc: 0.8437 - val_loss: 0.3623 - val_acc: 0.8426\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3556 - acc: 0.8485 - val_loss: 0.3570 - val_acc: 0.8482\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3566 - acc: 0.8463 - val_loss: 0.3779 - val_acc: 0.8380\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3525 - acc: 0.8502 - val_loss: 0.3502 - val_acc: 0.8494\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3538 - acc: 0.8497 - val_loss: 0.3539 - val_acc: 0.8483\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3514 - acc: 0.8480 - val_loss: 0.3540 - val_acc: 0.8485\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3526 - acc: 0.8493 - val_loss: 0.3518 - val_acc: 0.8489\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3534 - acc: 0.8494 - val_loss: 0.3514 - val_acc: 0.8521\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3560 - acc: 0.8493 - val_loss: 0.3535 - val_acc: 0.8515\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3497 - acc: 0.8517 - val_loss: 0.3533 - val_acc: 0.8503\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3516 - acc: 0.8506 - val_loss: 0.3457 - val_acc: 0.8539\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.3526 - acc: 0.8495 - val_loss: 0.3502 - val_acc: 0.8539\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 16s 103ms/step - loss: 0.3479 - acc: 0.8489 - val_loss: 0.3490 - val_acc: 0.8557\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3393 - acc: 0.8575 - val_loss: 0.3428 - val_acc: 0.8541\n",
      "Epoch 41/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3450 - acc: 0.8557 - val_loss: 0.3490 - val_acc: 0.8530\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3528 - acc: 0.8489 - val_loss: 0.3545 - val_acc: 0.8521\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3416 - acc: 0.8539 - val_loss: 0.3402 - val_acc: 0.8556\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3412 - acc: 0.8550 - val_loss: 0.3367 - val_acc: 0.8604\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3418 - acc: 0.8543 - val_loss: 0.3382 - val_acc: 0.8572\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3334 - acc: 0.8598 - val_loss: 0.3352 - val_acc: 0.8597\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3432 - acc: 0.8513 - val_loss: 0.3365 - val_acc: 0.8571\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3389 - acc: 0.8560 - val_loss: 0.3574 - val_acc: 0.8467\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3374 - acc: 0.8571 - val_loss: 0.3496 - val_acc: 0.8529\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3354 - acc: 0.8560 - val_loss: 0.3370 - val_acc: 0.8566\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3416 - acc: 0.8522 - val_loss: 0.3355 - val_acc: 0.8584\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3337 - acc: 0.8572 - val_loss: 0.3335 - val_acc: 0.8609\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3359 - acc: 0.8582 - val_loss: 0.3367 - val_acc: 0.8597\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3325 - acc: 0.8579 - val_loss: 0.3370 - val_acc: 0.8602\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3334 - acc: 0.8575 - val_loss: 0.3367 - val_acc: 0.8594\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3346 - acc: 0.8562 - val_loss: 0.3479 - val_acc: 0.8554\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3360 - acc: 0.8570 - val_loss: 0.3330 - val_acc: 0.8567\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3364 - acc: 0.8570 - val_loss: 0.3268 - val_acc: 0.8640\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3280 - acc: 0.8583 - val_loss: 0.3293 - val_acc: 0.8624\n",
      "Epoch 60/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3320 - acc: 0.8593 - val_loss: 0.3301 - val_acc: 0.8642\n",
      "Epoch 61/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3281 - acc: 0.8612 - val_loss: 0.3292 - val_acc: 0.8606\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 16s 103ms/step - loss: 0.3263 - acc: 0.8601 - val_loss: 0.3408 - val_acc: 0.8542\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3257 - acc: 0.8608 - val_loss: 0.3305 - val_acc: 0.8604\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3354 - acc: 0.8568 - val_loss: 0.3241 - val_acc: 0.8607\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3268 - acc: 0.8630 - val_loss: 0.3313 - val_acc: 0.8606\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3277 - acc: 0.8609 - val_loss: 0.3258 - val_acc: 0.8634\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3271 - acc: 0.8578 - val_loss: 0.3308 - val_acc: 0.8595\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3259 - acc: 0.8613 - val_loss: 0.3535 - val_acc: 0.8456\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3250 - acc: 0.8615 - val_loss: 0.3262 - val_acc: 0.8636\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3305 - acc: 0.8589 - val_loss: 0.3410 - val_acc: 0.8592\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3231 - acc: 0.8640 - val_loss: 0.3215 - val_acc: 0.8659\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3247 - acc: 0.8617 - val_loss: 0.3303 - val_acc: 0.8582\n",
      "Epoch 73/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3266 - acc: 0.8620 - val_loss: 0.3264 - val_acc: 0.8669\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3190 - acc: 0.8643 - val_loss: 0.3251 - val_acc: 0.8591\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3175 - acc: 0.8656 - val_loss: 0.3229 - val_acc: 0.8685\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3238 - acc: 0.8620 - val_loss: 0.3183 - val_acc: 0.8673\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3244 - acc: 0.8646 - val_loss: 0.3241 - val_acc: 0.8636\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3245 - acc: 0.8610 - val_loss: 0.3176 - val_acc: 0.8670\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3253 - acc: 0.8613 - val_loss: 0.3221 - val_acc: 0.8631\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3122 - acc: 0.8690 - val_loss: 0.3238 - val_acc: 0.8642\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3182 - acc: 0.8649 - val_loss: 0.3247 - val_acc: 0.8629\n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.3226 - acc: 0.8617 - val_loss: 0.3181 - val_acc: 0.8663\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3237 - acc: 0.8615 - val_loss: 0.3194 - val_acc: 0.8659\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3154 - acc: 0.8658 - val_loss: 0.3249 - val_acc: 0.8597\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3181 - acc: 0.8664 - val_loss: 0.3164 - val_acc: 0.8661\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3187 - acc: 0.8622 - val_loss: 0.3241 - val_acc: 0.8607\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3206 - acc: 0.8644 - val_loss: 0.3118 - val_acc: 0.8702\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3180 - acc: 0.8656 - val_loss: 0.3242 - val_acc: 0.8620\n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3085 - acc: 0.8697 - val_loss: 0.3227 - val_acc: 0.8672\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3155 - acc: 0.8654 - val_loss: 0.3178 - val_acc: 0.8630\n",
      "\n",
      "Training process completed in: 0 h 23 m 19 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1204.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1206 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_181 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_181 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_182 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_183 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_184 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_184 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.5589 - acc: 0.7200 - val_loss: 0.4459 - val_acc: 0.7989\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4190 - acc: 0.8215 - val_loss: 0.4184 - val_acc: 0.8244\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4156 - acc: 0.8225 - val_loss: 0.4330 - val_acc: 0.8098\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4095 - acc: 0.8246 - val_loss: 0.4022 - val_acc: 0.8242\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4094 - acc: 0.8241 - val_loss: 0.4022 - val_acc: 0.8292\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4034 - acc: 0.8280 - val_loss: 0.4055 - val_acc: 0.8237\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4059 - acc: 0.8255 - val_loss: 0.4033 - val_acc: 0.8269\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4015 - acc: 0.8275 - val_loss: 0.3874 - val_acc: 0.8354\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3917 - acc: 0.8323 - val_loss: 0.3906 - val_acc: 0.8299\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3937 - acc: 0.8282 - val_loss: 0.3979 - val_acc: 0.8253\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3856 - acc: 0.8358 - val_loss: 0.3915 - val_acc: 0.8275\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3882 - acc: 0.8314 - val_loss: 0.3855 - val_acc: 0.8324\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3837 - acc: 0.8357 - val_loss: 0.3786 - val_acc: 0.8336\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3810 - acc: 0.8381 - val_loss: 0.3787 - val_acc: 0.8360\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3808 - acc: 0.8345 - val_loss: 0.3868 - val_acc: 0.8332\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3788 - acc: 0.8364 - val_loss: 0.3717 - val_acc: 0.8368\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3742 - acc: 0.8384 - val_loss: 0.3810 - val_acc: 0.8353\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3772 - acc: 0.8372 - val_loss: 0.3693 - val_acc: 0.8392\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3702 - acc: 0.8396 - val_loss: 0.3734 - val_acc: 0.8380\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3753 - acc: 0.8379 - val_loss: 0.3695 - val_acc: 0.8458\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3659 - acc: 0.8454 - val_loss: 0.3681 - val_acc: 0.8442\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3624 - acc: 0.8459 - val_loss: 0.3750 - val_acc: 0.8340\n",
      "Epoch 23/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3627 - acc: 0.8444 - val_loss: 0.3616 - val_acc: 0.8457\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3636 - acc: 0.8439 - val_loss: 0.3613 - val_acc: 0.8418\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3611 - acc: 0.8468 - val_loss: 0.3692 - val_acc: 0.8390\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3552 - acc: 0.8469 - val_loss: 0.3576 - val_acc: 0.8435\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3584 - acc: 0.8453 - val_loss: 0.3637 - val_acc: 0.8476\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3611 - acc: 0.8465 - val_loss: 0.3767 - val_acc: 0.8343\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3564 - acc: 0.8487 - val_loss: 0.3697 - val_acc: 0.8458\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3540 - acc: 0.8491 - val_loss: 0.3529 - val_acc: 0.8503\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3442 - acc: 0.8537 - val_loss: 0.3428 - val_acc: 0.8553\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3524 - acc: 0.8499 - val_loss: 0.3542 - val_acc: 0.8494\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3541 - acc: 0.8494 - val_loss: 0.3491 - val_acc: 0.8536\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3448 - acc: 0.8528 - val_loss: 0.3478 - val_acc: 0.8537\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3546 - acc: 0.8467 - val_loss: 0.3432 - val_acc: 0.8529\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3461 - acc: 0.8530 - val_loss: 0.3557 - val_acc: 0.8459\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3413 - acc: 0.8548 - val_loss: 0.3584 - val_acc: 0.8490\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3442 - acc: 0.8521 - val_loss: 0.3495 - val_acc: 0.8504\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3434 - acc: 0.8543 - val_loss: 0.3418 - val_acc: 0.8585\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3416 - acc: 0.8564 - val_loss: 0.3376 - val_acc: 0.8578\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3431 - acc: 0.8518 - val_loss: 0.3381 - val_acc: 0.8543\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3426 - acc: 0.8547 - val_loss: 0.3381 - val_acc: 0.8591\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3386 - acc: 0.8575 - val_loss: 0.3414 - val_acc: 0.8582\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3350 - acc: 0.8567 - val_loss: 0.3317 - val_acc: 0.8590\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3386 - acc: 0.8542 - val_loss: 0.3610 - val_acc: 0.8437\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3387 - acc: 0.8560 - val_loss: 0.3350 - val_acc: 0.8608\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3321 - acc: 0.8594 - val_loss: 0.3413 - val_acc: 0.8576\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3415 - acc: 0.8542 - val_loss: 0.3386 - val_acc: 0.8577\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3281 - acc: 0.8626 - val_loss: 0.3467 - val_acc: 0.8512\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3356 - acc: 0.8576 - val_loss: 0.3365 - val_acc: 0.8601\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3350 - acc: 0.8570 - val_loss: 0.3344 - val_acc: 0.8590\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3404 - acc: 0.8542 - val_loss: 0.3339 - val_acc: 0.8590\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3311 - acc: 0.8595 - val_loss: 0.3359 - val_acc: 0.8559\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3258 - acc: 0.8625 - val_loss: 0.3301 - val_acc: 0.8607\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3335 - acc: 0.8585 - val_loss: 0.3260 - val_acc: 0.8658\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.3294 - acc: 0.8606 - val_loss: 0.3288 - val_acc: 0.8613\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3282 - acc: 0.8624 - val_loss: 0.3327 - val_acc: 0.8636\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3320 - acc: 0.8603 - val_loss: 0.3339 - val_acc: 0.8602\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3302 - acc: 0.8600 - val_loss: 0.3268 - val_acc: 0.8632\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3249 - acc: 0.8633 - val_loss: 0.3263 - val_acc: 0.8599\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3266 - acc: 0.8600 - val_loss: 0.3332 - val_acc: 0.8601\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3248 - acc: 0.8638 - val_loss: 0.3210 - val_acc: 0.8652\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3219 - acc: 0.8628 - val_loss: 0.3195 - val_acc: 0.8671\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3184 - acc: 0.8670 - val_loss: 0.3245 - val_acc: 0.8631\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3199 - acc: 0.8629 - val_loss: 0.3223 - val_acc: 0.8628\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3278 - acc: 0.8602 - val_loss: 0.3205 - val_acc: 0.8659\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3249 - acc: 0.8621 - val_loss: 0.3301 - val_acc: 0.8596\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3222 - acc: 0.8641 - val_loss: 0.3232 - val_acc: 0.8625\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3208 - acc: 0.8630 - val_loss: 0.3194 - val_acc: 0.8646\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3240 - acc: 0.8625 - val_loss: 0.3294 - val_acc: 0.8617\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3195 - acc: 0.8618 - val_loss: 0.3229 - val_acc: 0.8635\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3221 - acc: 0.8652 - val_loss: 0.3232 - val_acc: 0.8619\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3192 - acc: 0.8637 - val_loss: 0.3179 - val_acc: 0.8661\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3140 - acc: 0.8668 - val_loss: 0.3224 - val_acc: 0.8641\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3206 - acc: 0.8623 - val_loss: 0.3214 - val_acc: 0.8642\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3182 - acc: 0.8653 - val_loss: 0.3270 - val_acc: 0.8607\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3137 - acc: 0.8669 - val_loss: 0.3164 - val_acc: 0.8658\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3186 - acc: 0.8639 - val_loss: 0.3140 - val_acc: 0.8691\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3192 - acc: 0.8635 - val_loss: 0.3200 - val_acc: 0.8650\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3167 - acc: 0.8631 - val_loss: 0.3245 - val_acc: 0.8640\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3132 - acc: 0.8668 - val_loss: 0.3133 - val_acc: 0.8694\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3075 - acc: 0.8727 - val_loss: 0.3191 - val_acc: 0.8646\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3164 - acc: 0.8648 - val_loss: 0.3158 - val_acc: 0.8693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3128 - acc: 0.8671 - val_loss: 0.3269 - val_acc: 0.8565\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3154 - acc: 0.8670 - val_loss: 0.3303 - val_acc: 0.8588\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3133 - acc: 0.8677 - val_loss: 0.3031 - val_acc: 0.8734\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3079 - acc: 0.8694 - val_loss: 0.3166 - val_acc: 0.8668\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3097 - acc: 0.8693 - val_loss: 0.3238 - val_acc: 0.8677\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3107 - acc: 0.8668 - val_loss: 0.3317 - val_acc: 0.8633\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3085 - acc: 0.8687 - val_loss: 0.3157 - val_acc: 0.8639\n",
      "\n",
      "Training process completed in: 0 h 23 m 40 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1205.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1207 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_185 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_185 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_186 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_187 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_188 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4724 - acc: 0.7841 - val_loss: 0.4236 - val_acc: 0.8103\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4183 - acc: 0.8218 - val_loss: 0.4864 - val_acc: 0.8174\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3987 - acc: 0.8301 - val_loss: 0.4098 - val_acc: 0.8280\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3975 - acc: 0.8286 - val_loss: 0.4230 - val_acc: 0.8323\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3862 - acc: 0.8318 - val_loss: 0.4034 - val_acc: 0.8117\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3816 - acc: 0.8353 - val_loss: 0.3882 - val_acc: 0.8250\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3807 - acc: 0.8364 - val_loss: 0.3792 - val_acc: 0.8388\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3767 - acc: 0.8383 - val_loss: 0.3761 - val_acc: 0.8403\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3718 - acc: 0.8412 - val_loss: 0.3892 - val_acc: 0.8487\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3686 - acc: 0.8422 - val_loss: 0.3755 - val_acc: 0.8468\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3677 - acc: 0.8427 - val_loss: 0.3875 - val_acc: 0.8399\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3605 - acc: 0.8448 - val_loss: 0.3655 - val_acc: 0.8534\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3544 - acc: 0.8500 - val_loss: 0.3584 - val_acc: 0.8500\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3496 - acc: 0.8512 - val_loss: 0.3745 - val_acc: 0.8420\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3508 - acc: 0.8535 - val_loss: 0.3666 - val_acc: 0.8531\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3429 - acc: 0.8537 - val_loss: 0.3453 - val_acc: 0.8538\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3443 - acc: 0.8528 - val_loss: 0.3879 - val_acc: 0.8316\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3384 - acc: 0.8551 - val_loss: 0.3513 - val_acc: 0.8538\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3472 - acc: 0.8504 - val_loss: 0.3576 - val_acc: 0.8566\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3397 - acc: 0.8584 - val_loss: 0.3355 - val_acc: 0.8599\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3398 - acc: 0.8554 - val_loss: 0.3542 - val_acc: 0.8579\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3274 - acc: 0.8629 - val_loss: 0.3438 - val_acc: 0.8585\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3391 - acc: 0.8569 - val_loss: 0.3541 - val_acc: 0.8524\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3279 - acc: 0.8611 - val_loss: 0.3305 - val_acc: 0.8603\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3297 - acc: 0.8633 - val_loss: 0.3401 - val_acc: 0.8570\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3355 - acc: 0.8578 - val_loss: 0.3631 - val_acc: 0.8500\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3337 - acc: 0.8588 - val_loss: 0.3402 - val_acc: 0.8532\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3255 - acc: 0.8655 - val_loss: 0.3434 - val_acc: 0.8605\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3229 - acc: 0.8637 - val_loss: 0.3313 - val_acc: 0.8681\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3296 - acc: 0.8592 - val_loss: 0.3529 - val_acc: 0.8559\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3219 - acc: 0.8632 - val_loss: 0.3389 - val_acc: 0.8652\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3240 - acc: 0.8626 - val_loss: 0.3306 - val_acc: 0.8627\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3224 - acc: 0.8636 - val_loss: 0.3303 - val_acc: 0.8693\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3240 - acc: 0.8636 - val_loss: 0.3307 - val_acc: 0.8617\n",
      "Epoch 35/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3221 - acc: 0.8638 - val_loss: 0.3312 - val_acc: 0.8617\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3177 - acc: 0.8663 - val_loss: 0.3341 - val_acc: 0.8635\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3160 - acc: 0.8667 - val_loss: 0.3448 - val_acc: 0.8638\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3189 - acc: 0.8653 - val_loss: 0.3231 - val_acc: 0.8638\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3161 - acc: 0.8668 - val_loss: 0.3215 - val_acc: 0.8687\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3201 - acc: 0.8646 - val_loss: 0.3379 - val_acc: 0.8600\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3170 - acc: 0.8662 - val_loss: 0.3269 - val_acc: 0.8664\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3170 - acc: 0.8649 - val_loss: 0.3347 - val_acc: 0.8704\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3121 - acc: 0.8715 - val_loss: 0.3282 - val_acc: 0.8677\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3126 - acc: 0.8677 - val_loss: 0.3222 - val_acc: 0.8679\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.3064 - acc: 0.8700 - val_loss: 0.3265 - val_acc: 0.8643\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3103 - acc: 0.8695 - val_loss: 0.3063 - val_acc: 0.8709\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3184 - acc: 0.8659 - val_loss: 0.3411 - val_acc: 0.8614\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3136 - acc: 0.8668 - val_loss: 0.3177 - val_acc: 0.8689\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3102 - acc: 0.8695 - val_loss: 0.3434 - val_acc: 0.8598\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3120 - acc: 0.8698 - val_loss: 0.3145 - val_acc: 0.8713\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3092 - acc: 0.8696 - val_loss: 0.3165 - val_acc: 0.8670\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3083 - acc: 0.8700 - val_loss: 0.3343 - val_acc: 0.8683\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3099 - acc: 0.8684 - val_loss: 0.3374 - val_acc: 0.8560\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3093 - acc: 0.8699 - val_loss: 0.3279 - val_acc: 0.8681\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3053 - acc: 0.8733 - val_loss: 0.3177 - val_acc: 0.8677\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2998 - acc: 0.8743 - val_loss: 0.3076 - val_acc: 0.8731\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3021 - acc: 0.8747 - val_loss: 0.3393 - val_acc: 0.8575\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3056 - acc: 0.8708 - val_loss: 0.3155 - val_acc: 0.8719\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3074 - acc: 0.8701 - val_loss: 0.3159 - val_acc: 0.8711\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3065 - acc: 0.8708 - val_loss: 0.3113 - val_acc: 0.8728\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3144 - acc: 0.8674 - val_loss: 0.3297 - val_acc: 0.8694\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3068 - acc: 0.8706 - val_loss: 0.3266 - val_acc: 0.8601\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3088 - acc: 0.8712 - val_loss: 0.3106 - val_acc: 0.8692\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3029 - acc: 0.8729 - val_loss: 0.3195 - val_acc: 0.8640\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3058 - acc: 0.8698 - val_loss: 0.3588 - val_acc: 0.8482\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3056 - acc: 0.8725 - val_loss: 0.3172 - val_acc: 0.8681\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3035 - acc: 0.8713 - val_loss: 0.3291 - val_acc: 0.8631\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.3036 - acc: 0.8715 - val_loss: 0.3188 - val_acc: 0.8637\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3009 - acc: 0.8723 - val_loss: 0.3212 - val_acc: 0.8716\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2990 - acc: 0.8745 - val_loss: 0.3286 - val_acc: 0.8701\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2996 - acc: 0.8741 - val_loss: 0.3249 - val_acc: 0.8697\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2970 - acc: 0.8745 - val_loss: 0.3349 - val_acc: 0.8699\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3019 - acc: 0.8745 - val_loss: 0.3050 - val_acc: 0.8783\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.3008 - acc: 0.8748 - val_loss: 0.3220 - val_acc: 0.8604\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2999 - acc: 0.8748 - val_loss: 0.3193 - val_acc: 0.8711\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2995 - acc: 0.8738 - val_loss: 0.3140 - val_acc: 0.8697\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2940 - acc: 0.8772 - val_loss: 0.3143 - val_acc: 0.8700\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2963 - acc: 0.8753 - val_loss: 0.3225 - val_acc: 0.8647\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2958 - acc: 0.8768 - val_loss: 0.3141 - val_acc: 0.8710\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2979 - acc: 0.8754 - val_loss: 0.3046 - val_acc: 0.8818\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2968 - acc: 0.8758 - val_loss: 0.3220 - val_acc: 0.8689\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2982 - acc: 0.8761 - val_loss: 0.3116 - val_acc: 0.8650\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.3042 - acc: 0.8717 - val_loss: 0.3214 - val_acc: 0.8645\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2950 - acc: 0.8761 - val_loss: 0.3024 - val_acc: 0.8762\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2927 - acc: 0.8758 - val_loss: 0.3154 - val_acc: 0.8665\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2984 - acc: 0.8742 - val_loss: 0.3195 - val_acc: 0.8654\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2985 - acc: 0.8765 - val_loss: 0.3222 - val_acc: 0.8721\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.2951 - acc: 0.8783 - val_loss: 0.3195 - val_acc: 0.8715\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2939 - acc: 0.8774 - val_loss: 0.3093 - val_acc: 0.8729\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.2953 - acc: 0.8757 - val_loss: 0.3108 - val_acc: 0.8710\n",
      "\n",
      "Training process completed in: 0 h 23 m 55 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1206.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1208 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_189 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_189 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_190 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_191 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_192 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.4741 - acc: 0.7875 - val_loss: 0.4153 - val_acc: 0.8205\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.4157 - acc: 0.8229 - val_loss: 0.4105 - val_acc: 0.8315\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3977 - acc: 0.8306 - val_loss: 0.4070 - val_acc: 0.8269\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3860 - acc: 0.8341 - val_loss: 0.3706 - val_acc: 0.8392\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3841 - acc: 0.8358 - val_loss: 0.3941 - val_acc: 0.8352\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3751 - acc: 0.8388 - val_loss: 0.3811 - val_acc: 0.8443\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3737 - acc: 0.8415 - val_loss: 0.3932 - val_acc: 0.8439\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3654 - acc: 0.8450 - val_loss: 0.3668 - val_acc: 0.8412\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3632 - acc: 0.8435 - val_loss: 0.3621 - val_acc: 0.8500\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3577 - acc: 0.8455 - val_loss: 0.3531 - val_acc: 0.8549\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3580 - acc: 0.8462 - val_loss: 0.3607 - val_acc: 0.8548\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3484 - acc: 0.8520 - val_loss: 0.3954 - val_acc: 0.8362\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3519 - acc: 0.8487 - val_loss: 0.3611 - val_acc: 0.8505\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3393 - acc: 0.8552 - val_loss: 0.3443 - val_acc: 0.8536\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3471 - acc: 0.8526 - val_loss: 0.3456 - val_acc: 0.8590\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3413 - acc: 0.8553 - val_loss: 0.3503 - val_acc: 0.8526\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3398 - acc: 0.8555 - val_loss: 0.3329 - val_acc: 0.8601\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3360 - acc: 0.8573 - val_loss: 0.3343 - val_acc: 0.8563\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3379 - acc: 0.8579 - val_loss: 0.3386 - val_acc: 0.8636\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3269 - acc: 0.8610 - val_loss: 0.3299 - val_acc: 0.8577\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3300 - acc: 0.8600 - val_loss: 0.3418 - val_acc: 0.8462\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3310 - acc: 0.8582 - val_loss: 0.3326 - val_acc: 0.8632\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3299 - acc: 0.8603 - val_loss: 0.3415 - val_acc: 0.8596\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3251 - acc: 0.8613 - val_loss: 0.3618 - val_acc: 0.8521\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3268 - acc: 0.8614 - val_loss: 0.3272 - val_acc: 0.8649\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3207 - acc: 0.8630 - val_loss: 0.3714 - val_acc: 0.8412\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3257 - acc: 0.8620 - val_loss: 0.3441 - val_acc: 0.8591\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3183 - acc: 0.8664 - val_loss: 0.3195 - val_acc: 0.8641\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3196 - acc: 0.8638 - val_loss: 0.3218 - val_acc: 0.8703\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 20s 100ms/step - loss: 0.3166 - acc: 0.8658 - val_loss: 0.3459 - val_acc: 0.8549\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3139 - acc: 0.8660 - val_loss: 0.3796 - val_acc: 0.8354\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3185 - acc: 0.8653 - val_loss: 0.3157 - val_acc: 0.8664\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3194 - acc: 0.8652 - val_loss: 0.3280 - val_acc: 0.8632\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3109 - acc: 0.8688 - val_loss: 0.3206 - val_acc: 0.8631\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3172 - acc: 0.8651 - val_loss: 0.3347 - val_acc: 0.8626\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3144 - acc: 0.8663 - val_loss: 0.3180 - val_acc: 0.8728\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3128 - acc: 0.8690 - val_loss: 0.3301 - val_acc: 0.8624\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3119 - acc: 0.8682 - val_loss: 0.3268 - val_acc: 0.8652\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3161 - acc: 0.8672 - val_loss: 0.3333 - val_acc: 0.8623\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3135 - acc: 0.8673 - val_loss: 0.3150 - val_acc: 0.8689\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3069 - acc: 0.8714 - val_loss: 0.3135 - val_acc: 0.8691\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3131 - acc: 0.8674 - val_loss: 0.3252 - val_acc: 0.8668\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3097 - acc: 0.8691 - val_loss: 0.3123 - val_acc: 0.8701\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3075 - acc: 0.8702 - val_loss: 0.3282 - val_acc: 0.8639\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3048 - acc: 0.8700 - val_loss: 0.3336 - val_acc: 0.8644\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3077 - acc: 0.8716 - val_loss: 0.3164 - val_acc: 0.8661\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3040 - acc: 0.8709 - val_loss: 0.3066 - val_acc: 0.8739\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.3043 - acc: 0.8725 - val_loss: 0.3165 - val_acc: 0.8645\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3081 - acc: 0.8693 - val_loss: 0.3133 - val_acc: 0.8687\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3031 - acc: 0.8725 - val_loss: 0.3217 - val_acc: 0.8724\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3047 - acc: 0.8708 - val_loss: 0.3166 - val_acc: 0.8696\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3012 - acc: 0.8725 - val_loss: 0.3177 - val_acc: 0.8703\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3050 - acc: 0.8733 - val_loss: 0.3205 - val_acc: 0.8736\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2964 - acc: 0.8765 - val_loss: 0.3212 - val_acc: 0.8738\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.3067 - acc: 0.8711 - val_loss: 0.3226 - val_acc: 0.8670\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3005 - acc: 0.8730 - val_loss: 0.3254 - val_acc: 0.8640\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2996 - acc: 0.8730 - val_loss: 0.3201 - val_acc: 0.8727\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.3016 - acc: 0.8738 - val_loss: 0.3173 - val_acc: 0.8743\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3061 - acc: 0.8698 - val_loss: 0.3227 - val_acc: 0.8689\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2996 - acc: 0.8739 - val_loss: 0.3123 - val_acc: 0.8711\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2967 - acc: 0.8741 - val_loss: 0.3250 - val_acc: 0.8659\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2952 - acc: 0.8762 - val_loss: 0.3095 - val_acc: 0.8699\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2957 - acc: 0.8760 - val_loss: 0.3134 - val_acc: 0.8671\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2989 - acc: 0.8738 - val_loss: 0.3170 - val_acc: 0.8713\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2974 - acc: 0.8743 - val_loss: 0.3193 - val_acc: 0.8698\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2975 - acc: 0.8752 - val_loss: 0.2944 - val_acc: 0.8756\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2949 - acc: 0.8759 - val_loss: 0.3124 - val_acc: 0.8716\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2952 - acc: 0.8775 - val_loss: 0.3126 - val_acc: 0.8650\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2939 - acc: 0.8745 - val_loss: 0.3161 - val_acc: 0.8709\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2951 - acc: 0.8775 - val_loss: 0.3079 - val_acc: 0.8726\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2920 - acc: 0.8774 - val_loss: 0.3135 - val_acc: 0.8734\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2933 - acc: 0.8779 - val_loss: 0.3073 - val_acc: 0.8761\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2901 - acc: 0.8763 - val_loss: 0.3007 - val_acc: 0.8747\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2846 - acc: 0.8799 - val_loss: 0.3171 - val_acc: 0.8693\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2849 - acc: 0.8814 - val_loss: 0.3120 - val_acc: 0.8709\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2926 - acc: 0.8777 - val_loss: 0.3076 - val_acc: 0.8678\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2952 - acc: 0.8744 - val_loss: 0.3050 - val_acc: 0.8749\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2916 - acc: 0.8774 - val_loss: 0.3089 - val_acc: 0.8722\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2868 - acc: 0.8792 - val_loss: 0.3095 - val_acc: 0.8695\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2919 - acc: 0.8759 - val_loss: 0.3222 - val_acc: 0.8656\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2850 - acc: 0.8806 - val_loss: 0.3004 - val_acc: 0.8755\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2883 - acc: 0.8801 - val_loss: 0.3028 - val_acc: 0.8756\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2891 - acc: 0.8767 - val_loss: 0.3229 - val_acc: 0.8690\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2879 - acc: 0.8785 - val_loss: 0.3089 - val_acc: 0.8694\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2847 - acc: 0.8814 - val_loss: 0.3091 - val_acc: 0.8687\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2813 - acc: 0.8800 - val_loss: 0.3053 - val_acc: 0.8727\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2889 - acc: 0.8784 - val_loss: 0.3187 - val_acc: 0.8734\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2808 - acc: 0.8822 - val_loss: 0.3043 - val_acc: 0.8732\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2859 - acc: 0.8805 - val_loss: 0.3073 - val_acc: 0.8714\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 20s 98ms/step - loss: 0.2819 - acc: 0.8805 - val_loss: 0.3041 - val_acc: 0.8744\n",
      "\n",
      "Training process completed in: 0 h 29 m 11 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1207.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1209 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_193 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_193 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_194 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_195 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_196 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_196 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "160/160 [==============================] - 19s 121ms/step - loss: 0.4774 - acc: 0.7815 - val_loss: 0.4176 - val_acc: 0.8149\n",
      "Epoch 2/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.4225 - acc: 0.8200 - val_loss: 0.4248 - val_acc: 0.8144\n",
      "Epoch 3/40\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.4109 - acc: 0.8217 - val_loss: 0.4073 - val_acc: 0.8283\n",
      "Epoch 4/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.4066 - acc: 0.8261 - val_loss: 0.3941 - val_acc: 0.8281\n",
      "Epoch 5/40\n",
      "160/160 [==============================] - 17s 105ms/step - loss: 0.4018 - acc: 0.8255 - val_loss: 0.4027 - val_acc: 0.8281\n",
      "Epoch 6/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3886 - acc: 0.8337 - val_loss: 0.3878 - val_acc: 0.8374\n",
      "Epoch 7/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3813 - acc: 0.8362 - val_loss: 0.3677 - val_acc: 0.8397\n",
      "Epoch 8/40\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3807 - acc: 0.8387 - val_loss: 0.4077 - val_acc: 0.8328\n",
      "Epoch 9/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3776 - acc: 0.8389 - val_loss: 0.3777 - val_acc: 0.8399\n",
      "Epoch 10/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3743 - acc: 0.8399 - val_loss: 0.3696 - val_acc: 0.8459\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3718 - acc: 0.8382 - val_loss: 0.3715 - val_acc: 0.8436\n",
      "Epoch 12/40\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3587 - acc: 0.8493 - val_loss: 0.3665 - val_acc: 0.8463\n",
      "Epoch 13/40\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3672 - acc: 0.8429 - val_loss: 0.3801 - val_acc: 0.8397\n",
      "Epoch 14/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3656 - acc: 0.8450 - val_loss: 0.3560 - val_acc: 0.8509\n",
      "Epoch 15/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3686 - acc: 0.8446 - val_loss: 0.4183 - val_acc: 0.8184\n",
      "Epoch 16/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3642 - acc: 0.8443 - val_loss: 0.3691 - val_acc: 0.8459\n",
      "Epoch 17/40\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3609 - acc: 0.8469 - val_loss: 0.3588 - val_acc: 0.8469\n",
      "Epoch 18/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3526 - acc: 0.8502 - val_loss: 0.3600 - val_acc: 0.8558\n",
      "Epoch 19/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3504 - acc: 0.8509 - val_loss: 0.3792 - val_acc: 0.8476\n",
      "Epoch 20/40\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3466 - acc: 0.8546 - val_loss: 0.3688 - val_acc: 0.8492\n",
      "Epoch 21/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3472 - acc: 0.8522 - val_loss: 0.3543 - val_acc: 0.8575\n",
      "Epoch 22/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3442 - acc: 0.8522 - val_loss: 0.3520 - val_acc: 0.8581\n",
      "Epoch 23/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3488 - acc: 0.8525 - val_loss: 0.3617 - val_acc: 0.8539\n",
      "Epoch 24/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3397 - acc: 0.8577 - val_loss: 0.3306 - val_acc: 0.8624\n",
      "Epoch 25/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3391 - acc: 0.8562 - val_loss: 0.3688 - val_acc: 0.8511\n",
      "Epoch 26/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3436 - acc: 0.8539 - val_loss: 0.3363 - val_acc: 0.8587\n",
      "Epoch 27/40\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3315 - acc: 0.8592 - val_loss: 0.3343 - val_acc: 0.8586\n",
      "Epoch 28/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3341 - acc: 0.8583 - val_loss: 0.3299 - val_acc: 0.8621\n",
      "Epoch 29/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3306 - acc: 0.8594 - val_loss: 0.3246 - val_acc: 0.8661\n",
      "Epoch 30/40\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.3280 - acc: 0.8599 - val_loss: 0.3664 - val_acc: 0.8552\n",
      "Epoch 31/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3257 - acc: 0.8647 - val_loss: 0.3398 - val_acc: 0.8652\n",
      "Epoch 32/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3285 - acc: 0.8615 - val_loss: 0.3409 - val_acc: 0.8642\n",
      "Epoch 33/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3379 - acc: 0.8568 - val_loss: 0.3328 - val_acc: 0.8614\n",
      "Epoch 34/40\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3250 - acc: 0.8628 - val_loss: 0.3333 - val_acc: 0.8592\n",
      "Epoch 35/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3260 - acc: 0.8621 - val_loss: 0.3463 - val_acc: 0.8632\n",
      "Epoch 36/40\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3232 - acc: 0.8644 - val_loss: 0.3340 - val_acc: 0.8607\n",
      "Epoch 37/40\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3249 - acc: 0.8640 - val_loss: 0.3362 - val_acc: 0.8640\n",
      "Epoch 38/40\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3254 - acc: 0.8618 - val_loss: 0.3428 - val_acc: 0.8643\n",
      "Epoch 39/40\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3137 - acc: 0.8673 - val_loss: 0.3315 - val_acc: 0.8691\n",
      "Epoch 40/40\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3234 - acc: 0.8642 - val_loss: 0.3599 - val_acc: 0.8556\n",
      "\n",
      "Training process completed in: 0 h 11 m 0 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1208.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1210 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_197 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_197 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_198 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_199 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_200 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_200 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 120\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "170/170 [==============================] - 13s 79ms/step - loss: 0.4922 - acc: 0.7738 - val_loss: 0.4133 - val_acc: 0.8232\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.4166 - acc: 0.8217 - val_loss: 0.4343 - val_acc: 0.8250\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.4185 - acc: 0.8203 - val_loss: 0.4165 - val_acc: 0.8285\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.4151 - acc: 0.8218 - val_loss: 0.4479 - val_acc: 0.7863\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.4003 - acc: 0.8286 - val_loss: 0.4079 - val_acc: 0.8299\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3988 - acc: 0.8270 - val_loss: 0.4128 - val_acc: 0.8390\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3827 - acc: 0.8352 - val_loss: 0.3803 - val_acc: 0.8322\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.3929 - acc: 0.8307 - val_loss: 0.3975 - val_acc: 0.8308\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3815 - acc: 0.8355 - val_loss: 0.3987 - val_acc: 0.8374\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3740 - acc: 0.8414 - val_loss: 0.3768 - val_acc: 0.8367\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3791 - acc: 0.8354 - val_loss: 0.3864 - val_acc: 0.8253\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3739 - acc: 0.8395 - val_loss: 0.3756 - val_acc: 0.8346\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3740 - acc: 0.8374 - val_loss: 0.3996 - val_acc: 0.8429\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3677 - acc: 0.8409 - val_loss: 0.3702 - val_acc: 0.8456\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3674 - acc: 0.8439 - val_loss: 0.3848 - val_acc: 0.8503\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3600 - acc: 0.8451 - val_loss: 0.3570 - val_acc: 0.8503\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3698 - acc: 0.8413 - val_loss: 0.4100 - val_acc: 0.8242\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3590 - acc: 0.8490 - val_loss: 0.3612 - val_acc: 0.8458\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3523 - acc: 0.8523 - val_loss: 0.3702 - val_acc: 0.8303\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3566 - acc: 0.8499 - val_loss: 0.3744 - val_acc: 0.8394\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3558 - acc: 0.8473 - val_loss: 0.3585 - val_acc: 0.8506\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3577 - acc: 0.8470 - val_loss: 0.3579 - val_acc: 0.8490\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3394 - acc: 0.8600 - val_loss: 0.3581 - val_acc: 0.8553\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3550 - acc: 0.8464 - val_loss: 0.3607 - val_acc: 0.8553\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3465 - acc: 0.8522 - val_loss: 0.3419 - val_acc: 0.8550\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3406 - acc: 0.8572 - val_loss: 0.3618 - val_acc: 0.8549\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3411 - acc: 0.8548 - val_loss: 0.3629 - val_acc: 0.8428\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.3497 - acc: 0.8510 - val_loss: 0.3501 - val_acc: 0.8519\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3358 - acc: 0.8571 - val_loss: 0.3478 - val_acc: 0.8610\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3418 - acc: 0.8522 - val_loss: 0.3713 - val_acc: 0.8435\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3372 - acc: 0.8546 - val_loss: 0.3469 - val_acc: 0.8621\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3320 - acc: 0.8597 - val_loss: 0.3343 - val_acc: 0.8621\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3506 - acc: 0.8500 - val_loss: 0.3400 - val_acc: 0.8576\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3346 - acc: 0.8553 - val_loss: 0.3414 - val_acc: 0.8572\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3356 - acc: 0.8558 - val_loss: 0.3441 - val_acc: 0.8605\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3298 - acc: 0.8576 - val_loss: 0.3466 - val_acc: 0.8565\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3286 - acc: 0.8598 - val_loss: 0.3515 - val_acc: 0.8540\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3293 - acc: 0.8614 - val_loss: 0.3539 - val_acc: 0.8572\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3390 - acc: 0.8569 - val_loss: 0.3509 - val_acc: 0.8526\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3247 - acc: 0.8635 - val_loss: 0.3240 - val_acc: 0.8631\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3252 - acc: 0.8627 - val_loss: 0.3393 - val_acc: 0.8547\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3306 - acc: 0.8592 - val_loss: 0.3361 - val_acc: 0.8589\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 10s 59ms/step - loss: 0.3380 - acc: 0.8566 - val_loss: 0.3522 - val_acc: 0.8563\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3253 - acc: 0.8626 - val_loss: 0.3439 - val_acc: 0.8642\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3255 - acc: 0.8623 - val_loss: 0.3356 - val_acc: 0.8546\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3215 - acc: 0.8662 - val_loss: 0.3297 - val_acc: 0.8622\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3298 - acc: 0.8612 - val_loss: 0.3411 - val_acc: 0.8597\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3312 - acc: 0.8601 - val_loss: 0.3314 - val_acc: 0.8656\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 10s 60ms/step - loss: 0.3231 - acc: 0.8635 - val_loss: 0.3294 - val_acc: 0.8599\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 10s 61ms/step - loss: 0.3294 - acc: 0.8609 - val_loss: 0.3239 - val_acc: 0.8639\n",
      "\n",
      "Training process completed in: 0 h 8 m 32 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1209.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1211 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_201 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_201 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_202 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_203 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_204 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.4949 - acc: 0.7679 - val_loss: 0.4327 - val_acc: 0.8198\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.4233 - acc: 0.8195 - val_loss: 0.4236 - val_acc: 0.8210\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 101ms/step - loss: 0.4051 - acc: 0.8267 - val_loss: 0.3920 - val_acc: 0.8271\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3986 - acc: 0.8291 - val_loss: 0.3865 - val_acc: 0.8367\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3927 - acc: 0.8320 - val_loss: 0.4371 - val_acc: 0.8233\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3839 - acc: 0.8351 - val_loss: 0.3734 - val_acc: 0.8404\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3797 - acc: 0.8354 - val_loss: 0.3836 - val_acc: 0.8285\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3715 - acc: 0.8409 - val_loss: 0.3654 - val_acc: 0.8408\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3679 - acc: 0.8433 - val_loss: 0.3783 - val_acc: 0.8335\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3721 - acc: 0.8380 - val_loss: 0.3539 - val_acc: 0.8486\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3641 - acc: 0.8435 - val_loss: 0.3550 - val_acc: 0.8527\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3597 - acc: 0.8453 - val_loss: 0.3671 - val_acc: 0.8492\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3625 - acc: 0.8452 - val_loss: 0.3519 - val_acc: 0.8499\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3574 - acc: 0.8468 - val_loss: 0.3629 - val_acc: 0.8424\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3580 - acc: 0.8472 - val_loss: 0.3529 - val_acc: 0.8551\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3492 - acc: 0.8505 - val_loss: 0.3540 - val_acc: 0.8457\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3535 - acc: 0.8497 - val_loss: 0.3567 - val_acc: 0.8496\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3411 - acc: 0.8525 - val_loss: 0.3503 - val_acc: 0.8532\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3438 - acc: 0.8539 - val_loss: 0.3605 - val_acc: 0.8558\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3532 - acc: 0.8482 - val_loss: 0.3443 - val_acc: 0.8541\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3408 - acc: 0.8541 - val_loss: 0.3316 - val_acc: 0.8615\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.3420 - acc: 0.8536 - val_loss: 0.3484 - val_acc: 0.8574\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3450 - acc: 0.8534 - val_loss: 0.3712 - val_acc: 0.8466\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3320 - acc: 0.8625 - val_loss: 0.3421 - val_acc: 0.8587\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3310 - acc: 0.8607 - val_loss: 0.3377 - val_acc: 0.8568\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3388 - acc: 0.8548 - val_loss: 0.3276 - val_acc: 0.8624\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3322 - acc: 0.8596 - val_loss: 0.3342 - val_acc: 0.8653\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3285 - acc: 0.8616 - val_loss: 0.3351 - val_acc: 0.8577\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3279 - acc: 0.8603 - val_loss: 0.3320 - val_acc: 0.8626\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3270 - acc: 0.8611 - val_loss: 0.3258 - val_acc: 0.8642\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3215 - acc: 0.8659 - val_loss: 0.3413 - val_acc: 0.8639\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3337 - acc: 0.8583 - val_loss: 0.3428 - val_acc: 0.8599\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3267 - acc: 0.8625 - val_loss: 0.3245 - val_acc: 0.8625\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3222 - acc: 0.8629 - val_loss: 0.3451 - val_acc: 0.8617\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3250 - acc: 0.8619 - val_loss: 0.3304 - val_acc: 0.8635\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3163 - acc: 0.8661 - val_loss: 0.3475 - val_acc: 0.8557\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3195 - acc: 0.8651 - val_loss: 0.3503 - val_acc: 0.8556\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.3240 - acc: 0.8635 - val_loss: 0.3175 - val_acc: 0.8678\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3189 - acc: 0.8640 - val_loss: 0.3224 - val_acc: 0.8694\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3234 - acc: 0.8629 - val_loss: 0.3420 - val_acc: 0.8610\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3170 - acc: 0.8674 - val_loss: 0.3491 - val_acc: 0.8503\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3161 - acc: 0.8663 - val_loss: 0.3268 - val_acc: 0.8615\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3211 - acc: 0.8623 - val_loss: 0.3190 - val_acc: 0.8657\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3101 - acc: 0.8728 - val_loss: 0.3116 - val_acc: 0.8718\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.3221 - acc: 0.8642 - val_loss: 0.3258 - val_acc: 0.8665\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3055 - acc: 0.8719 - val_loss: 0.3328 - val_acc: 0.8610\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3128 - acc: 0.8659 - val_loss: 0.3130 - val_acc: 0.8730\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3101 - acc: 0.8685 - val_loss: 0.3118 - val_acc: 0.8696\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3152 - acc: 0.8676 - val_loss: 0.3235 - val_acc: 0.8660\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3127 - acc: 0.8696 - val_loss: 0.3081 - val_acc: 0.8704\n",
      "\n",
      "Training process completed in: 0 h 12 m 43 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1210.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1212 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_205 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_205 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_206 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_207 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_208 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 120\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.4933 - acc: 0.7683 - val_loss: 0.4543 - val_acc: 0.8168\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.4438 - acc: 0.8112 - val_loss: 0.4173 - val_acc: 0.8199\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.4147 - acc: 0.8222 - val_loss: 0.4173 - val_acc: 0.8088\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.4154 - acc: 0.8214 - val_loss: 0.4027 - val_acc: 0.8294\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.4110 - acc: 0.8254 - val_loss: 0.4024 - val_acc: 0.8277\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3992 - acc: 0.8266 - val_loss: 0.4001 - val_acc: 0.8291\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3881 - acc: 0.8318 - val_loss: 0.3983 - val_acc: 0.8359\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3886 - acc: 0.8323 - val_loss: 0.3896 - val_acc: 0.8314\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3771 - acc: 0.8383 - val_loss: 0.3863 - val_acc: 0.8255\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3765 - acc: 0.8413 - val_loss: 0.3807 - val_acc: 0.8324\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3774 - acc: 0.8406 - val_loss: 0.4122 - val_acc: 0.8141\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3701 - acc: 0.8438 - val_loss: 0.3677 - val_acc: 0.8401\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3676 - acc: 0.8410 - val_loss: 0.4170 - val_acc: 0.8327\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3641 - acc: 0.8438 - val_loss: 0.3628 - val_acc: 0.8411\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3609 - acc: 0.8476 - val_loss: 0.4087 - val_acc: 0.8278\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3513 - acc: 0.8504 - val_loss: 0.3607 - val_acc: 0.8384\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3583 - acc: 0.8452 - val_loss: 0.3702 - val_acc: 0.8371\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3615 - acc: 0.8447 - val_loss: 0.3661 - val_acc: 0.8441\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3585 - acc: 0.8462 - val_loss: 0.3535 - val_acc: 0.8458\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3472 - acc: 0.8522 - val_loss: 0.3506 - val_acc: 0.8553\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3440 - acc: 0.8539 - val_loss: 0.3559 - val_acc: 0.8520\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3475 - acc: 0.8543 - val_loss: 0.3600 - val_acc: 0.8478\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3388 - acc: 0.8576 - val_loss: 0.3546 - val_acc: 0.8522\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3494 - acc: 0.8515 - val_loss: 0.3766 - val_acc: 0.8446\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3481 - acc: 0.8521 - val_loss: 0.3434 - val_acc: 0.8593\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3500 - acc: 0.8534 - val_loss: 0.3440 - val_acc: 0.8549\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3402 - acc: 0.8555 - val_loss: 0.3439 - val_acc: 0.8592\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3466 - acc: 0.8541 - val_loss: 0.3726 - val_acc: 0.8437\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3436 - acc: 0.8529 - val_loss: 0.3548 - val_acc: 0.8473\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3439 - acc: 0.8541 - val_loss: 0.3621 - val_acc: 0.8462\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3349 - acc: 0.8573 - val_loss: 0.3508 - val_acc: 0.8547\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3402 - acc: 0.8560 - val_loss: 0.3385 - val_acc: 0.8598\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3303 - acc: 0.8561 - val_loss: 0.3644 - val_acc: 0.8531\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3377 - acc: 0.8574 - val_loss: 0.3519 - val_acc: 0.8423\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3343 - acc: 0.8581 - val_loss: 0.3587 - val_acc: 0.8558\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3373 - acc: 0.8582 - val_loss: 0.3827 - val_acc: 0.8466\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3421 - acc: 0.8563 - val_loss: 0.3406 - val_acc: 0.8553\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 12s 77ms/step - loss: 0.3381 - acc: 0.8564 - val_loss: 0.3581 - val_acc: 0.8564\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 11s 77ms/step - loss: 0.3352 - acc: 0.8564 - val_loss: 0.3326 - val_acc: 0.8617\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3292 - acc: 0.8612 - val_loss: 0.3345 - val_acc: 0.8657\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3238 - acc: 0.8656 - val_loss: 0.3397 - val_acc: 0.8548\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3343 - acc: 0.8596 - val_loss: 0.3389 - val_acc: 0.8511\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3354 - acc: 0.8588 - val_loss: 0.3421 - val_acc: 0.8483\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3332 - acc: 0.8603 - val_loss: 0.3564 - val_acc: 0.8444\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3288 - acc: 0.8624 - val_loss: 0.3428 - val_acc: 0.8656\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.3165 - acc: 0.8683 - val_loss: 0.3504 - val_acc: 0.8527\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3367 - acc: 0.8594 - val_loss: 0.3405 - val_acc: 0.8647\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3322 - acc: 0.8612 - val_loss: 0.3406 - val_acc: 0.8619\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3283 - acc: 0.8611 - val_loss: 0.3420 - val_acc: 0.8627\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3262 - acc: 0.8632 - val_loss: 0.3562 - val_acc: 0.8543\n",
      "\n",
      "Training process completed in: 0 h 9 m 19 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1211.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1213 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_209 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_209 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_210 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_210 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_211 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_212 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_212 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 80\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "80/80 [==============================] - 12s 148ms/step - loss: 0.5215 - acc: 0.7520 - val_loss: 0.4230 - val_acc: 0.8217\n",
      "Epoch 2/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.4464 - acc: 0.8101 - val_loss: 0.4547 - val_acc: 0.8154\n",
      "Epoch 3/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.4201 - acc: 0.8210 - val_loss: 0.4839 - val_acc: 0.8048\n",
      "Epoch 4/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4161 - acc: 0.8241 - val_loss: 0.4029 - val_acc: 0.8268\n",
      "Epoch 5/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.4108 - acc: 0.8224 - val_loss: 0.4790 - val_acc: 0.8087\n",
      "Epoch 6/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.4137 - acc: 0.8242 - val_loss: 0.3961 - val_acc: 0.8295\n",
      "Epoch 7/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3954 - acc: 0.8294 - val_loss: 0.3949 - val_acc: 0.8250\n",
      "Epoch 8/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3949 - acc: 0.8307 - val_loss: 0.4462 - val_acc: 0.8216\n",
      "Epoch 9/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.4007 - acc: 0.8290 - val_loss: 0.3976 - val_acc: 0.8332\n",
      "Epoch 10/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3942 - acc: 0.8301 - val_loss: 0.4096 - val_acc: 0.8347\n",
      "Epoch 11/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3945 - acc: 0.8302 - val_loss: 0.3998 - val_acc: 0.8312\n",
      "Epoch 12/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3924 - acc: 0.8340 - val_loss: 0.4735 - val_acc: 0.8169\n",
      "Epoch 13/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3899 - acc: 0.8292 - val_loss: 0.3877 - val_acc: 0.8350\n",
      "Epoch 14/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3777 - acc: 0.8390 - val_loss: 0.4037 - val_acc: 0.8293\n",
      "Epoch 15/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3815 - acc: 0.8362 - val_loss: 0.4135 - val_acc: 0.8379\n",
      "Epoch 16/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3798 - acc: 0.8378 - val_loss: 0.3797 - val_acc: 0.8344\n",
      "Epoch 17/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3803 - acc: 0.8380 - val_loss: 0.3811 - val_acc: 0.8366\n",
      "Epoch 18/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3626 - acc: 0.8440 - val_loss: 0.4090 - val_acc: 0.8396\n",
      "Epoch 19/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3751 - acc: 0.8426 - val_loss: 0.3793 - val_acc: 0.8365\n",
      "Epoch 20/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3763 - acc: 0.8413 - val_loss: 0.3833 - val_acc: 0.8340\n",
      "Epoch 21/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3695 - acc: 0.8425 - val_loss: 0.3743 - val_acc: 0.8389\n",
      "Epoch 22/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3717 - acc: 0.8423 - val_loss: 0.3771 - val_acc: 0.8380\n",
      "Epoch 23/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3620 - acc: 0.8449 - val_loss: 0.3851 - val_acc: 0.8465\n",
      "Epoch 24/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3741 - acc: 0.8392 - val_loss: 0.3599 - val_acc: 0.8437\n",
      "Epoch 25/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3634 - acc: 0.8437 - val_loss: 0.3846 - val_acc: 0.8469\n",
      "Epoch 26/90\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3705 - acc: 0.8398 - val_loss: 0.3808 - val_acc: 0.8412\n",
      "Epoch 27/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3621 - acc: 0.8476 - val_loss: 0.3748 - val_acc: 0.8419\n",
      "Epoch 28/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3635 - acc: 0.8475 - val_loss: 0.3944 - val_acc: 0.8433\n",
      "Epoch 29/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3647 - acc: 0.8423 - val_loss: 0.3748 - val_acc: 0.8514\n",
      "Epoch 30/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3520 - acc: 0.8505 - val_loss: 0.3641 - val_acc: 0.8416\n",
      "Epoch 31/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3598 - acc: 0.8460 - val_loss: 0.3673 - val_acc: 0.8505\n",
      "Epoch 32/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3602 - acc: 0.8479 - val_loss: 0.3712 - val_acc: 0.8388\n",
      "Epoch 33/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3591 - acc: 0.8484 - val_loss: 0.3811 - val_acc: 0.8436\n",
      "Epoch 34/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3606 - acc: 0.8447 - val_loss: 0.3584 - val_acc: 0.8436\n",
      "Epoch 35/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3614 - acc: 0.8461 - val_loss: 0.3852 - val_acc: 0.8443\n",
      "Epoch 36/90\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3583 - acc: 0.8493 - val_loss: 0.3870 - val_acc: 0.8478\n",
      "Epoch 37/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3559 - acc: 0.8506 - val_loss: 0.4041 - val_acc: 0.8436\n",
      "Epoch 38/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3539 - acc: 0.8499 - val_loss: 0.3774 - val_acc: 0.8474\n",
      "Epoch 39/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3515 - acc: 0.8520 - val_loss: 0.3663 - val_acc: 0.8474\n",
      "Epoch 40/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3552 - acc: 0.8488 - val_loss: 0.3818 - val_acc: 0.8527\n",
      "Epoch 41/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3635 - acc: 0.8461 - val_loss: 0.3701 - val_acc: 0.8457\n",
      "Epoch 42/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3638 - acc: 0.8461 - val_loss: 0.3850 - val_acc: 0.8455\n",
      "Epoch 43/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3478 - acc: 0.8530 - val_loss: 0.3679 - val_acc: 0.8500\n",
      "Epoch 44/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3473 - acc: 0.8524 - val_loss: 0.3625 - val_acc: 0.8480\n",
      "Epoch 45/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3455 - acc: 0.8494 - val_loss: 0.3765 - val_acc: 0.8493\n",
      "Epoch 46/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3547 - acc: 0.8488 - val_loss: 0.4336 - val_acc: 0.8377\n",
      "Epoch 47/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3407 - acc: 0.8551 - val_loss: 0.3621 - val_acc: 0.8498\n",
      "Epoch 48/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3427 - acc: 0.8550 - val_loss: 0.3699 - val_acc: 0.8532\n",
      "Epoch 49/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3581 - acc: 0.8480 - val_loss: 0.3836 - val_acc: 0.8461\n",
      "Epoch 50/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3366 - acc: 0.8571 - val_loss: 0.3546 - val_acc: 0.8580\n",
      "Epoch 51/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3571 - acc: 0.8440 - val_loss: 0.3672 - val_acc: 0.8551\n",
      "Epoch 52/90\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.3463 - acc: 0.8560 - val_loss: 0.3586 - val_acc: 0.8542\n",
      "Epoch 53/90\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.3400 - acc: 0.8563 - val_loss: 0.3628 - val_acc: 0.8468\n",
      "Epoch 54/90\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.3472 - acc: 0.8515 - val_loss: 0.3496 - val_acc: 0.8533\n",
      "Epoch 55/90\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3474 - acc: 0.8508 - val_loss: 0.3477 - val_acc: 0.8543\n",
      "Epoch 56/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3426 - acc: 0.8576 - val_loss: 0.3459 - val_acc: 0.8569\n",
      "Epoch 57/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3383 - acc: 0.8582 - val_loss: 0.3533 - val_acc: 0.8548\n",
      "Epoch 58/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3356 - acc: 0.8556 - val_loss: 0.3515 - val_acc: 0.8576\n",
      "Epoch 59/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3553 - acc: 0.8474 - val_loss: 0.3788 - val_acc: 0.8559\n",
      "Epoch 60/90\n",
      "80/80 [==============================] - 9s 112ms/step - loss: 0.3347 - acc: 0.8544 - val_loss: 0.3782 - val_acc: 0.8419\n",
      "Epoch 61/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3448 - acc: 0.8504 - val_loss: 0.3370 - val_acc: 0.8608\n",
      "Epoch 62/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3387 - acc: 0.8584 - val_loss: 0.3536 - val_acc: 0.8501\n",
      "Epoch 63/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3381 - acc: 0.8547 - val_loss: 0.3640 - val_acc: 0.8594\n",
      "Epoch 64/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3394 - acc: 0.8559 - val_loss: 0.3857 - val_acc: 0.8418\n",
      "Epoch 65/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3398 - acc: 0.8571 - val_loss: 0.3708 - val_acc: 0.8531\n",
      "Epoch 66/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3316 - acc: 0.8613 - val_loss: 0.3538 - val_acc: 0.8581\n",
      "Epoch 67/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3336 - acc: 0.8584 - val_loss: 0.3702 - val_acc: 0.8532\n",
      "Epoch 68/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3342 - acc: 0.8622 - val_loss: 0.3428 - val_acc: 0.8596\n",
      "Epoch 69/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3309 - acc: 0.8597 - val_loss: 0.3870 - val_acc: 0.8540\n",
      "Epoch 70/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3519 - acc: 0.8510 - val_loss: 0.3503 - val_acc: 0.8599\n",
      "Epoch 71/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3260 - acc: 0.8613 - val_loss: 0.3670 - val_acc: 0.8550\n",
      "Epoch 72/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3414 - acc: 0.8537 - val_loss: 0.3597 - val_acc: 0.8648\n",
      "Epoch 73/90\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.3298 - acc: 0.8586 - val_loss: 0.4028 - val_acc: 0.8498\n",
      "Epoch 74/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3348 - acc: 0.8570 - val_loss: 0.3811 - val_acc: 0.8498\n",
      "Epoch 75/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3345 - acc: 0.8568 - val_loss: 0.3846 - val_acc: 0.8517\n",
      "Epoch 76/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3344 - acc: 0.8566 - val_loss: 0.3810 - val_acc: 0.8547\n",
      "Epoch 77/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3226 - acc: 0.8610 - val_loss: 0.3964 - val_acc: 0.8362\n",
      "Epoch 78/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3334 - acc: 0.8590 - val_loss: 0.3613 - val_acc: 0.8507\n",
      "Epoch 79/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3306 - acc: 0.8597 - val_loss: 0.3733 - val_acc: 0.8500\n",
      "Epoch 80/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3235 - acc: 0.8644 - val_loss: 0.3575 - val_acc: 0.8601\n",
      "Epoch 81/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3292 - acc: 0.8594 - val_loss: 0.3610 - val_acc: 0.8525\n",
      "Epoch 82/90\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3307 - acc: 0.8609 - val_loss: 0.3661 - val_acc: 0.8588\n",
      "Epoch 83/90\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3409 - acc: 0.8563 - val_loss: 0.3767 - val_acc: 0.8635\n",
      "Epoch 84/90\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3260 - acc: 0.8608 - val_loss: 0.3598 - val_acc: 0.8564\n",
      "Epoch 85/90\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.3261 - acc: 0.8613 - val_loss: 0.3706 - val_acc: 0.8541\n",
      "Epoch 86/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3250 - acc: 0.8651 - val_loss: 0.3568 - val_acc: 0.8643\n",
      "Epoch 87/90\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3258 - acc: 0.8603 - val_loss: 0.3798 - val_acc: 0.8631\n",
      "Epoch 88/90\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.3276 - acc: 0.8620 - val_loss: 0.3569 - val_acc: 0.8573\n",
      "Epoch 89/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3293 - acc: 0.8613 - val_loss: 0.3458 - val_acc: 0.8609\n",
      "Epoch 90/90\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 0.3236 - acc: 0.8629 - val_loss: 0.3690 - val_acc: 0.8569\n",
      "\n",
      "Training process completed in: 0 h 13 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1212.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1214 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_213 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_213 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_214 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_214 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_215 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_215 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_216 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_216 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 80\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "80/80 [==============================] - 13s 168ms/step - loss: 0.5101 - acc: 0.7562 - val_loss: 0.4742 - val_acc: 0.7865\n",
      "Epoch 2/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.4421 - acc: 0.8128 - val_loss: 0.4373 - val_acc: 0.8092\n",
      "Epoch 3/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.4372 - acc: 0.8104 - val_loss: 0.4315 - val_acc: 0.8224\n",
      "Epoch 4/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.4218 - acc: 0.8186 - val_loss: 0.4105 - val_acc: 0.8195\n",
      "Epoch 5/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.4035 - acc: 0.8263 - val_loss: 0.4088 - val_acc: 0.8251\n",
      "Epoch 6/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.4026 - acc: 0.8264 - val_loss: 0.3979 - val_acc: 0.8242\n",
      "Epoch 7/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.4158 - acc: 0.8190 - val_loss: 0.4271 - val_acc: 0.7962\n",
      "Epoch 8/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3990 - acc: 0.8311 - val_loss: 0.3979 - val_acc: 0.8251\n",
      "Epoch 9/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3923 - acc: 0.8290 - val_loss: 0.3967 - val_acc: 0.8336\n",
      "Epoch 10/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3863 - acc: 0.8332 - val_loss: 0.4080 - val_acc: 0.8279\n",
      "Epoch 11/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3863 - acc: 0.8334 - val_loss: 0.4136 - val_acc: 0.8321\n",
      "Epoch 12/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3858 - acc: 0.8339 - val_loss: 0.3901 - val_acc: 0.8348\n",
      "Epoch 13/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3911 - acc: 0.8283 - val_loss: 0.3817 - val_acc: 0.8317\n",
      "Epoch 14/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3761 - acc: 0.8379 - val_loss: 0.3807 - val_acc: 0.8386\n",
      "Epoch 15/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3785 - acc: 0.8388 - val_loss: 0.3846 - val_acc: 0.8383\n",
      "Epoch 16/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3734 - acc: 0.8381 - val_loss: 0.3790 - val_acc: 0.8397\n",
      "Epoch 17/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3698 - acc: 0.8414 - val_loss: 0.3679 - val_acc: 0.8407\n",
      "Epoch 18/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3681 - acc: 0.8456 - val_loss: 0.3903 - val_acc: 0.8402\n",
      "Epoch 19/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3766 - acc: 0.8397 - val_loss: 0.3845 - val_acc: 0.8423\n",
      "Epoch 20/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3748 - acc: 0.8394 - val_loss: 0.3651 - val_acc: 0.8452\n",
      "Epoch 21/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3719 - acc: 0.8390 - val_loss: 0.3781 - val_acc: 0.8406\n",
      "Epoch 22/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3699 - acc: 0.8393 - val_loss: 0.3646 - val_acc: 0.8451\n",
      "Epoch 23/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3590 - acc: 0.8459 - val_loss: 0.3615 - val_acc: 0.8461\n",
      "Epoch 24/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3707 - acc: 0.8381 - val_loss: 0.3653 - val_acc: 0.8432\n",
      "Epoch 25/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3537 - acc: 0.8495 - val_loss: 0.3722 - val_acc: 0.8489\n",
      "Epoch 26/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3583 - acc: 0.8474 - val_loss: 0.3597 - val_acc: 0.8534\n",
      "Epoch 27/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3655 - acc: 0.8431 - val_loss: 0.3858 - val_acc: 0.8404\n",
      "Epoch 28/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3476 - acc: 0.8522 - val_loss: 0.3730 - val_acc: 0.8400\n",
      "Epoch 29/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3678 - acc: 0.8410 - val_loss: 0.3602 - val_acc: 0.8495\n",
      "Epoch 30/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3510 - acc: 0.8466 - val_loss: 0.3613 - val_acc: 0.8477\n",
      "Epoch 31/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3452 - acc: 0.8511 - val_loss: 0.3573 - val_acc: 0.8520\n",
      "Epoch 32/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3466 - acc: 0.8533 - val_loss: 0.3647 - val_acc: 0.8450\n",
      "Epoch 33/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3547 - acc: 0.8488 - val_loss: 0.3469 - val_acc: 0.8524\n",
      "Epoch 34/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3576 - acc: 0.8489 - val_loss: 0.3558 - val_acc: 0.8468\n",
      "Epoch 35/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3564 - acc: 0.8472 - val_loss: 0.3484 - val_acc: 0.8500\n",
      "Epoch 36/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3448 - acc: 0.8538 - val_loss: 0.3470 - val_acc: 0.8531\n",
      "Epoch 37/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3544 - acc: 0.8494 - val_loss: 0.3570 - val_acc: 0.8454\n",
      "Epoch 38/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3429 - acc: 0.8511 - val_loss: 0.3627 - val_acc: 0.8487\n",
      "Epoch 39/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3532 - acc: 0.8485 - val_loss: 0.3603 - val_acc: 0.8560\n",
      "Epoch 40/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3540 - acc: 0.8483 - val_loss: 0.3532 - val_acc: 0.8521\n",
      "Epoch 41/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3441 - acc: 0.8483 - val_loss: 0.3519 - val_acc: 0.8531\n",
      "Epoch 42/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3434 - acc: 0.8538 - val_loss: 0.3801 - val_acc: 0.8424\n",
      "Epoch 43/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3475 - acc: 0.8543 - val_loss: 0.3421 - val_acc: 0.8569\n",
      "Epoch 44/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3518 - acc: 0.8519 - val_loss: 0.3523 - val_acc: 0.8533\n",
      "Epoch 45/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3412 - acc: 0.8528 - val_loss: 0.3456 - val_acc: 0.8609\n",
      "Epoch 46/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3500 - acc: 0.8536 - val_loss: 0.3377 - val_acc: 0.8528\n",
      "Epoch 47/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3446 - acc: 0.8524 - val_loss: 0.3492 - val_acc: 0.8494\n",
      "Epoch 48/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3500 - acc: 0.8500 - val_loss: 0.3426 - val_acc: 0.8594\n",
      "Epoch 49/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3449 - acc: 0.8530 - val_loss: 0.3659 - val_acc: 0.8474\n",
      "Epoch 50/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3367 - acc: 0.8571 - val_loss: 0.3454 - val_acc: 0.8542\n",
      "Epoch 51/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3394 - acc: 0.8551 - val_loss: 0.3650 - val_acc: 0.8430\n",
      "Epoch 52/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3475 - acc: 0.8504 - val_loss: 0.3407 - val_acc: 0.8569\n",
      "Epoch 53/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3392 - acc: 0.8583 - val_loss: 0.3333 - val_acc: 0.8626\n",
      "Epoch 54/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3417 - acc: 0.8556 - val_loss: 0.3643 - val_acc: 0.8490\n",
      "Epoch 55/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3451 - acc: 0.8537 - val_loss: 0.3425 - val_acc: 0.8518\n",
      "Epoch 56/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3401 - acc: 0.8532 - val_loss: 0.3374 - val_acc: 0.8581\n",
      "Epoch 57/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3312 - acc: 0.8596 - val_loss: 0.3382 - val_acc: 0.8576\n",
      "Epoch 58/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3347 - acc: 0.8567 - val_loss: 0.3441 - val_acc: 0.8601\n",
      "Epoch 59/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3314 - acc: 0.8585 - val_loss: 0.3340 - val_acc: 0.8570\n",
      "Epoch 60/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3385 - acc: 0.8552 - val_loss: 0.3468 - val_acc: 0.8573\n",
      "Epoch 61/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3343 - acc: 0.8590 - val_loss: 0.3453 - val_acc: 0.8544\n",
      "Epoch 62/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3379 - acc: 0.8580 - val_loss: 0.3386 - val_acc: 0.8612\n",
      "Epoch 63/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3261 - acc: 0.8621 - val_loss: 0.3324 - val_acc: 0.8592\n",
      "Epoch 64/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3434 - acc: 0.8525 - val_loss: 0.3442 - val_acc: 0.8550\n",
      "Epoch 65/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3375 - acc: 0.8576 - val_loss: 0.3481 - val_acc: 0.8559\n",
      "Epoch 66/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3327 - acc: 0.8574 - val_loss: 0.3537 - val_acc: 0.8437\n",
      "Epoch 67/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3410 - acc: 0.8509 - val_loss: 0.3470 - val_acc: 0.8501\n",
      "Epoch 68/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3240 - acc: 0.8657 - val_loss: 0.3368 - val_acc: 0.8592\n",
      "Epoch 69/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3289 - acc: 0.8598 - val_loss: 0.3300 - val_acc: 0.8642\n",
      "Epoch 70/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3315 - acc: 0.8571 - val_loss: 0.3317 - val_acc: 0.8574\n",
      "Epoch 71/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3281 - acc: 0.8644 - val_loss: 0.3379 - val_acc: 0.8538\n",
      "Epoch 72/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3389 - acc: 0.8558 - val_loss: 0.3368 - val_acc: 0.8616\n",
      "Epoch 73/90\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3300 - acc: 0.8583 - val_loss: 0.3383 - val_acc: 0.8614\n",
      "Epoch 74/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 10s 125ms/step - loss: 0.3284 - acc: 0.8622 - val_loss: 0.3546 - val_acc: 0.8545\n",
      "Epoch 75/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3233 - acc: 0.8620 - val_loss: 0.3336 - val_acc: 0.8569\n",
      "Epoch 76/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3187 - acc: 0.8644 - val_loss: 0.3300 - val_acc: 0.8554\n",
      "Epoch 77/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3291 - acc: 0.8608 - val_loss: 0.3356 - val_acc: 0.8606\n",
      "Epoch 78/90\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3254 - acc: 0.8628 - val_loss: 0.3286 - val_acc: 0.8583\n",
      "Epoch 79/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3222 - acc: 0.8645 - val_loss: 0.3558 - val_acc: 0.8549\n",
      "Epoch 80/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3342 - acc: 0.8581 - val_loss: 0.3317 - val_acc: 0.8571\n",
      "Epoch 81/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3311 - acc: 0.8640 - val_loss: 0.3297 - val_acc: 0.8608\n",
      "Epoch 82/90\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3331 - acc: 0.8557 - val_loss: 0.3231 - val_acc: 0.8628\n",
      "Epoch 83/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3232 - acc: 0.8646 - val_loss: 0.3324 - val_acc: 0.8631\n",
      "Epoch 84/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3339 - acc: 0.8575 - val_loss: 0.3201 - val_acc: 0.8663\n",
      "Epoch 85/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3129 - acc: 0.8689 - val_loss: 0.3479 - val_acc: 0.8540\n",
      "Epoch 86/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3238 - acc: 0.8643 - val_loss: 0.3312 - val_acc: 0.8646\n",
      "Epoch 87/90\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3285 - acc: 0.8586 - val_loss: 0.3401 - val_acc: 0.8524\n",
      "Epoch 88/90\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3231 - acc: 0.8631 - val_loss: 0.3313 - val_acc: 0.8566\n",
      "Epoch 89/90\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.3230 - acc: 0.8597 - val_loss: 0.3308 - val_acc: 0.8558\n",
      "Epoch 90/90\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3220 - acc: 0.8659 - val_loss: 0.3498 - val_acc: 0.8512\n",
      "\n",
      "Training process completed in: 0 h 15 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1213.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1215 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_217 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_217 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_218 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_219 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_220 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_220 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 80\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "80/80 [==============================] - 13s 168ms/step - loss: 0.5567 - acc: 0.7287 - val_loss: 0.4547 - val_acc: 0.7996\n",
      "Epoch 2/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.4407 - acc: 0.8106 - val_loss: 0.4460 - val_acc: 0.8121\n",
      "Epoch 3/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.4399 - acc: 0.8094 - val_loss: 0.4457 - val_acc: 0.8051\n",
      "Epoch 4/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.4201 - acc: 0.8207 - val_loss: 0.4322 - val_acc: 0.8172\n",
      "Epoch 5/60\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.4156 - acc: 0.8219 - val_loss: 0.4067 - val_acc: 0.8319\n",
      "Epoch 6/60\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3979 - acc: 0.8301 - val_loss: 0.4011 - val_acc: 0.8270\n",
      "Epoch 7/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.4079 - acc: 0.8280 - val_loss: 0.4246 - val_acc: 0.8241\n",
      "Epoch 8/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3918 - acc: 0.8327 - val_loss: 0.3870 - val_acc: 0.8320\n",
      "Epoch 9/60\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.3918 - acc: 0.8310 - val_loss: 0.4033 - val_acc: 0.8404\n",
      "Epoch 10/60\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.3908 - acc: 0.8272 - val_loss: 0.3986 - val_acc: 0.8299\n",
      "Epoch 11/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3868 - acc: 0.8347 - val_loss: 0.3849 - val_acc: 0.8340\n",
      "Epoch 12/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3755 - acc: 0.8410 - val_loss: 0.4182 - val_acc: 0.8320\n",
      "Epoch 13/60\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 0.3740 - acc: 0.8399 - val_loss: 0.3859 - val_acc: 0.8228\n",
      "Epoch 14/60\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 0.3842 - acc: 0.8328 - val_loss: 0.3663 - val_acc: 0.8397\n",
      "Epoch 15/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3790 - acc: 0.8400 - val_loss: 0.3775 - val_acc: 0.8381\n",
      "Epoch 16/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3695 - acc: 0.8427 - val_loss: 0.4053 - val_acc: 0.8410\n",
      "Epoch 17/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3799 - acc: 0.8379 - val_loss: 0.3651 - val_acc: 0.8427\n",
      "Epoch 18/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3666 - acc: 0.8411 - val_loss: 0.4418 - val_acc: 0.8267\n",
      "Epoch 19/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3701 - acc: 0.8411 - val_loss: 0.3848 - val_acc: 0.8439\n",
      "Epoch 20/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3544 - acc: 0.8487 - val_loss: 0.3654 - val_acc: 0.8557\n",
      "Epoch 21/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3645 - acc: 0.8432 - val_loss: 0.3888 - val_acc: 0.8426\n",
      "Epoch 22/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3663 - acc: 0.8443 - val_loss: 0.3615 - val_acc: 0.8494\n",
      "Epoch 23/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3591 - acc: 0.8450 - val_loss: 0.3706 - val_acc: 0.8540\n",
      "Epoch 24/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3520 - acc: 0.8530 - val_loss: 0.3675 - val_acc: 0.8441\n",
      "Epoch 25/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3580 - acc: 0.8509 - val_loss: 0.3941 - val_acc: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3638 - acc: 0.8459 - val_loss: 0.3777 - val_acc: 0.8266\n",
      "Epoch 27/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3523 - acc: 0.8494 - val_loss: 0.3788 - val_acc: 0.8542\n",
      "Epoch 28/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3535 - acc: 0.8492 - val_loss: 0.4031 - val_acc: 0.8430\n",
      "Epoch 29/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3557 - acc: 0.8458 - val_loss: 0.3647 - val_acc: 0.8537\n",
      "Epoch 30/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3463 - acc: 0.8512 - val_loss: 0.3655 - val_acc: 0.8389\n",
      "Epoch 31/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3552 - acc: 0.8513 - val_loss: 0.3472 - val_acc: 0.8560\n",
      "Epoch 32/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3501 - acc: 0.8523 - val_loss: 0.3430 - val_acc: 0.8519\n",
      "Epoch 33/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3490 - acc: 0.8516 - val_loss: 0.3706 - val_acc: 0.8506\n",
      "Epoch 34/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3547 - acc: 0.8503 - val_loss: 0.3499 - val_acc: 0.8517\n",
      "Epoch 35/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3419 - acc: 0.8509 - val_loss: 0.3623 - val_acc: 0.8545\n",
      "Epoch 36/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3420 - acc: 0.8541 - val_loss: 0.3457 - val_acc: 0.8543\n",
      "Epoch 37/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3449 - acc: 0.8507 - val_loss: 0.3685 - val_acc: 0.8557\n",
      "Epoch 38/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3416 - acc: 0.8544 - val_loss: 0.3427 - val_acc: 0.8543\n",
      "Epoch 39/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3422 - acc: 0.8536 - val_loss: 0.3795 - val_acc: 0.8496\n",
      "Epoch 40/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3472 - acc: 0.8549 - val_loss: 0.3536 - val_acc: 0.8525\n",
      "Epoch 41/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3417 - acc: 0.8524 - val_loss: 0.3395 - val_acc: 0.8566\n",
      "Epoch 42/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3398 - acc: 0.8549 - val_loss: 0.3437 - val_acc: 0.8560\n",
      "Epoch 43/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3314 - acc: 0.8588 - val_loss: 0.3417 - val_acc: 0.8555\n",
      "Epoch 44/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3476 - acc: 0.8520 - val_loss: 0.3624 - val_acc: 0.8547\n",
      "Epoch 45/60\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3365 - acc: 0.8558 - val_loss: 0.3410 - val_acc: 0.8503\n",
      "Epoch 46/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3292 - acc: 0.8624 - val_loss: 0.3269 - val_acc: 0.8621\n",
      "Epoch 47/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3364 - acc: 0.8573 - val_loss: 0.3403 - val_acc: 0.8587\n",
      "Epoch 48/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3475 - acc: 0.8522 - val_loss: 0.3707 - val_acc: 0.8565\n",
      "Epoch 49/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3388 - acc: 0.8549 - val_loss: 0.3729 - val_acc: 0.8475\n",
      "Epoch 50/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3328 - acc: 0.8568 - val_loss: 0.3305 - val_acc: 0.8542\n",
      "Epoch 51/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3362 - acc: 0.8572 - val_loss: 0.3466 - val_acc: 0.8635\n",
      "Epoch 52/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3273 - acc: 0.8614 - val_loss: 0.3524 - val_acc: 0.8465\n",
      "Epoch 53/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3391 - acc: 0.8567 - val_loss: 0.3345 - val_acc: 0.8654\n",
      "Epoch 54/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3378 - acc: 0.8549 - val_loss: 0.3654 - val_acc: 0.8451\n",
      "Epoch 55/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3342 - acc: 0.8612 - val_loss: 0.3380 - val_acc: 0.8603\n",
      "Epoch 56/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3317 - acc: 0.8615 - val_loss: 0.3400 - val_acc: 0.8553\n",
      "Epoch 57/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3244 - acc: 0.8622 - val_loss: 0.3358 - val_acc: 0.8604\n",
      "Epoch 58/60\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3344 - acc: 0.8614 - val_loss: 0.3321 - val_acc: 0.8636\n",
      "Epoch 59/60\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3243 - acc: 0.8628 - val_loss: 0.3469 - val_acc: 0.8595\n",
      "Epoch 60/60\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3336 - acc: 0.8574 - val_loss: 0.3359 - val_acc: 0.8610\n",
      "\n",
      "Training process completed in: 0 h 10 m 12 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1214.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1216 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_221 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_221 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_222 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_222 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_223 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_223 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_224 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_224 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.4824 - acc: 0.7792 - val_loss: 0.4359 - val_acc: 0.8155\n",
      "Epoch 2/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.4165 - acc: 0.8215 - val_loss: 0.4154 - val_acc: 0.8252\n",
      "Epoch 3/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.4052 - acc: 0.8261 - val_loss: 0.3901 - val_acc: 0.8338\n",
      "Epoch 4/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3955 - acc: 0.8321 - val_loss: 0.4139 - val_acc: 0.8314\n",
      "Epoch 5/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3893 - acc: 0.8330 - val_loss: 0.3885 - val_acc: 0.8294\n",
      "Epoch 6/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3819 - acc: 0.8369 - val_loss: 0.4019 - val_acc: 0.8351\n",
      "Epoch 7/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3744 - acc: 0.8373 - val_loss: 0.3697 - val_acc: 0.8432\n",
      "Epoch 8/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3706 - acc: 0.8427 - val_loss: 0.3719 - val_acc: 0.8402\n",
      "Epoch 9/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3720 - acc: 0.8403 - val_loss: 0.3650 - val_acc: 0.8402\n",
      "Epoch 10/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3664 - acc: 0.8423 - val_loss: 0.3660 - val_acc: 0.8406\n",
      "Epoch 11/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3644 - acc: 0.8452 - val_loss: 0.3684 - val_acc: 0.8455\n",
      "Epoch 12/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3609 - acc: 0.8460 - val_loss: 0.3893 - val_acc: 0.8444\n",
      "Epoch 13/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3600 - acc: 0.8463 - val_loss: 0.3653 - val_acc: 0.8470\n",
      "Epoch 14/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3552 - acc: 0.8495 - val_loss: 0.3822 - val_acc: 0.8231\n",
      "Epoch 15/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3552 - acc: 0.8485 - val_loss: 0.3473 - val_acc: 0.8496\n",
      "Epoch 16/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3545 - acc: 0.8475 - val_loss: 0.3614 - val_acc: 0.8502\n",
      "Epoch 17/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3529 - acc: 0.8482 - val_loss: 0.3658 - val_acc: 0.8486\n",
      "Epoch 18/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3490 - acc: 0.8512 - val_loss: 0.3592 - val_acc: 0.8544\n",
      "Epoch 19/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3454 - acc: 0.8523 - val_loss: 0.3762 - val_acc: 0.8461\n",
      "Epoch 20/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3386 - acc: 0.8566 - val_loss: 0.3492 - val_acc: 0.8553\n",
      "Epoch 21/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3348 - acc: 0.8572 - val_loss: 0.3442 - val_acc: 0.8600\n",
      "Epoch 22/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3337 - acc: 0.8582 - val_loss: 0.3436 - val_acc: 0.8507\n",
      "Epoch 23/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3393 - acc: 0.8537 - val_loss: 0.3437 - val_acc: 0.8514\n",
      "Epoch 24/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3404 - acc: 0.8555 - val_loss: 0.3412 - val_acc: 0.8606\n",
      "Epoch 25/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3358 - acc: 0.8553 - val_loss: 0.3848 - val_acc: 0.8488\n",
      "Epoch 26/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3305 - acc: 0.8607 - val_loss: 0.3481 - val_acc: 0.8607\n",
      "Epoch 27/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3315 - acc: 0.8595 - val_loss: 0.3386 - val_acc: 0.8580\n",
      "Epoch 28/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3316 - acc: 0.8590 - val_loss: 0.3348 - val_acc: 0.8633\n",
      "Epoch 29/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3311 - acc: 0.8602 - val_loss: 0.3358 - val_acc: 0.8623\n",
      "Epoch 30/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3259 - acc: 0.8613 - val_loss: 0.3304 - val_acc: 0.8643\n",
      "Epoch 31/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3301 - acc: 0.8607 - val_loss: 0.3373 - val_acc: 0.8589\n",
      "Epoch 32/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3223 - acc: 0.8636 - val_loss: 0.3269 - val_acc: 0.8639\n",
      "Epoch 33/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3222 - acc: 0.8657 - val_loss: 0.3411 - val_acc: 0.8511\n",
      "Epoch 34/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3248 - acc: 0.8643 - val_loss: 0.3228 - val_acc: 0.8682\n",
      "Epoch 35/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3236 - acc: 0.8627 - val_loss: 0.3363 - val_acc: 0.8609\n",
      "Epoch 36/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3210 - acc: 0.8644 - val_loss: 0.3306 - val_acc: 0.8657\n",
      "Epoch 37/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3239 - acc: 0.8620 - val_loss: 0.3282 - val_acc: 0.8635\n",
      "Epoch 38/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3215 - acc: 0.8634 - val_loss: 0.3380 - val_acc: 0.8680\n",
      "Epoch 39/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3165 - acc: 0.8648 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 40/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3146 - acc: 0.8656 - val_loss: 0.3315 - val_acc: 0.8631\n",
      "Epoch 41/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3191 - acc: 0.8643 - val_loss: 0.3420 - val_acc: 0.8465\n",
      "Epoch 42/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3190 - acc: 0.8646 - val_loss: 0.3274 - val_acc: 0.8645\n",
      "Epoch 43/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3160 - acc: 0.8667 - val_loss: 0.3272 - val_acc: 0.8646\n",
      "Epoch 44/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3137 - acc: 0.8658 - val_loss: 0.3309 - val_acc: 0.8661\n",
      "Epoch 45/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3190 - acc: 0.8655 - val_loss: 0.3394 - val_acc: 0.8637\n",
      "Epoch 46/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3173 - acc: 0.8660 - val_loss: 0.3466 - val_acc: 0.8569\n",
      "Epoch 47/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3188 - acc: 0.8665 - val_loss: 0.3176 - val_acc: 0.8721\n",
      "Epoch 48/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3105 - acc: 0.8712 - val_loss: 0.3316 - val_acc: 0.8569\n",
      "Epoch 49/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3110 - acc: 0.8685 - val_loss: 0.3227 - val_acc: 0.8644\n",
      "Epoch 50/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3171 - acc: 0.8656 - val_loss: 0.3220 - val_acc: 0.8617\n",
      "Epoch 51/60\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3117 - acc: 0.8658 - val_loss: 0.3410 - val_acc: 0.8594\n",
      "Epoch 52/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3151 - acc: 0.8689 - val_loss: 0.3343 - val_acc: 0.8686\n",
      "Epoch 53/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3115 - acc: 0.8684 - val_loss: 0.3278 - val_acc: 0.8694\n",
      "Epoch 54/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3077 - acc: 0.8723 - val_loss: 0.3200 - val_acc: 0.8609\n",
      "Epoch 55/60\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3079 - acc: 0.8718 - val_loss: 0.3239 - val_acc: 0.8612\n",
      "Epoch 56/60\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3057 - acc: 0.8721 - val_loss: 0.3216 - val_acc: 0.8721\n",
      "Epoch 57/60\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3139 - acc: 0.8673 - val_loss: 0.3149 - val_acc: 0.8714\n",
      "Epoch 58/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3140 - acc: 0.8671 - val_loss: 0.3176 - val_acc: 0.8689\n",
      "Epoch 59/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3065 - acc: 0.8706 - val_loss: 0.3202 - val_acc: 0.8678\n",
      "Epoch 60/60\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3122 - acc: 0.8680 - val_loss: 0.3268 - val_acc: 0.8659\n",
      "\n",
      "Training process completed in: 0 h 16 m 32 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1215.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1217 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_225 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_225 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_226 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_226 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_227 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_227 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_228 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_228 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "180/180 [==============================] - 18s 101ms/step - loss: 0.4890 - acc: 0.7752 - val_loss: 0.4419 - val_acc: 0.8129\n",
      "Epoch 2/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.4184 - acc: 0.8231 - val_loss: 0.4138 - val_acc: 0.8303\n",
      "Epoch 3/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.4048 - acc: 0.8275 - val_loss: 0.3995 - val_acc: 0.8283\n",
      "Epoch 4/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3989 - acc: 0.8294 - val_loss: 0.3914 - val_acc: 0.8373\n",
      "Epoch 5/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3828 - acc: 0.8376 - val_loss: 0.3897 - val_acc: 0.8345\n",
      "Epoch 6/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3850 - acc: 0.8351 - val_loss: 0.3783 - val_acc: 0.8357\n",
      "Epoch 7/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3823 - acc: 0.8371 - val_loss: 0.3705 - val_acc: 0.8396\n",
      "Epoch 8/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3807 - acc: 0.8377 - val_loss: 0.3935 - val_acc: 0.8291\n",
      "Epoch 9/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3806 - acc: 0.8367 - val_loss: 0.3724 - val_acc: 0.8404\n",
      "Epoch 10/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3738 - acc: 0.8385 - val_loss: 0.4179 - val_acc: 0.8458\n",
      "Epoch 11/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3694 - acc: 0.8409 - val_loss: 0.3820 - val_acc: 0.8446\n",
      "Epoch 12/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3651 - acc: 0.8432 - val_loss: 0.3594 - val_acc: 0.8497\n",
      "Epoch 13/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3606 - acc: 0.8470 - val_loss: 0.3788 - val_acc: 0.8427\n",
      "Epoch 14/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3510 - acc: 0.8516 - val_loss: 0.3798 - val_acc: 0.8371\n",
      "Epoch 15/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3520 - acc: 0.8506 - val_loss: 0.4105 - val_acc: 0.8543\n",
      "Epoch 16/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3433 - acc: 0.8547 - val_loss: 0.3995 - val_acc: 0.8440\n",
      "Epoch 17/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3491 - acc: 0.8510 - val_loss: 0.3750 - val_acc: 0.8538\n",
      "Epoch 18/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3512 - acc: 0.8511 - val_loss: 0.3763 - val_acc: 0.8374\n",
      "Epoch 19/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3479 - acc: 0.8517 - val_loss: 0.3569 - val_acc: 0.8566\n",
      "Epoch 20/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3446 - acc: 0.8540 - val_loss: 0.3589 - val_acc: 0.8540\n",
      "Epoch 21/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3410 - acc: 0.8565 - val_loss: 0.3635 - val_acc: 0.8560\n",
      "Epoch 22/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3334 - acc: 0.8565 - val_loss: 0.3594 - val_acc: 0.8620\n",
      "Epoch 23/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3434 - acc: 0.8536 - val_loss: 0.3665 - val_acc: 0.8473\n",
      "Epoch 24/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3360 - acc: 0.8579 - val_loss: 0.3590 - val_acc: 0.8612\n",
      "Epoch 25/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3320 - acc: 0.8591 - val_loss: 0.3418 - val_acc: 0.8633\n",
      "Epoch 26/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3321 - acc: 0.8589 - val_loss: 0.3486 - val_acc: 0.8616\n",
      "Epoch 27/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3362 - acc: 0.8579 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 28/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3262 - acc: 0.8610 - val_loss: 0.3603 - val_acc: 0.8592\n",
      "Epoch 29/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3228 - acc: 0.8635 - val_loss: 0.3452 - val_acc: 0.8651\n",
      "Epoch 30/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.3282 - acc: 0.8598 - val_loss: 0.3582 - val_acc: 0.8665\n",
      "Epoch 31/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3264 - acc: 0.8631 - val_loss: 0.3408 - val_acc: 0.8672\n",
      "Epoch 32/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3297 - acc: 0.8604 - val_loss: 0.3564 - val_acc: 0.8591\n",
      "Epoch 33/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3202 - acc: 0.8625 - val_loss: 0.3374 - val_acc: 0.8715\n",
      "Epoch 34/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3255 - acc: 0.8622 - val_loss: 0.3784 - val_acc: 0.8653\n",
      "Epoch 35/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3243 - acc: 0.8631 - val_loss: 0.3519 - val_acc: 0.8616\n",
      "Epoch 36/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3253 - acc: 0.8603 - val_loss: 0.3717 - val_acc: 0.8561\n",
      "Epoch 37/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.3183 - acc: 0.8662 - val_loss: 0.3343 - val_acc: 0.8674\n",
      "Epoch 38/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3235 - acc: 0.8643 - val_loss: 0.3467 - val_acc: 0.8629\n",
      "Epoch 39/40\n",
      "180/180 [==============================] - 16s 87ms/step - loss: 0.3243 - acc: 0.8645 - val_loss: 0.3411 - val_acc: 0.8700\n",
      "Epoch 40/40\n",
      "180/180 [==============================] - 16s 87ms/step - loss: 0.3157 - acc: 0.8656 - val_loss: 0.4116 - val_acc: 0.8383\n",
      "\n",
      "Training process completed in: 0 h 9 m 56 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1216.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1218 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_229 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_229 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_230 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_230 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_231 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_231 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_232 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_232 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.5458 - acc: 0.7268 - val_loss: 0.4581 - val_acc: 0.8090\n",
      "Epoch 2/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4462 - acc: 0.8083 - val_loss: 0.4319 - val_acc: 0.8133\n",
      "Epoch 3/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4201 - acc: 0.8237 - val_loss: 0.4524 - val_acc: 0.8152\n",
      "Epoch 4/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4184 - acc: 0.8204 - val_loss: 0.4304 - val_acc: 0.8162\n",
      "Epoch 5/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4134 - acc: 0.8252 - val_loss: 0.4388 - val_acc: 0.8062\n",
      "Epoch 6/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4198 - acc: 0.8204 - val_loss: 0.4221 - val_acc: 0.8138\n",
      "Epoch 7/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4210 - acc: 0.8151 - val_loss: 0.4167 - val_acc: 0.8171\n",
      "Epoch 8/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4226 - acc: 0.8230 - val_loss: 0.4129 - val_acc: 0.8224\n",
      "Epoch 9/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4055 - acc: 0.8266 - val_loss: 0.4058 - val_acc: 0.8279\n",
      "Epoch 10/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4052 - acc: 0.8279 - val_loss: 0.3983 - val_acc: 0.8283\n",
      "Epoch 11/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4081 - acc: 0.8263 - val_loss: 0.3982 - val_acc: 0.8333\n",
      "Epoch 12/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3983 - acc: 0.8307 - val_loss: 0.4113 - val_acc: 0.8186\n",
      "Epoch 13/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.4073 - acc: 0.8238 - val_loss: 0.3873 - val_acc: 0.8383\n",
      "Epoch 14/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3973 - acc: 0.8286 - val_loss: 0.4120 - val_acc: 0.8238\n",
      "Epoch 15/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4078 - acc: 0.8236 - val_loss: 0.3894 - val_acc: 0.8331\n",
      "Epoch 16/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3908 - acc: 0.8314 - val_loss: 0.4388 - val_acc: 0.8102\n",
      "Epoch 17/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3921 - acc: 0.8282 - val_loss: 0.4084 - val_acc: 0.8202\n",
      "Epoch 18/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4016 - acc: 0.8218 - val_loss: 0.4064 - val_acc: 0.8369\n",
      "Epoch 19/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3859 - acc: 0.8346 - val_loss: 0.3837 - val_acc: 0.8317\n",
      "Epoch 20/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3840 - acc: 0.8371 - val_loss: 0.3795 - val_acc: 0.8356\n",
      "Epoch 21/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3891 - acc: 0.8311 - val_loss: 0.3810 - val_acc: 0.8345\n",
      "Epoch 22/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3909 - acc: 0.8325 - val_loss: 0.3988 - val_acc: 0.8217\n",
      "Epoch 23/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3840 - acc: 0.8350 - val_loss: 0.3773 - val_acc: 0.8355\n",
      "Epoch 24/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3839 - acc: 0.8360 - val_loss: 0.3886 - val_acc: 0.8298\n",
      "Epoch 25/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3729 - acc: 0.8413 - val_loss: 0.3729 - val_acc: 0.8371\n",
      "Epoch 26/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3727 - acc: 0.8397 - val_loss: 0.3819 - val_acc: 0.8381\n",
      "Epoch 27/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3871 - acc: 0.8347 - val_loss: 0.3870 - val_acc: 0.8384\n",
      "Epoch 28/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3757 - acc: 0.8379 - val_loss: 0.3683 - val_acc: 0.8414\n",
      "Epoch 29/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3842 - acc: 0.8323 - val_loss: 0.3864 - val_acc: 0.8350\n",
      "Epoch 30/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3714 - acc: 0.8389 - val_loss: 0.3988 - val_acc: 0.8307\n",
      "Epoch 31/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3819 - acc: 0.8336 - val_loss: 0.3755 - val_acc: 0.8340\n",
      "Epoch 32/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3812 - acc: 0.8368 - val_loss: 0.3781 - val_acc: 0.8419\n",
      "Epoch 33/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3707 - acc: 0.8404 - val_loss: 0.3656 - val_acc: 0.8467\n",
      "Epoch 34/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3675 - acc: 0.8430 - val_loss: 0.3793 - val_acc: 0.8416\n",
      "Epoch 35/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3738 - acc: 0.8367 - val_loss: 0.3740 - val_acc: 0.8390\n",
      "Epoch 36/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3757 - acc: 0.8371 - val_loss: 0.3613 - val_acc: 0.8419\n",
      "Epoch 37/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3640 - acc: 0.8468 - val_loss: 0.3708 - val_acc: 0.8388\n",
      "Epoch 38/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3639 - acc: 0.8455 - val_loss: 0.3673 - val_acc: 0.8395\n",
      "Epoch 39/40\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3625 - acc: 0.8437 - val_loss: 0.3676 - val_acc: 0.8421\n",
      "Epoch 40/40\n",
      "190/190 [==============================] - 6s 34ms/step - loss: 0.3657 - acc: 0.8435 - val_loss: 0.3615 - val_acc: 0.8454\n",
      "\n",
      "Training process completed in: 0 h 4 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1217.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1219 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_233 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_233 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_234 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_234 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_235 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_235 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_236 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_236 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "180/180 [==============================] - 10s 57ms/step - loss: 0.5542 - acc: 0.7219 - val_loss: 0.4813 - val_acc: 0.8041\n",
      "Epoch 2/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.4472 - acc: 0.8023 - val_loss: 0.4320 - val_acc: 0.8054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.4385 - acc: 0.8111 - val_loss: 0.4250 - val_acc: 0.8122\n",
      "Epoch 4/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4253 - acc: 0.8169 - val_loss: 0.4400 - val_acc: 0.8031\n",
      "Epoch 5/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4261 - acc: 0.8143 - val_loss: 0.4373 - val_acc: 0.8098\n",
      "Epoch 6/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4096 - acc: 0.8225 - val_loss: 0.4151 - val_acc: 0.8194\n",
      "Epoch 7/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4175 - acc: 0.8181 - val_loss: 0.4116 - val_acc: 0.8220\n",
      "Epoch 8/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.4136 - acc: 0.8213 - val_loss: 0.4113 - val_acc: 0.8281\n",
      "Epoch 9/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.4084 - acc: 0.8242 - val_loss: 0.4043 - val_acc: 0.8239\n",
      "Epoch 10/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4087 - acc: 0.8204 - val_loss: 0.4061 - val_acc: 0.8215\n",
      "Epoch 11/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.4056 - acc: 0.8256 - val_loss: 0.3976 - val_acc: 0.8284\n",
      "Epoch 12/40\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3959 - acc: 0.8344 - val_loss: 0.4100 - val_acc: 0.8204\n",
      "Epoch 13/40\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3986 - acc: 0.8270 - val_loss: 0.4083 - val_acc: 0.8178\n",
      "Epoch 14/40\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.3896 - acc: 0.8348 - val_loss: 0.3882 - val_acc: 0.8304\n",
      "Epoch 15/40\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.4065 - acc: 0.8238 - val_loss: 0.4054 - val_acc: 0.8244\n",
      "Epoch 16/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3868 - acc: 0.8344 - val_loss: 0.3816 - val_acc: 0.8366\n",
      "Epoch 17/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3978 - acc: 0.8274 - val_loss: 0.3983 - val_acc: 0.8187\n",
      "Epoch 18/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3960 - acc: 0.8279 - val_loss: 0.4030 - val_acc: 0.8219\n",
      "Epoch 19/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3894 - acc: 0.8314 - val_loss: 0.4035 - val_acc: 0.8191\n",
      "Epoch 20/40\n",
      "180/180 [==============================] - 7s 38ms/step - loss: 0.3934 - acc: 0.8256 - val_loss: 0.3859 - val_acc: 0.8356\n",
      "Epoch 21/40\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.3906 - acc: 0.8319 - val_loss: 0.3930 - val_acc: 0.8302\n",
      "Epoch 22/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3932 - acc: 0.8280 - val_loss: 0.3855 - val_acc: 0.8372\n",
      "Epoch 23/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3908 - acc: 0.8281 - val_loss: 0.3885 - val_acc: 0.8298\n",
      "Epoch 24/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3946 - acc: 0.8285 - val_loss: 0.4187 - val_acc: 0.8276\n",
      "Epoch 25/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3907 - acc: 0.8321 - val_loss: 0.3982 - val_acc: 0.8317\n",
      "Epoch 26/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3873 - acc: 0.8320 - val_loss: 0.3805 - val_acc: 0.8341\n",
      "Epoch 27/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3816 - acc: 0.8328 - val_loss: 0.4003 - val_acc: 0.8256\n",
      "Epoch 28/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3847 - acc: 0.8327 - val_loss: 0.3779 - val_acc: 0.8335\n",
      "Epoch 29/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3754 - acc: 0.8364 - val_loss: 0.3854 - val_acc: 0.8402\n",
      "Epoch 30/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3767 - acc: 0.8378 - val_loss: 0.4182 - val_acc: 0.8317\n",
      "Epoch 31/40\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.3713 - acc: 0.8395 - val_loss: 0.3755 - val_acc: 0.8353\n",
      "Epoch 32/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3784 - acc: 0.8357 - val_loss: 0.4131 - val_acc: 0.8302\n",
      "Epoch 33/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3727 - acc: 0.8385 - val_loss: 0.3789 - val_acc: 0.8361\n",
      "Epoch 34/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3682 - acc: 0.8481 - val_loss: 0.3768 - val_acc: 0.8328\n",
      "Epoch 35/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3740 - acc: 0.8369 - val_loss: 0.3687 - val_acc: 0.8433\n",
      "Epoch 36/40\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.3757 - acc: 0.8350 - val_loss: 0.3780 - val_acc: 0.8324\n",
      "Epoch 37/40\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.3724 - acc: 0.8413 - val_loss: 0.3700 - val_acc: 0.8412\n",
      "Epoch 38/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3663 - acc: 0.8402 - val_loss: 0.3719 - val_acc: 0.8391\n",
      "Epoch 39/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3755 - acc: 0.8403 - val_loss: 0.3725 - val_acc: 0.8380\n",
      "Epoch 40/40\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.3797 - acc: 0.8365 - val_loss: 0.3728 - val_acc: 0.8352\n",
      "\n",
      "Training process completed in: 0 h 4 m 24 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1218.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1220 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_237 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_237 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_238 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_238 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_239 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_239 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_240 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_240 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "180/180 [==============================] - 18s 102ms/step - loss: 0.5335 - acc: 0.7411 - val_loss: 0.4367 - val_acc: 0.8184\n",
      "Epoch 2/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.4200 - acc: 0.8206 - val_loss: 0.4201 - val_acc: 0.8213\n",
      "Epoch 3/40\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.4134 - acc: 0.8273 - val_loss: 0.4224 - val_acc: 0.8157\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 15s 81ms/step - loss: 0.4084 - acc: 0.8257 - val_loss: 0.4001 - val_acc: 0.8283\n",
      "Epoch 5/40\n",
      "180/180 [==============================] - 15s 81ms/step - loss: 0.4074 - acc: 0.8231 - val_loss: 0.4148 - val_acc: 0.8180\n",
      "Epoch 6/40\n",
      "180/180 [==============================] - 16s 86ms/step - loss: 0.4036 - acc: 0.8261 - val_loss: 0.3973 - val_acc: 0.8279\n",
      "Epoch 7/40\n",
      "180/180 [==============================] - 16s 87ms/step - loss: 0.3976 - acc: 0.8272 - val_loss: 0.4104 - val_acc: 0.8225\n",
      "Epoch 8/40\n",
      "180/180 [==============================] - 16s 88ms/step - loss: 0.4007 - acc: 0.8274 - val_loss: 0.3960 - val_acc: 0.8280\n",
      "Epoch 9/40\n",
      "180/180 [==============================] - 16s 88ms/step - loss: 0.3944 - acc: 0.8302 - val_loss: 0.4017 - val_acc: 0.8237\n",
      "Epoch 10/40\n",
      "180/180 [==============================] - 16s 88ms/step - loss: 0.3917 - acc: 0.8292 - val_loss: 0.3880 - val_acc: 0.8322\n",
      "Epoch 11/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3834 - acc: 0.8348 - val_loss: 0.3909 - val_acc: 0.8279\n",
      "Epoch 12/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3898 - acc: 0.8296 - val_loss: 0.3793 - val_acc: 0.8369\n",
      "Epoch 13/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3832 - acc: 0.8338 - val_loss: 0.3888 - val_acc: 0.8328\n",
      "Epoch 14/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3776 - acc: 0.8390 - val_loss: 0.3808 - val_acc: 0.8340\n",
      "Epoch 15/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3855 - acc: 0.8342 - val_loss: 0.3791 - val_acc: 0.8307\n",
      "Epoch 16/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3780 - acc: 0.8380 - val_loss: 0.3836 - val_acc: 0.8296\n",
      "Epoch 17/40\n",
      "180/180 [==============================] - 16s 86ms/step - loss: 0.3753 - acc: 0.8389 - val_loss: 0.3805 - val_acc: 0.8333\n",
      "Epoch 18/40\n",
      "180/180 [==============================] - 16s 88ms/step - loss: 0.3729 - acc: 0.8398 - val_loss: 0.3694 - val_acc: 0.8388\n",
      "Epoch 19/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3723 - acc: 0.8391 - val_loss: 0.3720 - val_acc: 0.8362\n",
      "Epoch 20/40\n",
      "180/180 [==============================] - 16s 87ms/step - loss: 0.3724 - acc: 0.8388 - val_loss: 0.3655 - val_acc: 0.8448\n",
      "Epoch 21/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3654 - acc: 0.8415 - val_loss: 0.3655 - val_acc: 0.8392\n",
      "Epoch 22/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3635 - acc: 0.8453 - val_loss: 0.3606 - val_acc: 0.8461\n",
      "Epoch 23/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3619 - acc: 0.8449 - val_loss: 0.3643 - val_acc: 0.8405\n",
      "Epoch 24/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3587 - acc: 0.8474 - val_loss: 0.3571 - val_acc: 0.8509\n",
      "Epoch 25/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3646 - acc: 0.8432 - val_loss: 0.3539 - val_acc: 0.8460\n",
      "Epoch 26/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3616 - acc: 0.8437 - val_loss: 0.3794 - val_acc: 0.8403\n",
      "Epoch 27/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3583 - acc: 0.8466 - val_loss: 0.3644 - val_acc: 0.8482\n",
      "Epoch 28/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3504 - acc: 0.8517 - val_loss: 0.3564 - val_acc: 0.8472\n",
      "Epoch 29/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3438 - acc: 0.8542 - val_loss: 0.3444 - val_acc: 0.8537\n",
      "Epoch 30/40\n",
      "180/180 [==============================] - 15s 84ms/step - loss: 0.3544 - acc: 0.8489 - val_loss: 0.3515 - val_acc: 0.8545\n",
      "Epoch 31/40\n",
      "180/180 [==============================] - 16s 86ms/step - loss: 0.3476 - acc: 0.8512 - val_loss: 0.3525 - val_acc: 0.8520\n",
      "Epoch 32/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3415 - acc: 0.8537 - val_loss: 0.3505 - val_acc: 0.8481\n",
      "Epoch 33/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3452 - acc: 0.8514 - val_loss: 0.3399 - val_acc: 0.8539\n",
      "Epoch 34/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3501 - acc: 0.8509 - val_loss: 0.3475 - val_acc: 0.8540\n",
      "Epoch 35/40\n",
      "180/180 [==============================] - 15s 86ms/step - loss: 0.3414 - acc: 0.8540 - val_loss: 0.3426 - val_acc: 0.8558\n",
      "Epoch 36/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3465 - acc: 0.8535 - val_loss: 0.3491 - val_acc: 0.8489\n",
      "Epoch 37/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3384 - acc: 0.8593 - val_loss: 0.3318 - val_acc: 0.8591\n",
      "Epoch 38/40\n",
      "180/180 [==============================] - 16s 88ms/step - loss: 0.3401 - acc: 0.8565 - val_loss: 0.3320 - val_acc: 0.8599\n",
      "Epoch 39/40\n",
      "180/180 [==============================] - 15s 85ms/step - loss: 0.3401 - acc: 0.8541 - val_loss: 0.3393 - val_acc: 0.8563\n",
      "Epoch 40/40\n",
      "180/180 [==============================] - 15s 82ms/step - loss: 0.3382 - acc: 0.8577 - val_loss: 0.3394 - val_acc: 0.8560\n",
      "\n",
      "Training process completed in: 0 h 10 m 17 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1219.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1221 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_241 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_241 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_242 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_242 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_243 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_243 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_244 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_244 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "190/190 [==============================] - 21s 111ms/step - loss: 0.4797 - acc: 0.7855 - val_loss: 0.4156 - val_acc: 0.8193\n",
      "Epoch 2/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.4161 - acc: 0.8202 - val_loss: 0.4252 - val_acc: 0.8267\n",
      "Epoch 3/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.4030 - acc: 0.8255 - val_loss: 0.3885 - val_acc: 0.8301\n",
      "Epoch 4/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3921 - acc: 0.8309 - val_loss: 0.3868 - val_acc: 0.8380\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3869 - acc: 0.8346 - val_loss: 0.3897 - val_acc: 0.8252\n",
      "Epoch 6/40\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3918 - acc: 0.8305 - val_loss: 0.3882 - val_acc: 0.8425\n",
      "Epoch 7/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3760 - acc: 0.8402 - val_loss: 0.4094 - val_acc: 0.8436\n",
      "Epoch 8/40\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3718 - acc: 0.8412 - val_loss: 0.3719 - val_acc: 0.8359\n",
      "Epoch 9/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3716 - acc: 0.8409 - val_loss: 0.3737 - val_acc: 0.8412\n",
      "Epoch 10/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3601 - acc: 0.8494 - val_loss: 0.3896 - val_acc: 0.8469\n",
      "Epoch 11/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3699 - acc: 0.8444 - val_loss: 0.3777 - val_acc: 0.8396\n",
      "Epoch 12/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3594 - acc: 0.8449 - val_loss: 0.3634 - val_acc: 0.8474\n",
      "Epoch 13/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3588 - acc: 0.8470 - val_loss: 0.3584 - val_acc: 0.8505\n",
      "Epoch 14/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3567 - acc: 0.8470 - val_loss: 0.3638 - val_acc: 0.8522\n",
      "Epoch 15/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3544 - acc: 0.8473 - val_loss: 0.3744 - val_acc: 0.8467\n",
      "Epoch 16/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3529 - acc: 0.8481 - val_loss: 0.3493 - val_acc: 0.8573\n",
      "Epoch 17/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3491 - acc: 0.8536 - val_loss: 0.3675 - val_acc: 0.8407\n",
      "Epoch 18/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3510 - acc: 0.8483 - val_loss: 0.3543 - val_acc: 0.8512\n",
      "Epoch 19/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3433 - acc: 0.8568 - val_loss: 0.3445 - val_acc: 0.8598\n",
      "Epoch 20/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3477 - acc: 0.8535 - val_loss: 0.3606 - val_acc: 0.8445\n",
      "Epoch 21/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3447 - acc: 0.8540 - val_loss: 0.3545 - val_acc: 0.8590\n",
      "Epoch 22/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3410 - acc: 0.8549 - val_loss: 0.3420 - val_acc: 0.8535\n",
      "Epoch 23/40\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3422 - acc: 0.8526 - val_loss: 0.3451 - val_acc: 0.8528\n",
      "Epoch 24/40\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3356 - acc: 0.8594 - val_loss: 0.3445 - val_acc: 0.8607\n",
      "Epoch 25/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3320 - acc: 0.8595 - val_loss: 0.3463 - val_acc: 0.8521\n",
      "Epoch 26/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3381 - acc: 0.8553 - val_loss: 0.3471 - val_acc: 0.8594\n",
      "Epoch 27/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3390 - acc: 0.8551 - val_loss: 0.3507 - val_acc: 0.8601\n",
      "Epoch 28/40\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3324 - acc: 0.8583 - val_loss: 0.3405 - val_acc: 0.8563\n",
      "Epoch 29/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3320 - acc: 0.8596 - val_loss: 0.3343 - val_acc: 0.8621\n",
      "Epoch 30/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3290 - acc: 0.8614 - val_loss: 0.3390 - val_acc: 0.8612\n",
      "Epoch 31/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3296 - acc: 0.8595 - val_loss: 0.3482 - val_acc: 0.8583\n",
      "Epoch 32/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3252 - acc: 0.8620 - val_loss: 0.3429 - val_acc: 0.8622\n",
      "Epoch 33/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3256 - acc: 0.8619 - val_loss: 0.3231 - val_acc: 0.8632\n",
      "Epoch 34/40\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3275 - acc: 0.8577 - val_loss: 0.3443 - val_acc: 0.8626\n",
      "Epoch 35/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3338 - acc: 0.8594 - val_loss: 0.3340 - val_acc: 0.8634\n",
      "Epoch 36/40\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3312 - acc: 0.8580 - val_loss: 0.3293 - val_acc: 0.8658\n",
      "Epoch 37/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3283 - acc: 0.8606 - val_loss: 0.3501 - val_acc: 0.8634\n",
      "Epoch 38/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3212 - acc: 0.8649 - val_loss: 0.3266 - val_acc: 0.8604\n",
      "Epoch 39/40\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3275 - acc: 0.8605 - val_loss: 0.3501 - val_acc: 0.8546\n",
      "Epoch 40/40\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3222 - acc: 0.8629 - val_loss: 0.3248 - val_acc: 0.8641\n",
      "\n",
      "Training process completed in: 0 h 11 m 37 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1220.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1222 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_245 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_245 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_246 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_246 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_247 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_247 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_248 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_248 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 13s 65ms/step - loss: 0.5641 - acc: 0.7197 - val_loss: 0.5009 - val_acc: 0.7847\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4416 - acc: 0.8094 - val_loss: 0.4404 - val_acc: 0.8026\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4181 - acc: 0.8244 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4114 - acc: 0.8239 - val_loss: 0.4107 - val_acc: 0.8224\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4226 - acc: 0.8173 - val_loss: 0.4078 - val_acc: 0.8261\n",
      "Epoch 6/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4171 - acc: 0.8202 - val_loss: 0.4077 - val_acc: 0.8260\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4134 - acc: 0.8253 - val_loss: 0.4180 - val_acc: 0.8164\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.4130 - acc: 0.8237 - val_loss: 0.4197 - val_acc: 0.8209\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4177 - acc: 0.8181 - val_loss: 0.4025 - val_acc: 0.8264\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4093 - acc: 0.8234 - val_loss: 0.4065 - val_acc: 0.8229\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4031 - acc: 0.8281 - val_loss: 0.4056 - val_acc: 0.8212\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4073 - acc: 0.8250 - val_loss: 0.4106 - val_acc: 0.8219\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3994 - acc: 0.8301 - val_loss: 0.4077 - val_acc: 0.8232\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4034 - acc: 0.8261 - val_loss: 0.3985 - val_acc: 0.8260\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3962 - acc: 0.8328 - val_loss: 0.4031 - val_acc: 0.8269\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3881 - acc: 0.8363 - val_loss: 0.3879 - val_acc: 0.8362\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3976 - acc: 0.8284 - val_loss: 0.3871 - val_acc: 0.8315\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3960 - acc: 0.8298 - val_loss: 0.4030 - val_acc: 0.8218\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4009 - acc: 0.8262 - val_loss: 0.3941 - val_acc: 0.8329\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3915 - acc: 0.8297 - val_loss: 0.3972 - val_acc: 0.8213\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3894 - acc: 0.8345 - val_loss: 0.3895 - val_acc: 0.8332\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3897 - acc: 0.8324 - val_loss: 0.3990 - val_acc: 0.8324\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3770 - acc: 0.8356 - val_loss: 0.3763 - val_acc: 0.8386\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3694 - acc: 0.8436 - val_loss: 0.3628 - val_acc: 0.8469\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3837 - acc: 0.8345 - val_loss: 0.3778 - val_acc: 0.8362\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3824 - acc: 0.8336 - val_loss: 0.4167 - val_acc: 0.8221\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3753 - acc: 0.8382 - val_loss: 0.3890 - val_acc: 0.8326\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3751 - acc: 0.8386 - val_loss: 0.3715 - val_acc: 0.8365\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3787 - acc: 0.8374 - val_loss: 0.4097 - val_acc: 0.8279\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3745 - acc: 0.8366 - val_loss: 0.3843 - val_acc: 0.8390\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3746 - acc: 0.8377 - val_loss: 0.3750 - val_acc: 0.8411\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3688 - acc: 0.8428 - val_loss: 0.3668 - val_acc: 0.8433\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3694 - acc: 0.8403 - val_loss: 0.3873 - val_acc: 0.8372\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3722 - acc: 0.8418 - val_loss: 0.3722 - val_acc: 0.8449\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3668 - acc: 0.8399 - val_loss: 0.3787 - val_acc: 0.8426\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3727 - acc: 0.8403 - val_loss: 0.3833 - val_acc: 0.8367\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3596 - acc: 0.8477 - val_loss: 0.3645 - val_acc: 0.8422\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3692 - acc: 0.8423 - val_loss: 0.3708 - val_acc: 0.8365\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3633 - acc: 0.8438 - val_loss: 0.3573 - val_acc: 0.8422\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3604 - acc: 0.8472 - val_loss: 0.3569 - val_acc: 0.8467\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3593 - acc: 0.8459 - val_loss: 0.3583 - val_acc: 0.8468\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3656 - acc: 0.8454 - val_loss: 0.3628 - val_acc: 0.8440\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3619 - acc: 0.8451 - val_loss: 0.3746 - val_acc: 0.8398\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3594 - acc: 0.8474 - val_loss: 0.3489 - val_acc: 0.8533\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3660 - acc: 0.8444 - val_loss: 0.3580 - val_acc: 0.8497\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3544 - acc: 0.8488 - val_loss: 0.3601 - val_acc: 0.8469\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3539 - acc: 0.8525 - val_loss: 0.3632 - val_acc: 0.8412\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3570 - acc: 0.8464 - val_loss: 0.3652 - val_acc: 0.8418\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3568 - acc: 0.8455 - val_loss: 0.3442 - val_acc: 0.8493\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3486 - acc: 0.8514 - val_loss: 0.3518 - val_acc: 0.8482\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3491 - acc: 0.8516 - val_loss: 0.3657 - val_acc: 0.8447\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3537 - acc: 0.8501 - val_loss: 0.3540 - val_acc: 0.8496\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3527 - acc: 0.8479 - val_loss: 0.3612 - val_acc: 0.8486\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3521 - acc: 0.8493 - val_loss: 0.3496 - val_acc: 0.8465\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3491 - acc: 0.8498 - val_loss: 0.3381 - val_acc: 0.8569\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3476 - acc: 0.8533 - val_loss: 0.3568 - val_acc: 0.8449\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3499 - acc: 0.8518 - val_loss: 0.3453 - val_acc: 0.8492\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3369 - acc: 0.8583 - val_loss: 0.3452 - val_acc: 0.8608\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3571 - acc: 0.8492 - val_loss: 0.3475 - val_acc: 0.8517\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3457 - acc: 0.8550 - val_loss: 0.3455 - val_acc: 0.8568\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3476 - acc: 0.8512 - val_loss: 0.3465 - val_acc: 0.8507\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3378 - acc: 0.8544 - val_loss: 0.3399 - val_acc: 0.8516\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3509 - acc: 0.8469 - val_loss: 0.3345 - val_acc: 0.8557\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3366 - acc: 0.8565 - val_loss: 0.3417 - val_acc: 0.8574\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3381 - acc: 0.8567 - val_loss: 0.3647 - val_acc: 0.8499\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3459 - acc: 0.8533 - val_loss: 0.3562 - val_acc: 0.8486\n",
      "Epoch 67/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3440 - acc: 0.8569 - val_loss: 0.3489 - val_acc: 0.8501\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3455 - acc: 0.8538 - val_loss: 0.3374 - val_acc: 0.8607\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3427 - acc: 0.8554 - val_loss: 0.3342 - val_acc: 0.8563\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3363 - acc: 0.8583 - val_loss: 0.3361 - val_acc: 0.8526\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3389 - acc: 0.8585 - val_loss: 0.3376 - val_acc: 0.8587\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3478 - acc: 0.8520 - val_loss: 0.3453 - val_acc: 0.8579\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3449 - acc: 0.8566 - val_loss: 0.3333 - val_acc: 0.8632\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3320 - acc: 0.8586 - val_loss: 0.3362 - val_acc: 0.8622\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3358 - acc: 0.8562 - val_loss: 0.3442 - val_acc: 0.8525\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3381 - acc: 0.8547 - val_loss: 0.3415 - val_acc: 0.8561\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3384 - acc: 0.8574 - val_loss: 0.3425 - val_acc: 0.8551\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3349 - acc: 0.8602 - val_loss: 0.3249 - val_acc: 0.8608\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3333 - acc: 0.8601 - val_loss: 0.3417 - val_acc: 0.8586\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3399 - acc: 0.8531 - val_loss: 0.3393 - val_acc: 0.8535\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3264 - acc: 0.8592 - val_loss: 0.3379 - val_acc: 0.8565\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3395 - acc: 0.8558 - val_loss: 0.3424 - val_acc: 0.8572\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3297 - acc: 0.8579 - val_loss: 0.3266 - val_acc: 0.8636\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3357 - acc: 0.8561 - val_loss: 0.3531 - val_acc: 0.8510\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3244 - acc: 0.8642 - val_loss: 0.3303 - val_acc: 0.8598\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3267 - acc: 0.8611 - val_loss: 0.3693 - val_acc: 0.8422\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3292 - acc: 0.8624 - val_loss: 0.3400 - val_acc: 0.8590\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3318 - acc: 0.8576 - val_loss: 0.3296 - val_acc: 0.8597\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3316 - acc: 0.8601 - val_loss: 0.3162 - val_acc: 0.8628\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3303 - acc: 0.8574 - val_loss: 0.3311 - val_acc: 0.8624\n",
      "\n",
      "Training process completed in: 0 h 13 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1221.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1223 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_249 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_249 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_250 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_250 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_251 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_252 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_252 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.5583 - acc: 0.7252 - val_loss: 0.4381 - val_acc: 0.8089\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.4191 - acc: 0.8215 - val_loss: 0.4028 - val_acc: 0.8294\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.4151 - acc: 0.8234 - val_loss: 0.4188 - val_acc: 0.8173\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.4153 - acc: 0.8214 - val_loss: 0.4124 - val_acc: 0.8214\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.4065 - acc: 0.8276 - val_loss: 0.4112 - val_acc: 0.8306\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3996 - acc: 0.8301 - val_loss: 0.4011 - val_acc: 0.8277\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3973 - acc: 0.8291 - val_loss: 0.4057 - val_acc: 0.8233\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.4006 - acc: 0.8288 - val_loss: 0.3998 - val_acc: 0.8268\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3922 - acc: 0.8324 - val_loss: 0.4028 - val_acc: 0.8290\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3924 - acc: 0.8307 - val_loss: 0.3949 - val_acc: 0.8297\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3879 - acc: 0.8324 - val_loss: 0.3859 - val_acc: 0.8370\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3902 - acc: 0.8310 - val_loss: 0.3915 - val_acc: 0.8301\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3868 - acc: 0.8337 - val_loss: 0.4000 - val_acc: 0.8246\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3844 - acc: 0.8327 - val_loss: 0.3796 - val_acc: 0.8333\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3852 - acc: 0.8351 - val_loss: 0.3736 - val_acc: 0.8409\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3799 - acc: 0.8358 - val_loss: 0.3767 - val_acc: 0.8379\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3805 - acc: 0.8373 - val_loss: 0.3919 - val_acc: 0.8299\n",
      "Epoch 18/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3727 - acc: 0.8403 - val_loss: 0.3722 - val_acc: 0.8420\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3682 - acc: 0.8430 - val_loss: 0.3822 - val_acc: 0.8313\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3712 - acc: 0.8389 - val_loss: 0.3916 - val_acc: 0.8360\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3691 - acc: 0.8397 - val_loss: 0.3625 - val_acc: 0.8407\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3671 - acc: 0.8431 - val_loss: 0.3781 - val_acc: 0.8383\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3645 - acc: 0.8439 - val_loss: 0.3714 - val_acc: 0.8426\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3640 - acc: 0.8439 - val_loss: 0.4079 - val_acc: 0.8182\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3621 - acc: 0.8464 - val_loss: 0.3627 - val_acc: 0.8436\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3572 - acc: 0.8442 - val_loss: 0.3532 - val_acc: 0.8509\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3596 - acc: 0.8451 - val_loss: 0.3528 - val_acc: 0.8504\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3521 - acc: 0.8504 - val_loss: 0.3557 - val_acc: 0.8439\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3612 - acc: 0.8446 - val_loss: 0.3500 - val_acc: 0.8507\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3601 - acc: 0.8458 - val_loss: 0.3587 - val_acc: 0.8461\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3481 - acc: 0.8532 - val_loss: 0.3495 - val_acc: 0.8490\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3421 - acc: 0.8558 - val_loss: 0.3412 - val_acc: 0.8604\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3494 - acc: 0.8509 - val_loss: 0.3483 - val_acc: 0.8547\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3504 - acc: 0.8501 - val_loss: 0.3439 - val_acc: 0.8553\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3467 - acc: 0.8516 - val_loss: 0.3461 - val_acc: 0.8523\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3485 - acc: 0.8534 - val_loss: 0.3398 - val_acc: 0.8593\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3428 - acc: 0.8555 - val_loss: 0.3494 - val_acc: 0.8544\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3416 - acc: 0.8548 - val_loss: 0.3375 - val_acc: 0.8623\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3375 - acc: 0.8585 - val_loss: 0.3438 - val_acc: 0.8524\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3412 - acc: 0.8528 - val_loss: 0.3354 - val_acc: 0.8575\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3438 - acc: 0.8543 - val_loss: 0.3418 - val_acc: 0.8526\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3346 - acc: 0.8583 - val_loss: 0.3559 - val_acc: 0.8470\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.3396 - acc: 0.8563 - val_loss: 0.3310 - val_acc: 0.8660\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3371 - acc: 0.8563 - val_loss: 0.3572 - val_acc: 0.8430\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3370 - acc: 0.8588 - val_loss: 0.3338 - val_acc: 0.8553\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3324 - acc: 0.8600 - val_loss: 0.3331 - val_acc: 0.8571\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3309 - acc: 0.8601 - val_loss: 0.3317 - val_acc: 0.8613\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3288 - acc: 0.8617 - val_loss: 0.3438 - val_acc: 0.8539\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3320 - acc: 0.8583 - val_loss: 0.3391 - val_acc: 0.8549\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3306 - acc: 0.8610 - val_loss: 0.3393 - val_acc: 0.8554\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3326 - acc: 0.8594 - val_loss: 0.3162 - val_acc: 0.8683\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3284 - acc: 0.8601 - val_loss: 0.3386 - val_acc: 0.8574\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3322 - acc: 0.8574 - val_loss: 0.3193 - val_acc: 0.8687\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3299 - acc: 0.8608 - val_loss: 0.3211 - val_acc: 0.8651\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3339 - acc: 0.8577 - val_loss: 0.3345 - val_acc: 0.8584\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3175 - acc: 0.8677 - val_loss: 0.3462 - val_acc: 0.8510\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3218 - acc: 0.8623 - val_loss: 0.3305 - val_acc: 0.8597\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3186 - acc: 0.8660 - val_loss: 0.3576 - val_acc: 0.8440\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3292 - acc: 0.8606 - val_loss: 0.3307 - val_acc: 0.8610\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3253 - acc: 0.8629 - val_loss: 0.3180 - val_acc: 0.8654\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3241 - acc: 0.8638 - val_loss: 0.3261 - val_acc: 0.8663\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3269 - acc: 0.8606 - val_loss: 0.3257 - val_acc: 0.8577\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3219 - acc: 0.8654 - val_loss: 0.3130 - val_acc: 0.8694\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3253 - acc: 0.8608 - val_loss: 0.3320 - val_acc: 0.8643\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3196 - acc: 0.8647 - val_loss: 0.3162 - val_acc: 0.8727\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3205 - acc: 0.8659 - val_loss: 0.3212 - val_acc: 0.8613\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3120 - acc: 0.8692 - val_loss: 0.3224 - val_acc: 0.8607\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3210 - acc: 0.8635 - val_loss: 0.3156 - val_acc: 0.8687\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3143 - acc: 0.8671 - val_loss: 0.3089 - val_acc: 0.8701\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3258 - acc: 0.8619 - val_loss: 0.3194 - val_acc: 0.8663\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3242 - acc: 0.8629 - val_loss: 0.3246 - val_acc: 0.8629\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3243 - acc: 0.8635 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3167 - acc: 0.8677 - val_loss: 0.3230 - val_acc: 0.8600\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3128 - acc: 0.8691 - val_loss: 0.3091 - val_acc: 0.8691\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3101 - acc: 0.8699 - val_loss: 0.3233 - val_acc: 0.8609\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3180 - acc: 0.8648 - val_loss: 0.3081 - val_acc: 0.8742\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3088 - acc: 0.8699 - val_loss: 0.3144 - val_acc: 0.8674\n",
      "Epoch 78/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3158 - acc: 0.8680 - val_loss: 0.3196 - val_acc: 0.8664\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3118 - acc: 0.8665 - val_loss: 0.3089 - val_acc: 0.8681\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3110 - acc: 0.8703 - val_loss: 0.3104 - val_acc: 0.8684\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3131 - acc: 0.8685 - val_loss: 0.3122 - val_acc: 0.8664\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3051 - acc: 0.8738 - val_loss: 0.3201 - val_acc: 0.8669\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3035 - acc: 0.8716 - val_loss: 0.3320 - val_acc: 0.8559\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3123 - acc: 0.8688 - val_loss: 0.3149 - val_acc: 0.8704\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3094 - acc: 0.8675 - val_loss: 0.3465 - val_acc: 0.8481\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3110 - acc: 0.8693 - val_loss: 0.3164 - val_acc: 0.8617\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.3137 - acc: 0.8684 - val_loss: 0.3312 - val_acc: 0.8570\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.3130 - acc: 0.8665 - val_loss: 0.3105 - val_acc: 0.8675\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3035 - acc: 0.8713 - val_loss: 0.3027 - val_acc: 0.8696\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.3165 - acc: 0.8672 - val_loss: 0.3215 - val_acc: 0.8639\n",
      "\n",
      "Training process completed in: 0 h 20 m 19 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1222.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1224 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_253 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_253 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_254 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_254 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_255 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_256 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 110\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "110/110 [==============================] - 9s 83ms/step - loss: 0.6009 - acc: 0.7016 - val_loss: 0.5633 - val_acc: 0.7225\n",
      "Epoch 2/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.5363 - acc: 0.7215 - val_loss: 0.4792 - val_acc: 0.7888\n",
      "Epoch 3/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4428 - acc: 0.8068 - val_loss: 0.4292 - val_acc: 0.8192\n",
      "Epoch 4/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4184 - acc: 0.8224 - val_loss: 0.4035 - val_acc: 0.8320\n",
      "Epoch 5/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4310 - acc: 0.8139 - val_loss: 0.4509 - val_acc: 0.7980\n",
      "Epoch 6/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4250 - acc: 0.8175 - val_loss: 0.4635 - val_acc: 0.7945\n",
      "Epoch 7/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4251 - acc: 0.8158 - val_loss: 0.4189 - val_acc: 0.8211\n",
      "Epoch 8/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4193 - acc: 0.8226 - val_loss: 0.4248 - val_acc: 0.8153\n",
      "Epoch 9/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4174 - acc: 0.8216 - val_loss: 0.4322 - val_acc: 0.8105\n",
      "Epoch 10/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4074 - acc: 0.8273 - val_loss: 0.3976 - val_acc: 0.8260\n",
      "Epoch 11/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3992 - acc: 0.8309 - val_loss: 0.3987 - val_acc: 0.8307\n",
      "Epoch 12/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4162 - acc: 0.8227 - val_loss: 0.4025 - val_acc: 0.8200\n",
      "Epoch 13/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4184 - acc: 0.8177 - val_loss: 0.4070 - val_acc: 0.8210\n",
      "Epoch 14/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4050 - acc: 0.8263 - val_loss: 0.4112 - val_acc: 0.8174\n",
      "Epoch 15/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4130 - acc: 0.8236 - val_loss: 0.4005 - val_acc: 0.8255\n",
      "Epoch 16/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4110 - acc: 0.8228 - val_loss: 0.3964 - val_acc: 0.8217\n",
      "Epoch 17/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4092 - acc: 0.8218 - val_loss: 0.4000 - val_acc: 0.8313\n",
      "Epoch 18/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4124 - acc: 0.8259 - val_loss: 0.3888 - val_acc: 0.8355\n",
      "Epoch 19/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3899 - acc: 0.8312 - val_loss: 0.4118 - val_acc: 0.8185\n",
      "Epoch 20/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4017 - acc: 0.8276 - val_loss: 0.4095 - val_acc: 0.8180\n",
      "Epoch 21/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3914 - acc: 0.8306 - val_loss: 0.4110 - val_acc: 0.8209\n",
      "Epoch 22/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3893 - acc: 0.8306 - val_loss: 0.3942 - val_acc: 0.8268\n",
      "Epoch 23/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3902 - acc: 0.8314 - val_loss: 0.4214 - val_acc: 0.8115\n",
      "Epoch 24/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4030 - acc: 0.8220 - val_loss: 0.3905 - val_acc: 0.8268\n",
      "Epoch 25/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3960 - acc: 0.8328 - val_loss: 0.4312 - val_acc: 0.8095\n",
      "Epoch 26/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3890 - acc: 0.8294 - val_loss: 0.4361 - val_acc: 0.8112\n",
      "Epoch 27/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4038 - acc: 0.8206 - val_loss: 0.4138 - val_acc: 0.8255\n",
      "Epoch 28/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3873 - acc: 0.8325 - val_loss: 0.3987 - val_acc: 0.8259\n",
      "Epoch 29/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3904 - acc: 0.8259 - val_loss: 0.3902 - val_acc: 0.8325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3837 - acc: 0.8360 - val_loss: 0.3883 - val_acc: 0.8305\n",
      "Epoch 31/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3902 - acc: 0.8335 - val_loss: 0.3964 - val_acc: 0.8290\n",
      "Epoch 32/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3843 - acc: 0.8331 - val_loss: 0.3822 - val_acc: 0.8352\n",
      "Epoch 33/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3879 - acc: 0.8349 - val_loss: 0.3957 - val_acc: 0.8318\n",
      "Epoch 34/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3839 - acc: 0.8303 - val_loss: 0.3768 - val_acc: 0.8347\n",
      "Epoch 35/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3836 - acc: 0.8349 - val_loss: 0.3821 - val_acc: 0.8359\n",
      "Epoch 36/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3884 - acc: 0.8325 - val_loss: 0.4097 - val_acc: 0.8267\n",
      "Epoch 37/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3980 - acc: 0.8295 - val_loss: 0.3813 - val_acc: 0.8330\n",
      "Epoch 38/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3786 - acc: 0.8333 - val_loss: 0.3668 - val_acc: 0.8392\n",
      "Epoch 39/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3938 - acc: 0.8306 - val_loss: 0.3994 - val_acc: 0.8290\n",
      "Epoch 40/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3805 - acc: 0.8399 - val_loss: 0.3718 - val_acc: 0.8410\n",
      "Epoch 41/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3871 - acc: 0.8336 - val_loss: 0.4031 - val_acc: 0.8220\n",
      "Epoch 42/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3838 - acc: 0.8292 - val_loss: 0.3875 - val_acc: 0.8287\n",
      "Epoch 43/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3851 - acc: 0.8353 - val_loss: 0.3767 - val_acc: 0.8347\n",
      "Epoch 44/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3739 - acc: 0.8413 - val_loss: 0.3813 - val_acc: 0.8437\n",
      "Epoch 45/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3745 - acc: 0.8425 - val_loss: 0.3848 - val_acc: 0.8262\n",
      "Epoch 46/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3821 - acc: 0.8348 - val_loss: 0.3835 - val_acc: 0.8313\n",
      "Epoch 47/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3826 - acc: 0.8373 - val_loss: 0.3755 - val_acc: 0.8350\n",
      "Epoch 48/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3753 - acc: 0.8373 - val_loss: 0.3691 - val_acc: 0.8397\n",
      "Epoch 49/90\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.3797 - acc: 0.8374 - val_loss: 0.3804 - val_acc: 0.8364\n",
      "Epoch 50/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3687 - acc: 0.8452 - val_loss: 0.3824 - val_acc: 0.8362\n",
      "Epoch 51/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3737 - acc: 0.8391 - val_loss: 0.3719 - val_acc: 0.8428\n",
      "Epoch 52/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3814 - acc: 0.8339 - val_loss: 0.4029 - val_acc: 0.8277\n",
      "Epoch 53/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3693 - acc: 0.8435 - val_loss: 0.3680 - val_acc: 0.8405\n",
      "Epoch 54/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3792 - acc: 0.8341 - val_loss: 0.3612 - val_acc: 0.8483\n",
      "Epoch 55/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3665 - acc: 0.8408 - val_loss: 0.4000 - val_acc: 0.8325\n",
      "Epoch 56/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3733 - acc: 0.8422 - val_loss: 0.3740 - val_acc: 0.8352\n",
      "Epoch 57/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3741 - acc: 0.8406 - val_loss: 0.3729 - val_acc: 0.8400\n",
      "Epoch 58/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3785 - acc: 0.8328 - val_loss: 0.3921 - val_acc: 0.8283\n",
      "Epoch 59/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3651 - acc: 0.8456 - val_loss: 0.3683 - val_acc: 0.8375\n",
      "Epoch 60/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3688 - acc: 0.8443 - val_loss: 0.3694 - val_acc: 0.8430\n",
      "Epoch 61/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3742 - acc: 0.8405 - val_loss: 0.3573 - val_acc: 0.8430\n",
      "Epoch 62/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3728 - acc: 0.8395 - val_loss: 0.3770 - val_acc: 0.8400\n",
      "Epoch 63/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3621 - acc: 0.8461 - val_loss: 0.3810 - val_acc: 0.8379\n",
      "Epoch 64/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3688 - acc: 0.8439 - val_loss: 0.3867 - val_acc: 0.8428\n",
      "Epoch 65/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3725 - acc: 0.8410 - val_loss: 0.3507 - val_acc: 0.8460\n",
      "Epoch 66/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3680 - acc: 0.8385 - val_loss: 0.3771 - val_acc: 0.8345\n",
      "Epoch 67/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3705 - acc: 0.8411 - val_loss: 0.3861 - val_acc: 0.8365\n",
      "Epoch 68/90\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3665 - acc: 0.8455 - val_loss: 0.3641 - val_acc: 0.8465\n",
      "Epoch 69/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3640 - acc: 0.8425 - val_loss: 0.3724 - val_acc: 0.8398\n",
      "Epoch 70/90\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3535 - acc: 0.8565 - val_loss: 0.3656 - val_acc: 0.8434\n",
      "Epoch 71/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3644 - acc: 0.8435 - val_loss: 0.3641 - val_acc: 0.8415\n",
      "Epoch 72/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3625 - acc: 0.8462 - val_loss: 0.3460 - val_acc: 0.8577\n",
      "Epoch 73/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3644 - acc: 0.8445 - val_loss: 0.3546 - val_acc: 0.8445\n",
      "Epoch 74/90\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3596 - acc: 0.8448 - val_loss: 0.3688 - val_acc: 0.8407\n",
      "Epoch 75/90\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 0.3608 - acc: 0.8448 - val_loss: 0.3596 - val_acc: 0.8485\n",
      "Epoch 76/90\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 0.3567 - acc: 0.8452 - val_loss: 0.3628 - val_acc: 0.8430\n",
      "Epoch 77/90\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 0.3540 - acc: 0.8488 - val_loss: 0.3558 - val_acc: 0.8507\n",
      "Epoch 78/90\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 0.3637 - acc: 0.8439 - val_loss: 0.3786 - val_acc: 0.8423\n",
      "Epoch 79/90\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 0.3588 - acc: 0.8414 - val_loss: 0.3504 - val_acc: 0.8517\n",
      "Epoch 80/90\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.3587 - acc: 0.8458 - val_loss: 0.3718 - val_acc: 0.8363\n",
      "Epoch 81/90\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.3580 - acc: 0.8478 - val_loss: 0.3686 - val_acc: 0.8473\n",
      "Epoch 82/90\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 0.3553 - acc: 0.8503 - val_loss: 0.3367 - val_acc: 0.8530\n",
      "Epoch 83/90\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.3677 - acc: 0.8419 - val_loss: 0.3546 - val_acc: 0.8527\n",
      "Epoch 84/90\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.3500 - acc: 0.8535 - val_loss: 0.3587 - val_acc: 0.8487\n",
      "Epoch 85/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3638 - acc: 0.8433 - val_loss: 0.3640 - val_acc: 0.8485\n",
      "Epoch 86/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3534 - acc: 0.8455 - val_loss: 0.3388 - val_acc: 0.8545\n",
      "Epoch 87/90\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.3490 - acc: 0.8510 - val_loss: 0.3416 - val_acc: 0.8570\n",
      "Epoch 88/90\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.3550 - acc: 0.8495 - val_loss: 0.3514 - val_acc: 0.8545\n",
      "Epoch 89/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3515 - acc: 0.8475 - val_loss: 0.3652 - val_acc: 0.8462\n",
      "Epoch 90/90\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3499 - acc: 0.8533 - val_loss: 0.3570 - val_acc: 0.8442\n",
      "\n",
      "Training process completed in: 0 h 7 m 40 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: \" MODELS / model_breast_cancer_1223.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1225 of 1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_257 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_257 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_258 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_259 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_260 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_260 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.1\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 4.5018 - acc: 0.7188 - val_loss: 4.5873 - val_acc: 0.7154\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 4.5862 - acc: 0.7155 - val_loss: 4.5220 - val_acc: 0.7194\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 4.6086 - acc: 0.7141 - val_loss: 4.6024 - val_acc: 0.7145\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 4.6455 - acc: 0.7118 - val_loss: 4.5988 - val_acc: 0.7147\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 4.5925 - acc: 0.7151 - val_loss: 4.5960 - val_acc: 0.7149\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5775 - acc: 0.7160 - val_loss: 4.5706 - val_acc: 0.7164\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5626 - acc: 0.7169 - val_loss: 4.5766 - val_acc: 0.7161\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5206 - acc: 0.7195 - val_loss: 4.5425 - val_acc: 0.7182\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5516 - acc: 0.7176 - val_loss: 4.5895 - val_acc: 0.7153\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5067 - acc: 0.7204 - val_loss: 4.5821 - val_acc: 0.7157\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 4.5442 - acc: 0.7181 - val_loss: 4.5642 - val_acc: 0.7168\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 4.5701 - acc: 0.7165 - val_loss: 4.5843 - val_acc: 0.7156\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6034 - acc: 0.7144 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6489 - acc: 0.7116 - val_loss: 4.5572 - val_acc: 0.7173\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5735 - acc: 0.7162 - val_loss: 4.5591 - val_acc: 0.7171\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6140 - acc: 0.7137 - val_loss: 4.5185 - val_acc: 0.7197\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5821 - acc: 0.7157 - val_loss: 4.5898 - val_acc: 0.7152\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5724 - acc: 0.7163 - val_loss: 4.6282 - val_acc: 0.7129\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5638 - acc: 0.7169 - val_loss: 4.5783 - val_acc: 0.7160\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5752 - acc: 0.7161 - val_loss: 4.5198 - val_acc: 0.7196\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 4.6173 - acc: 0.7135 - val_loss: 4.6755 - val_acc: 0.7099\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5206 - acc: 0.7195 - val_loss: 4.5246 - val_acc: 0.7193\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5747 - acc: 0.7162 - val_loss: 4.5805 - val_acc: 0.7158\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5885 - acc: 0.7153 - val_loss: 4.6295 - val_acc: 0.7128\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5476 - acc: 0.7179 - val_loss: 4.5069 - val_acc: 0.7204\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6201 - acc: 0.7134 - val_loss: 4.6001 - val_acc: 0.7146\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5519 - acc: 0.7176 - val_loss: 4.5598 - val_acc: 0.7171\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.5534 - acc: 0.7175 - val_loss: 4.5374 - val_acc: 0.7185\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6409 - acc: 0.7121 - val_loss: 4.5843 - val_acc: 0.7156\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5701 - acc: 0.7165 - val_loss: 4.5527 - val_acc: 0.7175\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5752 - acc: 0.7161 - val_loss: 4.5792 - val_acc: 0.7159\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5372 - acc: 0.7185 - val_loss: 4.6333 - val_acc: 0.7125\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6023 - acc: 0.7145 - val_loss: 4.5438 - val_acc: 0.7181\n",
      "Epoch 34/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5781 - acc: 0.7160 - val_loss: 4.4953 - val_acc: 0.7211\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6553 - acc: 0.7112 - val_loss: 4.6154 - val_acc: 0.7137\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 4.6023 - acc: 0.7145 - val_loss: 4.6089 - val_acc: 0.7141\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.4854 - acc: 0.7217 - val_loss: 4.6192 - val_acc: 0.7134\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5867 - acc: 0.7154 - val_loss: 4.4682 - val_acc: 0.7228\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5384 - acc: 0.7184 - val_loss: 4.6269 - val_acc: 0.7129\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5318 - acc: 0.7188 - val_loss: 4.5947 - val_acc: 0.7149\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5833 - acc: 0.7156 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6691 - acc: 0.7103 - val_loss: 4.5182 - val_acc: 0.7197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.4969 - acc: 0.7210 - val_loss: 4.6811 - val_acc: 0.7096\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5770 - acc: 0.7160 - val_loss: 4.4606 - val_acc: 0.7233\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5873 - acc: 0.7154 - val_loss: 4.5753 - val_acc: 0.7161\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5960 - acc: 0.7149 - val_loss: 4.6538 - val_acc: 0.7113\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5706 - acc: 0.7164 - val_loss: 4.4592 - val_acc: 0.7233\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5476 - acc: 0.7179 - val_loss: 4.6167 - val_acc: 0.7136\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5956 - acc: 0.7149 - val_loss: 4.6308 - val_acc: 0.7127\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5965 - acc: 0.7148 - val_loss: 4.5540 - val_acc: 0.7175\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5372 - acc: 0.7185 - val_loss: 4.5585 - val_acc: 0.7172\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6576 - acc: 0.7110 - val_loss: 4.6231 - val_acc: 0.7132\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.5257 - acc: 0.7192 - val_loss: 4.5284 - val_acc: 0.7190\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5298 - acc: 0.7190 - val_loss: 4.5934 - val_acc: 0.7150\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.6351 - acc: 0.7124 - val_loss: 4.5630 - val_acc: 0.7169\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5568 - acc: 0.7173 - val_loss: 4.5908 - val_acc: 0.7152\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5660 - acc: 0.7167 - val_loss: 4.5323 - val_acc: 0.7188\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5856 - acc: 0.7155 - val_loss: 4.5560 - val_acc: 0.7173\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6104 - acc: 0.7140 - val_loss: 4.6461 - val_acc: 0.7117\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5550 - acc: 0.7174 - val_loss: 4.5301 - val_acc: 0.7189\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5706 - acc: 0.7164 - val_loss: 4.6551 - val_acc: 0.7112\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5568 - acc: 0.7173 - val_loss: 4.5095 - val_acc: 0.7202\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5925 - acc: 0.7151 - val_loss: 4.5770 - val_acc: 0.7160\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5637 - acc: 0.7169 - val_loss: 4.5962 - val_acc: 0.7148\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.6328 - acc: 0.7126 - val_loss: 4.5469 - val_acc: 0.7179\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.4993 - acc: 0.7209 - val_loss: 4.6167 - val_acc: 0.7136\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.5626 - acc: 0.7169 - val_loss: 4.6166 - val_acc: 0.7136\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 4.6230 - acc: 0.7132 - val_loss: 4.5412 - val_acc: 0.7183\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5312 - acc: 0.7189 - val_loss: 4.4953 - val_acc: 0.7211\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.4900 - acc: 0.7214 - val_loss: 4.6448 - val_acc: 0.7118\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.6322 - acc: 0.7126 - val_loss: 4.5018 - val_acc: 0.7207\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6483 - acc: 0.7116 - val_loss: 4.5873 - val_acc: 0.7154\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5989 - acc: 0.7147 - val_loss: 4.5960 - val_acc: 0.7149\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5516 - acc: 0.7176 - val_loss: 4.5553 - val_acc: 0.7174\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5257 - acc: 0.7192 - val_loss: 4.5809 - val_acc: 0.7158\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.6345 - acc: 0.7125 - val_loss: 4.5985 - val_acc: 0.7147\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 4.5516 - acc: 0.7176 - val_loss: 4.5694 - val_acc: 0.7165\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.5706 - acc: 0.7164 - val_loss: 4.4863 - val_acc: 0.7217\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5470 - acc: 0.7179 - val_loss: 4.6218 - val_acc: 0.7133\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5839 - acc: 0.7156 - val_loss: 4.6127 - val_acc: 0.7138\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5257 - acc: 0.7192 - val_loss: 4.5885 - val_acc: 0.7153\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6075 - acc: 0.7141 - val_loss: 4.6037 - val_acc: 0.7144\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 4.5603 - acc: 0.7171 - val_loss: 4.6001 - val_acc: 0.7146\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 4.6213 - acc: 0.7133 - val_loss: 4.5169 - val_acc: 0.7198\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 4.5505 - acc: 0.7177 - val_loss: 4.5753 - val_acc: 0.7161\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5988 - acc: 0.7147 - val_loss: 4.5783 - val_acc: 0.7160\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.6023 - acc: 0.7145 - val_loss: 4.5534 - val_acc: 0.7175\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5275 - acc: 0.7191 - val_loss: 4.6346 - val_acc: 0.7125\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5810 - acc: 0.7158 - val_loss: 4.3921 - val_acc: 0.7275\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 4.5963 - acc: 0.7148 - val_loss: 4.6231 - val_acc: 0.7132\n",
      "\n",
      "Training process completed in: 0 h 23 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1224.h5 \"\n",
      "######################################################################################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596284</td>\n",
       "      <td>0.717086</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.424821</td>\n",
       "      <td>0.824666</td>\n",
       "      <td>0:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.400397</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.821459</td>\n",
       "      <td>0:02:56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.342393</td>\n",
       "      <td>0.854934</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0:03:59</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.61192</td>\n",
       "      <td>0.713867</td>\n",
       "      <td>4.51508</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0:11:35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.57984</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>4.66014</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>0:04:34</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.414818</td>\n",
       "      <td>0.818889</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.355077</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0:11:37</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.598234</td>\n",
       "      <td>0.714492</td>\n",
       "      <td>0.587283</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0:11:21</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.415619</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.415587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0:03:26</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355923</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.340781</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0:04:54</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.386344</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>0.38406</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0:01:19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.578921</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.572354</td>\n",
       "      <td>0.707286</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.386086</td>\n",
       "      <td>0.829286</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.406065</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.821349</td>\n",
       "      <td>0:09:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.343212</td>\n",
       "      <td>0.854563</td>\n",
       "      <td>0.333918</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0:11:05</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.366198</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.378055</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0:02:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.36458</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>0.842172</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.398393</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.593772</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.418344</td>\n",
       "      <td>0.815605</td>\n",
       "      <td>0:06:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.369263</td>\n",
       "      <td>0.838594</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.846597</td>\n",
       "      <td>0:05:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.720147</td>\n",
       "      <td>0.593732</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0:03:39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.481815</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.503438</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0:01:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.60906</td>\n",
       "      <td>0.714044</td>\n",
       "      <td>4.5453</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0:20:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.63599</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>4.53844</td>\n",
       "      <td>0.718426</td>\n",
       "      <td>0:01:44</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.66619</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>4.60252</td>\n",
       "      <td>0.71445</td>\n",
       "      <td>0:06:20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.401561</td>\n",
       "      <td>0.824792</td>\n",
       "      <td>0.387844</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0:03:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.602757</td>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.592917</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0:07:09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.485893</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>0.79175</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>140</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311666</td>\n",
       "      <td>0.870913</td>\n",
       "      <td>0.34777</td>\n",
       "      <td>0.857951</td>\n",
       "      <td>0:15:19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.330268</td>\n",
       "      <td>0.857321</td>\n",
       "      <td>0.344401</td>\n",
       "      <td>0.848955</td>\n",
       "      <td>0:14:04</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.292693</td>\n",
       "      <td>0.877344</td>\n",
       "      <td>0.314819</td>\n",
       "      <td>0.86625</td>\n",
       "      <td>0:17:49</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>140</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.310754</td>\n",
       "      <td>0.868452</td>\n",
       "      <td>0.325059</td>\n",
       "      <td>0.869124</td>\n",
       "      <td>0:11:33</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.331094</td>\n",
       "      <td>0.858642</td>\n",
       "      <td>0.326456</td>\n",
       "      <td>0.85881</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.334385</td>\n",
       "      <td>0.857986</td>\n",
       "      <td>0.327107</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0:14:54</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.318752</td>\n",
       "      <td>0.864618</td>\n",
       "      <td>0.322973</td>\n",
       "      <td>0.863534</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>120</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.35385</td>\n",
       "      <td>0.850417</td>\n",
       "      <td>0.343852</td>\n",
       "      <td>0.856333</td>\n",
       "      <td>0:09:09</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.34228</td>\n",
       "      <td>0.854944</td>\n",
       "      <td>0.334369</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0:14:39</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.315523</td>\n",
       "      <td>0.865433</td>\n",
       "      <td>0.317805</td>\n",
       "      <td>0.862959</td>\n",
       "      <td>0:23:19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.308494</td>\n",
       "      <td>0.868723</td>\n",
       "      <td>0.315689</td>\n",
       "      <td>0.863931</td>\n",
       "      <td>0:23:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.295317</td>\n",
       "      <td>0.875767</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.87104</td>\n",
       "      <td>0:23:55</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>0.88045</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0:29:11</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>200</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.323443</td>\n",
       "      <td>0.864156</td>\n",
       "      <td>0.359869</td>\n",
       "      <td>0.855576</td>\n",
       "      <td>0:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.329399</td>\n",
       "      <td>0.860882</td>\n",
       "      <td>0.32394</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0:08:32</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.312709</td>\n",
       "      <td>0.869633</td>\n",
       "      <td>0.308132</td>\n",
       "      <td>0.870417</td>\n",
       "      <td>0:12:43</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.326245</td>\n",
       "      <td>0.863167</td>\n",
       "      <td>0.356179</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>0:09:19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.324173</td>\n",
       "      <td>0.862657</td>\n",
       "      <td>0.368982</td>\n",
       "      <td>0.856944</td>\n",
       "      <td>0:13:08</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.321955</td>\n",
       "      <td>0.865903</td>\n",
       "      <td>0.34979</td>\n",
       "      <td>0.851179</td>\n",
       "      <td>0:15:08</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.333642</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.335924</td>\n",
       "      <td>0.860972</td>\n",
       "      <td>0:10:12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.312157</td>\n",
       "      <td>0.868041</td>\n",
       "      <td>0.326772</td>\n",
       "      <td>0.865941</td>\n",
       "      <td>0:16:32</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.31575</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.411558</td>\n",
       "      <td>0.838283</td>\n",
       "      <td>0:09:56</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>60</td>\n",
       "      <td>190</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.365712</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.361469</td>\n",
       "      <td>0.845398</td>\n",
       "      <td>0:04:16</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>60</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.379731</td>\n",
       "      <td>0.836481</td>\n",
       "      <td>0.372809</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0:04:24</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.338212</td>\n",
       "      <td>0.857674</td>\n",
       "      <td>0.339351</td>\n",
       "      <td>0.856012</td>\n",
       "      <td>0:10:17</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.322194</td>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.324761</td>\n",
       "      <td>0.864125</td>\n",
       "      <td>0:11:37</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>80</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.33027</td>\n",
       "      <td>0.857438</td>\n",
       "      <td>0.331051</td>\n",
       "      <td>0.862361</td>\n",
       "      <td>0:13:47</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.316519</td>\n",
       "      <td>0.867179</td>\n",
       "      <td>0.321507</td>\n",
       "      <td>0.863857</td>\n",
       "      <td>0:20:19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.349878</td>\n",
       "      <td>0.853295</td>\n",
       "      <td>0.356955</td>\n",
       "      <td>0.84425</td>\n",
       "      <td>0:07:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.59636</td>\n",
       "      <td>0.714832</td>\n",
       "      <td>4.62308</td>\n",
       "      <td>0.713175</td>\n",
       "      <td>0:23:46</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1225 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc  val_loss   val_acc     time  gen  alive\n",
       "0            160               60                50      30        0.01000   0.596284  0.717086  0.602438  0.710375  0:02:47    1  False\n",
       "1            140              200                20      80        0.01000   0.419026  0.819964  0.424821  0.824666  0:14:00    1  False\n",
       "2            200               30                70      30        0.00010   0.400397  0.828667  0.407492  0.821459  0:02:56    1  False\n",
       "3             80              190                30      40        0.00100   0.342393  0.854934    0.3493     0.855  0:03:59    1  False\n",
       "4            100              150                80      90        0.10000    4.61192  0.713867   4.51508  0.719875  0:11:35    1  False\n",
       "5            200               70                40      40        0.10000    4.57984  0.715857   4.66014  0.710875  0:04:34    1  False\n",
       "6             60               30                80      40        0.00010   0.414818  0.818889  0.516359  0.784375  0:01:24    1  False\n",
       "7            200              110                70      60        0.00010   0.351962  0.852273  0.355077  0.848624  0:11:37    1  False\n",
       "8            160              160                20      70        0.01000   0.598234  0.714492  0.587283  0.726542  0:11:21    1  False\n",
       "9            120              110                20      40        0.00001   0.415619  0.823788  0.415587  0.819167  0:03:26    1  False\n",
       "10            40              130               100      90        0.00100   0.355923  0.847692  0.340781     0.862  0:04:54    1   True\n",
       "11           140              120                50      10        0.00100   0.386344   0.83375   0.38406  0.837714  0:01:19    1  False\n",
       "12           140               10                50      10        0.00010   0.578921  0.707143  0.572354  0.707286  0:00:27    1  False\n",
       "13            20              130                70      30        0.00100   0.396505  0.838462  0.386086  0.829286  0:00:46    1  False\n",
       "14           140              160                90      50        0.00001   0.406065  0.825893  0.408935  0.821349  0:09:57    1  False\n",
       "15           160              100                80      70        0.00010   0.343212  0.854563  0.333918  0.855412  0:11:05    1   True\n",
       "16           140               90                10      30        0.00100   0.366198  0.840635  0.378055  0.837143  0:02:27    1  False\n",
       "17            80               80                10      70        0.00100    0.36458  0.840156   0.34817  0.842172  0:03:00    1  False\n",
       "18           120               30                20      40        0.00100   0.398393  0.832778  0.461081  0.833333  0:01:07    1  False\n",
       "19            60              120                40      40        0.01000   0.596109  0.716944  0.593772  0.719167  0:02:15    1  False\n",
       "20           160               10                70     100        0.00010   0.409997    0.8225  0.418344  0.815605  0:06:57    1  False\n",
       "21           160              120                90      30        0.00010   0.369263  0.838594  0.359941  0.846597  0:05:47    1  False\n",
       "22           120              170                90      20        0.01000   0.593047  0.720147  0.593732  0.719444  0:03:39    1  False\n",
       "23            40               70                20      60        0.01000   0.481815      0.79  0.503438    0.7525  0:01:15    1  False\n",
       "24           160              170                50     100        0.10000    4.60906  0.714044    4.5453     0.718  0:20:24    1  False\n",
       "25           180              110                60      10        0.10000    4.63599  0.712374   4.53844  0.718426  0:01:44    1  False\n",
       "26           200               20               100      50        0.10000    4.66619    0.7105   4.60252   0.71445  0:06:20    1  False\n",
       "27            60               80                30      90        0.00001   0.401561  0.824792  0.387844     0.835  0:03:24    1  False\n",
       "28            80              120                30     100        0.01000   0.602757  0.709479  0.592917  0.720833  0:07:09    1  False\n",
       "29            80               70                50      20        0.00001   0.485893  0.765714  0.457634   0.79175  0:01:06    1  False\n",
       "...          ...              ...               ...     ...            ...        ...       ...       ...       ...      ...  ...    ...\n",
       "1195         140              180                50      80        0.00100   0.311666  0.870913   0.34777  0.857951  0:15:19    2   True\n",
       "1196         140              160                50      80        0.00010   0.330268  0.857321  0.344401  0.848955  0:14:04    2   True\n",
       "1197         160              160                50      90        0.00100   0.292693  0.877344  0.314819   0.86625  0:17:49    2   True\n",
       "1198         140              180                50      60        0.00100   0.310754  0.868452  0.325059  0.869124  0:11:33    2   True\n",
       "1199         180               90                70      90        0.00010   0.331094  0.858642  0.326456   0.85881  0:14:50    2   True\n",
       "1200         180              160                70      60        0.00010   0.334385  0.857986  0.327107  0.862512  0:14:54    2   True\n",
       "1201         180              160                50      90        0.00010   0.318752  0.864618  0.322973  0.863534  0:20:04    2   True\n",
       "1202         120              160                50      60        0.00010    0.35385  0.850417  0.343852  0.856333  0:09:09    2   True\n",
       "1203         200               90                50      90        0.00010    0.34228  0.854944  0.334369    0.8612  0:14:39    2   True\n",
       "1204         200              150                70      90        0.00010   0.315523  0.865433  0.317805  0.862959  0:23:19    2   True\n",
       "1205         160              200                70      90        0.00010   0.308494  0.868723  0.315689  0.863931  0:23:40    2   True\n",
       "1206         160              200                70      90        0.00100   0.295317  0.875767  0.310833   0.87104  0:23:55    2   True\n",
       "1207         200              200                70      90        0.00100   0.281896   0.88045  0.304133  0.874427  0:29:11    2   True\n",
       "1208         200              160                70      40        0.00100   0.323443  0.864156  0.359869  0.855576  0:11:00    2   True\n",
       "1209         120              170                60      50        0.00100   0.329399  0.860882   0.32394  0.863889  0:08:32    2   True\n",
       "1210         200              150                60      50        0.00100   0.312709  0.869633  0.308132  0.870417  0:12:43    2   True\n",
       "1211         120              150               100      50        0.00100   0.326245  0.863167  0.356179  0.854333  0:09:19    2   True\n",
       "1212         180               80                60      90        0.00100   0.324173  0.862657  0.368982  0.856944  0:13:08    2   True\n",
       "1213         180               80                80      90        0.00100   0.321955  0.865903   0.34979  0.851179  0:15:08    2   True\n",
       "1214         180               80                80      60        0.00100   0.333642  0.857431  0.335924  0.860972  0:10:12    2   True\n",
       "1215         180              190                60      60        0.00100   0.312157  0.868041  0.326772  0.865941  0:16:32    2   True\n",
       "1216         160              180                70      40        0.00100    0.31575  0.865625  0.411558  0.838283  0:09:56    2   True\n",
       "1217          60              190                70      40        0.00010   0.365712  0.843509  0.361469  0.845398  0:04:16    2   True\n",
       "1218          60              180                90      40        0.00010   0.379731  0.836481  0.372809  0.835185  0:04:24    2   True\n",
       "1219         160              180                70      40        0.00010   0.338212  0.857674  0.339351  0.856012  0:10:17    2   True\n",
       "1220         160              190               100      40        0.00100   0.322194  0.862862  0.324761  0.864125  0:11:37    2   True\n",
       "1221          80              200                90      90        0.00010    0.33027  0.857438  0.331051  0.862361  0:13:47    2   True\n",
       "1222         140              200                50      90        0.00010   0.316519  0.867179  0.321507  0.863857  0:20:19    2   True\n",
       "1223          80              110                50      90        0.00010   0.349878  0.853295  0.356955   0.84425  0:07:40    2   True\n",
       "1224         140              200                90      90        0.10000    4.59636  0.714832   4.62308  0.713175  0:23:46    2   True\n",
       "\n",
       "[1225 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate\n",
    "train_generation(model=model_7, image_size=(50,50), gen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.865789</td>\n",
       "      <td>0.292571</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0:11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.333464</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>0:05:13</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.311461</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.295427</td>\n",
       "      <td>0.881832</td>\n",
       "      <td>0:29:50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.321133</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0:10:42</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.306632</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0:14:31</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.344512</td>\n",
       "      <td>0.852526</td>\n",
       "      <td>0.317177</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0:07:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.294208</td>\n",
       "      <td>0.877200</td>\n",
       "      <td>0.308905</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0:21:22</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.316372</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.288847</td>\n",
       "      <td>0.876935</td>\n",
       "      <td>0:21:26</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.301332</td>\n",
       "      <td>0.874420</td>\n",
       "      <td>0.303735</td>\n",
       "      <td>0.876875</td>\n",
       "      <td>0:14:22</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.299698</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0:40:10</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "653          100              190                10      90         0.0001    0.317655   0.865789  0.292571  0.894000  0:11:41    1   True\n",
       "1178          80              190                30      50         0.0010    0.333464   0.858750  0.292957  0.884583  0:05:13    2   True\n",
       "1129         200              200                20      70         0.0001    0.311461   0.867375  0.295427  0.881832  0:29:50    2   True\n",
       "1107          80              160                10      80         0.0010    0.321133   0.866250  0.336637  0.881250  0:10:42    2   True\n",
       "1038         100              200                10      90         0.0010    0.306632   0.870800  0.317246  0.881000  0:14:31    2   True\n",
       "1039         100              190                10      50         0.0001    0.344512   0.852526  0.317177  0.878000  0:07:40    2   True\n",
       "1029         200              150                20      90         0.0010    0.294208   0.877200  0.308905  0.877500  0:21:22    2   True\n",
       "1106         140              200                10      80         0.0001    0.316372   0.865000  0.288847  0.876935  0:21:26    2   True\n",
       "1047         160              140                10      80         0.0010    0.301332   0.874420  0.303735  0.876875  0:14:22    2   True\n",
       "1125         200              120                90     100         0.0010    0.299698   0.874125  0.298709  0.876500  0:40:10    2   True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep top performing algorithms\n",
    "df_fittest = select_fittest(top_percent=10)\n",
    "df_fittest.nlargest(10, 'val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd GENERATION ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1150, 1074),\n",
       " (994, 693),\n",
       " (1083, 653),\n",
       " (1178, 1047),\n",
       " (996, 1067),\n",
       " (1068, 605),\n",
       " (1106, 1016),\n",
       " (1039, 1119),\n",
       " (1142, 963),\n",
       " (760, 548),\n",
       " (1125, 1107),\n",
       " (1032, 1134),\n",
       " (1029, 1103),\n",
       " (1176, 1171),\n",
       " (1038, 1129),\n",
       " (276, 1112)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = create_parents()\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read generations file\n",
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "    \n",
    "for pair in parents:\n",
    "    df_parents = df_generations.iloc[[pair[0], pair[1]]]\n",
    "    \n",
    "    # make children\n",
    "    df_child_1 = create_child(df_parents, generation=3)\n",
    "    df_child_2 = create_child(df_parents, generation=3)\n",
    "    df_child_3 = create_child(df_parents, generation=3)\n",
    "    df_child_4 = create_child(df_parents, generation=3)\n",
    "    df_child_5 = create_child(df_parents, generation=3, mutate=True)\n",
    "\n",
    "    df_children = df_child_1.append([df_child_2, df_child_3, df_child_4, df_child_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>0.311656</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>0:24:30</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.293139</td>\n",
       "      <td>0.878368</td>\n",
       "      <td>0.306576</td>\n",
       "      <td>0.873426</td>\n",
       "      <td>0:34:54</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "276          100              170                50      80         0.0001    0.335177   0.857294  0.311656  0.871600  0:24:30    1   True\n",
       "1112         180              160                60     100         0.0010    0.293139   0.878368  0.306576  0.873426  0:34:54    2   True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc val_loss val_acc time  gen  alive\n",
       "0         180              170                50      80         0.0001                                               3   True\n",
       "1         180              170                60      80         0.0010                                               3   True\n",
       "2         180              160                50     100         0.0010                                               3   True\n",
       "3         100              160                60      80         0.0010                                               3   True\n",
       "4         180               10                50     100         0.0010                                               3   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 1226 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_261 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_261 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_262 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_263 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_263 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_264 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_264 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 22s 115ms/step - loss: 0.4547 - acc: 0.7957 - val_loss: 0.4069 - val_acc: 0.8239\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.4097 - acc: 0.8244 - val_loss: 0.4107 - val_acc: 0.8211\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3938 - acc: 0.8330 - val_loss: 0.3910 - val_acc: 0.8279\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3821 - acc: 0.8375 - val_loss: 0.3779 - val_acc: 0.8384\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3853 - acc: 0.8351 - val_loss: 0.3797 - val_acc: 0.8311\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3735 - acc: 0.8397 - val_loss: 0.3913 - val_acc: 0.8234\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3689 - acc: 0.8407 - val_loss: 0.3832 - val_acc: 0.8309\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3607 - acc: 0.8471 - val_loss: 0.3762 - val_acc: 0.8311\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3623 - acc: 0.8450 - val_loss: 0.3965 - val_acc: 0.8395\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3596 - acc: 0.8461 - val_loss: 0.3626 - val_acc: 0.8415\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3604 - acc: 0.8472 - val_loss: 0.3430 - val_acc: 0.8525\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3508 - acc: 0.8501 - val_loss: 0.3672 - val_acc: 0.8455\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3454 - acc: 0.8528 - val_loss: 0.3431 - val_acc: 0.8502\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3424 - acc: 0.8552 - val_loss: 0.3395 - val_acc: 0.8563\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3396 - acc: 0.8562 - val_loss: 0.3392 - val_acc: 0.8562\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3407 - acc: 0.8550 - val_loss: 0.3502 - val_acc: 0.8605\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3396 - acc: 0.8552 - val_loss: 0.3477 - val_acc: 0.8586\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3382 - acc: 0.8567 - val_loss: 0.3278 - val_acc: 0.8583\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3328 - acc: 0.8584 - val_loss: 0.3488 - val_acc: 0.8525\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3331 - acc: 0.8587 - val_loss: 0.3320 - val_acc: 0.8571\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3316 - acc: 0.8609 - val_loss: 0.3371 - val_acc: 0.8574\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3240 - acc: 0.8620 - val_loss: 0.3304 - val_acc: 0.8571\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3211 - acc: 0.8637 - val_loss: 0.3331 - val_acc: 0.8599\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3333 - acc: 0.8585 - val_loss: 0.3266 - val_acc: 0.8649\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3297 - acc: 0.8615 - val_loss: 0.3173 - val_acc: 0.8681\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3246 - acc: 0.8613 - val_loss: 0.3299 - val_acc: 0.8607\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3256 - acc: 0.8625 - val_loss: 0.3210 - val_acc: 0.8636\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3271 - acc: 0.8622 - val_loss: 0.3419 - val_acc: 0.8561\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3168 - acc: 0.8673 - val_loss: 0.3187 - val_acc: 0.8680\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3194 - acc: 0.8642 - val_loss: 0.3244 - val_acc: 0.8634\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3193 - acc: 0.8658 - val_loss: 0.3379 - val_acc: 0.8567\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3172 - acc: 0.8670 - val_loss: 0.3308 - val_acc: 0.8654\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3221 - acc: 0.8628 - val_loss: 0.3410 - val_acc: 0.8600\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3170 - acc: 0.8662 - val_loss: 0.3141 - val_acc: 0.8729\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3085 - acc: 0.8706 - val_loss: 0.3148 - val_acc: 0.8656\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3113 - acc: 0.8687 - val_loss: 0.3141 - val_acc: 0.8634\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3112 - acc: 0.8701 - val_loss: 0.3197 - val_acc: 0.8666\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3157 - acc: 0.8656 - val_loss: 0.3381 - val_acc: 0.8594\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3186 - acc: 0.8651 - val_loss: 0.3277 - val_acc: 0.8583\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3112 - acc: 0.8705 - val_loss: 0.3185 - val_acc: 0.8764\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3100 - acc: 0.8681 - val_loss: 0.3228 - val_acc: 0.8639\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3129 - acc: 0.8664 - val_loss: 0.3219 - val_acc: 0.8610\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3065 - acc: 0.8735 - val_loss: 0.3389 - val_acc: 0.8496\n",
      "Epoch 44/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3141 - acc: 0.8681 - val_loss: 0.3371 - val_acc: 0.8625\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3108 - acc: 0.8706 - val_loss: 0.3181 - val_acc: 0.8665\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3064 - acc: 0.8703 - val_loss: 0.3213 - val_acc: 0.8651\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3043 - acc: 0.8726 - val_loss: 0.3296 - val_acc: 0.8630\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3056 - acc: 0.8727 - val_loss: 0.3265 - val_acc: 0.8656\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3065 - acc: 0.8703 - val_loss: 0.3251 - val_acc: 0.8612\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.2986 - acc: 0.8754 - val_loss: 0.3170 - val_acc: 0.8625\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3061 - acc: 0.8713 - val_loss: 0.3059 - val_acc: 0.8758\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3030 - acc: 0.8714 - val_loss: 0.3203 - val_acc: 0.8684\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3039 - acc: 0.8704 - val_loss: 0.3153 - val_acc: 0.8675\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2997 - acc: 0.8764 - val_loss: 0.3109 - val_acc: 0.8700\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.2976 - acc: 0.8740 - val_loss: 0.3345 - val_acc: 0.8553\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3070 - acc: 0.8706 - val_loss: 0.3308 - val_acc: 0.8681\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3057 - acc: 0.8712 - val_loss: 0.3085 - val_acc: 0.8709\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3040 - acc: 0.8718 - val_loss: 0.3176 - val_acc: 0.8705\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3034 - acc: 0.8731 - val_loss: 0.3042 - val_acc: 0.8719\n",
      "Epoch 60/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2927 - acc: 0.8774 - val_loss: 0.3149 - val_acc: 0.8719\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3034 - acc: 0.8728 - val_loss: 0.3159 - val_acc: 0.8699\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2971 - acc: 0.8761 - val_loss: 0.3116 - val_acc: 0.8702\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3011 - acc: 0.8712 - val_loss: 0.3076 - val_acc: 0.8692\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2948 - acc: 0.8773 - val_loss: 0.2993 - val_acc: 0.8774\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2974 - acc: 0.8765 - val_loss: 0.3053 - val_acc: 0.8744\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2971 - acc: 0.8758 - val_loss: 0.3271 - val_acc: 0.8550\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2981 - acc: 0.8752 - val_loss: 0.3152 - val_acc: 0.8687\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2934 - acc: 0.8763 - val_loss: 0.3100 - val_acc: 0.8709\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.2895 - acc: 0.8788 - val_loss: 0.3143 - val_acc: 0.8663\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2966 - acc: 0.8758 - val_loss: 0.3009 - val_acc: 0.8803\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.2939 - acc: 0.8751 - val_loss: 0.3116 - val_acc: 0.8671\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2857 - acc: 0.8804 - val_loss: 0.3074 - val_acc: 0.8699\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2953 - acc: 0.8746 - val_loss: 0.3149 - val_acc: 0.8692\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2924 - acc: 0.8781 - val_loss: 0.3032 - val_acc: 0.8752\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2935 - acc: 0.8752 - val_loss: 0.3194 - val_acc: 0.8674\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2896 - acc: 0.8791 - val_loss: 0.3147 - val_acc: 0.8680\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2857 - acc: 0.8808 - val_loss: 0.3050 - val_acc: 0.8771\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2917 - acc: 0.8762 - val_loss: 0.3209 - val_acc: 0.8632\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2855 - acc: 0.8821 - val_loss: 0.3035 - val_acc: 0.8743\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2915 - acc: 0.8779 - val_loss: 0.3130 - val_acc: 0.8698\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2866 - acc: 0.8799 - val_loss: 0.3170 - val_acc: 0.8698\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2917 - acc: 0.8791 - val_loss: 0.3099 - val_acc: 0.8675\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2871 - acc: 0.8808 - val_loss: 0.2958 - val_acc: 0.8755\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2850 - acc: 0.8812 - val_loss: 0.3053 - val_acc: 0.8791\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2888 - acc: 0.8780 - val_loss: 0.3053 - val_acc: 0.8723\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2899 - acc: 0.8782 - val_loss: 0.3103 - val_acc: 0.8683\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2870 - acc: 0.8803 - val_loss: 0.3031 - val_acc: 0.8676\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2830 - acc: 0.8825 - val_loss: 0.3139 - val_acc: 0.8689\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2872 - acc: 0.8811 - val_loss: 0.3022 - val_acc: 0.8718\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2775 - acc: 0.8844 - val_loss: 0.3065 - val_acc: 0.8729\n",
      "\n",
      "Training process completed in: 0 h 26 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1225.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1227 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_265 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_265 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_266 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_266 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_267 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_267 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_268 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_268 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 12s 134ms/step - loss: 0.5131 - acc: 0.7492 - val_loss: 0.4500 - val_acc: 0.8005\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 8s 84ms/step - loss: 0.4366 - acc: 0.8146 - val_loss: 0.4211 - val_acc: 0.8303\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.4174 - acc: 0.8231 - val_loss: 0.4109 - val_acc: 0.8143\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.4167 - acc: 0.8192 - val_loss: 0.4000 - val_acc: 0.8297\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.4050 - acc: 0.8279 - val_loss: 0.3993 - val_acc: 0.8285\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.4055 - acc: 0.8273 - val_loss: 0.4193 - val_acc: 0.8105\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3940 - acc: 0.8344 - val_loss: 0.4233 - val_acc: 0.8267\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.3875 - acc: 0.8356 - val_loss: 0.3954 - val_acc: 0.8330\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3990 - acc: 0.8296 - val_loss: 0.4162 - val_acc: 0.8300\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3808 - acc: 0.8353 - val_loss: 0.3894 - val_acc: 0.8398\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.3806 - acc: 0.8374 - val_loss: 0.3888 - val_acc: 0.8407\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3815 - acc: 0.8364 - val_loss: 0.4276 - val_acc: 0.8190\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3797 - acc: 0.8360 - val_loss: 0.3868 - val_acc: 0.8395\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3629 - acc: 0.8447 - val_loss: 0.3653 - val_acc: 0.8474\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3735 - acc: 0.8425 - val_loss: 0.3835 - val_acc: 0.8322\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3675 - acc: 0.8420 - val_loss: 0.3633 - val_acc: 0.8490\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3655 - acc: 0.8448 - val_loss: 0.3712 - val_acc: 0.8515\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3641 - acc: 0.8437 - val_loss: 0.3503 - val_acc: 0.8560\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3673 - acc: 0.8425 - val_loss: 0.4217 - val_acc: 0.8192\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3547 - acc: 0.8496 - val_loss: 0.3635 - val_acc: 0.8418\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3485 - acc: 0.8533 - val_loss: 0.3761 - val_acc: 0.8429\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3528 - acc: 0.8491 - val_loss: 0.4089 - val_acc: 0.8235\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3453 - acc: 0.8508 - val_loss: 0.3513 - val_acc: 0.8593\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3582 - acc: 0.8459 - val_loss: 0.4032 - val_acc: 0.8377\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3600 - acc: 0.8464 - val_loss: 0.3884 - val_acc: 0.8498\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3452 - acc: 0.8534 - val_loss: 0.3641 - val_acc: 0.8562\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3457 - acc: 0.8517 - val_loss: 0.3514 - val_acc: 0.8527\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3467 - acc: 0.8552 - val_loss: 0.3997 - val_acc: 0.8401\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3477 - acc: 0.8523 - val_loss: 0.3485 - val_acc: 0.8528\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3458 - acc: 0.8566 - val_loss: 0.3546 - val_acc: 0.8545\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3493 - acc: 0.8519 - val_loss: 0.3583 - val_acc: 0.8555\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3416 - acc: 0.8571 - val_loss: 0.3589 - val_acc: 0.8485\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3567 - acc: 0.8480 - val_loss: 0.3411 - val_acc: 0.8640\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3272 - acc: 0.8600 - val_loss: 0.3689 - val_acc: 0.8430\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3383 - acc: 0.8600 - val_loss: 0.3467 - val_acc: 0.8545\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3318 - acc: 0.8603 - val_loss: 0.3808 - val_acc: 0.8428\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3296 - acc: 0.8592 - val_loss: 0.3330 - val_acc: 0.8550\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.3360 - acc: 0.8613 - val_loss: 0.3617 - val_acc: 0.8607\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3264 - acc: 0.8607 - val_loss: 0.3706 - val_acc: 0.8512\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3368 - acc: 0.8573 - val_loss: 0.3606 - val_acc: 0.8478\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3359 - acc: 0.8603 - val_loss: 0.3438 - val_acc: 0.8588\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 8s 91ms/step - loss: 0.3389 - acc: 0.8579 - val_loss: 0.3450 - val_acc: 0.8512\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3326 - acc: 0.8582 - val_loss: 0.3326 - val_acc: 0.8595\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3278 - acc: 0.8611 - val_loss: 0.3261 - val_acc: 0.8665\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3297 - acc: 0.8613 - val_loss: 0.3410 - val_acc: 0.8557\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3315 - acc: 0.8602 - val_loss: 0.3609 - val_acc: 0.8563\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3233 - acc: 0.8644 - val_loss: 0.3495 - val_acc: 0.8588\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3223 - acc: 0.8617 - val_loss: 0.3388 - val_acc: 0.8610\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3369 - acc: 0.8567 - val_loss: 0.3703 - val_acc: 0.8608\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3298 - acc: 0.8605 - val_loss: 0.3300 - val_acc: 0.8645\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3269 - acc: 0.8625 - val_loss: 0.3511 - val_acc: 0.8565\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3278 - acc: 0.8600 - val_loss: 0.3623 - val_acc: 0.8568\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3180 - acc: 0.8665 - val_loss: 0.3458 - val_acc: 0.8595\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3193 - acc: 0.8654 - val_loss: 0.3331 - val_acc: 0.8663\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3240 - acc: 0.8628 - val_loss: 0.3403 - val_acc: 0.8570\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3245 - acc: 0.8638 - val_loss: 0.3430 - val_acc: 0.8565\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3231 - acc: 0.8631 - val_loss: 0.3405 - val_acc: 0.8645\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3254 - acc: 0.8630 - val_loss: 0.3304 - val_acc: 0.8645\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3242 - acc: 0.8621 - val_loss: 0.3337 - val_acc: 0.8677\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3303 - acc: 0.8604 - val_loss: 0.3467 - val_acc: 0.8550\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3200 - acc: 0.8666 - val_loss: 0.3538 - val_acc: 0.8590\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3246 - acc: 0.8624 - val_loss: 0.3321 - val_acc: 0.8770\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3235 - acc: 0.8658 - val_loss: 0.3140 - val_acc: 0.8682\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3227 - acc: 0.8655 - val_loss: 0.3513 - val_acc: 0.8633\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3225 - acc: 0.8656 - val_loss: 0.3328 - val_acc: 0.8682\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3140 - acc: 0.8647 - val_loss: 0.3222 - val_acc: 0.8688\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3315 - acc: 0.8594 - val_loss: 0.3437 - val_acc: 0.8510\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3225 - acc: 0.8647 - val_loss: 0.3474 - val_acc: 0.8582\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3177 - acc: 0.8638 - val_loss: 0.3304 - val_acc: 0.8698\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 8s 91ms/step - loss: 0.3131 - acc: 0.8686 - val_loss: 0.3302 - val_acc: 0.8679\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3096 - acc: 0.8671 - val_loss: 0.3430 - val_acc: 0.8705\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3190 - acc: 0.8648 - val_loss: 0.3680 - val_acc: 0.8468\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3172 - acc: 0.8686 - val_loss: 0.3591 - val_acc: 0.8558\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3319 - acc: 0.8591 - val_loss: 0.3455 - val_acc: 0.8533\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3095 - acc: 0.8704 - val_loss: 0.3217 - val_acc: 0.8722\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3185 - acc: 0.8663 - val_loss: 0.3403 - val_acc: 0.8642\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3082 - acc: 0.8715 - val_loss: 0.3283 - val_acc: 0.8702\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.3122 - acc: 0.8686 - val_loss: 0.3463 - val_acc: 0.8603\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3087 - acc: 0.8679 - val_loss: 0.3226 - val_acc: 0.8695\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3154 - acc: 0.8653 - val_loss: 0.3446 - val_acc: 0.8652\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3167 - acc: 0.8661 - val_loss: 0.3611 - val_acc: 0.8655\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3181 - acc: 0.8657 - val_loss: 0.3237 - val_acc: 0.8710\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3133 - acc: 0.8692 - val_loss: 0.3320 - val_acc: 0.8682\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 8s 92ms/step - loss: 0.3154 - acc: 0.8652 - val_loss: 0.3293 - val_acc: 0.8639\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3142 - acc: 0.8671 - val_loss: 0.3709 - val_acc: 0.8628\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3177 - acc: 0.8659 - val_loss: 0.3230 - val_acc: 0.8727\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3053 - acc: 0.8699 - val_loss: 0.3340 - val_acc: 0.8700\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3165 - acc: 0.8654 - val_loss: 0.3406 - val_acc: 0.8575\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3057 - acc: 0.8714 - val_loss: 0.3421 - val_acc: 0.8583\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3173 - acc: 0.8661 - val_loss: 0.3362 - val_acc: 0.8765\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.3148 - acc: 0.8687 - val_loss: 0.3150 - val_acc: 0.8687\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3133 - acc: 0.8659 - val_loss: 0.3387 - val_acc: 0.8613\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3117 - acc: 0.8674 - val_loss: 0.3269 - val_acc: 0.8633\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3144 - acc: 0.8701 - val_loss: 0.3123 - val_acc: 0.8710\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3053 - acc: 0.8726 - val_loss: 0.3387 - val_acc: 0.8662\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3129 - acc: 0.8703 - val_loss: 0.3384 - val_acc: 0.8680\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.3121 - acc: 0.8676 - val_loss: 0.3371 - val_acc: 0.8727\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.3083 - acc: 0.8678 - val_loss: 0.3239 - val_acc: 0.8634\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3126 - acc: 0.8693 - val_loss: 0.3382 - val_acc: 0.8655\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.3053 - acc: 0.8719 - val_loss: 0.3181 - val_acc: 0.8685\n",
      "\n",
      "Training process completed in: 0 h 13 m 14 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1226.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1228 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_269 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_269 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_270 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_270 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_271 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_271 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_272 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_272 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.4688 - acc: 0.7905 - val_loss: 0.4160 - val_acc: 0.8290\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4212 - acc: 0.8193 - val_loss: 0.4365 - val_acc: 0.8255\n",
      "Epoch 3/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3933 - acc: 0.8314 - val_loss: 0.3777 - val_acc: 0.8347\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3887 - acc: 0.8331 - val_loss: 0.3777 - val_acc: 0.8315\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3783 - acc: 0.8374 - val_loss: 0.3875 - val_acc: 0.8285\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3800 - acc: 0.8376 - val_loss: 0.4155 - val_acc: 0.8310\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3727 - acc: 0.8387 - val_loss: 0.3747 - val_acc: 0.8456\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3619 - acc: 0.8459 - val_loss: 0.3888 - val_acc: 0.8403\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3595 - acc: 0.8465 - val_loss: 0.3653 - val_acc: 0.8493\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3527 - acc: 0.8505 - val_loss: 0.3779 - val_acc: 0.8398\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3470 - acc: 0.8508 - val_loss: 0.3502 - val_acc: 0.8600\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3562 - acc: 0.8482 - val_loss: 0.3758 - val_acc: 0.8487\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3483 - acc: 0.8525 - val_loss: 0.3508 - val_acc: 0.8535\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3370 - acc: 0.8578 - val_loss: 0.3501 - val_acc: 0.8487\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3446 - acc: 0.8539 - val_loss: 0.3533 - val_acc: 0.8538\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3421 - acc: 0.8546 - val_loss: 0.3314 - val_acc: 0.8635\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3417 - acc: 0.8538 - val_loss: 0.3486 - val_acc: 0.8485\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3374 - acc: 0.8572 - val_loss: 0.3318 - val_acc: 0.8588\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3335 - acc: 0.8598 - val_loss: 0.3156 - val_acc: 0.8655\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3319 - acc: 0.8588 - val_loss: 0.3400 - val_acc: 0.8585\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3308 - acc: 0.8605 - val_loss: 0.3510 - val_acc: 0.8482\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3291 - acc: 0.8608 - val_loss: 0.3394 - val_acc: 0.8533\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3284 - acc: 0.8607 - val_loss: 0.3392 - val_acc: 0.8555\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3239 - acc: 0.8627 - val_loss: 0.3247 - val_acc: 0.8645\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3301 - acc: 0.8603 - val_loss: 0.3241 - val_acc: 0.8703\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3267 - acc: 0.8607 - val_loss: 0.3268 - val_acc: 0.8593\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3274 - acc: 0.8605 - val_loss: 0.3364 - val_acc: 0.8545\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3250 - acc: 0.8631 - val_loss: 0.3405 - val_acc: 0.8601\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3195 - acc: 0.8629 - val_loss: 0.3508 - val_acc: 0.8510\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3211 - acc: 0.8653 - val_loss: 0.3397 - val_acc: 0.8502\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3192 - acc: 0.8644 - val_loss: 0.3143 - val_acc: 0.8698\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3281 - acc: 0.8594 - val_loss: 0.3482 - val_acc: 0.8580\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3170 - acc: 0.8663 - val_loss: 0.3365 - val_acc: 0.8598\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3218 - acc: 0.8636 - val_loss: 0.3297 - val_acc: 0.8627\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3179 - acc: 0.8629 - val_loss: 0.3065 - val_acc: 0.8783\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3169 - acc: 0.8663 - val_loss: 0.3346 - val_acc: 0.8657\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3129 - acc: 0.8688 - val_loss: 0.3319 - val_acc: 0.8635\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3149 - acc: 0.8677 - val_loss: 0.3331 - val_acc: 0.8578\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3140 - acc: 0.8655 - val_loss: 0.3203 - val_acc: 0.8665\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3146 - acc: 0.8683 - val_loss: 0.3139 - val_acc: 0.8717\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3123 - acc: 0.8676 - val_loss: 0.3339 - val_acc: 0.8583\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3068 - acc: 0.8718 - val_loss: 0.3347 - val_acc: 0.8606\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3086 - acc: 0.8708 - val_loss: 0.3191 - val_acc: 0.8607\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3107 - acc: 0.8684 - val_loss: 0.3236 - val_acc: 0.8738\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3147 - acc: 0.8685 - val_loss: 0.3291 - val_acc: 0.8598\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3067 - acc: 0.8707 - val_loss: 0.3259 - val_acc: 0.8650\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3131 - acc: 0.8691 - val_loss: 0.3209 - val_acc: 0.8645\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3118 - acc: 0.8672 - val_loss: 0.2973 - val_acc: 0.8752\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3053 - acc: 0.8704 - val_loss: 0.3197 - val_acc: 0.8586\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3088 - acc: 0.8695 - val_loss: 0.3219 - val_acc: 0.8630\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3089 - acc: 0.8695 - val_loss: 0.3148 - val_acc: 0.8698\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3075 - acc: 0.8708 - val_loss: 0.3058 - val_acc: 0.8788\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3019 - acc: 0.8742 - val_loss: 0.3030 - val_acc: 0.8755\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3073 - acc: 0.8702 - val_loss: 0.3210 - val_acc: 0.8573\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3093 - acc: 0.8692 - val_loss: 0.3183 - val_acc: 0.8713\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3031 - acc: 0.8732 - val_loss: 0.3093 - val_acc: 0.8753\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2911 - acc: 0.8781 - val_loss: 0.3110 - val_acc: 0.8682\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3011 - acc: 0.8735 - val_loss: 0.3328 - val_acc: 0.8632\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2968 - acc: 0.8729 - val_loss: 0.3046 - val_acc: 0.8728\n",
      "Epoch 60/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2991 - acc: 0.8752 - val_loss: 0.3144 - val_acc: 0.8725\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3076 - acc: 0.8702 - val_loss: 0.3131 - val_acc: 0.8680\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3024 - acc: 0.8726 - val_loss: 0.3160 - val_acc: 0.8738\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2979 - acc: 0.8758 - val_loss: 0.3110 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2946 - acc: 0.8763 - val_loss: 0.3140 - val_acc: 0.8690\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2946 - acc: 0.8754 - val_loss: 0.3193 - val_acc: 0.8662\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2944 - acc: 0.8755 - val_loss: 0.3077 - val_acc: 0.8738\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2981 - acc: 0.8745 - val_loss: 0.2997 - val_acc: 0.8793\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2914 - acc: 0.8782 - val_loss: 0.3020 - val_acc: 0.8730\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2959 - acc: 0.8753 - val_loss: 0.3128 - val_acc: 0.8677\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2990 - acc: 0.8737 - val_loss: 0.3200 - val_acc: 0.8636\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2913 - acc: 0.8775 - val_loss: 0.3104 - val_acc: 0.8720\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2901 - acc: 0.8787 - val_loss: 0.3077 - val_acc: 0.8745\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2971 - acc: 0.8755 - val_loss: 0.2989 - val_acc: 0.8742\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2888 - acc: 0.8784 - val_loss: 0.3221 - val_acc: 0.8640\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2915 - acc: 0.8765 - val_loss: 0.3002 - val_acc: 0.8832\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2951 - acc: 0.8761 - val_loss: 0.3161 - val_acc: 0.8680\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2926 - acc: 0.8784 - val_loss: 0.2962 - val_acc: 0.8760\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.2908 - acc: 0.8752 - val_loss: 0.3050 - val_acc: 0.8763\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2917 - acc: 0.8771 - val_loss: 0.3151 - val_acc: 0.8700\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2881 - acc: 0.8784 - val_loss: 0.3107 - val_acc: 0.8742\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.2932 - acc: 0.8761 - val_loss: 0.3157 - val_acc: 0.8690\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2865 - acc: 0.8783 - val_loss: 0.3188 - val_acc: 0.8685\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.2875 - acc: 0.8794 - val_loss: 0.2861 - val_acc: 0.8772\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2867 - acc: 0.8799 - val_loss: 0.3138 - val_acc: 0.8689\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2891 - acc: 0.8799 - val_loss: 0.3397 - val_acc: 0.8523\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2999 - acc: 0.8727 - val_loss: 0.3028 - val_acc: 0.8745\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2848 - acc: 0.8804 - val_loss: 0.3150 - val_acc: 0.8672\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.2845 - acc: 0.8790 - val_loss: 0.2904 - val_acc: 0.8778\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2862 - acc: 0.8794 - val_loss: 0.3129 - val_acc: 0.8725\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.2871 - acc: 0.8793 - val_loss: 0.3151 - val_acc: 0.8730\n",
      "\n",
      "Training process completed in: 0 h 23 m 54 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1227.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1229 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_273 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_273 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_274 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_275 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_276 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_276 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 120\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.5169 - acc: 0.7517 - val_loss: 0.4226 - val_acc: 0.8210\n",
      "Epoch 2/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.4462 - acc: 0.8084 - val_loss: 0.4099 - val_acc: 0.8240\n",
      "Epoch 3/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.4182 - acc: 0.8224 - val_loss: 0.4131 - val_acc: 0.8227\n",
      "Epoch 4/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.4073 - acc: 0.8316 - val_loss: 0.4826 - val_acc: 0.8058\n",
      "Epoch 5/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4200 - acc: 0.8219 - val_loss: 0.4261 - val_acc: 0.8229\n",
      "Epoch 6/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4120 - acc: 0.8245 - val_loss: 0.4014 - val_acc: 0.8217\n",
      "Epoch 7/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4128 - acc: 0.8249 - val_loss: 0.4055 - val_acc: 0.8394\n",
      "Epoch 8/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4052 - acc: 0.8235 - val_loss: 0.4227 - val_acc: 0.8052\n",
      "Epoch 9/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3856 - acc: 0.8372 - val_loss: 0.4751 - val_acc: 0.8144\n",
      "Epoch 10/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4004 - acc: 0.8288 - val_loss: 0.4047 - val_acc: 0.8240\n",
      "Epoch 11/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3893 - acc: 0.8345 - val_loss: 0.4568 - val_acc: 0.8158\n",
      "Epoch 12/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3884 - acc: 0.8295 - val_loss: 0.3997 - val_acc: 0.8245\n",
      "Epoch 13/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3882 - acc: 0.8367 - val_loss: 0.3903 - val_acc: 0.8356\n",
      "Epoch 14/90\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.3904 - acc: 0.8314 - val_loss: 0.4012 - val_acc: 0.8237\n",
      "Epoch 15/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3950 - acc: 0.8278 - val_loss: 0.3859 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3860 - acc: 0.8329 - val_loss: 0.3924 - val_acc: 0.8467\n",
      "Epoch 17/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3823 - acc: 0.8348 - val_loss: 0.3778 - val_acc: 0.8402\n",
      "Epoch 18/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3802 - acc: 0.8369 - val_loss: 0.3730 - val_acc: 0.8427\n",
      "Epoch 19/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3735 - acc: 0.8401 - val_loss: 0.4289 - val_acc: 0.8258\n",
      "Epoch 20/90\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.3731 - acc: 0.8421 - val_loss: 0.3935 - val_acc: 0.8519\n",
      "Epoch 21/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3825 - acc: 0.8357 - val_loss: 0.3943 - val_acc: 0.8394\n",
      "Epoch 22/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3755 - acc: 0.8370 - val_loss: 0.3572 - val_acc: 0.8469\n",
      "Epoch 23/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3610 - acc: 0.8466 - val_loss: 0.3982 - val_acc: 0.8198\n",
      "Epoch 24/90\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.3659 - acc: 0.8446 - val_loss: 0.3790 - val_acc: 0.8421\n",
      "Epoch 25/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3635 - acc: 0.8440 - val_loss: 0.3744 - val_acc: 0.8431\n",
      "Epoch 26/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3675 - acc: 0.8448 - val_loss: 0.3643 - val_acc: 0.8346\n",
      "Epoch 27/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3682 - acc: 0.8419 - val_loss: 0.3578 - val_acc: 0.8527\n",
      "Epoch 28/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3577 - acc: 0.8457 - val_loss: 0.3672 - val_acc: 0.8442\n",
      "Epoch 29/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3587 - acc: 0.8479 - val_loss: 0.3563 - val_acc: 0.8434\n",
      "Epoch 30/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3584 - acc: 0.8427 - val_loss: 0.3616 - val_acc: 0.8496\n",
      "Epoch 31/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3641 - acc: 0.8423 - val_loss: 0.3597 - val_acc: 0.8485\n",
      "Epoch 32/90\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.3643 - acc: 0.8423 - val_loss: 0.3604 - val_acc: 0.8412\n",
      "Epoch 33/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3575 - acc: 0.8456 - val_loss: 0.4103 - val_acc: 0.8433\n",
      "Epoch 34/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3696 - acc: 0.8399 - val_loss: 0.3771 - val_acc: 0.8442\n",
      "Epoch 35/90\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.3552 - acc: 0.8476 - val_loss: 0.3649 - val_acc: 0.8487\n",
      "Epoch 36/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3553 - acc: 0.8498 - val_loss: 0.3678 - val_acc: 0.8381\n",
      "Epoch 37/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3643 - acc: 0.8455 - val_loss: 0.3806 - val_acc: 0.8479\n",
      "Epoch 38/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3682 - acc: 0.8446 - val_loss: 0.3339 - val_acc: 0.8658\n",
      "Epoch 39/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3512 - acc: 0.8506 - val_loss: 0.3604 - val_acc: 0.8498\n",
      "Epoch 40/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3558 - acc: 0.8444 - val_loss: 0.3581 - val_acc: 0.8510\n",
      "Epoch 41/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3423 - acc: 0.8538 - val_loss: 0.3697 - val_acc: 0.8425\n",
      "Epoch 42/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3512 - acc: 0.8474 - val_loss: 0.4007 - val_acc: 0.8419\n",
      "Epoch 43/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3543 - acc: 0.8468 - val_loss: 0.3710 - val_acc: 0.8504\n",
      "Epoch 44/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3529 - acc: 0.8517 - val_loss: 0.3558 - val_acc: 0.8452\n",
      "Epoch 45/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3620 - acc: 0.8462 - val_loss: 0.3481 - val_acc: 0.8537\n",
      "Epoch 46/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3458 - acc: 0.8466 - val_loss: 0.4236 - val_acc: 0.8213\n",
      "Epoch 47/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3560 - acc: 0.8445 - val_loss: 0.3676 - val_acc: 0.8470\n",
      "Epoch 48/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3546 - acc: 0.8459 - val_loss: 0.3472 - val_acc: 0.8592\n",
      "Epoch 49/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3398 - acc: 0.8593 - val_loss: 0.3448 - val_acc: 0.8606\n",
      "Epoch 50/90\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 0.3408 - acc: 0.8528 - val_loss: 0.3646 - val_acc: 0.8487\n",
      "Epoch 51/90\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.3409 - acc: 0.8523 - val_loss: 0.3829 - val_acc: 0.8465\n",
      "Epoch 52/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3426 - acc: 0.8502 - val_loss: 0.3522 - val_acc: 0.8463\n",
      "Epoch 53/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3551 - acc: 0.8458 - val_loss: 0.3675 - val_acc: 0.8385\n",
      "Epoch 54/90\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.3455 - acc: 0.8560 - val_loss: 0.3377 - val_acc: 0.8692\n",
      "Epoch 55/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3538 - acc: 0.8466 - val_loss: 0.3715 - val_acc: 0.8490\n",
      "Epoch 56/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3404 - acc: 0.8571 - val_loss: 0.3515 - val_acc: 0.8467\n",
      "Epoch 57/90\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.3394 - acc: 0.8541 - val_loss: 0.3502 - val_acc: 0.8569\n",
      "Epoch 58/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3409 - acc: 0.8567 - val_loss: 0.3505 - val_acc: 0.8627\n",
      "Epoch 59/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3407 - acc: 0.8554 - val_loss: 0.3653 - val_acc: 0.8540\n",
      "Epoch 60/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3336 - acc: 0.8588 - val_loss: 0.3338 - val_acc: 0.8613\n",
      "Epoch 61/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3392 - acc: 0.8591 - val_loss: 0.3314 - val_acc: 0.8612\n",
      "Epoch 62/90\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.3292 - acc: 0.8617 - val_loss: 0.3434 - val_acc: 0.8554\n",
      "Epoch 63/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3487 - acc: 0.8507 - val_loss: 0.3476 - val_acc: 0.8621\n",
      "Epoch 64/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3322 - acc: 0.8576 - val_loss: 0.3634 - val_acc: 0.8493\n",
      "Epoch 65/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3423 - acc: 0.8541 - val_loss: 0.3533 - val_acc: 0.8592\n",
      "Epoch 66/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3381 - acc: 0.8570 - val_loss: 0.3829 - val_acc: 0.8658\n",
      "Epoch 67/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3369 - acc: 0.8556 - val_loss: 0.3492 - val_acc: 0.8615\n",
      "Epoch 68/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3491 - acc: 0.8489 - val_loss: 0.3570 - val_acc: 0.8567\n",
      "Epoch 69/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3289 - acc: 0.8622 - val_loss: 0.3854 - val_acc: 0.8458\n",
      "Epoch 70/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3325 - acc: 0.8610 - val_loss: 0.3811 - val_acc: 0.8512\n",
      "Epoch 71/90\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.3340 - acc: 0.8590 - val_loss: 0.3531 - val_acc: 0.8533\n",
      "Epoch 72/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3434 - acc: 0.8538 - val_loss: 0.3401 - val_acc: 0.8573\n",
      "Epoch 73/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3335 - acc: 0.8569 - val_loss: 0.3482 - val_acc: 0.8569\n",
      "Epoch 74/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3381 - acc: 0.8565 - val_loss: 0.3598 - val_acc: 0.8548\n",
      "Epoch 75/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3323 - acc: 0.8582 - val_loss: 0.3570 - val_acc: 0.8523\n",
      "Epoch 76/90\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3238 - acc: 0.8623 - val_loss: 0.3561 - val_acc: 0.8601\n",
      "Epoch 77/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3337 - acc: 0.8573 - val_loss: 0.3636 - val_acc: 0.8496\n",
      "Epoch 78/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3356 - acc: 0.8561 - val_loss: 0.3343 - val_acc: 0.8675\n",
      "Epoch 79/90\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.3386 - acc: 0.8567 - val_loss: 0.3717 - val_acc: 0.8542\n",
      "Epoch 80/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3317 - acc: 0.8607 - val_loss: 0.3394 - val_acc: 0.8537\n",
      "Epoch 81/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3377 - acc: 0.8557 - val_loss: 0.3316 - val_acc: 0.8619\n",
      "Epoch 82/90\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3387 - acc: 0.8584 - val_loss: 0.3440 - val_acc: 0.8540\n",
      "Epoch 83/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3178 - acc: 0.8655 - val_loss: 0.3324 - val_acc: 0.8648\n",
      "Epoch 84/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3430 - acc: 0.8531 - val_loss: 0.3474 - val_acc: 0.8635\n",
      "Epoch 85/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3316 - acc: 0.8606 - val_loss: 0.3616 - val_acc: 0.8567\n",
      "Epoch 86/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3204 - acc: 0.8629 - val_loss: 0.3587 - val_acc: 0.8615\n",
      "Epoch 87/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3237 - acc: 0.8624 - val_loss: 0.3530 - val_acc: 0.8604\n",
      "Epoch 88/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3273 - acc: 0.8600 - val_loss: 0.3414 - val_acc: 0.8540\n",
      "Epoch 89/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3216 - acc: 0.8669 - val_loss: 0.3696 - val_acc: 0.8498\n",
      "Epoch 90/90\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3311 - acc: 0.8588 - val_loss: 0.3325 - val_acc: 0.8685\n",
      "\n",
      "Training process completed in: 0 h 8 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1228.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1230 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_277 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_277 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_278 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_279 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_279 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_280 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_280 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 90\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 149ms/step - loss: 0.5560 - acc: 0.7212 - val_loss: 0.5041 - val_acc: 0.7990\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4377 - acc: 0.8118 - val_loss: 0.5062 - val_acc: 0.8069\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4405 - acc: 0.8102 - val_loss: 0.4098 - val_acc: 0.8190\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4179 - acc: 0.8221 - val_loss: 0.4498 - val_acc: 0.8255\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4017 - acc: 0.8304 - val_loss: 0.4597 - val_acc: 0.8256\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4010 - acc: 0.8294 - val_loss: 0.4266 - val_acc: 0.8314\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.4055 - acc: 0.8251 - val_loss: 0.4359 - val_acc: 0.8218\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 9s 98ms/step - loss: 0.4015 - acc: 0.8276 - val_loss: 0.3947 - val_acc: 0.8295\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 9s 98ms/step - loss: 0.3991 - acc: 0.8304 - val_loss: 0.4362 - val_acc: 0.8316\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 9s 97ms/step - loss: 0.3923 - acc: 0.8303 - val_loss: 0.3945 - val_acc: 0.8366\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 9s 99ms/step - loss: 0.3859 - acc: 0.8353 - val_loss: 0.3999 - val_acc: 0.8409\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3743 - acc: 0.8393 - val_loss: 0.3933 - val_acc: 0.8322\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3849 - acc: 0.8368 - val_loss: 0.4001 - val_acc: 0.8424\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3770 - acc: 0.8374 - val_loss: 0.3959 - val_acc: 0.8356\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3710 - acc: 0.8419 - val_loss: 0.3936 - val_acc: 0.8449\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3675 - acc: 0.8449 - val_loss: 0.3602 - val_acc: 0.8475\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3664 - acc: 0.8423 - val_loss: 0.3823 - val_acc: 0.8410\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3677 - acc: 0.8457 - val_loss: 0.3816 - val_acc: 0.8512\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3692 - acc: 0.8452 - val_loss: 0.4038 - val_acc: 0.8439\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3596 - acc: 0.8456 - val_loss: 0.4266 - val_acc: 0.8221\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3683 - acc: 0.8456 - val_loss: 0.3728 - val_acc: 0.8473\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3688 - acc: 0.8454 - val_loss: 0.3987 - val_acc: 0.8462\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3543 - acc: 0.8466 - val_loss: 0.3710 - val_acc: 0.8460\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3507 - acc: 0.8498 - val_loss: 0.3674 - val_acc: 0.8476\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3458 - acc: 0.8546 - val_loss: 0.3645 - val_acc: 0.8472\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3462 - acc: 0.8540 - val_loss: 0.3740 - val_acc: 0.8567\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3419 - acc: 0.8549 - val_loss: 0.3626 - val_acc: 0.8573\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3484 - acc: 0.8548 - val_loss: 0.3719 - val_acc: 0.8470\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 9s 100ms/step - loss: 0.3540 - acc: 0.8480 - val_loss: 0.3898 - val_acc: 0.8419\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3430 - acc: 0.8528 - val_loss: 0.3965 - val_acc: 0.8478\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3482 - acc: 0.8541 - val_loss: 0.3613 - val_acc: 0.8568\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3462 - acc: 0.8537 - val_loss: 0.3599 - val_acc: 0.8569\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3433 - acc: 0.8537 - val_loss: 0.3538 - val_acc: 0.8543\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3425 - acc: 0.8534 - val_loss: 0.3533 - val_acc: 0.8515\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3345 - acc: 0.8561 - val_loss: 0.3469 - val_acc: 0.8609\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3432 - acc: 0.8536 - val_loss: 0.3599 - val_acc: 0.8458\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 9s 99ms/step - loss: 0.3485 - acc: 0.8543 - val_loss: 0.3673 - val_acc: 0.8636\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.3373 - acc: 0.8542 - val_loss: 0.3572 - val_acc: 0.8481\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3413 - acc: 0.8539 - val_loss: 0.3461 - val_acc: 0.8551\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3270 - acc: 0.8602 - val_loss: 0.3448 - val_acc: 0.8627\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3317 - acc: 0.8604 - val_loss: 0.3523 - val_acc: 0.8541\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3352 - acc: 0.8598 - val_loss: 0.3906 - val_acc: 0.8442\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 9s 100ms/step - loss: 0.3366 - acc: 0.8576 - val_loss: 0.3429 - val_acc: 0.8581\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3278 - acc: 0.8606 - val_loss: 0.3482 - val_acc: 0.8672\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 9s 100ms/step - loss: 0.3396 - acc: 0.8580 - val_loss: 0.3485 - val_acc: 0.8538\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3344 - acc: 0.8581 - val_loss: 0.3465 - val_acc: 0.8599\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3307 - acc: 0.8597 - val_loss: 0.3685 - val_acc: 0.8486\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3381 - acc: 0.8570 - val_loss: 0.4032 - val_acc: 0.8376\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3277 - acc: 0.8604 - val_loss: 0.3538 - val_acc: 0.8585\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3270 - acc: 0.8594 - val_loss: 0.3373 - val_acc: 0.8666\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3264 - acc: 0.8619 - val_loss: 0.3792 - val_acc: 0.8525\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3259 - acc: 0.8631 - val_loss: 0.3348 - val_acc: 0.8623\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 0.3338 - acc: 0.8576 - val_loss: 0.3783 - val_acc: 0.8427\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3270 - acc: 0.8612 - val_loss: 0.3406 - val_acc: 0.8669\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3287 - acc: 0.8587 - val_loss: 0.3429 - val_acc: 0.8593\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3264 - acc: 0.8597 - val_loss: 0.3666 - val_acc: 0.8602\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3200 - acc: 0.8638 - val_loss: 0.3866 - val_acc: 0.8501\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3349 - acc: 0.8561 - val_loss: 0.3374 - val_acc: 0.8648\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 9s 100ms/step - loss: 0.3191 - acc: 0.8667 - val_loss: 0.3465 - val_acc: 0.8605\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3265 - acc: 0.8584 - val_loss: 0.3635 - val_acc: 0.8607\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3267 - acc: 0.8628 - val_loss: 0.3529 - val_acc: 0.8631\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3277 - acc: 0.8595 - val_loss: 0.3531 - val_acc: 0.8590\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3200 - acc: 0.8658 - val_loss: 0.3722 - val_acc: 0.8580\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3303 - acc: 0.8578 - val_loss: 0.3555 - val_acc: 0.8600\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3216 - acc: 0.8649 - val_loss: 0.3387 - val_acc: 0.8645\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3145 - acc: 0.8676 - val_loss: 0.3539 - val_acc: 0.8594\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3279 - acc: 0.8612 - val_loss: 0.3726 - val_acc: 0.8564\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3234 - acc: 0.8639 - val_loss: 0.3524 - val_acc: 0.8486\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3126 - acc: 0.8679 - val_loss: 0.3345 - val_acc: 0.8688\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3263 - acc: 0.8595 - val_loss: 0.3426 - val_acc: 0.8626\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3223 - acc: 0.8643 - val_loss: 0.3545 - val_acc: 0.8640\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3271 - acc: 0.8598 - val_loss: 0.3405 - val_acc: 0.8654\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3201 - acc: 0.8653 - val_loss: 0.3739 - val_acc: 0.8488\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3290 - acc: 0.8601 - val_loss: 0.3457 - val_acc: 0.8545\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.3168 - acc: 0.8679 - val_loss: 0.3818 - val_acc: 0.8490\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3205 - acc: 0.8653 - val_loss: 0.3666 - val_acc: 0.8514\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3199 - acc: 0.8656 - val_loss: 0.3325 - val_acc: 0.8632\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3277 - acc: 0.8626 - val_loss: 0.3335 - val_acc: 0.8674\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3187 - acc: 0.8644 - val_loss: 0.3437 - val_acc: 0.8672\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3212 - acc: 0.8634 - val_loss: 0.3362 - val_acc: 0.8652\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3175 - acc: 0.8679 - val_loss: 0.3659 - val_acc: 0.8625\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3221 - acc: 0.8624 - val_loss: 0.3411 - val_acc: 0.8718\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3232 - acc: 0.8636 - val_loss: 0.3448 - val_acc: 0.8611\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3220 - acc: 0.8619 - val_loss: 0.3429 - val_acc: 0.8613\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3153 - acc: 0.8678 - val_loss: 0.3389 - val_acc: 0.8691\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3155 - acc: 0.8645 - val_loss: 0.3248 - val_acc: 0.8689\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3222 - acc: 0.8633 - val_loss: 0.3401 - val_acc: 0.8603\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3162 - acc: 0.8659 - val_loss: 0.3491 - val_acc: 0.8624\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3204 - acc: 0.8641 - val_loss: 0.3330 - val_acc: 0.8684\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.3257 - acc: 0.8619 - val_loss: 0.3406 - val_acc: 0.8621\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3054 - acc: 0.8709 - val_loss: 0.3211 - val_acc: 0.8711\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3260 - acc: 0.8614 - val_loss: 0.3285 - val_acc: 0.8700\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.3140 - acc: 0.8691 - val_loss: 0.3618 - val_acc: 0.8676\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3106 - acc: 0.8678 - val_loss: 0.3456 - val_acc: 0.8623\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3160 - acc: 0.8667 - val_loss: 0.3663 - val_acc: 0.8553\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3141 - acc: 0.8679 - val_loss: 0.3256 - val_acc: 0.8689\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3083 - acc: 0.8708 - val_loss: 0.3211 - val_acc: 0.8695\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3106 - acc: 0.8662 - val_loss: 0.3210 - val_acc: 0.8612\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.3089 - acc: 0.8681 - val_loss: 0.3260 - val_acc: 0.8647\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.3075 - acc: 0.8701 - val_loss: 0.3491 - val_acc: 0.8618\n",
      "\n",
      "Training process completed in: 0 h 15 m 26 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1229.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1231 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_281 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_281 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_282 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_282 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_283 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_283 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_284 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_284 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.5127 - acc: 0.7590 - val_loss: 0.4322 - val_acc: 0.8207\n",
      "Epoch 2/80\n",
      "160/160 [==============================] - 9s 55ms/step - loss: 0.4275 - acc: 0.8192 - val_loss: 0.4174 - val_acc: 0.8307\n",
      "Epoch 3/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.4045 - acc: 0.8282 - val_loss: 0.4062 - val_acc: 0.8207\n",
      "Epoch 4/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3937 - acc: 0.8293 - val_loss: 0.4090 - val_acc: 0.8321\n",
      "Epoch 5/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3976 - acc: 0.8288 - val_loss: 0.4318 - val_acc: 0.8093\n",
      "Epoch 6/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3872 - acc: 0.8367 - val_loss: 0.3635 - val_acc: 0.8479\n",
      "Epoch 7/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3904 - acc: 0.8316 - val_loss: 0.3702 - val_acc: 0.8379\n",
      "Epoch 8/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3868 - acc: 0.8310 - val_loss: 0.4029 - val_acc: 0.8457\n",
      "Epoch 9/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3798 - acc: 0.8354 - val_loss: 0.4055 - val_acc: 0.8207\n",
      "Epoch 10/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3896 - acc: 0.8326 - val_loss: 0.3729 - val_acc: 0.8343\n",
      "Epoch 11/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3745 - acc: 0.8425 - val_loss: 0.3477 - val_acc: 0.8557\n",
      "Epoch 12/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3755 - acc: 0.8403 - val_loss: 0.3696 - val_acc: 0.8329\n",
      "Epoch 13/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3670 - acc: 0.8431 - val_loss: 0.3938 - val_acc: 0.8293\n",
      "Epoch 14/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3720 - acc: 0.8417 - val_loss: 0.3841 - val_acc: 0.8429\n",
      "Epoch 15/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3570 - acc: 0.8492 - val_loss: 0.4007 - val_acc: 0.8236\n",
      "Epoch 16/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3698 - acc: 0.8450 - val_loss: 0.3486 - val_acc: 0.8486\n",
      "Epoch 17/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3597 - acc: 0.8473 - val_loss: 0.4076 - val_acc: 0.8536\n",
      "Epoch 18/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3628 - acc: 0.8476 - val_loss: 0.4251 - val_acc: 0.8164\n",
      "Epoch 19/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3666 - acc: 0.8434 - val_loss: 0.3674 - val_acc: 0.8407\n",
      "Epoch 20/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3597 - acc: 0.8479 - val_loss: 0.4085 - val_acc: 0.8367\n",
      "Epoch 21/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3540 - acc: 0.8506 - val_loss: 0.3726 - val_acc: 0.8514\n",
      "Epoch 22/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3584 - acc: 0.8452 - val_loss: 0.3404 - val_acc: 0.8607\n",
      "Epoch 23/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3482 - acc: 0.8544 - val_loss: 0.3782 - val_acc: 0.8514\n",
      "Epoch 24/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3467 - acc: 0.8530 - val_loss: 0.3842 - val_acc: 0.8486\n",
      "Epoch 25/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3444 - acc: 0.8555 - val_loss: 0.3740 - val_acc: 0.8500\n",
      "Epoch 26/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3468 - acc: 0.8518 - val_loss: 0.4026 - val_acc: 0.8286\n",
      "Epoch 27/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3547 - acc: 0.8496 - val_loss: 0.3420 - val_acc: 0.8571\n",
      "Epoch 28/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3475 - acc: 0.8513 - val_loss: 0.3513 - val_acc: 0.8593\n",
      "Epoch 29/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3486 - acc: 0.8541 - val_loss: 0.3447 - val_acc: 0.8564\n",
      "Epoch 30/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3454 - acc: 0.8543 - val_loss: 0.3450 - val_acc: 0.8521\n",
      "Epoch 31/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3484 - acc: 0.8533 - val_loss: 0.3774 - val_acc: 0.8514\n",
      "Epoch 32/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3448 - acc: 0.8525 - val_loss: 0.3422 - val_acc: 0.8679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3377 - acc: 0.8586 - val_loss: 0.3645 - val_acc: 0.8529\n",
      "Epoch 34/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3458 - acc: 0.8535 - val_loss: 0.3593 - val_acc: 0.8521\n",
      "Epoch 35/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3350 - acc: 0.8579 - val_loss: 0.3609 - val_acc: 0.8743\n",
      "Epoch 36/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3449 - acc: 0.8517 - val_loss: 0.3748 - val_acc: 0.8371\n",
      "Epoch 37/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3384 - acc: 0.8567 - val_loss: 0.3618 - val_acc: 0.8436\n",
      "Epoch 38/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3366 - acc: 0.8573 - val_loss: 0.3262 - val_acc: 0.8679\n",
      "Epoch 39/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3366 - acc: 0.8577 - val_loss: 0.3460 - val_acc: 0.8507\n",
      "Epoch 40/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3343 - acc: 0.8587 - val_loss: 0.3416 - val_acc: 0.8467\n",
      "Epoch 41/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3364 - acc: 0.8570 - val_loss: 0.3355 - val_acc: 0.8629\n",
      "Epoch 42/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3293 - acc: 0.8618 - val_loss: 0.3362 - val_acc: 0.8693\n",
      "Epoch 43/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3355 - acc: 0.8581 - val_loss: 0.3368 - val_acc: 0.8650\n",
      "Epoch 44/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3346 - acc: 0.8566 - val_loss: 0.4158 - val_acc: 0.8243\n",
      "Epoch 45/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3307 - acc: 0.8600 - val_loss: 0.3607 - val_acc: 0.8629\n",
      "Epoch 46/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3360 - acc: 0.8570 - val_loss: 0.3788 - val_acc: 0.8443\n",
      "Epoch 47/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3327 - acc: 0.8598 - val_loss: 0.3752 - val_acc: 0.8429\n",
      "Epoch 48/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3409 - acc: 0.8539 - val_loss: 0.3663 - val_acc: 0.8479\n",
      "Epoch 49/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3417 - acc: 0.8564 - val_loss: 0.4157 - val_acc: 0.8286\n",
      "Epoch 50/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3326 - acc: 0.8589 - val_loss: 0.3948 - val_acc: 0.8386\n",
      "Epoch 51/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3267 - acc: 0.8629 - val_loss: 0.3574 - val_acc: 0.8607\n",
      "Epoch 52/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3264 - acc: 0.8615 - val_loss: 0.3134 - val_acc: 0.8721\n",
      "Epoch 53/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3261 - acc: 0.8593 - val_loss: 0.3475 - val_acc: 0.8586\n",
      "Epoch 54/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3245 - acc: 0.8629 - val_loss: 0.3486 - val_acc: 0.8700\n",
      "Epoch 55/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3425 - acc: 0.8538 - val_loss: 0.3397 - val_acc: 0.8679\n",
      "Epoch 56/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3218 - acc: 0.8655 - val_loss: 0.3448 - val_acc: 0.8400\n",
      "Epoch 57/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3292 - acc: 0.8596 - val_loss: 0.3653 - val_acc: 0.8543\n",
      "Epoch 58/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3247 - acc: 0.8650 - val_loss: 0.3299 - val_acc: 0.8614\n",
      "Epoch 59/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3269 - acc: 0.8594 - val_loss: 0.3471 - val_acc: 0.8650\n",
      "Epoch 60/80\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3298 - acc: 0.8601 - val_loss: 0.3543 - val_acc: 0.8421\n",
      "Epoch 61/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3311 - acc: 0.8591 - val_loss: 0.3620 - val_acc: 0.8586\n",
      "Epoch 62/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3321 - acc: 0.8577 - val_loss: 0.3419 - val_acc: 0.8657\n",
      "Epoch 63/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3198 - acc: 0.8625 - val_loss: 0.3415 - val_acc: 0.8457\n",
      "Epoch 64/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3248 - acc: 0.8623 - val_loss: 0.3325 - val_acc: 0.8679\n",
      "Epoch 65/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3245 - acc: 0.8615 - val_loss: 0.3444 - val_acc: 0.8607\n",
      "Epoch 66/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3189 - acc: 0.8671 - val_loss: 0.3599 - val_acc: 0.8486\n",
      "Epoch 67/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3222 - acc: 0.8626 - val_loss: 0.3093 - val_acc: 0.8664\n",
      "Epoch 68/80\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3190 - acc: 0.8655 - val_loss: 0.3351 - val_acc: 0.8571\n",
      "Epoch 69/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3278 - acc: 0.8592 - val_loss: 0.3393 - val_acc: 0.8764\n",
      "Epoch 70/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3099 - acc: 0.8712 - val_loss: 0.3320 - val_acc: 0.8750\n",
      "Epoch 71/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3137 - acc: 0.8668 - val_loss: 0.3428 - val_acc: 0.8621\n",
      "Epoch 72/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3134 - acc: 0.8685 - val_loss: 0.3297 - val_acc: 0.8607\n",
      "Epoch 73/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3189 - acc: 0.8642 - val_loss: 0.3507 - val_acc: 0.8543\n",
      "Epoch 74/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3201 - acc: 0.8638 - val_loss: 0.3783 - val_acc: 0.8457\n",
      "Epoch 75/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3261 - acc: 0.8587 - val_loss: 0.3419 - val_acc: 0.8650\n",
      "Epoch 76/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3236 - acc: 0.8626 - val_loss: 0.3395 - val_acc: 0.8707\n",
      "Epoch 77/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3140 - acc: 0.8665 - val_loss: 0.3579 - val_acc: 0.8521\n",
      "Epoch 78/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3188 - acc: 0.8663 - val_loss: 0.3347 - val_acc: 0.8679\n",
      "Epoch 79/80\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3147 - acc: 0.8661 - val_loss: 0.3319 - val_acc: 0.8764\n",
      "Epoch 80/80\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 0.3184 - acc: 0.8626 - val_loss: 0.3289 - val_acc: 0.8615\n",
      "\n",
      "Training process completed in: 0 h 12 m 36 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1230.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1232 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_285 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_285 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_286 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_286 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_287 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_287 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_288 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_288 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.5312 - acc: 0.7429 - val_loss: 0.4557 - val_acc: 0.8014\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.4310 - acc: 0.8176 - val_loss: 0.4152 - val_acc: 0.8203\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.4154 - acc: 0.8208 - val_loss: 0.4125 - val_acc: 0.8229\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.4048 - acc: 0.8276 - val_loss: 0.3944 - val_acc: 0.8365\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3973 - acc: 0.8321 - val_loss: 0.4345 - val_acc: 0.8313\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.4014 - acc: 0.8282 - val_loss: 0.3999 - val_acc: 0.8313\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3842 - acc: 0.8343 - val_loss: 0.3825 - val_acc: 0.8367\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3810 - acc: 0.8329 - val_loss: 0.4062 - val_acc: 0.8360\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3843 - acc: 0.8367 - val_loss: 0.4007 - val_acc: 0.8179\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3789 - acc: 0.8390 - val_loss: 0.3867 - val_acc: 0.8389\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3709 - acc: 0.8395 - val_loss: 0.3676 - val_acc: 0.8369\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3659 - acc: 0.8434 - val_loss: 0.3889 - val_acc: 0.8476\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3641 - acc: 0.8419 - val_loss: 0.3759 - val_acc: 0.8386\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3631 - acc: 0.8417 - val_loss: 0.3871 - val_acc: 0.8466\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3695 - acc: 0.8435 - val_loss: 0.3745 - val_acc: 0.8420\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3568 - acc: 0.8481 - val_loss: 0.3676 - val_acc: 0.8426\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3546 - acc: 0.8495 - val_loss: 0.3634 - val_acc: 0.8520\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3646 - acc: 0.8452 - val_loss: 0.3564 - val_acc: 0.8457\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3527 - acc: 0.8485 - val_loss: 0.3898 - val_acc: 0.8416\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3562 - acc: 0.8479 - val_loss: 0.3632 - val_acc: 0.8445\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3414 - acc: 0.8548 - val_loss: 0.3701 - val_acc: 0.8524\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 11s 72ms/step - loss: 0.3508 - acc: 0.8520 - val_loss: 0.3507 - val_acc: 0.8549\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3471 - acc: 0.8508 - val_loss: 0.3580 - val_acc: 0.8506\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 11s 72ms/step - loss: 0.3510 - acc: 0.8532 - val_loss: 0.3498 - val_acc: 0.8606\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3465 - acc: 0.8538 - val_loss: 0.3771 - val_acc: 0.8521\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3458 - acc: 0.8539 - val_loss: 0.3659 - val_acc: 0.8549\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3390 - acc: 0.8557 - val_loss: 0.3499 - val_acc: 0.8553\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3402 - acc: 0.8598 - val_loss: 0.3554 - val_acc: 0.8530\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3429 - acc: 0.8546 - val_loss: 0.3605 - val_acc: 0.8553\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 11s 72ms/step - loss: 0.3405 - acc: 0.8558 - val_loss: 0.3720 - val_acc: 0.8509\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3398 - acc: 0.8573 - val_loss: 0.3560 - val_acc: 0.8630\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3425 - acc: 0.8566 - val_loss: 0.3664 - val_acc: 0.8366\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3401 - acc: 0.8550 - val_loss: 0.3725 - val_acc: 0.8553\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3331 - acc: 0.8568 - val_loss: 0.3362 - val_acc: 0.8539\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3384 - acc: 0.8566 - val_loss: 0.3454 - val_acc: 0.8584\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3340 - acc: 0.8596 - val_loss: 0.3358 - val_acc: 0.8642\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3328 - acc: 0.8582 - val_loss: 0.3375 - val_acc: 0.8564\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3389 - acc: 0.8565 - val_loss: 0.3515 - val_acc: 0.8541\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3312 - acc: 0.8598 - val_loss: 0.3524 - val_acc: 0.8619\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3340 - acc: 0.8567 - val_loss: 0.3460 - val_acc: 0.8633\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3287 - acc: 0.8608 - val_loss: 0.3749 - val_acc: 0.8457\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3297 - acc: 0.8623 - val_loss: 0.3391 - val_acc: 0.8606\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3278 - acc: 0.8602 - val_loss: 0.3412 - val_acc: 0.8569\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3408 - acc: 0.8539 - val_loss: 0.3295 - val_acc: 0.8629\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3257 - acc: 0.8626 - val_loss: 0.3347 - val_acc: 0.8600\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3289 - acc: 0.8613 - val_loss: 0.3390 - val_acc: 0.8644\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 11s 68ms/step - loss: 0.3245 - acc: 0.8614 - val_loss: 0.3348 - val_acc: 0.8600\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 11s 69ms/step - loss: 0.3275 - acc: 0.8611 - val_loss: 0.3541 - val_acc: 0.8497\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 11s 70ms/step - loss: 0.3243 - acc: 0.8601 - val_loss: 0.3394 - val_acc: 0.8604\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 11s 71ms/step - loss: 0.3295 - acc: 0.8600 - val_loss: 0.3603 - val_acc: 0.8597\n",
      "\n",
      "Training process completed in: 0 h 9 m 24 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1231.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1233 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_289 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_289 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_290 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_290 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_291 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_292 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_292 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.5235 - acc: 0.7495 - val_loss: 0.4388 - val_acc: 0.8014\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4285 - acc: 0.8216 - val_loss: 0.4854 - val_acc: 0.8129\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.4130 - acc: 0.8219 - val_loss: 0.4246 - val_acc: 0.8164\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.4089 - acc: 0.8256 - val_loss: 0.3899 - val_acc: 0.8421\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3982 - acc: 0.8306 - val_loss: 0.4045 - val_acc: 0.8179\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3880 - acc: 0.8336 - val_loss: 0.3735 - val_acc: 0.8364\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3849 - acc: 0.8371 - val_loss: 0.3906 - val_acc: 0.8400\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3757 - acc: 0.8401 - val_loss: 0.3670 - val_acc: 0.8543\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3734 - acc: 0.8406 - val_loss: 0.4453 - val_acc: 0.8379\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.3635 - acc: 0.8460 - val_loss: 0.3772 - val_acc: 0.8421\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3710 - acc: 0.8420 - val_loss: 0.3527 - val_acc: 0.8543\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3701 - acc: 0.8400 - val_loss: 0.3918 - val_acc: 0.8414\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3540 - acc: 0.8517 - val_loss: 0.3797 - val_acc: 0.8407\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3555 - acc: 0.8472 - val_loss: 0.3807 - val_acc: 0.8221\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3771 - acc: 0.8391 - val_loss: 0.4237 - val_acc: 0.8307\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3579 - acc: 0.8459 - val_loss: 0.3488 - val_acc: 0.8557\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3558 - acc: 0.8473 - val_loss: 0.3586 - val_acc: 0.8586\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3516 - acc: 0.8513 - val_loss: 0.3791 - val_acc: 0.8407\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3642 - acc: 0.8447 - val_loss: 0.3616 - val_acc: 0.8493\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3468 - acc: 0.8532 - val_loss: 0.3462 - val_acc: 0.8514\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3502 - acc: 0.8497 - val_loss: 0.3653 - val_acc: 0.8407\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3422 - acc: 0.8563 - val_loss: 0.3475 - val_acc: 0.8607\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3406 - acc: 0.8582 - val_loss: 0.3566 - val_acc: 0.8507\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3463 - acc: 0.8521 - val_loss: 0.3243 - val_acc: 0.8657\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3407 - acc: 0.8549 - val_loss: 0.3480 - val_acc: 0.8579\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3516 - acc: 0.8517 - val_loss: 0.3658 - val_acc: 0.8543\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3457 - acc: 0.8543 - val_loss: 0.3342 - val_acc: 0.8600\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3430 - acc: 0.8541 - val_loss: 0.3272 - val_acc: 0.8671\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3376 - acc: 0.8554 - val_loss: 0.3589 - val_acc: 0.8493\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3290 - acc: 0.8634 - val_loss: 0.3488 - val_acc: 0.8357\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3393 - acc: 0.8564 - val_loss: 0.3464 - val_acc: 0.8564\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3300 - acc: 0.8606 - val_loss: 0.3235 - val_acc: 0.8686\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3394 - acc: 0.8554 - val_loss: 0.3684 - val_acc: 0.8486\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3367 - acc: 0.8570 - val_loss: 0.3331 - val_acc: 0.8643\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3260 - acc: 0.8628 - val_loss: 0.3748 - val_acc: 0.8364\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3237 - acc: 0.8639 - val_loss: 0.3612 - val_acc: 0.8386\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3291 - acc: 0.8572 - val_loss: 0.3453 - val_acc: 0.8464\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3373 - acc: 0.8568 - val_loss: 0.3280 - val_acc: 0.8657\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3304 - acc: 0.8588 - val_loss: 0.3239 - val_acc: 0.8650\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.3399 - acc: 0.8575 - val_loss: 0.3470 - val_acc: 0.8522\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3295 - acc: 0.8604 - val_loss: 0.3406 - val_acc: 0.8557\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3224 - acc: 0.8639 - val_loss: 0.3260 - val_acc: 0.8621\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3231 - acc: 0.8587 - val_loss: 0.3348 - val_acc: 0.8621\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3193 - acc: 0.8657 - val_loss: 0.3632 - val_acc: 0.8471\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3284 - acc: 0.8593 - val_loss: 0.3165 - val_acc: 0.8564\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3301 - acc: 0.8604 - val_loss: 0.3297 - val_acc: 0.8729\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3193 - acc: 0.8649 - val_loss: 0.3258 - val_acc: 0.8657\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3268 - acc: 0.8631 - val_loss: 0.3140 - val_acc: 0.8779\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.3187 - acc: 0.8624 - val_loss: 0.3293 - val_acc: 0.8664\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.3213 - acc: 0.8646 - val_loss: 0.3404 - val_acc: 0.8614\n",
      "\n",
      "Training process completed in: 0 h 7 m 53 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1232.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1234 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_293 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_293 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_294 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_294 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_295 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_295 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_296 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_74 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 30\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 17s 94ms/step - loss: 0.4990 - acc: 0.7637 - val_loss: 0.4235 - val_acc: 0.8146\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.4393 - acc: 0.8121 - val_loss: 0.4402 - val_acc: 0.8166\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.4151 - acc: 0.8214 - val_loss: 0.4313 - val_acc: 0.8249\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.4056 - acc: 0.8256 - val_loss: 0.4474 - val_acc: 0.8224- l\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3954 - acc: 0.8279 - val_loss: 0.4375 - val_acc: 0.8253\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3933 - acc: 0.8303 - val_loss: 0.4161 - val_acc: 0.8170\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3827 - acc: 0.8360 - val_loss: 0.3767 - val_acc: 0.8450\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3958 - acc: 0.8304 - val_loss: 0.4291 - val_acc: 0.8244\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3788 - acc: 0.8377 - val_loss: 0.3870 - val_acc: 0.8350\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3764 - acc: 0.8390 - val_loss: 0.4115 - val_acc: 0.8360\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3683 - acc: 0.8429 - val_loss: 0.4144 - val_acc: 0.8404\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3695 - acc: 0.8419 - val_loss: 0.3741 - val_acc: 0.8580\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3737 - acc: 0.8395 - val_loss: 0.3733 - val_acc: 0.8477\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3624 - acc: 0.8451 - val_loss: 0.3631 - val_acc: 0.8443\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3632 - acc: 0.8424 - val_loss: 0.3575 - val_acc: 0.8571\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3623 - acc: 0.8453 - val_loss: 0.3681 - val_acc: 0.8511\n",
      "Epoch 17/30\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3573 - acc: 0.8487 - val_loss: 0.3609 - val_acc: 0.8533\n",
      "Epoch 18/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3553 - acc: 0.8485 - val_loss: 0.3742 - val_acc: 0.8550\n",
      "Epoch 19/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3576 - acc: 0.8452 - val_loss: 0.3874 - val_acc: 0.8446\n",
      "Epoch 20/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3520 - acc: 0.8505 - val_loss: 0.3596 - val_acc: 0.8495\n",
      "Epoch 21/30\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3391 - acc: 0.8561 - val_loss: 0.4334 - val_acc: 0.8274\n",
      "Epoch 22/30\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3430 - acc: 0.8531 - val_loss: 0.3432 - val_acc: 0.8574\n",
      "Epoch 23/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3528 - acc: 0.8509 - val_loss: 0.3562 - val_acc: 0.8496\n",
      "Epoch 24/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3547 - acc: 0.8471 - val_loss: 0.3319 - val_acc: 0.8668\n",
      "Epoch 25/30\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3353 - acc: 0.8579 - val_loss: 0.3527 - val_acc: 0.8607\n",
      "Epoch 26/30\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 0.3346 - acc: 0.8593 - val_loss: 0.3716 - val_acc: 0.8580\n",
      "Epoch 27/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3394 - acc: 0.8566 - val_loss: 0.3534 - val_acc: 0.8644\n",
      "Epoch 28/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3302 - acc: 0.8572 - val_loss: 0.3470 - val_acc: 0.8648\n",
      "Epoch 29/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3341 - acc: 0.8590 - val_loss: 0.3420 - val_acc: 0.8577\n",
      "Epoch 30/30\n",
      "180/180 [==============================] - 12s 69ms/step - loss: 0.3247 - acc: 0.8610 - val_loss: 0.3698 - val_acc: 0.8546\n",
      "\n",
      "Training process completed in: 0 h 6 m 15 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1233.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1235 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_297 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_297 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_298 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_298 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_299 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_299 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_300 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.5536 - acc: 0.7232 - val_loss: 0.4656 - val_acc: 0.7925\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4530 - acc: 0.8001 - val_loss: 0.4430 - val_acc: 0.8085\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4265 - acc: 0.8149 - val_loss: 0.4224 - val_acc: 0.8163\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4240 - acc: 0.8178 - val_loss: 0.4132 - val_acc: 0.8190\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4100 - acc: 0.8283 - val_loss: 0.4221 - val_acc: 0.8230\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4069 - acc: 0.8257 - val_loss: 0.4009 - val_acc: 0.8307\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4088 - acc: 0.8267 - val_loss: 0.4236 - val_acc: 0.8105\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4116 - acc: 0.8227 - val_loss: 0.4029 - val_acc: 0.8352\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4069 - acc: 0.8258 - val_loss: 0.4063 - val_acc: 0.8245\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4014 - acc: 0.8282 - val_loss: 0.4047 - val_acc: 0.8205\n",
      "Epoch 11/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3961 - acc: 0.8291 - val_loss: 0.3934 - val_acc: 0.8317\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3900 - acc: 0.8331 - val_loss: 0.4064 - val_acc: 0.8307\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3904 - acc: 0.8333 - val_loss: 0.3808 - val_acc: 0.8347\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4013 - acc: 0.8279 - val_loss: 0.3919 - val_acc: 0.8368\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3906 - acc: 0.8316 - val_loss: 0.3871 - val_acc: 0.8298\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3835 - acc: 0.8361 - val_loss: 0.3840 - val_acc: 0.8358\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3903 - acc: 0.8334 - val_loss: 0.4021 - val_acc: 0.8277\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3852 - acc: 0.8345 - val_loss: 0.4075 - val_acc: 0.8200\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3781 - acc: 0.8392 - val_loss: 0.3619 - val_acc: 0.8455\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3837 - acc: 0.8354 - val_loss: 0.3745 - val_acc: 0.8397\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3788 - acc: 0.8372 - val_loss: 0.3786 - val_acc: 0.8325\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3833 - acc: 0.8328 - val_loss: 0.3918 - val_acc: 0.8280\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3854 - acc: 0.8366 - val_loss: 0.3913 - val_acc: 0.8298\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3729 - acc: 0.8393 - val_loss: 0.3725 - val_acc: 0.8455\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3684 - acc: 0.8416 - val_loss: 0.3900 - val_acc: 0.8188\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3694 - acc: 0.8417 - val_loss: 0.3628 - val_acc: 0.8485\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3786 - acc: 0.8372 - val_loss: 0.3602 - val_acc: 0.8428\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3662 - acc: 0.8428 - val_loss: 0.3712 - val_acc: 0.8446\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3696 - acc: 0.8402 - val_loss: 0.3706 - val_acc: 0.8465\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3645 - acc: 0.8444 - val_loss: 0.3610 - val_acc: 0.8475\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3624 - acc: 0.8462 - val_loss: 0.3536 - val_acc: 0.8460\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3594 - acc: 0.8461 - val_loss: 0.3574 - val_acc: 0.8545\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3556 - acc: 0.8482 - val_loss: 0.3590 - val_acc: 0.8460\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3542 - acc: 0.8492 - val_loss: 0.3528 - val_acc: 0.8507\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3605 - acc: 0.8474 - val_loss: 0.3546 - val_acc: 0.8449\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3500 - acc: 0.8519 - val_loss: 0.3628 - val_acc: 0.8453\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3551 - acc: 0.8518 - val_loss: 0.3598 - val_acc: 0.8460\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3555 - acc: 0.8493 - val_loss: 0.3360 - val_acc: 0.8528\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3489 - acc: 0.8530 - val_loss: 0.3429 - val_acc: 0.8505\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3504 - acc: 0.8501 - val_loss: 0.3560 - val_acc: 0.8495\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3438 - acc: 0.8532 - val_loss: 0.3477 - val_acc: 0.8457\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3478 - acc: 0.8511 - val_loss: 0.3266 - val_acc: 0.8606\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3458 - acc: 0.8502 - val_loss: 0.3498 - val_acc: 0.8507\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3492 - acc: 0.8504 - val_loss: 0.3656 - val_acc: 0.8403\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3473 - acc: 0.8523 - val_loss: 0.3385 - val_acc: 0.8545\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3378 - acc: 0.8562 - val_loss: 0.3535 - val_acc: 0.8578\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3408 - acc: 0.8528 - val_loss: 0.3394 - val_acc: 0.8600\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3351 - acc: 0.8575 - val_loss: 0.3314 - val_acc: 0.8537\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3372 - acc: 0.8559 - val_loss: 0.3446 - val_acc: 0.8522\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3459 - acc: 0.8534 - val_loss: 0.3339 - val_acc: 0.8615\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3454 - acc: 0.8514 - val_loss: 0.3278 - val_acc: 0.8647\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3476 - acc: 0.8507 - val_loss: 0.3448 - val_acc: 0.8545\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3375 - acc: 0.8587 - val_loss: 0.3427 - val_acc: 0.8527\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3298 - acc: 0.8595 - val_loss: 0.3348 - val_acc: 0.8555\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3377 - acc: 0.8558 - val_loss: 0.3331 - val_acc: 0.8585\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3366 - acc: 0.8558 - val_loss: 0.3348 - val_acc: 0.8537\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3341 - acc: 0.8577 - val_loss: 0.3336 - val_acc: 0.8545\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3366 - acc: 0.8589 - val_loss: 0.3273 - val_acc: 0.8573\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3290 - acc: 0.8608 - val_loss: 0.3600 - val_acc: 0.8462\n",
      "Epoch 60/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3365 - acc: 0.8579 - val_loss: 0.3488 - val_acc: 0.8595\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3246 - acc: 0.8632 - val_loss: 0.3221 - val_acc: 0.8660\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3378 - acc: 0.8551 - val_loss: 0.3390 - val_acc: 0.8535\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3336 - acc: 0.8588 - val_loss: 0.3135 - val_acc: 0.8707\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3328 - acc: 0.8584 - val_loss: 0.3259 - val_acc: 0.8575\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3291 - acc: 0.8622 - val_loss: 0.3328 - val_acc: 0.8565\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3340 - acc: 0.8584 - val_loss: 0.3213 - val_acc: 0.8628\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3261 - acc: 0.8631 - val_loss: 0.3432 - val_acc: 0.8528\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3373 - acc: 0.8541 - val_loss: 0.3384 - val_acc: 0.8612\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3318 - acc: 0.8576 - val_loss: 0.3246 - val_acc: 0.8625\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3238 - acc: 0.8635 - val_loss: 0.3209 - val_acc: 0.8598\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3280 - acc: 0.8600 - val_loss: 0.3691 - val_acc: 0.8353\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3256 - acc: 0.8619 - val_loss: 0.3155 - val_acc: 0.8690\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3272 - acc: 0.8617 - val_loss: 0.3197 - val_acc: 0.8637\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3219 - acc: 0.8632 - val_loss: 0.3242 - val_acc: 0.8670\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3198 - acc: 0.8623 - val_loss: 0.3252 - val_acc: 0.8657\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3370 - acc: 0.8558 - val_loss: 0.3678 - val_acc: 0.8435\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3254 - acc: 0.8628 - val_loss: 0.3324 - val_acc: 0.8550\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3205 - acc: 0.8637 - val_loss: 0.3270 - val_acc: 0.8618\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3244 - acc: 0.8593 - val_loss: 0.3151 - val_acc: 0.8672\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3204 - acc: 0.8648 - val_loss: 0.3265 - val_acc: 0.8628\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3265 - acc: 0.8611 - val_loss: 0.3291 - val_acc: 0.8627\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3213 - acc: 0.8644 - val_loss: 0.3213 - val_acc: 0.8640\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 9s 49ms/step - loss: 0.3313 - acc: 0.8579 - val_loss: 0.3288 - val_acc: 0.8590\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3212 - acc: 0.8641 - val_loss: 0.3406 - val_acc: 0.8545\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3180 - acc: 0.8657 - val_loss: 0.3192 - val_acc: 0.8665\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3261 - acc: 0.8611 - val_loss: 0.3298 - val_acc: 0.8625\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3111 - acc: 0.8686 - val_loss: 0.3084 - val_acc: 0.8665\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3140 - acc: 0.8667 - val_loss: 0.3108 - val_acc: 0.8680\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3213 - acc: 0.8634 - val_loss: 0.3185 - val_acc: 0.8688\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3166 - acc: 0.8678 - val_loss: 0.3436 - val_acc: 0.8565\n",
      "\n",
      "Training process completed in: 0 h 13 m 44 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1234.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1236 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_301 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_301 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_302 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_302 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_303 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_303 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_304 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_304 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_76 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 100\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.5218 - acc: 0.7523 - val_loss: 0.4276 - val_acc: 0.8130\n",
      "Epoch 2/90\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.4388 - acc: 0.8114 - val_loss: 0.4484 - val_acc: 0.8275\n",
      "Epoch 3/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.4170 - acc: 0.8261 - val_loss: 0.4179 - val_acc: 0.8230\n",
      "Epoch 4/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.4071 - acc: 0.8260 - val_loss: 0.4567 - val_acc: 0.8230\n",
      "Epoch 5/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3992 - acc: 0.8308 - val_loss: 0.3788 - val_acc: 0.8430\n",
      "Epoch 6/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.4020 - acc: 0.8269 - val_loss: 0.4012 - val_acc: 0.8315\n",
      "Epoch 7/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3907 - acc: 0.8342 - val_loss: 0.4204 - val_acc: 0.8270\n",
      "Epoch 8/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3859 - acc: 0.8359 - val_loss: 0.4017 - val_acc: 0.8260\n",
      "Epoch 9/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3895 - acc: 0.8335 - val_loss: 0.4008 - val_acc: 0.8340\n",
      "Epoch 10/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3885 - acc: 0.8311 - val_loss: 0.4259 - val_acc: 0.8420\n",
      "Epoch 11/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3848 - acc: 0.8363 - val_loss: 0.3897 - val_acc: 0.8280\n",
      "Epoch 12/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3714 - acc: 0.8416 - val_loss: 0.4001 - val_acc: 0.8360\n",
      "Epoch 13/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3741 - acc: 0.8410 - val_loss: 0.4333 - val_acc: 0.8250\n",
      "Epoch 14/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3832 - acc: 0.8336 - val_loss: 0.3890 - val_acc: 0.8432\n",
      "Epoch 15/90\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3662 - acc: 0.8440 - val_loss: 0.3544 - val_acc: 0.8495\n",
      "Epoch 16/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3622 - acc: 0.8468 - val_loss: 0.3900 - val_acc: 0.8440\n",
      "Epoch 17/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3738 - acc: 0.8399 - val_loss: 0.3849 - val_acc: 0.8410\n",
      "Epoch 18/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3704 - acc: 0.8414 - val_loss: 0.3724 - val_acc: 0.8445\n",
      "Epoch 19/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3660 - acc: 0.8426 - val_loss: 0.4464 - val_acc: 0.8120\n",
      "Epoch 20/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3701 - acc: 0.8440 - val_loss: 0.3830 - val_acc: 0.8400\n",
      "Epoch 21/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3675 - acc: 0.8426 - val_loss: 0.4017 - val_acc: 0.8330\n",
      "Epoch 22/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3578 - acc: 0.8480 - val_loss: 0.3567 - val_acc: 0.8455\n",
      "Epoch 23/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3590 - acc: 0.8470 - val_loss: 0.3432 - val_acc: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3539 - acc: 0.8520 - val_loss: 0.3682 - val_acc: 0.8310\n",
      "Epoch 25/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3501 - acc: 0.8523 - val_loss: 0.4177 - val_acc: 0.8220\n",
      "Epoch 26/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3559 - acc: 0.8472 - val_loss: 0.3998 - val_acc: 0.8460\n",
      "Epoch 27/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3490 - acc: 0.8522 - val_loss: 0.3503 - val_acc: 0.8520\n",
      "Epoch 28/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3524 - acc: 0.8489 - val_loss: 0.3539 - val_acc: 0.8627\n",
      "Epoch 29/90\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.3552 - acc: 0.8493 - val_loss: 0.4021 - val_acc: 0.8290\n",
      "Epoch 30/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3528 - acc: 0.8532 - val_loss: 0.3715 - val_acc: 0.8385\n",
      "Epoch 31/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3389 - acc: 0.8577 - val_loss: 0.3673 - val_acc: 0.8620\n",
      "Epoch 32/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3513 - acc: 0.8504 - val_loss: 0.3547 - val_acc: 0.8520\n",
      "Epoch 33/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3409 - acc: 0.8565 - val_loss: 0.3369 - val_acc: 0.8530\n",
      "Epoch 34/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3389 - acc: 0.8547 - val_loss: 0.4236 - val_acc: 0.8145\n",
      "Epoch 35/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3380 - acc: 0.8569 - val_loss: 0.3505 - val_acc: 0.8625\n",
      "Epoch 36/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3391 - acc: 0.8573 - val_loss: 0.3653 - val_acc: 0.8460\n",
      "Epoch 37/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3377 - acc: 0.8577 - val_loss: 0.3319 - val_acc: 0.8655\n",
      "Epoch 38/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3333 - acc: 0.8561 - val_loss: 0.3519 - val_acc: 0.8690\n",
      "Epoch 39/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3382 - acc: 0.8564 - val_loss: 0.3714 - val_acc: 0.8495\n",
      "Epoch 40/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3435 - acc: 0.8548 - val_loss: 0.3711 - val_acc: 0.8590\n",
      "Epoch 41/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3294 - acc: 0.8635 - val_loss: 0.3245 - val_acc: 0.8720\n",
      "Epoch 42/90\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.3334 - acc: 0.8571 - val_loss: 0.3607 - val_acc: 0.8607\n",
      "Epoch 43/90\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.3285 - acc: 0.8611 - val_loss: 0.3342 - val_acc: 0.8540\n",
      "Epoch 44/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3299 - acc: 0.8616 - val_loss: 0.3328 - val_acc: 0.8710\n",
      "Epoch 45/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3261 - acc: 0.8631 - val_loss: 0.3631 - val_acc: 0.8580\n",
      "Epoch 46/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3351 - acc: 0.8581 - val_loss: 0.3554 - val_acc: 0.8575\n",
      "Epoch 47/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3354 - acc: 0.8563 - val_loss: 0.3361 - val_acc: 0.8605\n",
      "Epoch 48/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3244 - acc: 0.8613 - val_loss: 0.3490 - val_acc: 0.8565\n",
      "Epoch 49/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3302 - acc: 0.8611 - val_loss: 0.3681 - val_acc: 0.8590\n",
      "Epoch 50/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3234 - acc: 0.8626 - val_loss: 0.3550 - val_acc: 0.8570\n",
      "Epoch 51/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3271 - acc: 0.8608 - val_loss: 0.3475 - val_acc: 0.8550\n",
      "Epoch 52/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3241 - acc: 0.8652 - val_loss: 0.3392 - val_acc: 0.8580\n",
      "Epoch 53/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3283 - acc: 0.8608 - val_loss: 0.3683 - val_acc: 0.8510\n",
      "Epoch 54/90\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.3295 - acc: 0.8606 - val_loss: 0.3757 - val_acc: 0.8455\n",
      "Epoch 55/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3243 - acc: 0.8618 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 56/90\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.3266 - acc: 0.8637 - val_loss: 0.3382 - val_acc: 0.8678\n",
      "Epoch 57/90\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3145 - acc: 0.8696 - val_loss: 0.3169 - val_acc: 0.8825\n",
      "Epoch 58/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3268 - acc: 0.8596 - val_loss: 0.3701 - val_acc: 0.8460\n",
      "Epoch 59/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3195 - acc: 0.8676 - val_loss: 0.3445 - val_acc: 0.8580\n",
      "Epoch 60/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3144 - acc: 0.8657 - val_loss: 0.3332 - val_acc: 0.8605\n",
      "Epoch 61/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3211 - acc: 0.8630 - val_loss: 0.3530 - val_acc: 0.8575\n",
      "Epoch 62/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3219 - acc: 0.8642 - val_loss: 0.3154 - val_acc: 0.8715\n",
      "Epoch 63/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3172 - acc: 0.8667 - val_loss: 0.3282 - val_acc: 0.8695\n",
      "Epoch 64/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3209 - acc: 0.8643 - val_loss: 0.3332 - val_acc: 0.8660\n",
      "Epoch 65/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3210 - acc: 0.8669 - val_loss: 0.3285 - val_acc: 0.8665\n",
      "Epoch 66/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3253 - acc: 0.8618 - val_loss: 0.3360 - val_acc: 0.8645\n",
      "Epoch 67/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3199 - acc: 0.8643 - val_loss: 0.3538 - val_acc: 0.8470\n",
      "Epoch 68/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3193 - acc: 0.8669 - val_loss: 0.3395 - val_acc: 0.8610\n",
      "Epoch 69/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3079 - acc: 0.8714 - val_loss: 0.3547 - val_acc: 0.8505\n",
      "Epoch 70/90\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.3202 - acc: 0.8661 - val_loss: 0.3453 - val_acc: 0.8648\n",
      "Epoch 71/90\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.3155 - acc: 0.8653 - val_loss: 0.3332 - val_acc: 0.8545\n",
      "Epoch 72/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3194 - acc: 0.8637 - val_loss: 0.3170 - val_acc: 0.8735\n",
      "Epoch 73/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3200 - acc: 0.8643 - val_loss: 0.3325 - val_acc: 0.8470\n",
      "Epoch 74/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3131 - acc: 0.8687 - val_loss: 0.3313 - val_acc: 0.8670\n",
      "Epoch 75/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3190 - acc: 0.8663 - val_loss: 0.3648 - val_acc: 0.8530\n",
      "Epoch 76/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3282 - acc: 0.8622 - val_loss: 0.3489 - val_acc: 0.8610\n",
      "Epoch 77/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3170 - acc: 0.8658 - val_loss: 0.3438 - val_acc: 0.8640\n",
      "Epoch 78/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3165 - acc: 0.8669 - val_loss: 0.3025 - val_acc: 0.8795\n",
      "Epoch 79/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3072 - acc: 0.8705 - val_loss: 0.3156 - val_acc: 0.8740\n",
      "Epoch 80/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3166 - acc: 0.8674 - val_loss: 0.3214 - val_acc: 0.8645\n",
      "Epoch 81/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3057 - acc: 0.8719 - val_loss: 0.3403 - val_acc: 0.8565\n",
      "Epoch 82/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3146 - acc: 0.8668 - val_loss: 0.3435 - val_acc: 0.8670\n",
      "Epoch 83/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3105 - acc: 0.8704 - val_loss: 0.3384 - val_acc: 0.8600\n",
      "Epoch 84/90\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.3127 - acc: 0.8674 - val_loss: 0.3228 - val_acc: 0.8622\n",
      "Epoch 85/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3057 - acc: 0.8724 - val_loss: 0.3366 - val_acc: 0.8625\n",
      "Epoch 86/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3049 - acc: 0.8750 - val_loss: 0.3422 - val_acc: 0.8660\n",
      "Epoch 87/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3189 - acc: 0.8639 - val_loss: 0.3314 - val_acc: 0.8675\n",
      "Epoch 88/90\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3153 - acc: 0.8662 - val_loss: 0.3542 - val_acc: 0.8500\n",
      "Epoch 89/90\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3146 - acc: 0.8695 - val_loss: 0.3365 - val_acc: 0.8615\n",
      "Epoch 90/90\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3110 - acc: 0.8699 - val_loss: 0.3279 - val_acc: 0.8600\n",
      "\n",
      "Training process completed in: 0 h 12 m 34 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1235.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1237 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_305 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_305 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_306 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_306 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_307 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_307 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_308 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_308 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 100\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.5333 - acc: 0.7363 - val_loss: 0.4756 - val_acc: 0.7730\n",
      "Epoch 2/90\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.4334 - acc: 0.8149 - val_loss: 0.4446 - val_acc: 0.8060\n",
      "Epoch 3/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4367 - acc: 0.8120 - val_loss: 0.4291 - val_acc: 0.7950\n",
      "Epoch 4/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4206 - acc: 0.8202 - val_loss: 0.4482 - val_acc: 0.8130\n",
      "Epoch 5/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4174 - acc: 0.8198 - val_loss: 0.4449 - val_acc: 0.8050\n",
      "Epoch 6/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4075 - acc: 0.8243 - val_loss: 0.3946 - val_acc: 0.8370\n",
      "Epoch 7/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4028 - acc: 0.8268 - val_loss: 0.4199 - val_acc: 0.8250\n",
      "Epoch 8/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4074 - acc: 0.8219 - val_loss: 0.3780 - val_acc: 0.8420\n",
      "Epoch 9/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3940 - acc: 0.8321 - val_loss: 0.3863 - val_acc: 0.8390\n",
      "Epoch 10/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3955 - acc: 0.8301 - val_loss: 0.4383 - val_acc: 0.7960\n",
      "Epoch 11/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3890 - acc: 0.8332 - val_loss: 0.4008 - val_acc: 0.8420\n",
      "Epoch 12/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3842 - acc: 0.8371 - val_loss: 0.3932 - val_acc: 0.8290\n",
      "Epoch 13/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4164 - acc: 0.8221 - val_loss: 0.3952 - val_acc: 0.8380\n",
      "Epoch 14/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3860 - acc: 0.8362 - val_loss: 0.4070 - val_acc: 0.8350\n",
      "Epoch 15/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3904 - acc: 0.8321 - val_loss: 0.3893 - val_acc: 0.8270\n",
      "Epoch 16/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3944 - acc: 0.8353 - val_loss: 0.4075 - val_acc: 0.8210\n",
      "Epoch 17/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3860 - acc: 0.8342 - val_loss: 0.4022 - val_acc: 0.8410\n",
      "Epoch 18/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3783 - acc: 0.8418 - val_loss: 0.3955 - val_acc: 0.8450\n",
      "Epoch 19/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3723 - acc: 0.8423 - val_loss: 0.3533 - val_acc: 0.8440\n",
      "Epoch 20/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3709 - acc: 0.8403 - val_loss: 0.3858 - val_acc: 0.8330\n",
      "Epoch 21/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3797 - acc: 0.8414 - val_loss: 0.3639 - val_acc: 0.8300\n",
      "Epoch 22/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3740 - acc: 0.8420 - val_loss: 0.3926 - val_acc: 0.8400\n",
      "Epoch 23/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3706 - acc: 0.8435 - val_loss: 0.3694 - val_acc: 0.8450\n",
      "Epoch 24/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3766 - acc: 0.8379 - val_loss: 0.3992 - val_acc: 0.8410\n",
      "Epoch 25/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3669 - acc: 0.8406 - val_loss: 0.3560 - val_acc: 0.8400\n",
      "Epoch 26/90\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.3552 - acc: 0.8488 - val_loss: 0.3636 - val_acc: 0.8550\n",
      "Epoch 27/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3690 - acc: 0.8417 - val_loss: 0.3559 - val_acc: 0.8600\n",
      "Epoch 28/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3654 - acc: 0.8433 - val_loss: 0.3587 - val_acc: 0.8477\n",
      "Epoch 29/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3691 - acc: 0.8405 - val_loss: 0.3602 - val_acc: 0.8600\n",
      "Epoch 30/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3657 - acc: 0.8433 - val_loss: 0.3665 - val_acc: 0.8590\n",
      "Epoch 31/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3572 - acc: 0.8507 - val_loss: 0.4012 - val_acc: 0.8350\n",
      "Epoch 32/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3698 - acc: 0.8417 - val_loss: 0.3993 - val_acc: 0.8400\n",
      "Epoch 33/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3612 - acc: 0.8459 - val_loss: 0.4064 - val_acc: 0.8280\n",
      "Epoch 34/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3573 - acc: 0.8494 - val_loss: 0.3292 - val_acc: 0.8680\n",
      "Epoch 35/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3599 - acc: 0.8499 - val_loss: 0.3502 - val_acc: 0.8590\n",
      "Epoch 36/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3622 - acc: 0.8455 - val_loss: 0.3904 - val_acc: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3598 - acc: 0.8448 - val_loss: 0.3380 - val_acc: 0.8640\n",
      "Epoch 38/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3525 - acc: 0.8499 - val_loss: 0.4204 - val_acc: 0.8200\n",
      "Epoch 39/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3575 - acc: 0.8484 - val_loss: 0.3504 - val_acc: 0.8560\n",
      "Epoch 40/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3616 - acc: 0.8457 - val_loss: 0.3540 - val_acc: 0.8480\n",
      "Epoch 41/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3547 - acc: 0.8470 - val_loss: 0.3287 - val_acc: 0.8540\n",
      "Epoch 42/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3526 - acc: 0.8509 - val_loss: 0.3332 - val_acc: 0.8490\n",
      "Epoch 43/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3608 - acc: 0.8470 - val_loss: 0.3521 - val_acc: 0.8440\n",
      "Epoch 44/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3478 - acc: 0.8536 - val_loss: 0.3464 - val_acc: 0.8560\n",
      "Epoch 45/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3484 - acc: 0.8519 - val_loss: 0.3749 - val_acc: 0.8370\n",
      "Epoch 46/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3514 - acc: 0.8514 - val_loss: 0.3533 - val_acc: 0.8420\n",
      "Epoch 47/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3363 - acc: 0.8570 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 48/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3378 - acc: 0.8570 - val_loss: 0.3574 - val_acc: 0.8550\n",
      "Epoch 49/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3458 - acc: 0.8541 - val_loss: 0.3750 - val_acc: 0.8260\n",
      "Epoch 50/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3408 - acc: 0.8566 - val_loss: 0.3208 - val_acc: 0.8640\n",
      "Epoch 51/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3502 - acc: 0.8553 - val_loss: 0.3466 - val_acc: 0.8560\n",
      "Epoch 52/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3524 - acc: 0.8499 - val_loss: 0.3636 - val_acc: 0.8500\n",
      "Epoch 53/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3310 - acc: 0.8618 - val_loss: 0.3560 - val_acc: 0.8420\n",
      "Epoch 54/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3445 - acc: 0.8523 - val_loss: 0.3201 - val_acc: 0.8780\n",
      "Epoch 55/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3480 - acc: 0.8519 - val_loss: 0.3378 - val_acc: 0.8530\n",
      "Epoch 56/90\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 0.3447 - acc: 0.8508 - val_loss: 0.3704 - val_acc: 0.8435\n",
      "Epoch 57/90\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.3387 - acc: 0.8578 - val_loss: 0.3297 - val_acc: 0.8560\n",
      "Epoch 58/90\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3434 - acc: 0.8539 - val_loss: 0.3706 - val_acc: 0.8310\n",
      "Epoch 59/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3406 - acc: 0.8541 - val_loss: 0.3424 - val_acc: 0.8720\n",
      "Epoch 60/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3447 - acc: 0.8518 - val_loss: 0.3801 - val_acc: 0.8530\n",
      "Epoch 61/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3457 - acc: 0.8518 - val_loss: 0.3181 - val_acc: 0.8600\n",
      "Epoch 62/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3423 - acc: 0.8528 - val_loss: 0.3419 - val_acc: 0.8680\n",
      "Epoch 63/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3476 - acc: 0.8551 - val_loss: 0.3539 - val_acc: 0.8490\n",
      "Epoch 64/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3335 - acc: 0.8573 - val_loss: 0.3389 - val_acc: 0.8560\n",
      "Epoch 65/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3284 - acc: 0.8591 - val_loss: 0.3366 - val_acc: 0.8610\n",
      "Epoch 66/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3270 - acc: 0.8604 - val_loss: 0.3867 - val_acc: 0.8260\n",
      "Epoch 67/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3342 - acc: 0.8563 - val_loss: 0.3457 - val_acc: 0.8450\n",
      "Epoch 68/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3456 - acc: 0.8519 - val_loss: 0.3432 - val_acc: 0.8530\n",
      "Epoch 69/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3566 - acc: 0.8496 - val_loss: 0.3567 - val_acc: 0.8460\n",
      "Epoch 70/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3221 - acc: 0.8631 - val_loss: 0.2805 - val_acc: 0.8900\n",
      "Epoch 71/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3246 - acc: 0.8626 - val_loss: 0.3324 - val_acc: 0.8760\n",
      "Epoch 72/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3325 - acc: 0.8615 - val_loss: 0.3318 - val_acc: 0.8610\n",
      "Epoch 73/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3361 - acc: 0.8544 - val_loss: 0.3562 - val_acc: 0.8420\n",
      "Epoch 74/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3290 - acc: 0.8615 - val_loss: 0.3584 - val_acc: 0.8540\n",
      "Epoch 75/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3336 - acc: 0.8584 - val_loss: 0.3402 - val_acc: 0.8640\n",
      "Epoch 76/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3231 - acc: 0.8609 - val_loss: 0.3551 - val_acc: 0.8540\n",
      "Epoch 77/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3304 - acc: 0.8647 - val_loss: 0.3212 - val_acc: 0.8650\n",
      "Epoch 78/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3342 - acc: 0.8576 - val_loss: 0.3391 - val_acc: 0.8590\n",
      "Epoch 79/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3243 - acc: 0.8613 - val_loss: 0.3114 - val_acc: 0.8710\n",
      "Epoch 80/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3384 - acc: 0.8547 - val_loss: 0.3268 - val_acc: 0.8710\n",
      "Epoch 81/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3174 - acc: 0.8684 - val_loss: 0.3391 - val_acc: 0.8490\n",
      "Epoch 82/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3322 - acc: 0.8577 - val_loss: 0.3476 - val_acc: 0.8560\n",
      "Epoch 83/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3339 - acc: 0.8569 - val_loss: 0.3369 - val_acc: 0.8690\n",
      "Epoch 84/90\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.3267 - acc: 0.8641 - val_loss: 0.3056 - val_acc: 0.8739\n",
      "Epoch 85/90\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3368 - acc: 0.8567 - val_loss: 0.3302 - val_acc: 0.8670\n",
      "Epoch 86/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3293 - acc: 0.8645 - val_loss: 0.3551 - val_acc: 0.8560\n",
      "Epoch 87/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3370 - acc: 0.8557 - val_loss: 0.3579 - val_acc: 0.8550\n",
      "Epoch 88/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3174 - acc: 0.8657 - val_loss: 0.3581 - val_acc: 0.8440\n",
      "Epoch 89/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3267 - acc: 0.8603 - val_loss: 0.3363 - val_acc: 0.8650\n",
      "Epoch 90/90\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.3130 - acc: 0.8697 - val_loss: 0.3303 - val_acc: 0.8650\n",
      "\n",
      "Training process completed in: 0 h 6 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1236.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1238 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_309 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_309 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_310 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_310 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_311 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_311 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_312 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_312 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 20s 104ms/step - loss: 0.5770 - acc: 0.7161 - val_loss: 0.5393 - val_acc: 0.7095\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 15s 78ms/step - loss: 0.4476 - acc: 0.7969 - val_loss: 0.3883 - val_acc: 0.8410\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4187 - acc: 0.8219 - val_loss: 0.4277 - val_acc: 0.8155\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4225 - acc: 0.8166 - val_loss: 0.4120 - val_acc: 0.8165\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4129 - acc: 0.8228 - val_loss: 0.4104 - val_acc: 0.8175\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4054 - acc: 0.8258 - val_loss: 0.4142 - val_acc: 0.8150\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4052 - acc: 0.8241 - val_loss: 0.3974 - val_acc: 0.8295\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3964 - acc: 0.8281 - val_loss: 0.4118 - val_acc: 0.8275\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3925 - acc: 0.8314 - val_loss: 0.3984 - val_acc: 0.8365\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3934 - acc: 0.8312 - val_loss: 0.3889 - val_acc: 0.8275\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3916 - acc: 0.8325 - val_loss: 0.3899 - val_acc: 0.8330\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3861 - acc: 0.8324 - val_loss: 0.3775 - val_acc: 0.8405\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3917 - acc: 0.8331 - val_loss: 0.3824 - val_acc: 0.8335\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3817 - acc: 0.8378 - val_loss: 0.3898 - val_acc: 0.8248\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3798 - acc: 0.8381 - val_loss: 0.3872 - val_acc: 0.8380\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3778 - acc: 0.8386 - val_loss: 0.3954 - val_acc: 0.8345\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3799 - acc: 0.8370 - val_loss: 0.3886 - val_acc: 0.8315\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3695 - acc: 0.8423 - val_loss: 0.3568 - val_acc: 0.8415\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3708 - acc: 0.8400 - val_loss: 0.3691 - val_acc: 0.8415\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3731 - acc: 0.8377 - val_loss: 0.3770 - val_acc: 0.8405\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3709 - acc: 0.8431 - val_loss: 0.3841 - val_acc: 0.8225\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3706 - acc: 0.8413 - val_loss: 0.3435 - val_acc: 0.8540\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3648 - acc: 0.8452 - val_loss: 0.3762 - val_acc: 0.8320\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3614 - acc: 0.8449 - val_loss: 0.3853 - val_acc: 0.8370\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3642 - acc: 0.8452 - val_loss: 0.3622 - val_acc: 0.8450\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3603 - acc: 0.8454 - val_loss: 0.3458 - val_acc: 0.8530\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3596 - acc: 0.8471 - val_loss: 0.3502 - val_acc: 0.8430\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3607 - acc: 0.8445 - val_loss: 0.3636 - val_acc: 0.8443\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3529 - acc: 0.8499 - val_loss: 0.3805 - val_acc: 0.8500\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3539 - acc: 0.8514 - val_loss: 0.3466 - val_acc: 0.8540\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3503 - acc: 0.8521 - val_loss: 0.3689 - val_acc: 0.8375\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3461 - acc: 0.8516 - val_loss: 0.3281 - val_acc: 0.8670\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3500 - acc: 0.8505 - val_loss: 0.3643 - val_acc: 0.8435\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3468 - acc: 0.8527 - val_loss: 0.3689 - val_acc: 0.8370\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3487 - acc: 0.8524 - val_loss: 0.3340 - val_acc: 0.8590\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3502 - acc: 0.8498 - val_loss: 0.3756 - val_acc: 0.8395\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3399 - acc: 0.8559 - val_loss: 0.3335 - val_acc: 0.8650\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3368 - acc: 0.8560 - val_loss: 0.3431 - val_acc: 0.8585\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3394 - acc: 0.8556 - val_loss: 0.3492 - val_acc: 0.8535\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3418 - acc: 0.8550 - val_loss: 0.3324 - val_acc: 0.8635\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3440 - acc: 0.8535 - val_loss: 0.3011 - val_acc: 0.8815\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3371 - acc: 0.8566 - val_loss: 0.3296 - val_acc: 0.8627\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3279 - acc: 0.8616 - val_loss: 0.3328 - val_acc: 0.8615\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3309 - acc: 0.8592 - val_loss: 0.3359 - val_acc: 0.8525\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3401 - acc: 0.8549 - val_loss: 0.3500 - val_acc: 0.8555\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3347 - acc: 0.8587 - val_loss: 0.3193 - val_acc: 0.8660\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3319 - acc: 0.8601 - val_loss: 0.3302 - val_acc: 0.8635\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 15s 82ms/step - loss: 0.3291 - acc: 0.8621 - val_loss: 0.3420 - val_acc: 0.8535\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3341 - acc: 0.8589 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3298 - acc: 0.8585 - val_loss: 0.3380 - val_acc: 0.8510\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3234 - acc: 0.8625 - val_loss: 0.3155 - val_acc: 0.8580\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3264 - acc: 0.8622 - val_loss: 0.3338 - val_acc: 0.8620\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3269 - acc: 0.8627 - val_loss: 0.3455 - val_acc: 0.8575\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3248 - acc: 0.8621 - val_loss: 0.3341 - val_acc: 0.8650\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3287 - acc: 0.8618 - val_loss: 0.3350 - val_acc: 0.8585\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3282 - acc: 0.8580 - val_loss: 0.3258 - val_acc: 0.8730\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3273 - acc: 0.8611 - val_loss: 0.3281 - val_acc: 0.8555\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3214 - acc: 0.8637 - val_loss: 0.3388 - val_acc: 0.8615\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3228 - acc: 0.8639 - val_loss: 0.3139 - val_acc: 0.8600\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3249 - acc: 0.8602 - val_loss: 0.2885 - val_acc: 0.8860\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3183 - acc: 0.8661 - val_loss: 0.3291 - val_acc: 0.8590\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3168 - acc: 0.8658 - val_loss: 0.3285 - val_acc: 0.8590\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3184 - acc: 0.8643 - val_loss: 0.3311 - val_acc: 0.8550\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3250 - acc: 0.8613 - val_loss: 0.3343 - val_acc: 0.8550\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 15s 82ms/step - loss: 0.3199 - acc: 0.8647 - val_loss: 0.3112 - val_acc: 0.8735\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3170 - acc: 0.8663 - val_loss: 0.3260 - val_acc: 0.8645\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3210 - acc: 0.8633 - val_loss: 0.3065 - val_acc: 0.8715\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3182 - acc: 0.8637 - val_loss: 0.3411 - val_acc: 0.8515\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3126 - acc: 0.8672 - val_loss: 0.3222 - val_acc: 0.8635\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 16s 83ms/step - loss: 0.3193 - acc: 0.8641 - val_loss: 0.3123 - val_acc: 0.8658\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3178 - acc: 0.8644 - val_loss: 0.3311 - val_acc: 0.8555\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3149 - acc: 0.8655 - val_loss: 0.3086 - val_acc: 0.8680\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3133 - acc: 0.8659 - val_loss: 0.3017 - val_acc: 0.8740\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3142 - acc: 0.8677 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3111 - acc: 0.8686 - val_loss: 0.3113 - val_acc: 0.8690\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 15s 82ms/step - loss: 0.3162 - acc: 0.8656 - val_loss: 0.3088 - val_acc: 0.8800\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3126 - acc: 0.8682 - val_loss: 0.3172 - val_acc: 0.8710\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3094 - acc: 0.8679 - val_loss: 0.3180 - val_acc: 0.8580\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3089 - acc: 0.8713 - val_loss: 0.3032 - val_acc: 0.8690\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3113 - acc: 0.8675 - val_loss: 0.3010 - val_acc: 0.8745\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3098 - acc: 0.8681 - val_loss: 0.2916 - val_acc: 0.8770\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3103 - acc: 0.8683 - val_loss: 0.3131 - val_acc: 0.8715\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3057 - acc: 0.8716 - val_loss: 0.3424 - val_acc: 0.8570\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.3097 - acc: 0.8684 - val_loss: 0.3031 - val_acc: 0.8750\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 15s 79ms/step - loss: 0.3057 - acc: 0.8702 - val_loss: 0.3197 - val_acc: 0.8610\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 15s 82ms/step - loss: 0.3036 - acc: 0.8711 - val_loss: 0.3026 - val_acc: 0.8785\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3076 - acc: 0.8689 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3105 - acc: 0.8681 - val_loss: 0.3089 - val_acc: 0.8665\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3010 - acc: 0.8726 - val_loss: 0.2785 - val_acc: 0.8810\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 15s 82ms/step - loss: 0.3078 - acc: 0.8684 - val_loss: 0.3147 - val_acc: 0.8670\n",
      "\n",
      "Training process completed in: 0 h 23 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1237.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1239 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_313 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_313 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_314 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_314 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_315 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_315 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_316 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_316 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 0.4972 - acc: 0.7695 - val_loss: 0.4108 - val_acc: 0.8230\n",
      "Epoch 2/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.4152 - acc: 0.8248 - val_loss: 0.4054 - val_acc: 0.8246\n",
      "Epoch 3/90\n",
      "140/140 [==============================] - 13s 95ms/step - loss: 0.4061 - acc: 0.8264 - val_loss: 0.3954 - val_acc: 0.8252\n",
      "Epoch 4/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3971 - acc: 0.8279 - val_loss: 0.4000 - val_acc: 0.8257\n",
      "Epoch 5/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3949 - acc: 0.8325 - val_loss: 0.4023 - val_acc: 0.8244\n",
      "Epoch 6/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3931 - acc: 0.8343 - val_loss: 0.3982 - val_acc: 0.8309\n",
      "Epoch 7/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3876 - acc: 0.8339 - val_loss: 0.3902 - val_acc: 0.8395\n",
      "Epoch 8/90\n",
      "140/140 [==============================] - 13s 95ms/step - loss: 0.3745 - acc: 0.8392 - val_loss: 0.4120 - val_acc: 0.8320\n",
      "Epoch 9/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3762 - acc: 0.8381 - val_loss: 0.3676 - val_acc: 0.8441\n",
      "Epoch 10/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3647 - acc: 0.8461 - val_loss: 0.3694 - val_acc: 0.8422\n",
      "Epoch 11/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3654 - acc: 0.8439 - val_loss: 0.3900 - val_acc: 0.8466\n",
      "Epoch 12/90\n",
      "140/140 [==============================] - 14s 96ms/step - loss: 0.3689 - acc: 0.8437 - val_loss: 0.3623 - val_acc: 0.8425\n",
      "Epoch 13/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3611 - acc: 0.8450 - val_loss: 0.3696 - val_acc: 0.8418\n",
      "Epoch 14/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3601 - acc: 0.8445 - val_loss: 0.3584 - val_acc: 0.8554\n",
      "Epoch 15/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3525 - acc: 0.8515 - val_loss: 0.3953 - val_acc: 0.8273\n",
      "Epoch 16/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3540 - acc: 0.8497 - val_loss: 0.3600 - val_acc: 0.8549\n",
      "Epoch 17/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3437 - acc: 0.8546 - val_loss: 0.3576 - val_acc: 0.8420\n",
      "Epoch 18/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3485 - acc: 0.8541 - val_loss: 0.3530 - val_acc: 0.8509\n",
      "Epoch 19/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3456 - acc: 0.8535 - val_loss: 0.3617 - val_acc: 0.8539\n",
      "Epoch 20/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3347 - acc: 0.8582 - val_loss: 0.3603 - val_acc: 0.8522\n",
      "Epoch 21/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3401 - acc: 0.8554 - val_loss: 0.3374 - val_acc: 0.8568\n",
      "Epoch 22/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3382 - acc: 0.8563 - val_loss: 0.3480 - val_acc: 0.8473\n",
      "Epoch 23/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3364 - acc: 0.8586 - val_loss: 0.3334 - val_acc: 0.8624\n",
      "Epoch 24/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3407 - acc: 0.8540 - val_loss: 0.3445 - val_acc: 0.8576\n",
      "Epoch 25/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3308 - acc: 0.8585 - val_loss: 0.3290 - val_acc: 0.8657\n",
      "Epoch 26/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3249 - acc: 0.8630 - val_loss: 0.3285 - val_acc: 0.8660\n",
      "Epoch 27/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3266 - acc: 0.8629 - val_loss: 0.3343 - val_acc: 0.8602\n",
      "Epoch 28/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3296 - acc: 0.8630 - val_loss: 0.3426 - val_acc: 0.8492\n",
      "Epoch 29/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3339 - acc: 0.8588 - val_loss: 0.3348 - val_acc: 0.8621\n",
      "Epoch 30/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3285 - acc: 0.8597 - val_loss: 0.3305 - val_acc: 0.8666\n",
      "Epoch 31/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3372 - acc: 0.8593 - val_loss: 0.3389 - val_acc: 0.8640\n",
      "Epoch 32/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3306 - acc: 0.8592 - val_loss: 0.3346 - val_acc: 0.8646\n",
      "Epoch 33/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3186 - acc: 0.8654 - val_loss: 0.3334 - val_acc: 0.8623\n",
      "Epoch 34/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3206 - acc: 0.8651 - val_loss: 0.3283 - val_acc: 0.8600\n",
      "Epoch 35/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3276 - acc: 0.8610 - val_loss: 0.3582 - val_acc: 0.8613\n",
      "Epoch 36/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3215 - acc: 0.8650 - val_loss: 0.3435 - val_acc: 0.8654\n",
      "Epoch 37/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3289 - acc: 0.8609 - val_loss: 0.3406 - val_acc: 0.8606\n",
      "Epoch 38/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3203 - acc: 0.8648 - val_loss: 0.3297 - val_acc: 0.8701\n",
      "Epoch 39/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3206 - acc: 0.8637 - val_loss: 0.3353 - val_acc: 0.8614\n",
      "Epoch 40/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3234 - acc: 0.8630 - val_loss: 0.3199 - val_acc: 0.8653\n",
      "Epoch 41/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3146 - acc: 0.8685 - val_loss: 0.3242 - val_acc: 0.8690\n",
      "Epoch 42/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3270 - acc: 0.8620 - val_loss: 0.3198 - val_acc: 0.8672\n",
      "Epoch 43/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3152 - acc: 0.8690 - val_loss: 0.3383 - val_acc: 0.8678\n",
      "Epoch 44/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3202 - acc: 0.8657 - val_loss: 0.3293 - val_acc: 0.8611\n",
      "Epoch 45/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3169 - acc: 0.8661 - val_loss: 0.3357 - val_acc: 0.8626\n",
      "Epoch 46/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3141 - acc: 0.8678 - val_loss: 0.3269 - val_acc: 0.8653\n",
      "Epoch 47/90\n",
      "140/140 [==============================] - 14s 96ms/step - loss: 0.3207 - acc: 0.8652 - val_loss: 0.3239 - val_acc: 0.8655\n",
      "Epoch 48/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3223 - acc: 0.8645 - val_loss: 0.3184 - val_acc: 0.8664\n",
      "Epoch 49/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3137 - acc: 0.8675 - val_loss: 0.3249 - val_acc: 0.8654\n",
      "Epoch 50/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3143 - acc: 0.8674 - val_loss: 0.3245 - val_acc: 0.8675\n",
      "Epoch 51/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3102 - acc: 0.8711 - val_loss: 0.3047 - val_acc: 0.8761\n",
      "Epoch 52/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3128 - acc: 0.8675 - val_loss: 0.3210 - val_acc: 0.8675\n",
      "Epoch 53/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3157 - acc: 0.8671 - val_loss: 0.3472 - val_acc: 0.8652\n",
      "Epoch 54/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3120 - acc: 0.8701 - val_loss: 0.3390 - val_acc: 0.8630\n",
      "Epoch 55/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3147 - acc: 0.8680 - val_loss: 0.3398 - val_acc: 0.8589\n",
      "Epoch 56/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3075 - acc: 0.8706 - val_loss: 0.3242 - val_acc: 0.8629\n",
      "Epoch 57/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3078 - acc: 0.8694 - val_loss: 0.3074 - val_acc: 0.8705\n",
      "Epoch 58/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3053 - acc: 0.8724 - val_loss: 0.3274 - val_acc: 0.8640\n",
      "Epoch 59/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3037 - acc: 0.8721 - val_loss: 0.3367 - val_acc: 0.8561\n",
      "Epoch 60/90\n",
      "140/140 [==============================] - 14s 100ms/step - loss: 0.3128 - acc: 0.8690 - val_loss: 0.3254 - val_acc: 0.8638\n",
      "Epoch 61/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3198 - acc: 0.8658 - val_loss: 0.3283 - val_acc: 0.8708\n",
      "Epoch 62/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3111 - acc: 0.8699 - val_loss: 0.3160 - val_acc: 0.8697\n",
      "Epoch 63/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3122 - acc: 0.8706 - val_loss: 0.3112 - val_acc: 0.8707\n",
      "Epoch 64/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3052 - acc: 0.8714 - val_loss: 0.3115 - val_acc: 0.8684\n",
      "Epoch 65/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3089 - acc: 0.8704 - val_loss: 0.3332 - val_acc: 0.8590\n",
      "Epoch 66/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3001 - acc: 0.8732 - val_loss: 0.3371 - val_acc: 0.8603\n",
      "Epoch 67/90\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.3047 - acc: 0.8738 - val_loss: 0.3078 - val_acc: 0.8741\n",
      "Epoch 68/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3105 - acc: 0.8701 - val_loss: 0.3128 - val_acc: 0.8767\n",
      "Epoch 69/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3034 - acc: 0.8724 - val_loss: 0.3218 - val_acc: 0.8656\n",
      "Epoch 70/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3014 - acc: 0.8746 - val_loss: 0.3199 - val_acc: 0.8652\n",
      "Epoch 71/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3080 - acc: 0.8714 - val_loss: 0.3237 - val_acc: 0.8695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3061 - acc: 0.8716 - val_loss: 0.3093 - val_acc: 0.8726\n",
      "Epoch 73/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3024 - acc: 0.8722 - val_loss: 0.3367 - val_acc: 0.8647\n",
      "Epoch 74/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3004 - acc: 0.8739 - val_loss: 0.3142 - val_acc: 0.8679\n",
      "Epoch 75/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3048 - acc: 0.8719 - val_loss: 0.3122 - val_acc: 0.8719\n",
      "Epoch 76/90\n",
      "140/140 [==============================] - 14s 96ms/step - loss: 0.3133 - acc: 0.8698 - val_loss: 0.3615 - val_acc: 0.8471\n",
      "Epoch 77/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3095 - acc: 0.8706 - val_loss: 0.3117 - val_acc: 0.8745\n",
      "Epoch 78/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3059 - acc: 0.8728 - val_loss: 0.3136 - val_acc: 0.8690\n",
      "Epoch 79/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.2977 - acc: 0.8737 - val_loss: 0.3300 - val_acc: 0.8665\n",
      "Epoch 80/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.2954 - acc: 0.8760 - val_loss: 0.3245 - val_acc: 0.8687\n",
      "Epoch 81/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.2983 - acc: 0.8744 - val_loss: 0.3134 - val_acc: 0.8654\n",
      "Epoch 82/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.3000 - acc: 0.8741 - val_loss: 0.3036 - val_acc: 0.8729\n",
      "Epoch 83/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3019 - acc: 0.8709 - val_loss: 0.3104 - val_acc: 0.8719\n",
      "Epoch 84/90\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.2977 - acc: 0.8761 - val_loss: 0.3045 - val_acc: 0.8707\n",
      "Epoch 85/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.2996 - acc: 0.8761 - val_loss: 0.3080 - val_acc: 0.8693\n",
      "Epoch 86/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3018 - acc: 0.8751 - val_loss: 0.3143 - val_acc: 0.8720\n",
      "Epoch 87/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.3032 - acc: 0.8716 - val_loss: 0.3120 - val_acc: 0.8724\n",
      "Epoch 88/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.2990 - acc: 0.8751 - val_loss: 0.3418 - val_acc: 0.8694\n",
      "Epoch 89/90\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.2998 - acc: 0.8739 - val_loss: 0.3314 - val_acc: 0.8670\n",
      "Epoch 90/90\n",
      "140/140 [==============================] - 14s 98ms/step - loss: 0.3102 - acc: 0.8681 - val_loss: 0.3142 - val_acc: 0.8721\n",
      "\n",
      "Training process completed in: 0 h 20 m 28 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1238.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1240 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_317 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_317 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_318 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_319 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_319 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_320 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.5102 - acc: 0.7641 - val_loss: 0.4536 - val_acc: 0.7975\n",
      "Epoch 2/50\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.4385 - acc: 0.8137 - val_loss: 0.4136 - val_acc: 0.8262\n",
      "Epoch 3/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.4205 - acc: 0.8218 - val_loss: 0.4338 - val_acc: 0.8113\n",
      "Epoch 4/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3910 - acc: 0.8327 - val_loss: 0.3905 - val_acc: 0.8350\n",
      "Epoch 5/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3929 - acc: 0.8347 - val_loss: 0.4287 - val_acc: 0.8200\n",
      "Epoch 6/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.4061 - acc: 0.8226 - val_loss: 0.3749 - val_acc: 0.8337\n",
      "Epoch 7/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3961 - acc: 0.8253 - val_loss: 0.4065 - val_acc: 0.8438\n",
      "Epoch 8/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3909 - acc: 0.8322 - val_loss: 0.4152 - val_acc: 0.8175\n",
      "Epoch 9/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3782 - acc: 0.8362 - val_loss: 0.3903 - val_acc: 0.8250\n",
      "Epoch 10/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3799 - acc: 0.8349 - val_loss: 0.3993 - val_acc: 0.8175\n",
      "Epoch 11/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3682 - acc: 0.8419 - val_loss: 0.3924 - val_acc: 0.8262\n",
      "Epoch 12/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3749 - acc: 0.8384 - val_loss: 0.4024 - val_acc: 0.8587\n",
      "Epoch 13/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3765 - acc: 0.8424 - val_loss: 0.4363 - val_acc: 0.7950\n",
      "Epoch 14/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3810 - acc: 0.8403 - val_loss: 0.3496 - val_acc: 0.8550\n",
      "Epoch 15/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3596 - acc: 0.8492 - val_loss: 0.3784 - val_acc: 0.8562\n",
      "Epoch 16/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3644 - acc: 0.8409 - val_loss: 0.4004 - val_acc: 0.8363\n",
      "Epoch 17/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3626 - acc: 0.8455 - val_loss: 0.3728 - val_acc: 0.8675\n",
      "Epoch 18/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3634 - acc: 0.8427 - val_loss: 0.3621 - val_acc: 0.8488\n",
      "Epoch 19/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3566 - acc: 0.8480 - val_loss: 0.3494 - val_acc: 0.8725\n",
      "Epoch 20/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3617 - acc: 0.8466 - val_loss: 0.3994 - val_acc: 0.8463\n",
      "Epoch 21/50\n",
      "190/190 [==============================] - 7s 37ms/step - loss: 0.3595 - acc: 0.8478 - val_loss: 0.3518 - val_acc: 0.8613\n",
      "Epoch 22/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3551 - acc: 0.8499 - val_loss: 0.3710 - val_acc: 0.8463\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3530 - acc: 0.8479 - val_loss: 0.3562 - val_acc: 0.8575\n",
      "Epoch 24/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3495 - acc: 0.8522 - val_loss: 0.3299 - val_acc: 0.8625\n",
      "Epoch 25/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3569 - acc: 0.8503 - val_loss: 0.3387 - val_acc: 0.8588\n",
      "Epoch 26/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3600 - acc: 0.8461 - val_loss: 0.3531 - val_acc: 0.8325\n",
      "Epoch 27/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3506 - acc: 0.8500 - val_loss: 0.3531 - val_acc: 0.8525\n",
      "Epoch 28/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3432 - acc: 0.8561 - val_loss: 0.3349 - val_acc: 0.8650\n",
      "Epoch 29/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3475 - acc: 0.8545 - val_loss: 0.3510 - val_acc: 0.8575\n",
      "Epoch 30/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3502 - acc: 0.8498 - val_loss: 0.3537 - val_acc: 0.8337\n",
      "Epoch 31/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3472 - acc: 0.8521 - val_loss: 0.3836 - val_acc: 0.8363\n",
      "Epoch 32/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3384 - acc: 0.8579 - val_loss: 0.3635 - val_acc: 0.8500\n",
      "Epoch 33/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3463 - acc: 0.8540 - val_loss: 0.3599 - val_acc: 0.8500\n",
      "Epoch 34/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3443 - acc: 0.8544 - val_loss: 0.3571 - val_acc: 0.8587\n",
      "Epoch 35/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3469 - acc: 0.8500 - val_loss: 0.3623 - val_acc: 0.8409\n",
      "Epoch 36/50\n",
      "190/190 [==============================] - 7s 34ms/step - loss: 0.3317 - acc: 0.8610 - val_loss: 0.3454 - val_acc: 0.8487\n",
      "Epoch 37/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3425 - acc: 0.8541 - val_loss: 0.3580 - val_acc: 0.8675\n",
      "Epoch 38/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3406 - acc: 0.8549 - val_loss: 0.3762 - val_acc: 0.8525\n",
      "Epoch 39/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3323 - acc: 0.8573 - val_loss: 0.3317 - val_acc: 0.8525\n",
      "Epoch 40/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3399 - acc: 0.8546 - val_loss: 0.3376 - val_acc: 0.8663\n",
      "Epoch 41/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3331 - acc: 0.8554 - val_loss: 0.3076 - val_acc: 0.8763\n",
      "Epoch 42/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3344 - acc: 0.8600 - val_loss: 0.3283 - val_acc: 0.8663\n",
      "Epoch 43/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3413 - acc: 0.8557 - val_loss: 0.3354 - val_acc: 0.8613\n",
      "Epoch 44/50\n",
      "190/190 [==============================] - 7s 36ms/step - loss: 0.3260 - acc: 0.8613 - val_loss: 0.3583 - val_acc: 0.8350\n",
      "Epoch 45/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3285 - acc: 0.8596 - val_loss: 0.3564 - val_acc: 0.8350\n",
      "Epoch 46/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3421 - acc: 0.8553 - val_loss: 0.3746 - val_acc: 0.8363\n",
      "Epoch 47/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3354 - acc: 0.8606 - val_loss: 0.3617 - val_acc: 0.8462\n",
      "Epoch 48/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3390 - acc: 0.8527 - val_loss: 0.3552 - val_acc: 0.8463\n",
      "Epoch 49/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3293 - acc: 0.8598 - val_loss: 0.3720 - val_acc: 0.8513\n",
      "Epoch 50/50\n",
      "190/190 [==============================] - 7s 35ms/step - loss: 0.3356 - acc: 0.8574 - val_loss: 0.3433 - val_acc: 0.8575\n",
      "\n",
      "Training process completed in: 0 h 5 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1239.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1241 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_321 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_321 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_322 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_322 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_323 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_324 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_324 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 14s 101ms/step - loss: 0.4723 - acc: 0.7840 - val_loss: 0.4263 - val_acc: 0.8150\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.4270 - acc: 0.8182 - val_loss: 0.4124 - val_acc: 0.8125\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.4155 - acc: 0.8209 - val_loss: 0.3994 - val_acc: 0.8338\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.4050 - acc: 0.8293 - val_loss: 0.4376 - val_acc: 0.8231\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.4017 - acc: 0.8277 - val_loss: 0.3838 - val_acc: 0.8306\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3939 - acc: 0.8288 - val_loss: 0.3843 - val_acc: 0.8287\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3731 - acc: 0.8417 - val_loss: 0.3613 - val_acc: 0.8481\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3847 - acc: 0.8350 - val_loss: 0.4293 - val_acc: 0.8363\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3832 - acc: 0.8367 - val_loss: 0.4003 - val_acc: 0.8306\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3775 - acc: 0.8387 - val_loss: 0.4103 - val_acc: 0.8313\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3665 - acc: 0.8449 - val_loss: 0.3605 - val_acc: 0.8456\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3770 - acc: 0.8376 - val_loss: 0.3803 - val_acc: 0.8394\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3722 - acc: 0.8415 - val_loss: 0.3727 - val_acc: 0.8400\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3657 - acc: 0.8430 - val_loss: 0.3897 - val_acc: 0.8325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3665 - acc: 0.8421 - val_loss: 0.3584 - val_acc: 0.8650\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3672 - acc: 0.8431 - val_loss: 0.3829 - val_acc: 0.8369\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3595 - acc: 0.8458 - val_loss: 0.3674 - val_acc: 0.8600\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 10s 69ms/step - loss: 0.3536 - acc: 0.8511 - val_loss: 0.3712 - val_acc: 0.8433\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 9s 65ms/step - loss: 0.3581 - acc: 0.8474 - val_loss: 0.3771 - val_acc: 0.8369\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 10s 68ms/step - loss: 0.3551 - acc: 0.8474 - val_loss: 0.4195 - val_acc: 0.8044\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3564 - acc: 0.8488 - val_loss: 0.3656 - val_acc: 0.8456\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3422 - acc: 0.8557 - val_loss: 0.3548 - val_acc: 0.8494\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3495 - acc: 0.8510 - val_loss: 0.3672 - val_acc: 0.8600\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3524 - acc: 0.8496 - val_loss: 0.3703 - val_acc: 0.8438\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3504 - acc: 0.8490 - val_loss: 0.3762 - val_acc: 0.8438\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3429 - acc: 0.8548 - val_loss: 0.3671 - val_acc: 0.8550\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3377 - acc: 0.8566 - val_loss: 0.3765 - val_acc: 0.8356\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3324 - acc: 0.8578 - val_loss: 0.3389 - val_acc: 0.8531\n",
      "Epoch 29/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3477 - acc: 0.8516 - val_loss: 0.3594 - val_acc: 0.8550\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3366 - acc: 0.8575 - val_loss: 0.3066 - val_acc: 0.8737\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3333 - acc: 0.8591 - val_loss: 0.3566 - val_acc: 0.8488\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3322 - acc: 0.8617 - val_loss: 0.3553 - val_acc: 0.8656\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3324 - acc: 0.8569 - val_loss: 0.3278 - val_acc: 0.8713\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3272 - acc: 0.8601 - val_loss: 0.3555 - val_acc: 0.8506\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3390 - acc: 0.8551 - val_loss: 0.3450 - val_acc: 0.8604\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3336 - acc: 0.8579 - val_loss: 0.3664 - val_acc: 0.8456\n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3284 - acc: 0.8593 - val_loss: 0.3268 - val_acc: 0.8688\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3233 - acc: 0.8642 - val_loss: 0.3482 - val_acc: 0.8469\n",
      "Epoch 39/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3325 - acc: 0.8592 - val_loss: 0.3674 - val_acc: 0.8425\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3277 - acc: 0.8624 - val_loss: 0.3538 - val_acc: 0.8575\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3239 - acc: 0.8629 - val_loss: 0.3301 - val_acc: 0.8794\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3211 - acc: 0.8626 - val_loss: 0.3430 - val_acc: 0.8644\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3269 - acc: 0.8606 - val_loss: 0.3221 - val_acc: 0.8675\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3361 - acc: 0.8571 - val_loss: 0.3489 - val_acc: 0.8625\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3238 - acc: 0.8632 - val_loss: 0.3551 - val_acc: 0.8587\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3264 - acc: 0.8621 - val_loss: 0.3232 - val_acc: 0.8606\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3188 - acc: 0.8653 - val_loss: 0.3268 - val_acc: 0.8669\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3294 - acc: 0.8597 - val_loss: 0.3242 - val_acc: 0.8631\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3192 - acc: 0.8666 - val_loss: 0.3507 - val_acc: 0.8363\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3183 - acc: 0.8635 - val_loss: 0.3327 - val_acc: 0.8662\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3268 - acc: 0.8628 - val_loss: 0.3451 - val_acc: 0.8625\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3204 - acc: 0.8625 - val_loss: 0.3565 - val_acc: 0.8500\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 10s 71ms/step - loss: 0.3241 - acc: 0.8620 - val_loss: 0.3426 - val_acc: 0.8585\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 9s 64ms/step - loss: 0.3279 - acc: 0.8614 - val_loss: 0.3483 - val_acc: 0.8537\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3168 - acc: 0.8668 - val_loss: 0.3734 - val_acc: 0.8406\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3115 - acc: 0.8688 - val_loss: 0.3358 - val_acc: 0.8725\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3135 - acc: 0.8665 - val_loss: 0.3256 - val_acc: 0.8681\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3223 - acc: 0.8607 - val_loss: 0.3673 - val_acc: 0.8488\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3229 - acc: 0.8629 - val_loss: 0.3297 - val_acc: 0.8544\n",
      "Epoch 60/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3223 - acc: 0.8622 - val_loss: 0.3344 - val_acc: 0.8606\n",
      "Epoch 61/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3175 - acc: 0.8658 - val_loss: 0.3062 - val_acc: 0.8669\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3161 - acc: 0.8657 - val_loss: 0.3436 - val_acc: 0.8563\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3135 - acc: 0.8688 - val_loss: 0.3505 - val_acc: 0.8563\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3077 - acc: 0.8696 - val_loss: 0.3128 - val_acc: 0.8744\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3132 - acc: 0.8690 - val_loss: 0.3477 - val_acc: 0.8638\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3078 - acc: 0.8692 - val_loss: 0.3443 - val_acc: 0.8506\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3229 - acc: 0.8647 - val_loss: 0.3307 - val_acc: 0.8719\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3134 - acc: 0.8670 - val_loss: 0.3316 - val_acc: 0.8531\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3124 - acc: 0.8660 - val_loss: 0.3299 - val_acc: 0.8725\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 10s 69ms/step - loss: 0.3097 - acc: 0.8695 - val_loss: 0.3315 - val_acc: 0.8717\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 9s 66ms/step - loss: 0.3086 - acc: 0.8720 - val_loss: 0.2832 - val_acc: 0.8862\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3155 - acc: 0.8653 - val_loss: 0.3358 - val_acc: 0.8556\n",
      "Epoch 73/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3153 - acc: 0.8657 - val_loss: 0.3434 - val_acc: 0.8637\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3107 - acc: 0.8699 - val_loss: 0.3262 - val_acc: 0.8631\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3067 - acc: 0.8698 - val_loss: 0.3526 - val_acc: 0.8544\n",
      "Epoch 76/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3078 - acc: 0.8701 - val_loss: 0.3107 - val_acc: 0.8837\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 0.3035 - acc: 0.8723 - val_loss: 0.3354 - val_acc: 0.8562\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3128 - acc: 0.8656 - val_loss: 0.3645 - val_acc: 0.8588\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3144 - acc: 0.8693 - val_loss: 0.3376 - val_acc: 0.8619\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 0.3095 - acc: 0.8707 - val_loss: 0.2989 - val_acc: 0.8863\n",
      "\n",
      "Training process completed in: 0 h 12 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1240.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1242 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_325 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_325 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_326 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_327 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_328 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_328 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_82 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.5107 - acc: 0.7561 - val_loss: 0.4104 - val_acc: 0.8237\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4333 - acc: 0.8191 - val_loss: 0.4093 - val_acc: 0.8208\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.4256 - acc: 0.8171 - val_loss: 0.4333 - val_acc: 0.8196\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4272 - acc: 0.8148 - val_loss: 0.4377 - val_acc: 0.8004\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4009 - acc: 0.8303 - val_loss: 0.3865 - val_acc: 0.8262\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4082 - acc: 0.8279 - val_loss: 0.4191 - val_acc: 0.8183\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4036 - acc: 0.8284 - val_loss: 0.4026 - val_acc: 0.8275\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.4062 - acc: 0.8258 - val_loss: 0.4344 - val_acc: 0.8279\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3861 - acc: 0.8364 - val_loss: 0.3655 - val_acc: 0.8421\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3858 - acc: 0.8387 - val_loss: 0.4137 - val_acc: 0.8333\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3928 - acc: 0.8314 - val_loss: 0.3842 - val_acc: 0.8354\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3900 - acc: 0.8318 - val_loss: 0.3888 - val_acc: 0.8319\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3991 - acc: 0.8274 - val_loss: 0.3701 - val_acc: 0.8379\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3826 - acc: 0.8384 - val_loss: 0.3839 - val_acc: 0.8383\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3809 - acc: 0.8354 - val_loss: 0.3714 - val_acc: 0.8400\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3709 - acc: 0.8420 - val_loss: 0.3904 - val_acc: 0.8354\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3709 - acc: 0.8458 - val_loss: 0.3591 - val_acc: 0.8433\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3750 - acc: 0.8355 - val_loss: 0.3687 - val_acc: 0.8525\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3806 - acc: 0.8354 - val_loss: 0.3724 - val_acc: 0.8450\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3683 - acc: 0.8460 - val_loss: 0.3744 - val_acc: 0.8483\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3785 - acc: 0.8385 - val_loss: 0.3809 - val_acc: 0.8417\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3718 - acc: 0.8409 - val_loss: 0.3908 - val_acc: 0.8358\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3629 - acc: 0.8426 - val_loss: 0.3665 - val_acc: 0.8417\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3617 - acc: 0.8445 - val_loss: 0.3648 - val_acc: 0.8508\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3617 - acc: 0.8467 - val_loss: 0.3638 - val_acc: 0.8383\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3693 - acc: 0.8459 - val_loss: 0.3620 - val_acc: 0.8512\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3624 - acc: 0.8457 - val_loss: 0.4052 - val_acc: 0.8346\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3624 - acc: 0.8470 - val_loss: 0.3562 - val_acc: 0.8567\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3625 - acc: 0.8466 - val_loss: 0.3565 - val_acc: 0.8517\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3574 - acc: 0.8500 - val_loss: 0.3663 - val_acc: 0.8479\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3746 - acc: 0.8429 - val_loss: 0.3909 - val_acc: 0.8217\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3592 - acc: 0.8479 - val_loss: 0.3444 - val_acc: 0.8504\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3636 - acc: 0.8427 - val_loss: 0.3830 - val_acc: 0.8321\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3538 - acc: 0.8528 - val_loss: 0.3639 - val_acc: 0.8454\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3519 - acc: 0.8496 - val_loss: 0.3658 - val_acc: 0.8482\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3542 - acc: 0.8482 - val_loss: 0.3448 - val_acc: 0.8708\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3630 - acc: 0.8426 - val_loss: 0.3662 - val_acc: 0.8392\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3631 - acc: 0.8440 - val_loss: 0.3712 - val_acc: 0.8454\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3581 - acc: 0.8493 - val_loss: 0.3736 - val_acc: 0.8433\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3356 - acc: 0.8596 - val_loss: 0.3576 - val_acc: 0.8479\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3575 - acc: 0.8500 - val_loss: 0.3566 - val_acc: 0.8529\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3492 - acc: 0.8521 - val_loss: 0.3595 - val_acc: 0.8421\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3550 - acc: 0.8490 - val_loss: 0.3799 - val_acc: 0.8354\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3560 - acc: 0.8491 - val_loss: 0.4009 - val_acc: 0.8408\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3526 - acc: 0.8468 - val_loss: 0.3543 - val_acc: 0.8496\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3454 - acc: 0.8543 - val_loss: 0.3507 - val_acc: 0.8508\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3356 - acc: 0.8553 - val_loss: 0.3390 - val_acc: 0.8595\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3486 - acc: 0.8548 - val_loss: 0.3470 - val_acc: 0.8546\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3443 - acc: 0.8536 - val_loss: 0.3619 - val_acc: 0.8517\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3443 - acc: 0.8559 - val_loss: 0.3738 - val_acc: 0.8408\n",
      "\n",
      "Training process completed in: 0 h 4 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1241.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1243 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_329 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_329 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_330 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_330 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_331 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_331 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_332 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_332 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 11s 77ms/step - loss: 0.5101 - acc: 0.7561 - val_loss: 0.4513 - val_acc: 0.8087\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4360 - acc: 0.8121 - val_loss: 0.4768 - val_acc: 0.8200\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4219 - acc: 0.8140 - val_loss: 0.4311 - val_acc: 0.8067\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4171 - acc: 0.8223 - val_loss: 0.4041 - val_acc: 0.8237\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4174 - acc: 0.8236 - val_loss: 0.4176 - val_acc: 0.8183\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4136 - acc: 0.8237 - val_loss: 0.4147 - val_acc: 0.8229\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.4138 - acc: 0.8219 - val_loss: 0.3970 - val_acc: 0.8271\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3955 - acc: 0.8267 - val_loss: 0.4026 - val_acc: 0.8233\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3937 - acc: 0.8353 - val_loss: 0.4162 - val_acc: 0.8175\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3902 - acc: 0.8333 - val_loss: 0.4078 - val_acc: 0.8300\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3821 - acc: 0.8395 - val_loss: 0.3647 - val_acc: 0.8400\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3945 - acc: 0.8315 - val_loss: 0.3987 - val_acc: 0.8315\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3981 - acc: 0.8294 - val_loss: 0.3921 - val_acc: 0.8333\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3863 - acc: 0.8334 - val_loss: 0.3848 - val_acc: 0.8437\n",
      "Epoch 15/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3856 - acc: 0.8367 - val_loss: 0.3913 - val_acc: 0.8408\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3860 - acc: 0.8347 - val_loss: 0.3857 - val_acc: 0.8367\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3725 - acc: 0.8384 - val_loss: 0.3815 - val_acc: 0.8408\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3731 - acc: 0.8362 - val_loss: 0.3864 - val_acc: 0.8404\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3800 - acc: 0.8378 - val_loss: 0.3941 - val_acc: 0.8350\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3761 - acc: 0.8421 - val_loss: 0.3428 - val_acc: 0.8633\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3740 - acc: 0.8430 - val_loss: 0.3872 - val_acc: 0.8288\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3666 - acc: 0.8447 - val_loss: 0.3990 - val_acc: 0.8346\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3610 - acc: 0.8446 - val_loss: 0.3937 - val_acc: 0.8288\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3774 - acc: 0.8400 - val_loss: 0.4384 - val_acc: 0.8131\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3659 - acc: 0.8425 - val_loss: 0.3802 - val_acc: 0.8417\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3583 - acc: 0.8487 - val_loss: 0.3800 - val_acc: 0.8413\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3713 - acc: 0.8388 - val_loss: 0.3741 - val_acc: 0.8358\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3797 - acc: 0.8383 - val_loss: 0.3610 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3746 - acc: 0.8420 - val_loss: 0.3975 - val_acc: 0.8487\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3653 - acc: 0.8428 - val_loss: 0.3740 - val_acc: 0.8358\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3592 - acc: 0.8507 - val_loss: 0.3811 - val_acc: 0.8529\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3574 - acc: 0.8476 - val_loss: 0.3462 - val_acc: 0.8467\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3643 - acc: 0.8459 - val_loss: 0.3839 - val_acc: 0.8392\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3484 - acc: 0.8504 - val_loss: 0.3815 - val_acc: 0.8508\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3668 - acc: 0.8451 - val_loss: 0.3815 - val_acc: 0.8311\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3641 - acc: 0.8430 - val_loss: 0.3651 - val_acc: 0.8433\n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3662 - acc: 0.8454 - val_loss: 0.3947 - val_acc: 0.8525\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3615 - acc: 0.8473 - val_loss: 0.3702 - val_acc: 0.8558\n",
      "Epoch 39/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3393 - acc: 0.8601 - val_loss: 0.3642 - val_acc: 0.8550\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3476 - acc: 0.8516 - val_loss: 0.3487 - val_acc: 0.8596\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3604 - acc: 0.8468 - val_loss: 0.3827 - val_acc: 0.8417\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3545 - acc: 0.8501 - val_loss: 0.3644 - val_acc: 0.8521\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3358 - acc: 0.8561 - val_loss: 0.3968 - val_acc: 0.8308\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3378 - acc: 0.8550 - val_loss: 0.3580 - val_acc: 0.8533\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3549 - acc: 0.8513 - val_loss: 0.3904 - val_acc: 0.8454\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3564 - acc: 0.8515 - val_loss: 0.3709 - val_acc: 0.8571\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3464 - acc: 0.8560 - val_loss: 0.3594 - val_acc: 0.8495\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3364 - acc: 0.8563 - val_loss: 0.3708 - val_acc: 0.8396\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3514 - acc: 0.8505 - val_loss: 0.3553 - val_acc: 0.8479\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3473 - acc: 0.8548 - val_loss: 0.3444 - val_acc: 0.8563\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3494 - acc: 0.8548 - val_loss: 0.3529 - val_acc: 0.8533\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3451 - acc: 0.8530 - val_loss: 0.3607 - val_acc: 0.8571\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3443 - acc: 0.8506 - val_loss: 0.3850 - val_acc: 0.8612\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3412 - acc: 0.8557 - val_loss: 0.3617 - val_acc: 0.8458\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3343 - acc: 0.8558 - val_loss: 0.3684 - val_acc: 0.8479\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3308 - acc: 0.8589 - val_loss: 0.3311 - val_acc: 0.8592\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3400 - acc: 0.8587 - val_loss: 0.3315 - val_acc: 0.8521\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3403 - acc: 0.8536 - val_loss: 0.4155 - val_acc: 0.8294\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3380 - acc: 0.8532 - val_loss: 0.3481 - val_acc: 0.8533\n",
      "Epoch 60/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3287 - acc: 0.8609 - val_loss: 0.3627 - val_acc: 0.8454\n",
      "Epoch 61/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3247 - acc: 0.8634 - val_loss: 0.3579 - val_acc: 0.8621\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3255 - acc: 0.8650 - val_loss: 0.3330 - val_acc: 0.8571\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3304 - acc: 0.8603 - val_loss: 0.3571 - val_acc: 0.8558\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3303 - acc: 0.8643 - val_loss: 0.3210 - val_acc: 0.8700\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3313 - acc: 0.8614 - val_loss: 0.3361 - val_acc: 0.8658\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3305 - acc: 0.8592 - val_loss: 0.3433 - val_acc: 0.8638\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3359 - acc: 0.8637 - val_loss: 0.3792 - val_acc: 0.8383\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3363 - acc: 0.8569 - val_loss: 0.3610 - val_acc: 0.8546\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3291 - acc: 0.8587 - val_loss: 0.3589 - val_acc: 0.8625\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.3408 - acc: 0.8521 - val_loss: 0.3302 - val_acc: 0.8625\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3430 - acc: 0.8519 - val_loss: 0.3717 - val_acc: 0.8533\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3290 - acc: 0.8614 - val_loss: 0.3655 - val_acc: 0.8612\n",
      "Epoch 73/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3324 - acc: 0.8570 - val_loss: 0.3302 - val_acc: 0.8592\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3261 - acc: 0.8600 - val_loss: 0.3302 - val_acc: 0.8613\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3318 - acc: 0.8577 - val_loss: 0.3259 - val_acc: 0.8679\n",
      "Epoch 76/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3309 - acc: 0.8580 - val_loss: 0.3360 - val_acc: 0.8537\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3297 - acc: 0.8598 - val_loss: 0.3530 - val_acc: 0.8596\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 0.3400 - acc: 0.8587 - val_loss: 0.3538 - val_acc: 0.8529\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3238 - acc: 0.8621 - val_loss: 0.3433 - val_acc: 0.8575\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.3395 - acc: 0.8574 - val_loss: 0.3487 - val_acc: 0.8667\n",
      "\n",
      "Training process completed in: 0 h 7 m 26 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1242.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1244 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_333 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_333 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_334 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_334 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_335 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_335 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_336 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_336 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_84 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 16s 111ms/step - loss: 0.4983 - acc: 0.7689 - val_loss: 0.4539 - val_acc: 0.7994\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.4266 - acc: 0.8181 - val_loss: 0.4080 - val_acc: 0.8225\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.4177 - acc: 0.8221 - val_loss: 0.3986 - val_acc: 0.8285\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.4090 - acc: 0.8248 - val_loss: 0.4481 - val_acc: 0.8221\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3926 - acc: 0.8317 - val_loss: 0.3930 - val_acc: 0.8283\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3894 - acc: 0.8342 - val_loss: 0.4507 - val_acc: 0.8343\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 10s 71ms/step - loss: 0.3936 - acc: 0.8319 - val_loss: 0.4255 - val_acc: 0.8269\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 10s 71ms/step - loss: 0.3875 - acc: 0.8305 - val_loss: 0.4029 - val_acc: 0.8200\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3775 - acc: 0.8354 - val_loss: 0.3918 - val_acc: 0.8321\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 10s 73ms/step - loss: 0.3826 - acc: 0.8344 - val_loss: 0.3749 - val_acc: 0.8390\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3807 - acc: 0.8356 - val_loss: 0.4040 - val_acc: 0.8435\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3708 - acc: 0.8425 - val_loss: 0.3933 - val_acc: 0.8406\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3636 - acc: 0.8457 - val_loss: 0.3563 - val_acc: 0.8525\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3707 - acc: 0.8430 - val_loss: 0.3669 - val_acc: 0.8456\n",
      "Epoch 15/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3622 - acc: 0.8446 - val_loss: 0.3881 - val_acc: 0.8396\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3627 - acc: 0.8479 - val_loss: 0.3718 - val_acc: 0.8617\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3555 - acc: 0.8471 - val_loss: 0.3669 - val_acc: 0.8435\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 10s 73ms/step - loss: 0.3533 - acc: 0.8517 - val_loss: 0.3720 - val_acc: 0.8553\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3471 - acc: 0.8520 - val_loss: 0.3657 - val_acc: 0.8506\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3461 - acc: 0.8546 - val_loss: 0.3494 - val_acc: 0.8556\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3526 - acc: 0.8498 - val_loss: 0.4003 - val_acc: 0.8502\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3428 - acc: 0.8546 - val_loss: 0.3450 - val_acc: 0.8475\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3516 - acc: 0.8521 - val_loss: 0.3914 - val_acc: 0.8452\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3431 - acc: 0.8552 - val_loss: 0.3551 - val_acc: 0.8521\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3340 - acc: 0.8591 - val_loss: 0.3442 - val_acc: 0.8552\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3430 - acc: 0.8521 - val_loss: 0.3561 - val_acc: 0.8542\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3436 - acc: 0.8542 - val_loss: 0.3456 - val_acc: 0.8606\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3455 - acc: 0.8511 - val_loss: 0.3574 - val_acc: 0.8567\n",
      "Epoch 29/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3418 - acc: 0.8546 - val_loss: 0.3506 - val_acc: 0.8606\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 10s 73ms/step - loss: 0.3433 - acc: 0.8531 - val_loss: 0.3449 - val_acc: 0.8623\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3310 - acc: 0.8591 - val_loss: 0.3353 - val_acc: 0.8658\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3315 - acc: 0.8583 - val_loss: 0.3462 - val_acc: 0.8577\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3264 - acc: 0.8618 - val_loss: 0.3399 - val_acc: 0.8590\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3271 - acc: 0.8612 - val_loss: 0.3314 - val_acc: 0.8638\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3338 - acc: 0.8583 - val_loss: 0.3475 - val_acc: 0.8608\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3354 - acc: 0.8573 - val_loss: 0.3407 - val_acc: 0.8558\n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3440 - acc: 0.8543 - val_loss: 0.3753 - val_acc: 0.8550\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3266 - acc: 0.8615 - val_loss: 0.3535 - val_acc: 0.8433\n",
      "Epoch 39/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3233 - acc: 0.8650 - val_loss: 0.3452 - val_acc: 0.8585\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.3308 - acc: 0.8585 - val_loss: 0.3279 - val_acc: 0.8679\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3254 - acc: 0.8602 - val_loss: 0.3329 - val_acc: 0.8610\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3244 - acc: 0.8641 - val_loss: 0.3367 - val_acc: 0.8646\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3307 - acc: 0.8602 - val_loss: 0.3483 - val_acc: 0.8608\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3273 - acc: 0.8637 - val_loss: 0.3464 - val_acc: 0.8648\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3249 - acc: 0.8655 - val_loss: 0.3481 - val_acc: 0.8615\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3239 - acc: 0.8607 - val_loss: 0.3458 - val_acc: 0.8513\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 10s 73ms/step - loss: 0.3237 - acc: 0.8656 - val_loss: 0.3378 - val_acc: 0.8597\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3137 - acc: 0.8673 - val_loss: 0.3205 - val_acc: 0.8644\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3239 - acc: 0.8637 - val_loss: 0.3586 - val_acc: 0.8527\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3242 - acc: 0.8634 - val_loss: 0.3491 - val_acc: 0.8558\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3107 - acc: 0.8696 - val_loss: 0.3451 - val_acc: 0.8540\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3165 - acc: 0.8676 - val_loss: 0.3453 - val_acc: 0.8615\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3303 - acc: 0.8580 - val_loss: 0.3371 - val_acc: 0.8599\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3205 - acc: 0.8659 - val_loss: 0.3327 - val_acc: 0.8725\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3150 - acc: 0.8685 - val_loss: 0.3173 - val_acc: 0.8648\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3166 - acc: 0.8682 - val_loss: 0.3342 - val_acc: 0.8629\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3214 - acc: 0.8654 - val_loss: 0.3532 - val_acc: 0.8529\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3171 - acc: 0.8650 - val_loss: 0.3448 - val_acc: 0.8652\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3209 - acc: 0.8644 - val_loss: 0.3413 - val_acc: 0.8600\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3102 - acc: 0.8683 - val_loss: 0.3545 - val_acc: 0.8621\n",
      "Epoch 61/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.3124 - acc: 0.8696 - val_loss: 0.3206 - val_acc: 0.8673\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.3116 - acc: 0.8687 - val_loss: 0.3303 - val_acc: 0.8640\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.3171 - acc: 0.8631 - val_loss: 0.3574 - val_acc: 0.8573\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 11s 76ms/step - loss: 0.3152 - acc: 0.8676 - val_loss: 0.3312 - val_acc: 0.8676\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3159 - acc: 0.8675 - val_loss: 0.3330 - val_acc: 0.8715\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3128 - acc: 0.8667 - val_loss: 0.3309 - val_acc: 0.8627\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 10s 75ms/step - loss: 0.3169 - acc: 0.8694 - val_loss: 0.3081 - val_acc: 0.8773\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3169 - acc: 0.8672 - val_loss: 0.3299 - val_acc: 0.8635\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3127 - acc: 0.8685 - val_loss: 0.3323 - val_acc: 0.8575\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.3062 - acc: 0.8723 - val_loss: 0.3260 - val_acc: 0.8676\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3092 - acc: 0.8711 - val_loss: 0.3088 - val_acc: 0.8685\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3134 - acc: 0.8675 - val_loss: 0.3694 - val_acc: 0.8598\n",
      "Epoch 73/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3137 - acc: 0.8721 - val_loss: 0.3056 - val_acc: 0.8723\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3092 - acc: 0.8704 - val_loss: 0.3096 - val_acc: 0.8737\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3100 - acc: 0.8693 - val_loss: 0.3305 - val_acc: 0.8625\n",
      "Epoch 76/80\n",
      "140/140 [==============================] - 10s 73ms/step - loss: 0.3113 - acc: 0.8679 - val_loss: 0.3507 - val_acc: 0.8584\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3075 - acc: 0.8687 - val_loss: 0.3256 - val_acc: 0.8685\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3093 - acc: 0.8696 - val_loss: 0.3600 - val_acc: 0.8556\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 10s 72ms/step - loss: 0.3029 - acc: 0.8721 - val_loss: 0.3166 - val_acc: 0.8679\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 0.3019 - acc: 0.8720 - val_loss: 0.3088 - val_acc: 0.8708\n",
      "\n",
      "Training process completed in: 0 h 13 m 54 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1243.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1245 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_337 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_337 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_338 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_338 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_339 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_339 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_340 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_340 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.5083 - acc: 0.7604 - val_loss: 0.4094 - val_acc: 0.8275\n",
      "Epoch 2/80\n",
      "170/170 [==============================] - 6s 34ms/step - loss: 0.4322 - acc: 0.8165 - val_loss: 0.4505 - val_acc: 0.8000\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.4153 - acc: 0.8226 - val_loss: 0.3981 - val_acc: 0.8163\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.4022 - acc: 0.8292 - val_loss: 0.4355 - val_acc: 0.8000\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.4066 - acc: 0.8249 - val_loss: 0.3958 - val_acc: 0.8550\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.4061 - acc: 0.8273 - val_loss: 0.4116 - val_acc: 0.8275\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.4048 - acc: 0.8254 - val_loss: 0.4045 - val_acc: 0.8250\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3962 - acc: 0.8298 - val_loss: 0.4130 - val_acc: 0.8350\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3863 - acc: 0.8319 - val_loss: 0.3741 - val_acc: 0.8300\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3902 - acc: 0.8301 - val_loss: 0.3815 - val_acc: 0.8237\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3870 - acc: 0.8356 - val_loss: 0.4080 - val_acc: 0.8238\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3743 - acc: 0.8385 - val_loss: 0.4089 - val_acc: 0.8262\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3798 - acc: 0.8390 - val_loss: 0.3619 - val_acc: 0.8412\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3760 - acc: 0.8389 - val_loss: 0.3842 - val_acc: 0.8450\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3819 - acc: 0.8349 - val_loss: 0.3614 - val_acc: 0.8338\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3676 - acc: 0.8450 - val_loss: 0.4060 - val_acc: 0.8388\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3548 - acc: 0.8527 - val_loss: 0.3575 - val_acc: 0.8525\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3659 - acc: 0.8436 - val_loss: 0.3736 - val_acc: 0.8475\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3596 - acc: 0.8483 - val_loss: 0.3538 - val_acc: 0.8600\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3564 - acc: 0.8468 - val_loss: 0.3765 - val_acc: 0.8537\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3648 - acc: 0.8429 - val_loss: 0.3448 - val_acc: 0.8512\n",
      "Epoch 22/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3519 - acc: 0.8534 - val_loss: 0.3854 - val_acc: 0.8425\n",
      "Epoch 23/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3509 - acc: 0.8501 - val_loss: 0.3506 - val_acc: 0.8538\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3444 - acc: 0.8499 - val_loss: 0.3295 - val_acc: 0.8662\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3421 - acc: 0.8527 - val_loss: 0.3322 - val_acc: 0.8662\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3560 - acc: 0.8488 - val_loss: 0.3857 - val_acc: 0.8450\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3507 - acc: 0.8513 - val_loss: 0.3397 - val_acc: 0.8613\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3437 - acc: 0.8568 - val_loss: 0.3591 - val_acc: 0.8425\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3472 - acc: 0.8578 - val_loss: 0.3769 - val_acc: 0.8450\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3500 - acc: 0.8501 - val_loss: 0.3563 - val_acc: 0.8438\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3467 - acc: 0.8538 - val_loss: 0.3726 - val_acc: 0.8288\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3432 - acc: 0.8552 - val_loss: 0.3413 - val_acc: 0.8538\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3450 - acc: 0.8539 - val_loss: 0.3239 - val_acc: 0.8500\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3446 - acc: 0.8522 - val_loss: 0.3613 - val_acc: 0.8450\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3351 - acc: 0.8587 - val_loss: 0.3693 - val_acc: 0.8384\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3318 - acc: 0.8601 - val_loss: 0.3369 - val_acc: 0.8512\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3417 - acc: 0.8535 - val_loss: 0.3367 - val_acc: 0.8525\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3449 - acc: 0.8533 - val_loss: 0.3106 - val_acc: 0.8725\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3383 - acc: 0.8557 - val_loss: 0.3479 - val_acc: 0.8488\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3366 - acc: 0.8559 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3367 - acc: 0.8586 - val_loss: 0.3569 - val_acc: 0.8463\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3319 - acc: 0.8569 - val_loss: 0.3514 - val_acc: 0.8587\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3367 - acc: 0.8581 - val_loss: 0.3361 - val_acc: 0.8588\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3314 - acc: 0.8582 - val_loss: 0.3402 - val_acc: 0.8725\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3361 - acc: 0.8608 - val_loss: 0.3237 - val_acc: 0.8712\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3310 - acc: 0.8599 - val_loss: 0.3406 - val_acc: 0.8700\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3301 - acc: 0.8610 - val_loss: 0.3439 - val_acc: 0.8613\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3372 - acc: 0.8576 - val_loss: 0.3382 - val_acc: 0.8513\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3266 - acc: 0.8612 - val_loss: 0.3652 - val_acc: 0.8413\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3262 - acc: 0.8624 - val_loss: 0.3346 - val_acc: 0.8588\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3291 - acc: 0.8594 - val_loss: 0.3320 - val_acc: 0.8725\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3214 - acc: 0.8638 - val_loss: 0.3464 - val_acc: 0.8638\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3273 - acc: 0.8627 - val_loss: 0.3617 - val_acc: 0.8563\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3281 - acc: 0.8611 - val_loss: 0.3042 - val_acc: 0.8812\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3315 - acc: 0.8621 - val_loss: 0.3111 - val_acc: 0.8837\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3292 - acc: 0.8571 - val_loss: 0.3593 - val_acc: 0.8650\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3391 - acc: 0.8568 - val_loss: 0.3688 - val_acc: 0.8500\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3217 - acc: 0.8660 - val_loss: 0.3209 - val_acc: 0.8800\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3299 - acc: 0.8606 - val_loss: 0.3497 - val_acc: 0.8475\n",
      "Epoch 60/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3294 - acc: 0.8649 - val_loss: 0.3319 - val_acc: 0.8513\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3361 - acc: 0.8565 - val_loss: 0.3120 - val_acc: 0.8650\n",
      "Epoch 62/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3151 - acc: 0.8710 - val_loss: 0.3076 - val_acc: 0.8625\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3260 - acc: 0.8590 - val_loss: 0.3067 - val_acc: 0.8737\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3241 - acc: 0.8649 - val_loss: 0.3125 - val_acc: 0.8650\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3243 - acc: 0.8640 - val_loss: 0.3283 - val_acc: 0.8700\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3241 - acc: 0.8624 - val_loss: 0.3106 - val_acc: 0.8725\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3117 - acc: 0.8676 - val_loss: 0.3641 - val_acc: 0.8538\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3203 - acc: 0.8644 - val_loss: 0.3380 - val_acc: 0.8512\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3241 - acc: 0.8633 - val_loss: 0.3384 - val_acc: 0.8650\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3246 - acc: 0.8658 - val_loss: 0.3037 - val_acc: 0.8927\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 6s 34ms/step - loss: 0.3177 - acc: 0.8665 - val_loss: 0.3393 - val_acc: 0.8500\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3115 - acc: 0.8722 - val_loss: 0.3090 - val_acc: 0.8663\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3163 - acc: 0.8693 - val_loss: 0.3097 - val_acc: 0.8750\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3182 - acc: 0.8659 - val_loss: 0.3364 - val_acc: 0.8688\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3300 - acc: 0.8602 - val_loss: 0.3591 - val_acc: 0.8450\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3195 - acc: 0.8686 - val_loss: 0.3308 - val_acc: 0.8738\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3164 - acc: 0.8668 - val_loss: 0.3417 - val_acc: 0.8562\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3217 - acc: 0.8663 - val_loss: 0.3503 - val_acc: 0.8575\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3252 - acc: 0.8651 - val_loss: 0.3545 - val_acc: 0.8475\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.3326 - acc: 0.8614 - val_loss: 0.3240 - val_acc: 0.8675\n",
      "\n",
      "Training process completed in: 0 h 8 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1244.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1246 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_341 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_341 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_342 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_342 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_343 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_343 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_344 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_344 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_86 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 11s 75ms/step - loss: 0.5118 - acc: 0.7591 - val_loss: 0.4358 - val_acc: 0.8000\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 5s 34ms/step - loss: 0.4368 - acc: 0.8141 - val_loss: 0.3846 - val_acc: 0.8450\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.4142 - acc: 0.8255 - val_loss: 0.4066 - val_acc: 0.8325\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.4218 - acc: 0.8248 - val_loss: 0.4108 - val_acc: 0.8262\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.4271 - acc: 0.8147 - val_loss: 0.3451 - val_acc: 0.8475\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.3863 - acc: 0.8362 - val_loss: 0.4416 - val_acc: 0.8213\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3926 - acc: 0.8351 - val_loss: 0.3982 - val_acc: 0.8450\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.4081 - acc: 0.8268 - val_loss: 0.4054 - val_acc: 0.8475\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.3910 - acc: 0.8336 - val_loss: 0.4379 - val_acc: 0.8125\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3893 - acc: 0.8327 - val_loss: 0.4013 - val_acc: 0.8363\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3896 - acc: 0.8340 - val_loss: 0.4173 - val_acc: 0.8387\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3896 - acc: 0.8305 - val_loss: 0.4148 - val_acc: 0.8175\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3801 - acc: 0.8422 - val_loss: 0.3762 - val_acc: 0.8425\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3860 - acc: 0.8367 - val_loss: 0.4002 - val_acc: 0.8288\n",
      "Epoch 15/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3779 - acc: 0.8388 - val_loss: 0.4078 - val_acc: 0.8250\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3863 - acc: 0.8335 - val_loss: 0.3764 - val_acc: 0.8462\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3839 - acc: 0.8326 - val_loss: 0.3996 - val_acc: 0.8363\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3776 - acc: 0.8380 - val_loss: 0.4180 - val_acc: 0.8425\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3738 - acc: 0.8413 - val_loss: 0.3762 - val_acc: 0.8438\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3766 - acc: 0.8392 - val_loss: 0.3935 - val_acc: 0.8537\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3614 - acc: 0.8479 - val_loss: 0.3905 - val_acc: 0.8500\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3723 - acc: 0.8416 - val_loss: 0.3826 - val_acc: 0.8437\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3747 - acc: 0.8417 - val_loss: 0.3811 - val_acc: 0.8387\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3627 - acc: 0.8472 - val_loss: 0.4241 - val_acc: 0.8263\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3684 - acc: 0.8439 - val_loss: 0.4100 - val_acc: 0.8275\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3561 - acc: 0.8500 - val_loss: 0.3762 - val_acc: 0.8350\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3586 - acc: 0.8504 - val_loss: 0.4301 - val_acc: 0.8163\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3679 - acc: 0.8444 - val_loss: 0.3321 - val_acc: 0.8575\n",
      "Epoch 29/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3621 - acc: 0.8449 - val_loss: 0.3941 - val_acc: 0.8550\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3605 - acc: 0.8453 - val_loss: 0.3895 - val_acc: 0.8275\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3624 - acc: 0.8442 - val_loss: 0.3707 - val_acc: 0.8425\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3563 - acc: 0.8479 - val_loss: 0.3805 - val_acc: 0.8388\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3660 - acc: 0.8459 - val_loss: 0.3620 - val_acc: 0.8437\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3664 - acc: 0.8443 - val_loss: 0.3571 - val_acc: 0.8525\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3593 - acc: 0.8483 - val_loss: 0.3404 - val_acc: 0.8573\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.3593 - acc: 0.8434 - val_loss: 0.3677 - val_acc: 0.8400\n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3519 - acc: 0.8532 - val_loss: 0.3629 - val_acc: 0.8500\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3490 - acc: 0.8532 - val_loss: 0.3980 - val_acc: 0.8300\n",
      "Epoch 39/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3542 - acc: 0.8453 - val_loss: 0.3436 - val_acc: 0.8425\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3547 - acc: 0.8485 - val_loss: 0.3696 - val_acc: 0.8350\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3499 - acc: 0.8505 - val_loss: 0.3468 - val_acc: 0.8512\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3563 - acc: 0.8504 - val_loss: 0.3744 - val_acc: 0.8475\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3592 - acc: 0.8453 - val_loss: 0.3583 - val_acc: 0.8437\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3501 - acc: 0.8517 - val_loss: 0.3635 - val_acc: 0.8300\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3449 - acc: 0.8504 - val_loss: 0.3655 - val_acc: 0.8425\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3516 - acc: 0.8511 - val_loss: 0.3765 - val_acc: 0.8487\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3404 - acc: 0.8556 - val_loss: 0.3629 - val_acc: 0.8488\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3482 - acc: 0.8545 - val_loss: 0.3617 - val_acc: 0.8538\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3494 - acc: 0.8511 - val_loss: 0.4087 - val_acc: 0.8300\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3462 - acc: 0.8565 - val_loss: 0.3469 - val_acc: 0.8600\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3503 - acc: 0.8516 - val_loss: 0.3680 - val_acc: 0.8325\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3383 - acc: 0.8551 - val_loss: 0.3352 - val_acc: 0.8613\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3440 - acc: 0.8532 - val_loss: 0.3543 - val_acc: 0.8525\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3402 - acc: 0.8543 - val_loss: 0.3779 - val_acc: 0.8562\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3455 - acc: 0.8527 - val_loss: 0.3528 - val_acc: 0.8537\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3474 - acc: 0.8538 - val_loss: 0.3308 - val_acc: 0.8675\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3469 - acc: 0.8502 - val_loss: 0.3735 - val_acc: 0.8375\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3468 - acc: 0.8544 - val_loss: 0.3301 - val_acc: 0.8663\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3506 - acc: 0.8496 - val_loss: 0.3216 - val_acc: 0.8788\n",
      "Epoch 60/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3456 - acc: 0.8525 - val_loss: 0.3177 - val_acc: 0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3343 - acc: 0.8574 - val_loss: 0.3555 - val_acc: 0.8562\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3360 - acc: 0.8599 - val_loss: 0.3386 - val_acc: 0.8663\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3455 - acc: 0.8530 - val_loss: 0.3480 - val_acc: 0.8475\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3403 - acc: 0.8546 - val_loss: 0.3303 - val_acc: 0.8625\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3405 - acc: 0.8543 - val_loss: 0.3554 - val_acc: 0.8537\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3273 - acc: 0.8609 - val_loss: 0.3241 - val_acc: 0.8638\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3288 - acc: 0.8596 - val_loss: 0.3505 - val_acc: 0.8650\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3348 - acc: 0.8588 - val_loss: 0.3436 - val_acc: 0.8575\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3397 - acc: 0.8560 - val_loss: 0.3566 - val_acc: 0.8488\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.3407 - acc: 0.8528 - val_loss: 0.3744 - val_acc: 0.8460\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 5s 34ms/step - loss: 0.3383 - acc: 0.8551 - val_loss: 0.3727 - val_acc: 0.8362\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3367 - acc: 0.8566 - val_loss: 0.2950 - val_acc: 0.8863\n",
      "Epoch 73/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3300 - acc: 0.8582 - val_loss: 0.3703 - val_acc: 0.8400\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3392 - acc: 0.8603 - val_loss: 0.3501 - val_acc: 0.8425\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3339 - acc: 0.8571 - val_loss: 0.3587 - val_acc: 0.8575\n",
      "Epoch 76/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3277 - acc: 0.8631 - val_loss: 0.3737 - val_acc: 0.8387\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3447 - acc: 0.8526 - val_loss: 0.3262 - val_acc: 0.8650\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3404 - acc: 0.8573 - val_loss: 0.3460 - val_acc: 0.8637\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3333 - acc: 0.8585 - val_loss: 0.3135 - val_acc: 0.8738\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.3310 - acc: 0.8597 - val_loss: 0.3041 - val_acc: 0.8675\n",
      "\n",
      "Training process completed in: 0 h 6 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1245.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1247 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_345 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_345 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_346 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_346 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_347 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_347 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_348 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_348 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 20s 120ms/step - loss: 0.4673 - acc: 0.7862 - val_loss: 0.4390 - val_acc: 0.8152\n",
      "Epoch 2/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.4203 - acc: 0.8221 - val_loss: 0.4209 - val_acc: 0.8185\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.4068 - acc: 0.8269 - val_loss: 0.4218 - val_acc: 0.8331\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3928 - acc: 0.8331 - val_loss: 0.4676 - val_acc: 0.8299\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3948 - acc: 0.8282 - val_loss: 0.3801 - val_acc: 0.8369\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 15s 87ms/step - loss: 0.3829 - acc: 0.8335 - val_loss: 0.3983 - val_acc: 0.8365\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 15s 87ms/step - loss: 0.3788 - acc: 0.8388 - val_loss: 0.3851 - val_acc: 0.8253\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 15s 87ms/step - loss: 0.3880 - acc: 0.8342 - val_loss: 0.4244 - val_acc: 0.8514\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3807 - acc: 0.8342 - val_loss: 0.4103 - val_acc: 0.8275\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3631 - acc: 0.8446 - val_loss: 0.3868 - val_acc: 0.8267\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3714 - acc: 0.8431 - val_loss: 0.3877 - val_acc: 0.8390\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3655 - acc: 0.8422 - val_loss: 0.3993 - val_acc: 0.8362\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3531 - acc: 0.8500 - val_loss: 0.3686 - val_acc: 0.8516\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3560 - acc: 0.8478 - val_loss: 0.3818 - val_acc: 0.8548\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3556 - acc: 0.8496 - val_loss: 0.3935 - val_acc: 0.8379\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3465 - acc: 0.8543 - val_loss: 0.3960 - val_acc: 0.8446\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3471 - acc: 0.8519 - val_loss: 0.3736 - val_acc: 0.8526\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3505 - acc: 0.8523 - val_loss: 0.4450 - val_acc: 0.8220\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3465 - acc: 0.8532 - val_loss: 0.3500 - val_acc: 0.8633\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3430 - acc: 0.8556 - val_loss: 0.3594 - val_acc: 0.8461\n",
      "Epoch 21/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3467 - acc: 0.8535 - val_loss: 0.3511 - val_acc: 0.8571\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3339 - acc: 0.8570 - val_loss: 0.3530 - val_acc: 0.8590\n",
      "Epoch 23/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3440 - acc: 0.8539 - val_loss: 0.3548 - val_acc: 0.8550\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3389 - acc: 0.8540 - val_loss: 0.3812 - val_acc: 0.8438\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3332 - acc: 0.8583 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3386 - acc: 0.8553 - val_loss: 0.3388 - val_acc: 0.8607\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3307 - acc: 0.8578 - val_loss: 0.3492 - val_acc: 0.8549\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3330 - acc: 0.8590 - val_loss: 0.3525 - val_acc: 0.8601\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3286 - acc: 0.8635 - val_loss: 0.3424 - val_acc: 0.8603\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3336 - acc: 0.8594 - val_loss: 0.3418 - val_acc: 0.8587\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3275 - acc: 0.8624 - val_loss: 0.3329 - val_acc: 0.8648\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3336 - acc: 0.8596 - val_loss: 0.3400 - val_acc: 0.8666\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3290 - acc: 0.8610 - val_loss: 0.3899 - val_acc: 0.8437\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3271 - acc: 0.8614 - val_loss: 0.3509 - val_acc: 0.8550\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3259 - acc: 0.8600 - val_loss: 0.3294 - val_acc: 0.8662\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3195 - acc: 0.8647 - val_loss: 0.3351 - val_acc: 0.8663\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3254 - acc: 0.8619 - val_loss: 0.3857 - val_acc: 0.8439\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3230 - acc: 0.8626 - val_loss: 0.3336 - val_acc: 0.8624\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3218 - acc: 0.8633 - val_loss: 0.3465 - val_acc: 0.8577\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3175 - acc: 0.8672 - val_loss: 0.3231 - val_acc: 0.8683\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3250 - acc: 0.8646 - val_loss: 0.3793 - val_acc: 0.8482\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3216 - acc: 0.8626 - val_loss: 0.3399 - val_acc: 0.8599\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3108 - acc: 0.8695 - val_loss: 0.3326 - val_acc: 0.8647\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3200 - acc: 0.8666 - val_loss: 0.3332 - val_acc: 0.8651\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3149 - acc: 0.8646 - val_loss: 0.3316 - val_acc: 0.8625\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3101 - acc: 0.8689 - val_loss: 0.3801 - val_acc: 0.8657\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3203 - acc: 0.8651 - val_loss: 0.3465 - val_acc: 0.8611\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3215 - acc: 0.8651 - val_loss: 0.3316 - val_acc: 0.8671\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3177 - acc: 0.8673 - val_loss: 0.3478 - val_acc: 0.8597\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3143 - acc: 0.8675 - val_loss: 0.3525 - val_acc: 0.8583\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3114 - acc: 0.8695 - val_loss: 0.3209 - val_acc: 0.8737\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3153 - acc: 0.8655 - val_loss: 0.3706 - val_acc: 0.8618\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3067 - acc: 0.8728 - val_loss: 0.3368 - val_acc: 0.8636\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3141 - acc: 0.8669 - val_loss: 0.3528 - val_acc: 0.8663\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3143 - acc: 0.8646 - val_loss: 0.3274 - val_acc: 0.8673\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3152 - acc: 0.8660 - val_loss: 0.3560 - val_acc: 0.8650\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3157 - acc: 0.8669 - val_loss: 0.3250 - val_acc: 0.8679\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3105 - acc: 0.8676 - val_loss: 0.3310 - val_acc: 0.8650\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3084 - acc: 0.8705 - val_loss: 0.3162 - val_acc: 0.8710\n",
      "Epoch 60/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3090 - acc: 0.8713 - val_loss: 0.3257 - val_acc: 0.8741\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3109 - acc: 0.8686 - val_loss: 0.3360 - val_acc: 0.8636\n",
      "Epoch 62/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3125 - acc: 0.8695 - val_loss: 0.3297 - val_acc: 0.8681\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3133 - acc: 0.8686 - val_loss: 0.3222 - val_acc: 0.8687\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3097 - acc: 0.8686 - val_loss: 0.3265 - val_acc: 0.8677\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3075 - acc: 0.8701 - val_loss: 0.3163 - val_acc: 0.8684\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3110 - acc: 0.8677 - val_loss: 0.3495 - val_acc: 0.8677\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.2978 - acc: 0.8757 - val_loss: 0.3418 - val_acc: 0.8642\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3058 - acc: 0.8716 - val_loss: 0.3507 - val_acc: 0.8706\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3070 - acc: 0.8714 - val_loss: 0.3329 - val_acc: 0.8685\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 15s 88ms/step - loss: 0.3050 - acc: 0.8728 - val_loss: 0.3288 - val_acc: 0.8736\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3084 - acc: 0.8696 - val_loss: 0.3285 - val_acc: 0.8667\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 15s 89ms/step - loss: 0.3017 - acc: 0.8740 - val_loss: 0.3159 - val_acc: 0.8779\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3040 - acc: 0.8704 - val_loss: 0.3597 - val_acc: 0.8598\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3064 - acc: 0.8732 - val_loss: 0.3319 - val_acc: 0.8681\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3012 - acc: 0.8727 - val_loss: 0.3267 - val_acc: 0.8737\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3010 - acc: 0.8747 - val_loss: 0.3173 - val_acc: 0.8688\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3064 - acc: 0.8710 - val_loss: 0.3250 - val_acc: 0.8685\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3035 - acc: 0.8714 - val_loss: 0.3357 - val_acc: 0.8645\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 15s 90ms/step - loss: 0.3013 - acc: 0.8743 - val_loss: 0.3245 - val_acc: 0.8722\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 15s 91ms/step - loss: 0.3004 - acc: 0.8716 - val_loss: 0.3151 - val_acc: 0.8716\n",
      "\n",
      "Training process completed in: 0 h 20 m 15 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1246.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1248 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_349 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_349 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_350 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_350 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_351 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_351 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_352 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_352 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_88 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 0.4776 - acc: 0.7781 - val_loss: 0.4183 - val_acc: 0.8225\n",
      "Epoch 2/80\n",
      "170/170 [==============================] - 11s 63ms/step - loss: 0.4111 - acc: 0.8260 - val_loss: 0.3981 - val_acc: 0.8281\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.4104 - acc: 0.8222 - val_loss: 0.3859 - val_acc: 0.8163\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 11s 68ms/step - loss: 0.3912 - acc: 0.8315 - val_loss: 0.4098 - val_acc: 0.8300\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3842 - acc: 0.8356 - val_loss: 0.3827 - val_acc: 0.8394\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 11s 68ms/step - loss: 0.3870 - acc: 0.8328 - val_loss: 0.3785 - val_acc: 0.8544\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3746 - acc: 0.8398 - val_loss: 0.4227 - val_acc: 0.8325\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3747 - acc: 0.8350 - val_loss: 0.3695 - val_acc: 0.8381\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 12s 70ms/step - loss: 0.3695 - acc: 0.8410 - val_loss: 0.3922 - val_acc: 0.8594\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3717 - acc: 0.8390 - val_loss: 0.3988 - val_acc: 0.8325\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3586 - acc: 0.8464 - val_loss: 0.3621 - val_acc: 0.8406\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3637 - acc: 0.8412 - val_loss: 0.3767 - val_acc: 0.8444\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3612 - acc: 0.8451 - val_loss: 0.3541 - val_acc: 0.8600\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3554 - acc: 0.8473 - val_loss: 0.4413 - val_acc: 0.7975\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3516 - acc: 0.8507 - val_loss: 0.3829 - val_acc: 0.8375\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3479 - acc: 0.8525 - val_loss: 0.3651 - val_acc: 0.8475\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3518 - acc: 0.8495 - val_loss: 0.3548 - val_acc: 0.8525\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 12s 70ms/step - loss: 0.3492 - acc: 0.8514 - val_loss: 0.3779 - val_acc: 0.8333\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 11s 66ms/step - loss: 0.3455 - acc: 0.8541 - val_loss: 0.3645 - val_acc: 0.8419\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3510 - acc: 0.8491 - val_loss: 0.3364 - val_acc: 0.8488\n",
      "Epoch 21/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3446 - acc: 0.8538 - val_loss: 0.3510 - val_acc: 0.8481\n",
      "Epoch 22/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3364 - acc: 0.8599 - val_loss: 0.3421 - val_acc: 0.8444\n",
      "Epoch 23/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3428 - acc: 0.8529 - val_loss: 0.4089 - val_acc: 0.8231\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3348 - acc: 0.8585 - val_loss: 0.3519 - val_acc: 0.8488\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3353 - acc: 0.8585 - val_loss: 0.3321 - val_acc: 0.8619\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3414 - acc: 0.8560 - val_loss: 0.3289 - val_acc: 0.8612\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3381 - acc: 0.8545 - val_loss: 0.3413 - val_acc: 0.8569\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3314 - acc: 0.8599 - val_loss: 0.3537 - val_acc: 0.8569\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3382 - acc: 0.8576 - val_loss: 0.3417 - val_acc: 0.8600\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3317 - acc: 0.8593 - val_loss: 0.3497 - val_acc: 0.8475\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3341 - acc: 0.8575 - val_loss: 0.3563 - val_acc: 0.8606\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3299 - acc: 0.8596 - val_loss: 0.3578 - val_acc: 0.8488\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3297 - acc: 0.8603 - val_loss: 0.3325 - val_acc: 0.8562\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3292 - acc: 0.8600 - val_loss: 0.3021 - val_acc: 0.8700\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3281 - acc: 0.8611 - val_loss: 0.3400 - val_acc: 0.8512\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3335 - acc: 0.8573 - val_loss: 0.3536 - val_acc: 0.8525\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3234 - acc: 0.8631 - val_loss: 0.3181 - val_acc: 0.8606\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3281 - acc: 0.8623 - val_loss: 0.3310 - val_acc: 0.8600\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3271 - acc: 0.8615 - val_loss: 0.3358 - val_acc: 0.8650\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3254 - acc: 0.8615 - val_loss: 0.3472 - val_acc: 0.8513\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 12s 70ms/step - loss: 0.3209 - acc: 0.8652 - val_loss: 0.3486 - val_acc: 0.8544\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3268 - acc: 0.8607 - val_loss: 0.3615 - val_acc: 0.8437\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3218 - acc: 0.8669 - val_loss: 0.3282 - val_acc: 0.8694\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3210 - acc: 0.8643 - val_loss: 0.3422 - val_acc: 0.8463\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3231 - acc: 0.8645 - val_loss: 0.3219 - val_acc: 0.8706\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3181 - acc: 0.8651 - val_loss: 0.3321 - val_acc: 0.8675\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3223 - acc: 0.8633 - val_loss: 0.3541 - val_acc: 0.8537\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3228 - acc: 0.8627 - val_loss: 0.3250 - val_acc: 0.8619\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3177 - acc: 0.8640 - val_loss: 0.3336 - val_acc: 0.8631\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3161 - acc: 0.8658 - val_loss: 0.3232 - val_acc: 0.8825\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3130 - acc: 0.8689 - val_loss: 0.3292 - val_acc: 0.8762\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3163 - acc: 0.8678 - val_loss: 0.3275 - val_acc: 0.8738\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 12s 71ms/step - loss: 0.3203 - acc: 0.8659 - val_loss: 0.3203 - val_acc: 0.8724\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 11s 65ms/step - loss: 0.3197 - acc: 0.8653 - val_loss: 0.3297 - val_acc: 0.8712\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3127 - acc: 0.8692 - val_loss: 0.3100 - val_acc: 0.8656\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3132 - acc: 0.8656 - val_loss: 0.3301 - val_acc: 0.8538\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 11s 68ms/step - loss: 0.3123 - acc: 0.8671 - val_loss: 0.3084 - val_acc: 0.8700\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3163 - acc: 0.8651 - val_loss: 0.3254 - val_acc: 0.8619\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3135 - acc: 0.8674 - val_loss: 0.3162 - val_acc: 0.8687\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3091 - acc: 0.8686 - val_loss: 0.3512 - val_acc: 0.8575\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3127 - acc: 0.8665 - val_loss: 0.3209 - val_acc: 0.8737\n",
      "Epoch 62/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3119 - acc: 0.8687 - val_loss: 0.3272 - val_acc: 0.8706\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3051 - acc: 0.8700 - val_loss: 0.3114 - val_acc: 0.8581\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3101 - acc: 0.8690 - val_loss: 0.3276 - val_acc: 0.8750\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3042 - acc: 0.8747 - val_loss: 0.3248 - val_acc: 0.8619\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3068 - acc: 0.8711 - val_loss: 0.3494 - val_acc: 0.8481\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3158 - acc: 0.8635 - val_loss: 0.3099 - val_acc: 0.8831\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3099 - acc: 0.8708 - val_loss: 0.3028 - val_acc: 0.8688\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 11s 67ms/step - loss: 0.3030 - acc: 0.8688 - val_loss: 0.3505 - val_acc: 0.8488\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3161 - acc: 0.8674 - val_loss: 0.3356 - val_acc: 0.8552\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 11s 66ms/step - loss: 0.3017 - acc: 0.8732 - val_loss: 0.3351 - val_acc: 0.8475\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3140 - acc: 0.8689 - val_loss: 0.3346 - val_acc: 0.8581\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 12s 68ms/step - loss: 0.3026 - acc: 0.8731 - val_loss: 0.3096 - val_acc: 0.8637\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3126 - acc: 0.8680 - val_loss: 0.3094 - val_acc: 0.8744\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 12s 70ms/step - loss: 0.3048 - acc: 0.8714 - val_loss: 0.3356 - val_acc: 0.8594\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3076 - acc: 0.8695 - val_loss: 0.3193 - val_acc: 0.8594\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.2999 - acc: 0.8739 - val_loss: 0.2970 - val_acc: 0.8788\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3002 - acc: 0.8735 - val_loss: 0.2895 - val_acc: 0.8806\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3091 - acc: 0.8676 - val_loss: 0.3438 - val_acc: 0.8556\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.3082 - acc: 0.8690 - val_loss: 0.3349 - val_acc: 0.8606\n",
      "\n",
      "Training process completed in: 0 h 15 m 32 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1247.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1249 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_353 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_353 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_354 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_354 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_355 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_355 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_356 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_356 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_89 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 10\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 12s 69ms/step - loss: 0.4872 - acc: 0.7778 - val_loss: 0.5016 - val_acc: 0.7413\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 6s 35ms/step - loss: 0.4374 - acc: 0.8128 - val_loss: 0.4031 - val_acc: 0.8313\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 6s 37ms/step - loss: 0.4285 - acc: 0.8158 - val_loss: 0.4533 - val_acc: 0.8150\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 6s 37ms/step - loss: 0.4154 - acc: 0.8200 - val_loss: 0.4064 - val_acc: 0.8388\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 6s 37ms/step - loss: 0.4055 - acc: 0.8246 - val_loss: 0.4232 - val_acc: 0.8287\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.4035 - acc: 0.8312 - val_loss: 0.4085 - val_acc: 0.8200\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3869 - acc: 0.8328 - val_loss: 0.3746 - val_acc: 0.8387\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 6s 36ms/step - loss: 0.3989 - acc: 0.8324 - val_loss: 0.3732 - val_acc: 0.8288\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 6s 37ms/step - loss: 0.3926 - acc: 0.8333 - val_loss: 0.3957 - val_acc: 0.8238\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 6s 37ms/step - loss: 0.3942 - acc: 0.8295 - val_loss: 0.4090 - val_acc: 0.8163\n",
      "\n",
      "Training process completed in: 0 h 1 m 7 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1248.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1250 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_357 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_357 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_358 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_358 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_359 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_359 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_360 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_360 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_90 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 12s 63ms/step - loss: 0.5052 - acc: 0.7683 - val_loss: 0.4429 - val_acc: 0.8133\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4413 - acc: 0.8125 - val_loss: 0.4398 - val_acc: 0.8125\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4222 - acc: 0.8162 - val_loss: 0.4031 - val_acc: 0.8304\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4071 - acc: 0.8302 - val_loss: 0.4050 - val_acc: 0.8304\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3965 - acc: 0.8318 - val_loss: 0.3859 - val_acc: 0.8338\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.4085 - acc: 0.8283 - val_loss: 0.3912 - val_acc: 0.8213\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3973 - acc: 0.8324 - val_loss: 0.4098 - val_acc: 0.8283\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3906 - acc: 0.8368 - val_loss: 0.4019 - val_acc: 0.8321\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3880 - acc: 0.8335 - val_loss: 0.3966 - val_acc: 0.8279\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3763 - acc: 0.8411 - val_loss: 0.3843 - val_acc: 0.8204\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3718 - acc: 0.8450 - val_loss: 0.4095 - val_acc: 0.8504\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3741 - acc: 0.8413 - val_loss: 0.4223 - val_acc: 0.8415\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3838 - acc: 0.8374 - val_loss: 0.3963 - val_acc: 0.8204\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3849 - acc: 0.8347 - val_loss: 0.3959 - val_acc: 0.8258\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3816 - acc: 0.8393 - val_loss: 0.3946 - val_acc: 0.8313\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3665 - acc: 0.8476 - val_loss: 0.3624 - val_acc: 0.8458\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3685 - acc: 0.8416 - val_loss: 0.3936 - val_acc: 0.8292\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3737 - acc: 0.8415 - val_loss: 0.3677 - val_acc: 0.8483\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 6s 33ms/step - loss: 0.3662 - acc: 0.8398 - val_loss: 0.3424 - val_acc: 0.8583\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3752 - acc: 0.8401 - val_loss: 0.3657 - val_acc: 0.8429\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3665 - acc: 0.8461 - val_loss: 0.3808 - val_acc: 0.8396\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3585 - acc: 0.8473 - val_loss: 0.3730 - val_acc: 0.8479\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3600 - acc: 0.8470 - val_loss: 0.3724 - val_acc: 0.8296\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3572 - acc: 0.8468 - val_loss: 0.3509 - val_acc: 0.8546\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3632 - acc: 0.8467 - val_loss: 0.3791 - val_acc: 0.8379\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3583 - acc: 0.8455 - val_loss: 0.3562 - val_acc: 0.8483\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3555 - acc: 0.8481 - val_loss: 0.3589 - val_acc: 0.8521\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3625 - acc: 0.8448 - val_loss: 0.3722 - val_acc: 0.8438\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3789 - acc: 0.8356 - val_loss: 0.3732 - val_acc: 0.8308\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3514 - acc: 0.8504 - val_loss: 0.3426 - val_acc: 0.8479\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3531 - acc: 0.8495 - val_loss: 0.3632 - val_acc: 0.8454\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3568 - acc: 0.8474 - val_loss: 0.3711 - val_acc: 0.8563\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3497 - acc: 0.8517 - val_loss: 0.3432 - val_acc: 0.8575\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3608 - acc: 0.8480 - val_loss: 0.3592 - val_acc: 0.8479\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3670 - acc: 0.8427 - val_loss: 0.3789 - val_acc: 0.8423\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3635 - acc: 0.8425 - val_loss: 0.3770 - val_acc: 0.8304\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3343 - acc: 0.8583 - val_loss: 0.3553 - val_acc: 0.8421\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3464 - acc: 0.8566 - val_loss: 0.3250 - val_acc: 0.8642\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3520 - acc: 0.8490 - val_loss: 0.3839 - val_acc: 0.8396\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3483 - acc: 0.8546 - val_loss: 0.3527 - val_acc: 0.8475\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3532 - acc: 0.8489 - val_loss: 0.3404 - val_acc: 0.8563\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3539 - acc: 0.8468 - val_loss: 0.3309 - val_acc: 0.8562\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3376 - acc: 0.8588 - val_loss: 0.3469 - val_acc: 0.8579\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3531 - acc: 0.8507 - val_loss: 0.3716 - val_acc: 0.8442\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3416 - acc: 0.8540 - val_loss: 0.3727 - val_acc: 0.8267\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3487 - acc: 0.8517 - val_loss: 0.3455 - val_acc: 0.8629\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3488 - acc: 0.8513 - val_loss: 0.3497 - val_acc: 0.8512\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3382 - acc: 0.8585 - val_loss: 0.3477 - val_acc: 0.8588\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3368 - acc: 0.8587 - val_loss: 0.3402 - val_acc: 0.8563\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3435 - acc: 0.8568 - val_loss: 0.3348 - val_acc: 0.8554\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3509 - acc: 0.8528 - val_loss: 0.3596 - val_acc: 0.8500\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3474 - acc: 0.8523 - val_loss: 0.3467 - val_acc: 0.8596\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3387 - acc: 0.8571 - val_loss: 0.3370 - val_acc: 0.8525\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3443 - acc: 0.8560 - val_loss: 0.3487 - val_acc: 0.8550\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3385 - acc: 0.8589 - val_loss: 0.3292 - val_acc: 0.8625\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3302 - acc: 0.8636 - val_loss: 0.3703 - val_acc: 0.8317\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3343 - acc: 0.8566 - val_loss: 0.3311 - val_acc: 0.8621\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3312 - acc: 0.8585 - val_loss: 0.3549 - val_acc: 0.8440\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3276 - acc: 0.8625 - val_loss: 0.3433 - val_acc: 0.8596\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3361 - acc: 0.8548 - val_loss: 0.3612 - val_acc: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3390 - acc: 0.8587 - val_loss: 0.3440 - val_acc: 0.8492\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3354 - acc: 0.8571 - val_loss: 0.3347 - val_acc: 0.8621\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3327 - acc: 0.8589 - val_loss: 0.3645 - val_acc: 0.8479\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3362 - acc: 0.8595 - val_loss: 0.3324 - val_acc: 0.8600\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3423 - acc: 0.8535 - val_loss: 0.3395 - val_acc: 0.8617\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3365 - acc: 0.8566 - val_loss: 0.3796 - val_acc: 0.8471\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3360 - acc: 0.8561 - val_loss: 0.3282 - val_acc: 0.8571\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3309 - acc: 0.8618 - val_loss: 0.3728 - val_acc: 0.8417\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3409 - acc: 0.8565 - val_loss: 0.3303 - val_acc: 0.8654\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3390 - acc: 0.8535 - val_loss: 0.3276 - val_acc: 0.8621\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 6s 32ms/step - loss: 0.3411 - acc: 0.8549 - val_loss: 0.3380 - val_acc: 0.8621\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3326 - acc: 0.8607 - val_loss: 0.3421 - val_acc: 0.8533\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3382 - acc: 0.8571 - val_loss: 0.3338 - val_acc: 0.8663\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3358 - acc: 0.8588 - val_loss: 0.3173 - val_acc: 0.8625\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3309 - acc: 0.8579 - val_loss: 0.3328 - val_acc: 0.8638\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3384 - acc: 0.8588 - val_loss: 0.3407 - val_acc: 0.8625\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3418 - acc: 0.8538 - val_loss: 0.3473 - val_acc: 0.8542\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3312 - acc: 0.8590 - val_loss: 0.3350 - val_acc: 0.8663\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3227 - acc: 0.8649 - val_loss: 0.3309 - val_acc: 0.8604\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 0.3351 - acc: 0.8576 - val_loss: 0.3322 - val_acc: 0.8504\n",
      "\n",
      "Training process completed in: 0 h 8 m 7 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1249.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1251 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_361 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_361 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_362 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_362 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_363 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_363 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_364 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_364 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_91 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.4643 - acc: 0.7907 - val_loss: 0.4151 - val_acc: 0.8192\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.4182 - acc: 0.8205 - val_loss: 0.4132 - val_acc: 0.8338\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.4062 - acc: 0.8244 - val_loss: 0.3953 - val_acc: 0.8303\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3921 - acc: 0.8341 - val_loss: 0.3980 - val_acc: 0.8327\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3938 - acc: 0.8304 - val_loss: 0.3958 - val_acc: 0.8295\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3771 - acc: 0.8383 - val_loss: 0.4025 - val_acc: 0.8293\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3797 - acc: 0.8381 - val_loss: 0.3889 - val_acc: 0.8360\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3737 - acc: 0.8405 - val_loss: 0.3742 - val_acc: 0.8455\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3701 - acc: 0.8413 - val_loss: 0.3911 - val_acc: 0.8448\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3672 - acc: 0.8454 - val_loss: 0.4078 - val_acc: 0.8380\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3641 - acc: 0.8435 - val_loss: 0.3639 - val_acc: 0.8440\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3562 - acc: 0.8482 - val_loss: 0.3694 - val_acc: 0.8425\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3580 - acc: 0.8477 - val_loss: 0.3963 - val_acc: 0.8497\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3580 - acc: 0.8456 - val_loss: 0.3401 - val_acc: 0.8621\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3576 - acc: 0.8480 - val_loss: 0.4141 - val_acc: 0.8335\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3487 - acc: 0.8532 - val_loss: 0.3850 - val_acc: 0.8587\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3499 - acc: 0.8510 - val_loss: 0.3821 - val_acc: 0.8492\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3467 - acc: 0.8524 - val_loss: 0.3412 - val_acc: 0.8563\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3442 - acc: 0.8519 - val_loss: 0.3531 - val_acc: 0.8602\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3471 - acc: 0.8528 - val_loss: 0.3612 - val_acc: 0.8587\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3369 - acc: 0.8568 - val_loss: 0.3626 - val_acc: 0.8582\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3370 - acc: 0.8567 - val_loss: 0.3406 - val_acc: 0.8632\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3342 - acc: 0.8573 - val_loss: 0.3365 - val_acc: 0.8643\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3415 - acc: 0.8535 - val_loss: 0.3420 - val_acc: 0.8474\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3353 - acc: 0.8573 - val_loss: 0.3495 - val_acc: 0.8605\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3330 - acc: 0.8592 - val_loss: 0.3844 - val_acc: 0.8457\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3293 - acc: 0.8600 - val_loss: 0.3643 - val_acc: 0.8565\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3269 - acc: 0.8597 - val_loss: 0.3375 - val_acc: 0.8629\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3308 - acc: 0.8593 - val_loss: 0.3511 - val_acc: 0.8575\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3222 - acc: 0.8633 - val_loss: 0.3360 - val_acc: 0.8610\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3236 - acc: 0.8633 - val_loss: 0.3257 - val_acc: 0.8653\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3244 - acc: 0.8637 - val_loss: 0.3491 - val_acc: 0.8650\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3334 - acc: 0.8596 - val_loss: 0.3694 - val_acc: 0.8503\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3279 - acc: 0.8619 - val_loss: 0.3280 - val_acc: 0.8635\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3168 - acc: 0.8652 - val_loss: 0.3366 - val_acc: 0.8685\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3180 - acc: 0.8656 - val_loss: 0.3203 - val_acc: 0.8715\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3202 - acc: 0.8650 - val_loss: 0.3328 - val_acc: 0.8578\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3159 - acc: 0.8659 - val_loss: 0.3742 - val_acc: 0.8481\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3226 - acc: 0.8636 - val_loss: 0.3433 - val_acc: 0.8617\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3108 - acc: 0.8687 - val_loss: 0.3292 - val_acc: 0.8617\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3195 - acc: 0.8656 - val_loss: 0.3583 - val_acc: 0.8655\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3224 - acc: 0.8643 - val_loss: 0.3428 - val_acc: 0.8634\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3076 - acc: 0.8711 - val_loss: 0.3393 - val_acc: 0.8648\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3116 - acc: 0.8702 - val_loss: 0.3184 - val_acc: 0.8678\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3172 - acc: 0.8665 - val_loss: 0.3416 - val_acc: 0.8620\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3113 - acc: 0.8692 - val_loss: 0.3234 - val_acc: 0.8665\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3078 - acc: 0.8712 - val_loss: 0.3167 - val_acc: 0.8681\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3139 - acc: 0.8669 - val_loss: 0.3285 - val_acc: 0.8647\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3082 - acc: 0.8712 - val_loss: 0.3348 - val_acc: 0.8650\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3110 - acc: 0.8686 - val_loss: 0.3334 - val_acc: 0.8678\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3070 - acc: 0.8724 - val_loss: 0.3219 - val_acc: 0.8686\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3033 - acc: 0.8718 - val_loss: 0.3593 - val_acc: 0.8610\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3118 - acc: 0.8695 - val_loss: 0.3303 - val_acc: 0.8743\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3069 - acc: 0.8711 - val_loss: 0.3210 - val_acc: 0.8692\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3123 - acc: 0.8686 - val_loss: 0.3609 - val_acc: 0.8607\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3007 - acc: 0.8721 - val_loss: 0.3288 - val_acc: 0.8659\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3056 - acc: 0.8721 - val_loss: 0.3229 - val_acc: 0.8682\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3004 - acc: 0.8761 - val_loss: 0.3214 - val_acc: 0.8692\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3064 - acc: 0.8693 - val_loss: 0.3367 - val_acc: 0.8680\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2993 - acc: 0.8751 - val_loss: 0.3149 - val_acc: 0.8717\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3038 - acc: 0.8728 - val_loss: 0.3183 - val_acc: 0.8668\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3077 - acc: 0.8701 - val_loss: 0.3297 - val_acc: 0.8762\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3028 - acc: 0.8738 - val_loss: 0.3210 - val_acc: 0.8615\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2982 - acc: 0.8750 - val_loss: 0.3221 - val_acc: 0.8683\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2971 - acc: 0.8758 - val_loss: 0.3195 - val_acc: 0.8698\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3018 - acc: 0.8715 - val_loss: 0.3314 - val_acc: 0.8692\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3007 - acc: 0.8747 - val_loss: 0.3477 - val_acc: 0.8683\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2971 - acc: 0.8763 - val_loss: 0.3062 - val_acc: 0.8732\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3025 - acc: 0.8725 - val_loss: 0.3328 - val_acc: 0.8573\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2973 - acc: 0.8749 - val_loss: 0.3224 - val_acc: 0.8718\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2991 - acc: 0.8741 - val_loss: 0.3141 - val_acc: 0.8775\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2953 - acc: 0.8765 - val_loss: 0.3215 - val_acc: 0.8718\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2937 - acc: 0.8766 - val_loss: 0.3174 - val_acc: 0.8697\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2976 - acc: 0.8746 - val_loss: 0.3089 - val_acc: 0.8733\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3024 - acc: 0.8728 - val_loss: 0.2980 - val_acc: 0.8747\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2916 - acc: 0.8786 - val_loss: 0.3056 - val_acc: 0.8740\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2909 - acc: 0.8786 - val_loss: 0.3365 - val_acc: 0.8693\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2995 - acc: 0.8738 - val_loss: 0.2995 - val_acc: 0.8738\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2961 - acc: 0.8761 - val_loss: 0.3303 - val_acc: 0.8651\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2901 - acc: 0.8794 - val_loss: 0.3309 - val_acc: 0.8727\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2906 - acc: 0.8772 - val_loss: 0.3079 - val_acc: 0.8712\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2961 - acc: 0.8746 - val_loss: 0.3161 - val_acc: 0.8755\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2940 - acc: 0.8774 - val_loss: 0.3070 - val_acc: 0.8740\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2854 - acc: 0.8805 - val_loss: 0.3052 - val_acc: 0.8780\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2908 - acc: 0.8770 - val_loss: 0.3213 - val_acc: 0.8712\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2895 - acc: 0.8787 - val_loss: 0.3083 - val_acc: 0.8698\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2920 - acc: 0.8781 - val_loss: 0.2963 - val_acc: 0.8842\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2898 - acc: 0.8784 - val_loss: 0.3196 - val_acc: 0.8673\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2828 - acc: 0.8833 - val_loss: 0.3027 - val_acc: 0.8726\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2963 - acc: 0.8761 - val_loss: 0.3062 - val_acc: 0.8770\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2882 - acc: 0.8792 - val_loss: 0.3068 - val_acc: 0.8807\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2925 - acc: 0.8788 - val_loss: 0.3264 - val_acc: 0.8688\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2908 - acc: 0.8780 - val_loss: 0.3230 - val_acc: 0.8705\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2849 - acc: 0.8825 - val_loss: 0.3213 - val_acc: 0.8735\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2848 - acc: 0.8801 - val_loss: 0.2976 - val_acc: 0.8763\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2927 - acc: 0.8774 - val_loss: 0.3046 - val_acc: 0.8740\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2827 - acc: 0.8827 - val_loss: 0.3056 - val_acc: 0.8685\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3430 - val_acc: 0.8703\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2807 - acc: 0.8808 - val_loss: 0.3184 - val_acc: 0.8792\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2848 - acc: 0.8810 - val_loss: 0.2985 - val_acc: 0.8785\n",
      "\n",
      "Training process completed in: 0 h 28 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1250.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1252 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_365 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_365 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_366 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_366 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_367 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_367 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_368 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_368 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_92 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 0.4660 - acc: 0.7897 - val_loss: 0.4211 - val_acc: 0.8185\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4181 - acc: 0.8178 - val_loss: 0.4054 - val_acc: 0.8263\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4000 - acc: 0.8290 - val_loss: 0.4297 - val_acc: 0.8202\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3872 - acc: 0.8330 - val_loss: 0.3804 - val_acc: 0.8298\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3791 - acc: 0.8367 - val_loss: 0.3678 - val_acc: 0.8345\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3705 - acc: 0.8419 - val_loss: 0.3902 - val_acc: 0.8400\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3639 - acc: 0.8449 - val_loss: 0.3771 - val_acc: 0.8430\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3647 - acc: 0.8439 - val_loss: 0.3536 - val_acc: 0.8443\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3543 - acc: 0.8501 - val_loss: 0.3418 - val_acc: 0.8573\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3547 - acc: 0.8472 - val_loss: 0.3507 - val_acc: 0.8441\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3499 - acc: 0.8490 - val_loss: 0.3388 - val_acc: 0.8583\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3390 - acc: 0.8562 - val_loss: 0.3305 - val_acc: 0.8642\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3371 - acc: 0.8561 - val_loss: 0.3660 - val_acc: 0.8492\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3427 - acc: 0.8540 - val_loss: 0.3463 - val_acc: 0.8522\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3388 - acc: 0.8556 - val_loss: 0.3490 - val_acc: 0.8538\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3450 - acc: 0.8537 - val_loss: 0.3347 - val_acc: 0.8622\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3353 - acc: 0.8577 - val_loss: 0.3341 - val_acc: 0.8547\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3303 - acc: 0.8598 - val_loss: 0.3425 - val_acc: 0.8547\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3324 - acc: 0.8583 - val_loss: 0.3288 - val_acc: 0.8572\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3285 - acc: 0.8600 - val_loss: 0.3311 - val_acc: 0.8690\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3303 - acc: 0.8601 - val_loss: 0.3682 - val_acc: 0.8477\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3269 - acc: 0.8614 - val_loss: 0.3658 - val_acc: 0.8418\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3259 - acc: 0.8608 - val_loss: 0.3317 - val_acc: 0.8547\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3217 - acc: 0.8636 - val_loss: 0.3240 - val_acc: 0.8658\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3250 - acc: 0.8616 - val_loss: 0.3265 - val_acc: 0.8602\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3205 - acc: 0.8642 - val_loss: 0.3376 - val_acc: 0.8583\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3289 - acc: 0.8623 - val_loss: 0.3401 - val_acc: 0.8528\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3274 - acc: 0.8621 - val_loss: 0.3451 - val_acc: 0.8490\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3209 - acc: 0.8634 - val_loss: 0.3209 - val_acc: 0.8698\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3140 - acc: 0.8669 - val_loss: 0.3333 - val_acc: 0.8583\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3246 - acc: 0.8642 - val_loss: 0.3446 - val_acc: 0.8487\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3243 - acc: 0.8625 - val_loss: 0.3269 - val_acc: 0.8595\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3181 - acc: 0.8666 - val_loss: 0.3418 - val_acc: 0.8579\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.3165 - acc: 0.8673 - val_loss: 0.3311 - val_acc: 0.8590\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3159 - acc: 0.8684 - val_loss: 0.3216 - val_acc: 0.8622\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3191 - acc: 0.8658 - val_loss: 0.3300 - val_acc: 0.8570\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3173 - acc: 0.8654 - val_loss: 0.3118 - val_acc: 0.8702\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3157 - acc: 0.8672 - val_loss: 0.3139 - val_acc: 0.8732\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3185 - acc: 0.8656 - val_loss: 0.3316 - val_acc: 0.8592\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3120 - acc: 0.8681 - val_loss: 0.3061 - val_acc: 0.8783\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3099 - acc: 0.8679 - val_loss: 0.3375 - val_acc: 0.8562\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3116 - acc: 0.8678 - val_loss: 0.3410 - val_acc: 0.8454\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3097 - acc: 0.8703 - val_loss: 0.3071 - val_acc: 0.8742\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3112 - acc: 0.8673 - val_loss: 0.3273 - val_acc: 0.8595\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3081 - acc: 0.8706 - val_loss: 0.3263 - val_acc: 0.8670\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3082 - acc: 0.8692 - val_loss: 0.3206 - val_acc: 0.8645\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3076 - acc: 0.8703 - val_loss: 0.3043 - val_acc: 0.8758\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3040 - acc: 0.8736 - val_loss: 0.3421 - val_acc: 0.8528\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3059 - acc: 0.8703 - val_loss: 0.3265 - val_acc: 0.8617\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3105 - acc: 0.8675 - val_loss: 0.3190 - val_acc: 0.8603\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2993 - acc: 0.8749 - val_loss: 0.3082 - val_acc: 0.8740\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3059 - acc: 0.8708 - val_loss: 0.3247 - val_acc: 0.8640\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3020 - acc: 0.8725 - val_loss: 0.3101 - val_acc: 0.8697\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3012 - acc: 0.8730 - val_loss: 0.3077 - val_acc: 0.8728\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3057 - acc: 0.8708 - val_loss: 0.3237 - val_acc: 0.8650\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3105 - acc: 0.8681 - val_loss: 0.3092 - val_acc: 0.8668\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2942 - acc: 0.8772 - val_loss: 0.3170 - val_acc: 0.8642\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2997 - acc: 0.8746 - val_loss: 0.3333 - val_acc: 0.8672\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3000 - acc: 0.8728 - val_loss: 0.3179 - val_acc: 0.8665\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3029 - acc: 0.8724 - val_loss: 0.3129 - val_acc: 0.8685\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2967 - acc: 0.8750 - val_loss: 0.3137 - val_acc: 0.8710\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.2951 - acc: 0.8764 - val_loss: 0.3058 - val_acc: 0.8677\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2982 - acc: 0.8747 - val_loss: 0.3084 - val_acc: 0.8723\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2936 - acc: 0.8755 - val_loss: 0.3050 - val_acc: 0.8718\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2999 - acc: 0.8736 - val_loss: 0.3161 - val_acc: 0.8636\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3008 - acc: 0.8728 - val_loss: 0.3228 - val_acc: 0.8612\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3021 - acc: 0.8720 - val_loss: 0.3368 - val_acc: 0.8562\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2890 - acc: 0.8780 - val_loss: 0.2955 - val_acc: 0.8762\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2970 - acc: 0.8755 - val_loss: 0.3172 - val_acc: 0.8662\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2947 - acc: 0.8752 - val_loss: 0.3145 - val_acc: 0.8728\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2992 - acc: 0.8737 - val_loss: 0.3306 - val_acc: 0.8610\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2966 - acc: 0.8758 - val_loss: 0.3044 - val_acc: 0.8750\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2888 - acc: 0.8788 - val_loss: 0.3322 - val_acc: 0.8633\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2907 - acc: 0.8792 - val_loss: 0.3216 - val_acc: 0.8577\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2925 - acc: 0.8766 - val_loss: 0.3017 - val_acc: 0.8740\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2903 - acc: 0.8775 - val_loss: 0.3267 - val_acc: 0.8623\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2975 - acc: 0.8750 - val_loss: 0.3015 - val_acc: 0.8750\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2917 - acc: 0.8768 - val_loss: 0.3074 - val_acc: 0.8663\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2866 - acc: 0.8798 - val_loss: 0.3034 - val_acc: 0.8711\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2871 - acc: 0.8779 - val_loss: 0.3224 - val_acc: 0.8658\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2863 - acc: 0.8801 - val_loss: 0.3148 - val_acc: 0.8655\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2903 - acc: 0.8774 - val_loss: 0.3091 - val_acc: 0.8745\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2933 - acc: 0.8762 - val_loss: 0.3161 - val_acc: 0.8662\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2877 - acc: 0.8788 - val_loss: 0.3065 - val_acc: 0.8700\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2908 - acc: 0.8778 - val_loss: 0.3128 - val_acc: 0.8693\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2878 - acc: 0.8793 - val_loss: 0.3021 - val_acc: 0.8733\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2873 - acc: 0.8806 - val_loss: 0.2966 - val_acc: 0.8738\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2873 - acc: 0.8767 - val_loss: 0.3074 - val_acc: 0.8747\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2840 - acc: 0.8804 - val_loss: 0.3162 - val_acc: 0.8690\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2861 - acc: 0.8807 - val_loss: 0.3129 - val_acc: 0.8660\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2849 - acc: 0.8797 - val_loss: 0.3108 - val_acc: 0.8665\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2828 - acc: 0.8815 - val_loss: 0.3017 - val_acc: 0.8752\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2874 - acc: 0.8784 - val_loss: 0.3138 - val_acc: 0.8653\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.2921 - acc: 0.8772 - val_loss: 0.3175 - val_acc: 0.8618\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.2806 - acc: 0.8832 - val_loss: 0.3480 - val_acc: 0.8657\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2785 - acc: 0.8830 - val_loss: 0.2965 - val_acc: 0.8810\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2895 - acc: 0.8788 - val_loss: 0.3099 - val_acc: 0.8688\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2753 - acc: 0.8849 - val_loss: 0.3045 - val_acc: 0.8726\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.2828 - acc: 0.8812 - val_loss: 0.2960 - val_acc: 0.8713\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2847 - acc: 0.8805 - val_loss: 0.3070 - val_acc: 0.8713\n",
      "\n",
      "Training process completed in: 0 h 29 m 54 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1251.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1253 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_369 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_369 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_370 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_370 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_371 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_371 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_372 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_372 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_93 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "200/200 [==============================] - 12s 62ms/step - loss: 0.5607 - acc: 0.7155 - val_loss: 0.5066 - val_acc: 0.7550\n",
      "Epoch 2/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4441 - acc: 0.8083 - val_loss: 0.4428 - val_acc: 0.8133\n",
      "Epoch 3/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4302 - acc: 0.8128 - val_loss: 0.4091 - val_acc: 0.8228\n",
      "Epoch 4/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4138 - acc: 0.8238 - val_loss: 0.4178 - val_acc: 0.8200\n",
      "Epoch 5/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4189 - acc: 0.8195 - val_loss: 0.4281 - val_acc: 0.8111\n",
      "Epoch 6/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4147 - acc: 0.8240 - val_loss: 0.4052 - val_acc: 0.8233\n",
      "Epoch 7/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4148 - acc: 0.8223 - val_loss: 0.4218 - val_acc: 0.8189\n",
      "Epoch 8/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4138 - acc: 0.8224 - val_loss: 0.4229 - val_acc: 0.8111\n",
      "Epoch 9/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4090 - acc: 0.8257 - val_loss: 0.3983 - val_acc: 0.8211\n",
      "Epoch 10/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4076 - acc: 0.8245 - val_loss: 0.4042 - val_acc: 0.8267\n",
      "Epoch 11/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4027 - acc: 0.8233 - val_loss: 0.3860 - val_acc: 0.8300\n",
      "Epoch 12/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3947 - acc: 0.8286 - val_loss: 0.4166 - val_acc: 0.8211\n",
      "Epoch 13/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4010 - acc: 0.8272 - val_loss: 0.4230 - val_acc: 0.8106\n",
      "Epoch 14/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3989 - acc: 0.8302 - val_loss: 0.4081 - val_acc: 0.8100\n",
      "Epoch 15/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3898 - acc: 0.8294 - val_loss: 0.4055 - val_acc: 0.8194\n",
      "Epoch 16/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3824 - acc: 0.8342 - val_loss: 0.3984 - val_acc: 0.8205\n",
      "Epoch 17/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4018 - acc: 0.8233 - val_loss: 0.4063 - val_acc: 0.8233\n",
      "Epoch 18/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3872 - acc: 0.8397 - val_loss: 0.4057 - val_acc: 0.8239\n",
      "Epoch 19/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3921 - acc: 0.8338 - val_loss: 0.3665 - val_acc: 0.8422\n",
      "Epoch 20/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3814 - acc: 0.8377 - val_loss: 0.3794 - val_acc: 0.8300\n",
      "Epoch 21/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3926 - acc: 0.8312 - val_loss: 0.3972 - val_acc: 0.8261\n",
      "Epoch 22/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3841 - acc: 0.8331 - val_loss: 0.4340 - val_acc: 0.8172\n",
      "Epoch 23/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3883 - acc: 0.8308 - val_loss: 0.3839 - val_acc: 0.8311\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3875 - acc: 0.8315 - val_loss: 0.4066 - val_acc: 0.8228\n",
      "Epoch 25/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3867 - acc: 0.8325 - val_loss: 0.4028 - val_acc: 0.8294\n",
      "Epoch 26/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3858 - acc: 0.8324 - val_loss: 0.3615 - val_acc: 0.8450\n",
      "Epoch 27/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3746 - acc: 0.8398 - val_loss: 0.4162 - val_acc: 0.8322\n",
      "Epoch 28/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3827 - acc: 0.8339 - val_loss: 0.3829 - val_acc: 0.8378\n",
      "Epoch 29/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3807 - acc: 0.8341 - val_loss: 0.3532 - val_acc: 0.8483\n",
      "Epoch 30/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3697 - acc: 0.8423 - val_loss: 0.3689 - val_acc: 0.8506\n",
      "Epoch 31/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3728 - acc: 0.8406 - val_loss: 0.3713 - val_acc: 0.8414\n",
      "Epoch 32/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3688 - acc: 0.8420 - val_loss: 0.3793 - val_acc: 0.8350\n",
      "Epoch 33/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3815 - acc: 0.8287 - val_loss: 0.4085 - val_acc: 0.8239\n",
      "Epoch 34/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3691 - acc: 0.8408 - val_loss: 0.3737 - val_acc: 0.8428\n",
      "Epoch 35/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3684 - acc: 0.8434 - val_loss: 0.3956 - val_acc: 0.8289\n",
      "Epoch 36/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3662 - acc: 0.8396 - val_loss: 0.3803 - val_acc: 0.8411\n",
      "Epoch 37/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3740 - acc: 0.8399 - val_loss: 0.3728 - val_acc: 0.8461\n",
      "Epoch 38/80\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.3767 - acc: 0.8360 - val_loss: 0.3772 - val_acc: 0.8350\n",
      "Epoch 39/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3658 - acc: 0.8393 - val_loss: 0.3720 - val_acc: 0.8456\n",
      "Epoch 40/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3710 - acc: 0.8380 - val_loss: 0.3573 - val_acc: 0.8428\n",
      "Epoch 41/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3620 - acc: 0.8409 - val_loss: 0.3757 - val_acc: 0.8367\n",
      "Epoch 42/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3704 - acc: 0.8417 - val_loss: 0.3637 - val_acc: 0.8394\n",
      "Epoch 43/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3669 - acc: 0.8425 - val_loss: 0.3872 - val_acc: 0.8383\n",
      "Epoch 44/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3672 - acc: 0.8436 - val_loss: 0.3793 - val_acc: 0.8428\n",
      "Epoch 45/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3582 - acc: 0.8452 - val_loss: 0.3880 - val_acc: 0.8322\n",
      "Epoch 46/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3561 - acc: 0.8443 - val_loss: 0.3619 - val_acc: 0.8422\n",
      "Epoch 47/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3606 - acc: 0.8453 - val_loss: 0.3597 - val_acc: 0.8403\n",
      "Epoch 48/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3608 - acc: 0.8461 - val_loss: 0.3473 - val_acc: 0.8478\n",
      "Epoch 49/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3572 - acc: 0.8483 - val_loss: 0.3650 - val_acc: 0.8456\n",
      "Epoch 50/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3526 - acc: 0.8497 - val_loss: 0.3784 - val_acc: 0.8472\n",
      "Epoch 51/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3563 - acc: 0.8481 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 52/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3626 - acc: 0.8453 - val_loss: 0.3769 - val_acc: 0.8389\n",
      "Epoch 53/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3551 - acc: 0.8485 - val_loss: 0.3705 - val_acc: 0.8394\n",
      "Epoch 54/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3514 - acc: 0.8476 - val_loss: 0.3588 - val_acc: 0.8506\n",
      "Epoch 55/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3612 - acc: 0.8446 - val_loss: 0.3543 - val_acc: 0.8528\n",
      "Epoch 56/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3612 - acc: 0.8448 - val_loss: 0.3672 - val_acc: 0.8461\n",
      "Epoch 57/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3435 - acc: 0.8582 - val_loss: 0.3956 - val_acc: 0.8267\n",
      "Epoch 58/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3550 - acc: 0.8468 - val_loss: 0.3515 - val_acc: 0.8500\n",
      "Epoch 59/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3556 - acc: 0.8485 - val_loss: 0.3521 - val_acc: 0.8444\n",
      "Epoch 60/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3535 - acc: 0.8478 - val_loss: 0.3645 - val_acc: 0.8294\n",
      "Epoch 61/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3410 - acc: 0.8557 - val_loss: 0.3383 - val_acc: 0.8617\n",
      "Epoch 62/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3412 - acc: 0.8550 - val_loss: 0.3595 - val_acc: 0.8448\n",
      "Epoch 63/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3489 - acc: 0.8494 - val_loss: 0.3505 - val_acc: 0.8556\n",
      "Epoch 64/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3477 - acc: 0.8513 - val_loss: 0.3556 - val_acc: 0.8378\n",
      "Epoch 65/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3494 - acc: 0.8507 - val_loss: 0.3629 - val_acc: 0.8572\n",
      "Epoch 66/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3561 - acc: 0.8471 - val_loss: 0.3508 - val_acc: 0.8522\n",
      "Epoch 67/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3462 - acc: 0.8490 - val_loss: 0.3590 - val_acc: 0.8433\n",
      "Epoch 68/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3572 - acc: 0.8450 - val_loss: 0.3228 - val_acc: 0.8667\n",
      "Epoch 69/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3448 - acc: 0.8520 - val_loss: 0.3293 - val_acc: 0.8644\n",
      "Epoch 70/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3413 - acc: 0.8572 - val_loss: 0.3716 - val_acc: 0.8267\n",
      "Epoch 71/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3364 - acc: 0.8549 - val_loss: 0.3748 - val_acc: 0.8350\n",
      "Epoch 72/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3429 - acc: 0.8552 - val_loss: 0.3497 - val_acc: 0.8478\n",
      "Epoch 73/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3376 - acc: 0.8552 - val_loss: 0.3451 - val_acc: 0.8472\n",
      "Epoch 74/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3478 - acc: 0.8478 - val_loss: 0.3434 - val_acc: 0.8589\n",
      "Epoch 75/80\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.3408 - acc: 0.8552 - val_loss: 0.3457 - val_acc: 0.8544\n",
      "Epoch 76/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3442 - acc: 0.8553 - val_loss: 0.3274 - val_acc: 0.8522\n",
      "Epoch 77/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3386 - acc: 0.8556 - val_loss: 0.3490 - val_acc: 0.8494\n",
      "Epoch 78/80\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.3262 - acc: 0.8635 - val_loss: 0.3295 - val_acc: 0.8634\n",
      "Epoch 79/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3378 - acc: 0.8562 - val_loss: 0.3661 - val_acc: 0.8367\n",
      "Epoch 80/80\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.3312 - acc: 0.8608 - val_loss: 0.3250 - val_acc: 0.8578\n",
      "\n",
      "Training process completed in: 0 h 8 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1252.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1254 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_373 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_373 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_374 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_374 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_375 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_375 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_376 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_376 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_94 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 60\n",
      "Learning Rate: 0.1\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 12s 63ms/step - loss: 4.5252 - acc: 0.7160 - val_loss: 4.8265 - val_acc: 0.7006\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5385 - acc: 0.7184 - val_loss: 4.4146 - val_acc: 0.7261\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5852 - acc: 0.7155 - val_loss: 4.6116 - val_acc: 0.7139\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5173 - acc: 0.7197 - val_loss: 4.5220 - val_acc: 0.7194\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6587 - acc: 0.7110 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.4791 - acc: 0.7221 - val_loss: 4.4862 - val_acc: 0.7217\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5682 - acc: 0.7166 - val_loss: 4.7101 - val_acc: 0.7078\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5060 - acc: 0.7204 - val_loss: 4.7638 - val_acc: 0.7044\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6757 - acc: 0.7099 - val_loss: 4.6922 - val_acc: 0.7089\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5159 - acc: 0.7198 - val_loss: 4.6205 - val_acc: 0.7133\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6926 - acc: 0.7089 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6205 - acc: 0.7133 - val_loss: 4.7101 - val_acc: 0.7078\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6290 - acc: 0.7128 - val_loss: 4.3608 - val_acc: 0.7294\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5159 - acc: 0.7198 - val_loss: 4.3161 - val_acc: 0.7322\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6078 - acc: 0.7141 - val_loss: 4.4056 - val_acc: 0.7267\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5484 - acc: 0.7178 - val_loss: 4.7481 - val_acc: 0.7054\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6092 - acc: 0.7140 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5117 - acc: 0.7201 - val_loss: 4.2444 - val_acc: 0.7367\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5809 - acc: 0.7158 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5258 - acc: 0.7192 - val_loss: 4.4862 - val_acc: 0.7217\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5724 - acc: 0.7163 - val_loss: 4.4414 - val_acc: 0.7244\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5314 - acc: 0.7189 - val_loss: 4.4146 - val_acc: 0.7261\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5456 - acc: 0.7180 - val_loss: 4.5220 - val_acc: 0.7194\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6177 - acc: 0.7135 - val_loss: 4.4952 - val_acc: 0.7211\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6120 - acc: 0.7139 - val_loss: 4.8175 - val_acc: 0.7011\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6686 - acc: 0.7104 - val_loss: 4.7280 - val_acc: 0.7067\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5710 - acc: 0.7164 - val_loss: 4.7101 - val_acc: 0.7078\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5569 - acc: 0.7173 - val_loss: 4.4056 - val_acc: 0.7267\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6276 - acc: 0.7129 - val_loss: 4.5489 - val_acc: 0.7178\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5894 - acc: 0.7153 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6516 - acc: 0.7114 - val_loss: 4.8209 - val_acc: 0.7009\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.4636 - acc: 0.7231 - val_loss: 4.4414 - val_acc: 0.7244\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4593 - acc: 0.7233 - val_loss: 4.4414 - val_acc: 0.7244\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.7081 - acc: 0.7079 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5682 - acc: 0.7166 - val_loss: 4.3340 - val_acc: 0.7311\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5272 - acc: 0.7191 - val_loss: 4.5399 - val_acc: 0.7183\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5442 - acc: 0.7181 - val_loss: 4.5399 - val_acc: 0.7183\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6290 - acc: 0.7128 - val_loss: 4.5489 - val_acc: 0.7178\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5937 - acc: 0.7150 - val_loss: 4.3429 - val_acc: 0.7306\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6488 - acc: 0.7116 - val_loss: 4.7727 - val_acc: 0.7039\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6502 - acc: 0.7115 - val_loss: 4.7907 - val_acc: 0.7028\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5470 - acc: 0.7179 - val_loss: 4.9071 - val_acc: 0.6956\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5880 - acc: 0.7154 - val_loss: 4.5847 - val_acc: 0.7156\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5838 - acc: 0.7156 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5314 - acc: 0.7189 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5555 - acc: 0.7174 - val_loss: 4.4593 - val_acc: 0.7233\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4438 - acc: 0.7243 - val_loss: 4.7390 - val_acc: 0.7060\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5838 - acc: 0.7156 - val_loss: 4.6563 - val_acc: 0.7111\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6064 - acc: 0.7142 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5484 - acc: 0.7178 - val_loss: 4.3608 - val_acc: 0.7294\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6502 - acc: 0.7115 - val_loss: 4.4504 - val_acc: 0.7239\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4099 - acc: 0.7264 - val_loss: 4.7190 - val_acc: 0.7072\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5993 - acc: 0.7146 - val_loss: 4.7280 - val_acc: 0.7067\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6686 - acc: 0.7104 - val_loss: 4.5489 - val_acc: 0.7178\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5823 - acc: 0.7157 - val_loss: 4.5757 - val_acc: 0.7161\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6092 - acc: 0.7140 - val_loss: 4.6563 - val_acc: 0.7111\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6375 - acc: 0.7123 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4537 - acc: 0.7237 - val_loss: 4.6653 - val_acc: 0.7106\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6700 - acc: 0.7103 - val_loss: 4.2892 - val_acc: 0.7339\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6431 - acc: 0.7119 - val_loss: 4.3608 - val_acc: 0.7294\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4692 - acc: 0.7227 - val_loss: 4.4235 - val_acc: 0.7256\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5682 - acc: 0.7166 - val_loss: 4.7572 - val_acc: 0.7049\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5117 - acc: 0.7201 - val_loss: 4.7190 - val_acc: 0.7072\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5173 - acc: 0.7197 - val_loss: 4.7638 - val_acc: 0.7044\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5074 - acc: 0.7204 - val_loss: 4.7638 - val_acc: 0.7044\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5329 - acc: 0.7188 - val_loss: 4.7727 - val_acc: 0.7039\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5852 - acc: 0.7155 - val_loss: 4.2713 - val_acc: 0.7350\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5428 - acc: 0.7182 - val_loss: 4.6832 - val_acc: 0.7094\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6191 - acc: 0.7134 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6601 - acc: 0.7109 - val_loss: 4.6742 - val_acc: 0.7100\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5597 - acc: 0.7171 - val_loss: 4.4235 - val_acc: 0.7256\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5541 - acc: 0.7175 - val_loss: 4.4952 - val_acc: 0.7211\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5512 - acc: 0.7176 - val_loss: 4.6922 - val_acc: 0.7089\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6658 - acc: 0.7105 - val_loss: 4.7638 - val_acc: 0.7044\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5498 - acc: 0.7177 - val_loss: 4.2982 - val_acc: 0.7333\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6573 - acc: 0.7111 - val_loss: 4.3071 - val_acc: 0.7328\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6148 - acc: 0.7137 - val_loss: 4.5131 - val_acc: 0.7200\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5512 - acc: 0.7176 - val_loss: 4.6299 - val_acc: 0.7128\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.4805 - acc: 0.7220 - val_loss: 4.5937 - val_acc: 0.7150\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5781 - acc: 0.7160 - val_loss: 4.5847 - val_acc: 0.7156\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6022 - acc: 0.7145 - val_loss: 4.4772 - val_acc: 0.7222\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4904 - acc: 0.7214 - val_loss: 4.8086 - val_acc: 0.7017\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.5696 - acc: 0.7165 - val_loss: 4.4504 - val_acc: 0.7239\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.7039 - acc: 0.7082 - val_loss: 4.7101 - val_acc: 0.7078\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6007 - acc: 0.7146 - val_loss: 4.7459 - val_acc: 0.7056\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5753 - acc: 0.7161 - val_loss: 4.4862 - val_acc: 0.7217\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4933 - acc: 0.7212 - val_loss: 4.2623 - val_acc: 0.7356\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6375 - acc: 0.7123 - val_loss: 4.8354 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5823 - acc: 0.7157 - val_loss: 4.3519 - val_acc: 0.7300\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.6163 - acc: 0.7136 - val_loss: 4.8444 - val_acc: 0.6994\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6021 - acc: 0.7145 - val_loss: 4.4235 - val_acc: 0.7256\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.4749 - acc: 0.7224 - val_loss: 4.5489 - val_acc: 0.7178\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 6s 31ms/step - loss: 4.4777 - acc: 0.7222 - val_loss: 4.3297 - val_acc: 0.7314\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5329 - acc: 0.7188 - val_loss: 4.4146 - val_acc: 0.7261\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5456 - acc: 0.7180 - val_loss: 4.4146 - val_acc: 0.7261\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6417 - acc: 0.7120 - val_loss: 4.5668 - val_acc: 0.7167\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.6403 - acc: 0.7121 - val_loss: 4.7369 - val_acc: 0.7061\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.7011 - acc: 0.7083 - val_loss: 4.7996 - val_acc: 0.7022\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5399 - acc: 0.7183 - val_loss: 4.6922 - val_acc: 0.7089\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 6s 30ms/step - loss: 4.5074 - acc: 0.7204 - val_loss: 4.3608 - val_acc: 0.7294\n",
      "\n",
      "Training process completed in: 0 h 9 m 44 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1253.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1255 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_377 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_377 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_378 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_378 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_379 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_379 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_380 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_380 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_95 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 21s 163ms/step - loss: 0.5877 - acc: 0.7138 - val_loss: 0.5638 - val_acc: 0.7166\n",
      "Epoch 2/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.5083 - acc: 0.7493 - val_loss: 0.4547 - val_acc: 0.7957\n",
      "Epoch 3/80\n",
      "130/130 [==============================] - 15s 118ms/step - loss: 0.4391 - acc: 0.8135 - val_loss: 0.4883 - val_acc: 0.7924\n",
      "Epoch 4/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.4268 - acc: 0.8187 - val_loss: 0.4193 - val_acc: 0.8189\n",
      "Epoch 5/80\n",
      "130/130 [==============================] - 15s 117ms/step - loss: 0.4196 - acc: 0.8218 - val_loss: 0.4269 - val_acc: 0.8160\n",
      "Epoch 6/80\n",
      "130/130 [==============================] - 15s 117ms/step - loss: 0.4191 - acc: 0.8183 - val_loss: 0.4216 - val_acc: 0.8160\n",
      "Epoch 7/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.4106 - acc: 0.8225 - val_loss: 0.4148 - val_acc: 0.8202\n",
      "Epoch 8/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.4039 - acc: 0.8257 - val_loss: 0.3973 - val_acc: 0.8273\n",
      "Epoch 9/80\n",
      "130/130 [==============================] - 15s 118ms/step - loss: 0.4087 - acc: 0.8243 - val_loss: 0.4083 - val_acc: 0.8231\n",
      "Epoch 10/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.4055 - acc: 0.8275 - val_loss: 0.4100 - val_acc: 0.8225\n",
      "Epoch 11/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.4057 - acc: 0.8250 - val_loss: 0.3998 - val_acc: 0.8274\n",
      "Epoch 12/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.4039 - acc: 0.8254 - val_loss: 0.3999 - val_acc: 0.8280\n",
      "Epoch 13/80\n",
      "130/130 [==============================] - 15s 118ms/step - loss: 0.3999 - acc: 0.8276 - val_loss: 0.4163 - val_acc: 0.8179\n",
      "Epoch 14/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3932 - acc: 0.8301 - val_loss: 0.3978 - val_acc: 0.8290\n",
      "Epoch 15/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3913 - acc: 0.8325 - val_loss: 0.3973 - val_acc: 0.8349\n",
      "Epoch 16/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3950 - acc: 0.8298 - val_loss: 0.4125 - val_acc: 0.8215\n",
      "Epoch 17/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3863 - acc: 0.8354 - val_loss: 0.3863 - val_acc: 0.8332\n",
      "Epoch 18/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3904 - acc: 0.8345 - val_loss: 0.3847 - val_acc: 0.8303\n",
      "Epoch 19/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3883 - acc: 0.8334 - val_loss: 0.3842 - val_acc: 0.8353\n",
      "Epoch 20/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3799 - acc: 0.8381 - val_loss: 0.3863 - val_acc: 0.8344\n",
      "Epoch 21/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3822 - acc: 0.8362 - val_loss: 0.3877 - val_acc: 0.8341\n",
      "Epoch 22/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3915 - acc: 0.8333 - val_loss: 0.3850 - val_acc: 0.8343\n",
      "Epoch 23/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3865 - acc: 0.8352 - val_loss: 0.3790 - val_acc: 0.8346\n",
      "Epoch 24/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3757 - acc: 0.8411 - val_loss: 0.3731 - val_acc: 0.8387\n",
      "Epoch 25/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3663 - acc: 0.8437 - val_loss: 0.3771 - val_acc: 0.8373\n",
      "Epoch 26/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3769 - acc: 0.8384 - val_loss: 0.3840 - val_acc: 0.8329\n",
      "Epoch 27/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3776 - acc: 0.8372 - val_loss: 0.3766 - val_acc: 0.8401\n",
      "Epoch 28/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3724 - acc: 0.8412 - val_loss: 0.3698 - val_acc: 0.8412\n",
      "Epoch 29/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3676 - acc: 0.8427 - val_loss: 0.3715 - val_acc: 0.8430\n",
      "Epoch 30/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3647 - acc: 0.8463 - val_loss: 0.3602 - val_acc: 0.8435\n",
      "Epoch 31/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3657 - acc: 0.8437 - val_loss: 0.3647 - val_acc: 0.8454\n",
      "Epoch 32/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3667 - acc: 0.8438 - val_loss: 0.3797 - val_acc: 0.8377\n",
      "Epoch 33/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3684 - acc: 0.8429 - val_loss: 0.3552 - val_acc: 0.8486\n",
      "Epoch 34/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3680 - acc: 0.8444 - val_loss: 0.3698 - val_acc: 0.8422\n",
      "Epoch 35/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3601 - acc: 0.8443 - val_loss: 0.3606 - val_acc: 0.8480\n",
      "Epoch 36/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3611 - acc: 0.8468 - val_loss: 0.3636 - val_acc: 0.8467\n",
      "Epoch 37/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3635 - acc: 0.8461 - val_loss: 0.3666 - val_acc: 0.8459\n",
      "Epoch 38/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3630 - acc: 0.8440 - val_loss: 0.3547 - val_acc: 0.8513\n",
      "Epoch 39/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3527 - acc: 0.8517 - val_loss: 0.3685 - val_acc: 0.8415\n",
      "Epoch 40/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3588 - acc: 0.8478 - val_loss: 0.3602 - val_acc: 0.8481\n",
      "Epoch 41/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3517 - acc: 0.8510 - val_loss: 0.3836 - val_acc: 0.8346\n",
      "Epoch 42/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3548 - acc: 0.8515 - val_loss: 0.3507 - val_acc: 0.8513\n",
      "Epoch 43/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3556 - acc: 0.8482 - val_loss: 0.3879 - val_acc: 0.8396\n",
      "Epoch 44/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3571 - acc: 0.8478 - val_loss: 0.3584 - val_acc: 0.8465\n",
      "Epoch 45/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3543 - acc: 0.8476 - val_loss: 0.3579 - val_acc: 0.8465\n",
      "Epoch 46/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3427 - acc: 0.8534 - val_loss: 0.3443 - val_acc: 0.8581\n",
      "Epoch 47/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3502 - acc: 0.8520 - val_loss: 0.3491 - val_acc: 0.8514\n",
      "Epoch 48/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3485 - acc: 0.8523 - val_loss: 0.3482 - val_acc: 0.8514\n",
      "Epoch 49/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3481 - acc: 0.8518 - val_loss: 0.3525 - val_acc: 0.8545\n",
      "Epoch 50/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3508 - acc: 0.8508 - val_loss: 0.3468 - val_acc: 0.8529\n",
      "Epoch 51/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3471 - acc: 0.8544 - val_loss: 0.3431 - val_acc: 0.8538\n",
      "Epoch 52/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3471 - acc: 0.8523 - val_loss: 0.3599 - val_acc: 0.8446\n",
      "Epoch 53/80\n",
      "130/130 [==============================] - 15s 118ms/step - loss: 0.3435 - acc: 0.8547 - val_loss: 0.3421 - val_acc: 0.8518\n",
      "Epoch 54/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3383 - acc: 0.8571 - val_loss: 0.3427 - val_acc: 0.8559\n",
      "Epoch 55/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3475 - acc: 0.8532 - val_loss: 0.3440 - val_acc: 0.8539\n",
      "Epoch 56/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3443 - acc: 0.8529 - val_loss: 0.3376 - val_acc: 0.8569\n",
      "Epoch 57/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3414 - acc: 0.8554 - val_loss: 0.3642 - val_acc: 0.8416\n",
      "Epoch 58/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3463 - acc: 0.8528 - val_loss: 0.3400 - val_acc: 0.8559\n",
      "Epoch 59/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3468 - acc: 0.8548 - val_loss: 0.3526 - val_acc: 0.8501\n",
      "Epoch 60/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3501 - acc: 0.8505 - val_loss: 0.3495 - val_acc: 0.8560\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3368 - acc: 0.8566 - val_loss: 0.3382 - val_acc: 0.8553\n",
      "Epoch 62/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3414 - acc: 0.8540 - val_loss: 0.3488 - val_acc: 0.8521\n",
      "Epoch 63/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3378 - acc: 0.8571 - val_loss: 0.3384 - val_acc: 0.8585\n",
      "Epoch 64/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3383 - acc: 0.8547 - val_loss: 0.3373 - val_acc: 0.8544\n",
      "Epoch 65/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3406 - acc: 0.8550 - val_loss: 0.3321 - val_acc: 0.8612\n",
      "Epoch 66/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3375 - acc: 0.8576 - val_loss: 0.3444 - val_acc: 0.8566\n",
      "Epoch 67/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3295 - acc: 0.8610 - val_loss: 0.3365 - val_acc: 0.8595\n",
      "Epoch 68/80\n",
      "130/130 [==============================] - 15s 119ms/step - loss: 0.3356 - acc: 0.8581 - val_loss: 0.3369 - val_acc: 0.8588\n",
      "Epoch 69/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3401 - acc: 0.8550 - val_loss: 0.3422 - val_acc: 0.8552\n",
      "Epoch 70/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3321 - acc: 0.8589 - val_loss: 0.3276 - val_acc: 0.8659\n",
      "Epoch 71/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3318 - acc: 0.8591 - val_loss: 0.3326 - val_acc: 0.8586\n",
      "Epoch 72/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3286 - acc: 0.8623 - val_loss: 0.3364 - val_acc: 0.8561\n",
      "Epoch 73/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3338 - acc: 0.8587 - val_loss: 0.3293 - val_acc: 0.8612\n",
      "Epoch 74/80\n",
      "130/130 [==============================] - 16s 122ms/step - loss: 0.3390 - acc: 0.8562 - val_loss: 0.3421 - val_acc: 0.8557\n",
      "Epoch 75/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3332 - acc: 0.8564 - val_loss: 0.3311 - val_acc: 0.8601\n",
      "Epoch 76/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3298 - acc: 0.8589 - val_loss: 0.3228 - val_acc: 0.8653\n",
      "Epoch 77/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3319 - acc: 0.8597 - val_loss: 0.3325 - val_acc: 0.8603\n",
      "Epoch 78/80\n",
      "130/130 [==============================] - 16s 120ms/step - loss: 0.3246 - acc: 0.8635 - val_loss: 0.3390 - val_acc: 0.8562\n",
      "Epoch 79/80\n",
      "130/130 [==============================] - 16s 121ms/step - loss: 0.3294 - acc: 0.8602 - val_loss: 0.3327 - val_acc: 0.8579\n",
      "Epoch 80/80\n",
      "130/130 [==============================] - 16s 119ms/step - loss: 0.3398 - acc: 0.8554 - val_loss: 0.3314 - val_acc: 0.8578\n",
      "\n",
      "Training process completed in: 0 h 20 m 53 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1254.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1256 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_381 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_381 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_382 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_382 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_383 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_383 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_384 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_384 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 0.5450 - acc: 0.7284 - val_loss: 0.4674 - val_acc: 0.7885\n",
      "Epoch 2/80\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4221 - acc: 0.8200 - val_loss: 0.4489 - val_acc: 0.8100\n",
      "Epoch 3/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.4179 - acc: 0.8191 - val_loss: 0.4086 - val_acc: 0.8220\n",
      "Epoch 4/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.4078 - acc: 0.8248 - val_loss: 0.4083 - val_acc: 0.8235\n",
      "Epoch 5/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.4004 - acc: 0.8305 - val_loss: 0.3928 - val_acc: 0.8270\n",
      "Epoch 6/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3979 - acc: 0.8291 - val_loss: 0.4143 - val_acc: 0.8135\n",
      "Epoch 7/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3892 - acc: 0.8328 - val_loss: 0.4133 - val_acc: 0.8195\n",
      "Epoch 8/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3877 - acc: 0.8351 - val_loss: 0.3947 - val_acc: 0.8290\n",
      "Epoch 9/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3834 - acc: 0.8347 - val_loss: 0.4003 - val_acc: 0.8200\n",
      "Epoch 10/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3867 - acc: 0.8352 - val_loss: 0.4287 - val_acc: 0.8170\n",
      "Epoch 11/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3935 - acc: 0.8304 - val_loss: 0.3485 - val_acc: 0.8560\n",
      "Epoch 12/80\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.3806 - acc: 0.8368 - val_loss: 0.3764 - val_acc: 0.8390\n",
      "Epoch 13/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3777 - acc: 0.8390 - val_loss: 0.3896 - val_acc: 0.8290\n",
      "Epoch 14/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3769 - acc: 0.8400 - val_loss: 0.3552 - val_acc: 0.8550\n",
      "Epoch 15/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3684 - acc: 0.8409 - val_loss: 0.3690 - val_acc: 0.8405\n",
      "Epoch 16/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3700 - acc: 0.8432 - val_loss: 0.3849 - val_acc: 0.8360\n",
      "Epoch 17/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3674 - acc: 0.8448 - val_loss: 0.3854 - val_acc: 0.8345\n",
      "Epoch 18/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3683 - acc: 0.8407 - val_loss: 0.3751 - val_acc: 0.8325\n",
      "Epoch 19/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3637 - acc: 0.8459 - val_loss: 0.3533 - val_acc: 0.8410\n",
      "Epoch 20/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3634 - acc: 0.8448 - val_loss: 0.3611 - val_acc: 0.8500\n",
      "Epoch 21/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3587 - acc: 0.8477 - val_loss: 0.3547 - val_acc: 0.8455\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3541 - acc: 0.8491 - val_loss: 0.3777 - val_acc: 0.8355\n",
      "Epoch 23/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3547 - acc: 0.8465 - val_loss: 0.3984 - val_acc: 0.8300\n",
      "Epoch 24/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3527 - acc: 0.8487 - val_loss: 0.3730 - val_acc: 0.8400\n",
      "Epoch 25/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3514 - acc: 0.8514 - val_loss: 0.3550 - val_acc: 0.8565\n",
      "Epoch 26/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3508 - acc: 0.8511 - val_loss: 0.3645 - val_acc: 0.8440\n",
      "Epoch 27/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3520 - acc: 0.8511 - val_loss: 0.3374 - val_acc: 0.8490\n",
      "Epoch 28/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3521 - acc: 0.8496 - val_loss: 0.3221 - val_acc: 0.8637\n",
      "Epoch 29/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3478 - acc: 0.8530 - val_loss: 0.3553 - val_acc: 0.8565\n",
      "Epoch 30/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3425 - acc: 0.8555 - val_loss: 0.3352 - val_acc: 0.8570\n",
      "Epoch 31/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3479 - acc: 0.8521 - val_loss: 0.3423 - val_acc: 0.8515\n",
      "Epoch 32/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3368 - acc: 0.8588 - val_loss: 0.3436 - val_acc: 0.8600\n",
      "Epoch 33/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3430 - acc: 0.8533 - val_loss: 0.3388 - val_acc: 0.8565\n",
      "Epoch 34/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3393 - acc: 0.8578 - val_loss: 0.3929 - val_acc: 0.8280\n",
      "Epoch 35/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3417 - acc: 0.8542 - val_loss: 0.3320 - val_acc: 0.8640\n",
      "Epoch 36/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3317 - acc: 0.8596 - val_loss: 0.3554 - val_acc: 0.8600\n",
      "Epoch 37/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3442 - acc: 0.8546 - val_loss: 0.3509 - val_acc: 0.8515\n",
      "Epoch 38/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3342 - acc: 0.8581 - val_loss: 0.3252 - val_acc: 0.8565\n",
      "Epoch 39/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3389 - acc: 0.8551 - val_loss: 0.3580 - val_acc: 0.8475\n",
      "Epoch 40/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3392 - acc: 0.8551 - val_loss: 0.3609 - val_acc: 0.8480\n",
      "Epoch 41/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3388 - acc: 0.8557 - val_loss: 0.3234 - val_acc: 0.8625\n",
      "Epoch 42/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3329 - acc: 0.8599 - val_loss: 0.3416 - val_acc: 0.8566\n",
      "Epoch 43/80\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3290 - acc: 0.8620 - val_loss: 0.3396 - val_acc: 0.8590\n",
      "Epoch 44/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3284 - acc: 0.8618 - val_loss: 0.3309 - val_acc: 0.8625\n",
      "Epoch 45/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3290 - acc: 0.8607 - val_loss: 0.3350 - val_acc: 0.8555\n",
      "Epoch 46/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3304 - acc: 0.8596 - val_loss: 0.3229 - val_acc: 0.8630\n",
      "Epoch 47/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3309 - acc: 0.8589 - val_loss: 0.3339 - val_acc: 0.8485\n",
      "Epoch 48/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3245 - acc: 0.8630 - val_loss: 0.3271 - val_acc: 0.8635\n",
      "Epoch 49/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3284 - acc: 0.8606 - val_loss: 0.3257 - val_acc: 0.8580\n",
      "Epoch 50/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3222 - acc: 0.8646 - val_loss: 0.3287 - val_acc: 0.8660\n",
      "Epoch 51/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3246 - acc: 0.8625 - val_loss: 0.3312 - val_acc: 0.8665\n",
      "Epoch 52/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3260 - acc: 0.8633 - val_loss: 0.3251 - val_acc: 0.8640\n",
      "Epoch 53/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3209 - acc: 0.8644 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 54/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3246 - acc: 0.8628 - val_loss: 0.3399 - val_acc: 0.8455\n",
      "Epoch 55/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3273 - acc: 0.8599 - val_loss: 0.3154 - val_acc: 0.8630\n",
      "Epoch 56/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3187 - acc: 0.8663 - val_loss: 0.3128 - val_acc: 0.8719\n",
      "Epoch 57/80\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3210 - acc: 0.8636 - val_loss: 0.3463 - val_acc: 0.8520\n",
      "Epoch 58/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3171 - acc: 0.8663 - val_loss: 0.3630 - val_acc: 0.8410\n",
      "Epoch 59/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3222 - acc: 0.8658 - val_loss: 0.3198 - val_acc: 0.8645\n",
      "Epoch 60/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3187 - acc: 0.8648 - val_loss: 0.3083 - val_acc: 0.8660\n",
      "Epoch 61/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3169 - acc: 0.8661 - val_loss: 0.3127 - val_acc: 0.8690\n",
      "Epoch 62/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3217 - acc: 0.8639 - val_loss: 0.3349 - val_acc: 0.8630\n",
      "Epoch 63/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3164 - acc: 0.8648 - val_loss: 0.2970 - val_acc: 0.8690\n",
      "Epoch 64/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3146 - acc: 0.8688 - val_loss: 0.2966 - val_acc: 0.8850\n",
      "Epoch 65/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3200 - acc: 0.8636 - val_loss: 0.3493 - val_acc: 0.8520\n",
      "Epoch 66/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3150 - acc: 0.8680 - val_loss: 0.3020 - val_acc: 0.8745\n",
      "Epoch 67/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3152 - acc: 0.8687 - val_loss: 0.3343 - val_acc: 0.8610\n",
      "Epoch 68/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3113 - acc: 0.8693 - val_loss: 0.3308 - val_acc: 0.8580\n",
      "Epoch 69/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3122 - acc: 0.8674 - val_loss: 0.3081 - val_acc: 0.8645\n",
      "Epoch 70/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3162 - acc: 0.8645 - val_loss: 0.3425 - val_acc: 0.8545\n",
      "Epoch 71/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3135 - acc: 0.8688 - val_loss: 0.3066 - val_acc: 0.8715\n",
      "Epoch 72/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3053 - acc: 0.8696 - val_loss: 0.3248 - val_acc: 0.8575\n",
      "Epoch 73/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3108 - acc: 0.8694 - val_loss: 0.3102 - val_acc: 0.8655\n",
      "Epoch 74/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3112 - acc: 0.8691 - val_loss: 0.3021 - val_acc: 0.8685\n",
      "Epoch 75/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3125 - acc: 0.8674 - val_loss: 0.3296 - val_acc: 0.8625\n",
      "Epoch 76/80\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3106 - acc: 0.8692 - val_loss: 0.2884 - val_acc: 0.8815\n",
      "Epoch 77/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3034 - acc: 0.8708 - val_loss: 0.3066 - val_acc: 0.8725\n",
      "Epoch 78/80\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3101 - acc: 0.8718 - val_loss: 0.3151 - val_acc: 0.8670\n",
      "Epoch 79/80\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3099 - acc: 0.8683 - val_loss: 0.3111 - val_acc: 0.8680\n",
      "Epoch 80/80\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3083 - acc: 0.8688 - val_loss: 0.3244 - val_acc: 0.8610\n",
      "\n",
      "Training process completed in: 0 h 22 m 38 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1255.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1257 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_385 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_385 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_386 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_386 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_387 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_387 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_388 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_388 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_97 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "130/130 [==============================] - 14s 107ms/step - loss: 0.5113 - acc: 0.7613 - val_loss: 0.4705 - val_acc: 0.7879\n",
      "Epoch 2/80\n",
      "130/130 [==============================] - 7s 57ms/step - loss: 0.4468 - acc: 0.8109 - val_loss: 0.4323 - val_acc: 0.8043\n",
      "Epoch 3/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.4182 - acc: 0.8195 - val_loss: 0.4697 - val_acc: 0.8121\n",
      "Epoch 4/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.4111 - acc: 0.8230 - val_loss: 0.4001 - val_acc: 0.8307\n",
      "Epoch 5/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.4111 - acc: 0.8221 - val_loss: 0.3863 - val_acc: 0.8357\n",
      "Epoch 6/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.4039 - acc: 0.8275 - val_loss: 0.4359 - val_acc: 0.8150\n",
      "Epoch 7/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3840 - acc: 0.8352 - val_loss: 0.3919 - val_acc: 0.8314\n",
      "Epoch 8/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.4002 - acc: 0.8280 - val_loss: 0.4091 - val_acc: 0.8436\n",
      "Epoch 9/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3846 - acc: 0.8349 - val_loss: 0.3929 - val_acc: 0.8343\n",
      "Epoch 10/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3917 - acc: 0.8305 - val_loss: 0.3990 - val_acc: 0.8329\n",
      "Epoch 11/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3930 - acc: 0.8329 - val_loss: 0.4333 - val_acc: 0.8407\n",
      "Epoch 12/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3794 - acc: 0.8377 - val_loss: 0.3983 - val_acc: 0.8321\n",
      "Epoch 13/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3787 - acc: 0.8378 - val_loss: 0.4051 - val_acc: 0.8486\n",
      "Epoch 14/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3784 - acc: 0.8368 - val_loss: 0.4464 - val_acc: 0.8179\n",
      "Epoch 15/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3694 - acc: 0.8443 - val_loss: 0.4025 - val_acc: 0.8429\n",
      "Epoch 16/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3758 - acc: 0.8371 - val_loss: 0.4062 - val_acc: 0.8436\n",
      "Epoch 17/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3656 - acc: 0.8414 - val_loss: 0.3996 - val_acc: 0.8350\n",
      "Epoch 18/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3624 - acc: 0.8466 - val_loss: 0.3794 - val_acc: 0.8564\n",
      "Epoch 19/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3552 - acc: 0.8488 - val_loss: 0.4047 - val_acc: 0.8300\n",
      "Epoch 20/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3592 - acc: 0.8475 - val_loss: 0.3951 - val_acc: 0.8351\n",
      "Epoch 21/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3539 - acc: 0.8502 - val_loss: 0.4159 - val_acc: 0.8457\n",
      "Epoch 22/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3700 - acc: 0.8448 - val_loss: 0.3918 - val_acc: 0.8386\n",
      "Epoch 23/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3635 - acc: 0.8447 - val_loss: 0.3782 - val_acc: 0.8479\n",
      "Epoch 24/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3593 - acc: 0.8468 - val_loss: 0.3578 - val_acc: 0.8521\n",
      "Epoch 25/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3476 - acc: 0.8530 - val_loss: 0.3516 - val_acc: 0.8636\n",
      "Epoch 26/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3570 - acc: 0.8471 - val_loss: 0.3582 - val_acc: 0.8579\n",
      "Epoch 27/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3551 - acc: 0.8467 - val_loss: 0.3577 - val_acc: 0.8664\n",
      "Epoch 28/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3597 - acc: 0.8467 - val_loss: 0.4282 - val_acc: 0.8343\n",
      "Epoch 29/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3450 - acc: 0.8540 - val_loss: 0.3958 - val_acc: 0.8407\n",
      "Epoch 30/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3499 - acc: 0.8523 - val_loss: 0.3760 - val_acc: 0.8436\n",
      "Epoch 31/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3390 - acc: 0.8536 - val_loss: 0.3468 - val_acc: 0.8536s - loss: 0.3381\n",
      "Epoch 32/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3568 - acc: 0.8475 - val_loss: 0.3523 - val_acc: 0.8550\n",
      "Epoch 33/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3454 - acc: 0.8540 - val_loss: 0.3928 - val_acc: 0.8521\n",
      "Epoch 34/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3515 - acc: 0.8516 - val_loss: 0.3791 - val_acc: 0.8429\n",
      "Epoch 35/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3387 - acc: 0.8589 - val_loss: 0.3377 - val_acc: 0.8536\n",
      "Epoch 36/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3459 - acc: 0.8494 - val_loss: 0.3627 - val_acc: 0.8543\n",
      "Epoch 37/80\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.3415 - acc: 0.8537 - val_loss: 0.3531 - val_acc: 0.8536\n",
      "Epoch 38/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3412 - acc: 0.8560 - val_loss: 0.4097 - val_acc: 0.8571\n",
      "Epoch 39/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3382 - acc: 0.8565 - val_loss: 0.3520 - val_acc: 0.8529\n",
      "Epoch 40/80\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.3361 - acc: 0.8555 - val_loss: 0.3648 - val_acc: 0.8553\n",
      "Epoch 41/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3344 - acc: 0.8552 - val_loss: 0.3699 - val_acc: 0.8521.3331 - acc:\n",
      "Epoch 42/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3336 - acc: 0.8576 - val_loss: 0.3700 - val_acc: 0.8521\n",
      "Epoch 43/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3431 - acc: 0.8537 - val_loss: 0.3712 - val_acc: 0.8664\n",
      "Epoch 44/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3311 - acc: 0.8592 - val_loss: 0.3565 - val_acc: 0.8471\n",
      "Epoch 45/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3399 - acc: 0.8576 - val_loss: 0.3704 - val_acc: 0.8529\n",
      "Epoch 46/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3376 - acc: 0.8586 - val_loss: 0.3366 - val_acc: 0.8564\n",
      "Epoch 47/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3303 - acc: 0.8617 - val_loss: 0.3505 - val_acc: 0.8486\n",
      "Epoch 48/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3332 - acc: 0.8586 - val_loss: 0.3540 - val_acc: 0.8707\n",
      "Epoch 49/80\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.3315 - acc: 0.8587 - val_loss: 0.3540 - val_acc: 0.8536\n",
      "Epoch 50/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3240 - acc: 0.8651 - val_loss: 0.3078 - val_acc: 0.8707\n",
      "Epoch 51/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3345 - acc: 0.8573 - val_loss: 0.3694 - val_acc: 0.8693\n",
      "Epoch 52/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3223 - acc: 0.8631 - val_loss: 0.3352 - val_acc: 0.8579\n",
      "Epoch 53/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3356 - acc: 0.8565 - val_loss: 0.3488 - val_acc: 0.8429\n",
      "Epoch 54/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3306 - acc: 0.8595 - val_loss: 0.3402 - val_acc: 0.8793\n",
      "Epoch 55/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3400 - acc: 0.8558 - val_loss: 0.3433 - val_acc: 0.8643\n",
      "Epoch 56/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3308 - acc: 0.8614 - val_loss: 0.3321 - val_acc: 0.8686\n",
      "Epoch 57/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3252 - acc: 0.8627 - val_loss: 0.3594 - val_acc: 0.8514\n",
      "Epoch 58/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3222 - acc: 0.8632 - val_loss: 0.3833 - val_acc: 0.8414\n",
      "Epoch 59/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3378 - acc: 0.8551 - val_loss: 0.3553 - val_acc: 0.8579\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 8s 63ms/step - loss: 0.3231 - acc: 0.8635 - val_loss: 0.3219 - val_acc: 0.8700\n",
      "Epoch 61/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3225 - acc: 0.8634 - val_loss: 0.3543 - val_acc: 0.8571\n",
      "Epoch 62/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3198 - acc: 0.8640 - val_loss: 0.3333 - val_acc: 0.8671\n",
      "Epoch 63/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3265 - acc: 0.8602 - val_loss: 0.3576 - val_acc: 0.8529\n",
      "Epoch 64/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3222 - acc: 0.8671 - val_loss: 0.3697 - val_acc: 0.8521\n",
      "Epoch 65/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3233 - acc: 0.8643 - val_loss: 0.3474 - val_acc: 0.8714\n",
      "Epoch 66/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3157 - acc: 0.8636 - val_loss: 0.3157 - val_acc: 0.8786\n",
      "Epoch 67/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3187 - acc: 0.8622 - val_loss: 0.3393 - val_acc: 0.8536\n",
      "Epoch 68/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3269 - acc: 0.8611 - val_loss: 0.3522 - val_acc: 0.8679\n",
      "Epoch 69/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3255 - acc: 0.8617 - val_loss: 0.3463 - val_acc: 0.8643\n",
      "Epoch 70/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3233 - acc: 0.8629 - val_loss: 0.3367 - val_acc: 0.8686\n",
      "Epoch 71/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3146 - acc: 0.8693 - val_loss: 0.3459 - val_acc: 0.8493\n",
      "Epoch 72/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3234 - acc: 0.8624 - val_loss: 0.3358 - val_acc: 0.8550\n",
      "Epoch 73/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3136 - acc: 0.8707 - val_loss: 0.3673 - val_acc: 0.8571\n",
      "Epoch 74/80\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.3216 - acc: 0.8613 - val_loss: 0.3776 - val_acc: 0.8550\n",
      "Epoch 75/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3168 - acc: 0.8650 - val_loss: 0.3412 - val_acc: 0.8593\n",
      "Epoch 76/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3255 - acc: 0.8627 - val_loss: 0.3431 - val_acc: 0.8671\n",
      "Epoch 77/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3089 - acc: 0.8688 - val_loss: 0.3747 - val_acc: 0.8550\n",
      "Epoch 78/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3169 - acc: 0.8678 - val_loss: 0.3306 - val_acc: 0.8600\n",
      "Epoch 79/80\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 0.3085 - acc: 0.8694 - val_loss: 0.3269 - val_acc: 0.8714\n",
      "Epoch 80/80\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.3238 - acc: 0.8649 - val_loss: 0.3312 - val_acc: 0.8731\n",
      "\n",
      "Training process completed in: 0 h 10 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1256.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1258 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_389 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_389 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_390 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_390 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_391 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_391 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_392 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_392 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_98 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.4885 - acc: 0.7732 - val_loss: 0.4238 - val_acc: 0.8202\n",
      "Epoch 2/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.4206 - acc: 0.8212 - val_loss: 0.4241 - val_acc: 0.8122\n",
      "Epoch 3/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.4157 - acc: 0.8196 - val_loss: 0.4364 - val_acc: 0.8145\n",
      "Epoch 4/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3982 - acc: 0.8293 - val_loss: 0.4227 - val_acc: 0.8084\n",
      "Epoch 5/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.4053 - acc: 0.8287 - val_loss: 0.4086 - val_acc: 0.8263\n",
      "Epoch 6/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3960 - acc: 0.8284 - val_loss: 0.4501 - val_acc: 0.8269\n",
      "Epoch 7/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.4004 - acc: 0.8285 - val_loss: 0.3988 - val_acc: 0.8303\n",
      "Epoch 8/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3890 - acc: 0.8326 - val_loss: 0.4006 - val_acc: 0.8301\n",
      "Epoch 9/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3829 - acc: 0.8388 - val_loss: 0.3801 - val_acc: 0.8387\n",
      "Epoch 10/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3660 - acc: 0.8433 - val_loss: 0.3707 - val_acc: 0.8350\n",
      "Epoch 11/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3792 - acc: 0.8366 - val_loss: 0.3709 - val_acc: 0.8372\n",
      "Epoch 12/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3708 - acc: 0.8421 - val_loss: 0.3808 - val_acc: 0.8406\n",
      "Epoch 13/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3683 - acc: 0.8410 - val_loss: 0.3704 - val_acc: 0.8499\n",
      "Epoch 14/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3642 - acc: 0.8456 - val_loss: 0.3795 - val_acc: 0.8461\n",
      "Epoch 15/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3670 - acc: 0.8428 - val_loss: 0.3634 - val_acc: 0.8444\n",
      "Epoch 16/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3617 - acc: 0.8467 - val_loss: 0.4301 - val_acc: 0.8347\n",
      "Epoch 17/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3598 - acc: 0.8455 - val_loss: 0.3634 - val_acc: 0.8505\n",
      "Epoch 18/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3601 - acc: 0.8480 - val_loss: 0.4003 - val_acc: 0.8423\n",
      "Epoch 19/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3632 - acc: 0.8438 - val_loss: 0.3663 - val_acc: 0.8448\n",
      "Epoch 20/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3569 - acc: 0.8460 - val_loss: 0.4244 - val_acc: 0.8286\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3503 - acc: 0.8542 - val_loss: 0.3544 - val_acc: 0.8537\n",
      "Epoch 22/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3520 - acc: 0.8492 - val_loss: 0.3532 - val_acc: 0.8517\n",
      "Epoch 23/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3398 - acc: 0.8545 - val_loss: 0.3596 - val_acc: 0.8539\n",
      "Epoch 24/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3470 - acc: 0.8518 - val_loss: 0.3660 - val_acc: 0.8440\n",
      "Epoch 25/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3458 - acc: 0.8498 - val_loss: 0.3700 - val_acc: 0.8538\n",
      "Epoch 26/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3498 - acc: 0.8506 - val_loss: 0.3601 - val_acc: 0.8538\n",
      "Epoch 27/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3405 - acc: 0.8536 - val_loss: 0.3607 - val_acc: 0.8552\n",
      "Epoch 28/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3390 - acc: 0.8548 - val_loss: 0.3476 - val_acc: 0.8565\n",
      "Epoch 29/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3491 - acc: 0.8513 - val_loss: 0.3524 - val_acc: 0.8586\n",
      "Epoch 30/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3392 - acc: 0.8541 - val_loss: 0.3568 - val_acc: 0.8576\n",
      "Epoch 31/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3381 - acc: 0.8569 - val_loss: 0.3579 - val_acc: 0.8563\n",
      "Epoch 32/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3458 - acc: 0.8513 - val_loss: 0.3625 - val_acc: 0.8569\n",
      "Epoch 33/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3380 - acc: 0.8550 - val_loss: 0.3517 - val_acc: 0.8557\n",
      "Epoch 34/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3366 - acc: 0.8589 - val_loss: 0.3333 - val_acc: 0.8638\n",
      "Epoch 35/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3283 - acc: 0.8622 - val_loss: 0.3583 - val_acc: 0.8618\n",
      "Epoch 36/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3278 - acc: 0.8591 - val_loss: 0.3461 - val_acc: 0.8520\n",
      "Epoch 37/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3332 - acc: 0.8578 - val_loss: 0.3756 - val_acc: 0.8578\n",
      "Epoch 38/80\n",
      "130/130 [==============================] - 17s 133ms/step - loss: 0.3269 - acc: 0.8605 - val_loss: 0.3496 - val_acc: 0.8583\n",
      "Epoch 39/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3262 - acc: 0.8622 - val_loss: 0.3377 - val_acc: 0.8612\n",
      "Epoch 40/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3415 - acc: 0.8536 - val_loss: 0.3486 - val_acc: 0.8621\n",
      "Epoch 41/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3280 - acc: 0.8627 - val_loss: 0.3739 - val_acc: 0.8528\n",
      "Epoch 42/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3258 - acc: 0.8626 - val_loss: 0.3328 - val_acc: 0.8648\n",
      "Epoch 43/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3298 - acc: 0.8597 - val_loss: 0.3439 - val_acc: 0.8616\n",
      "Epoch 44/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3235 - acc: 0.8643 - val_loss: 0.3308 - val_acc: 0.8625\n",
      "Epoch 45/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3278 - acc: 0.8625 - val_loss: 0.3520 - val_acc: 0.8607\n",
      "Epoch 46/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3151 - acc: 0.8664 - val_loss: 0.3486 - val_acc: 0.8630\n",
      "Epoch 47/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3195 - acc: 0.8638 - val_loss: 0.3373 - val_acc: 0.8682\n",
      "Epoch 48/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3138 - acc: 0.8705 - val_loss: 0.3525 - val_acc: 0.8594\n",
      "Epoch 49/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3248 - acc: 0.8626 - val_loss: 0.3292 - val_acc: 0.8647\n",
      "Epoch 50/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3162 - acc: 0.8649 - val_loss: 0.3248 - val_acc: 0.8695\n",
      "Epoch 51/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3186 - acc: 0.8654 - val_loss: 0.3360 - val_acc: 0.8650\n",
      "Epoch 52/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3154 - acc: 0.8667 - val_loss: 0.3368 - val_acc: 0.8634\n",
      "Epoch 53/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3225 - acc: 0.8647 - val_loss: 0.3424 - val_acc: 0.8485\n",
      "Epoch 54/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3181 - acc: 0.8672 - val_loss: 0.3253 - val_acc: 0.8687\n",
      "Epoch 55/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3149 - acc: 0.8684 - val_loss: 0.3233 - val_acc: 0.8652\n",
      "Epoch 56/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3160 - acc: 0.8658 - val_loss: 0.3222 - val_acc: 0.8676\n",
      "Epoch 57/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3145 - acc: 0.8661 - val_loss: 0.3345 - val_acc: 0.8634\n",
      "Epoch 58/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3149 - acc: 0.8683 - val_loss: 0.3234 - val_acc: 0.8683\n",
      "Epoch 59/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3155 - acc: 0.8667 - val_loss: 0.3148 - val_acc: 0.8710\n",
      "Epoch 60/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3139 - acc: 0.8671 - val_loss: 0.3425 - val_acc: 0.8609\n",
      "Epoch 61/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3116 - acc: 0.8691 - val_loss: 0.3383 - val_acc: 0.8671\n",
      "Epoch 62/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3152 - acc: 0.8673 - val_loss: 0.3378 - val_acc: 0.8642\n",
      "Epoch 63/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3113 - acc: 0.8653 - val_loss: 0.3213 - val_acc: 0.8718\n",
      "Epoch 64/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3034 - acc: 0.8708 - val_loss: 0.3236 - val_acc: 0.8689\n",
      "Epoch 65/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3045 - acc: 0.8745 - val_loss: 0.3164 - val_acc: 0.8692\n",
      "Epoch 66/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3206 - acc: 0.8648 - val_loss: 0.3358 - val_acc: 0.8707\n",
      "Epoch 67/80\n",
      "130/130 [==============================] - 17s 129ms/step - loss: 0.3140 - acc: 0.8684 - val_loss: 0.3769 - val_acc: 0.8419\n",
      "Epoch 68/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3133 - acc: 0.8668 - val_loss: 0.3130 - val_acc: 0.8718\n",
      "Epoch 69/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3070 - acc: 0.8695 - val_loss: 0.3453 - val_acc: 0.8597\n",
      "Epoch 70/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3042 - acc: 0.8702 - val_loss: 0.3410 - val_acc: 0.8643\n",
      "Epoch 71/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3151 - acc: 0.8660 - val_loss: 0.3398 - val_acc: 0.8655\n",
      "Epoch 72/80\n",
      "130/130 [==============================] - 17s 134ms/step - loss: 0.3040 - acc: 0.8728 - val_loss: 0.3328 - val_acc: 0.8685\n",
      "Epoch 73/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.3088 - acc: 0.8693 - val_loss: 0.3360 - val_acc: 0.8694\n",
      "Epoch 74/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3111 - acc: 0.8673 - val_loss: 0.3346 - val_acc: 0.8683\n",
      "Epoch 75/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3136 - acc: 0.8678 - val_loss: 0.3215 - val_acc: 0.8720\n",
      "Epoch 76/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3024 - acc: 0.8743 - val_loss: 0.3314 - val_acc: 0.8693\n",
      "Epoch 77/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.3017 - acc: 0.8738 - val_loss: 0.3125 - val_acc: 0.8715\n",
      "Epoch 78/80\n",
      "130/130 [==============================] - 17s 131ms/step - loss: 0.2965 - acc: 0.8745 - val_loss: 0.3237 - val_acc: 0.8694\n",
      "Epoch 79/80\n",
      "130/130 [==============================] - 17s 132ms/step - loss: 0.2970 - acc: 0.8746 - val_loss: 0.3151 - val_acc: 0.8685\n",
      "Epoch 80/80\n",
      "130/130 [==============================] - 17s 130ms/step - loss: 0.3044 - acc: 0.8729 - val_loss: 0.3294 - val_acc: 0.8688\n",
      "\n",
      "Training process completed in: 0 h 22 m 48 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: \" MODELS / model_breast_cancer_1257.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1259 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_393 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_393 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_394 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_394 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_395 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_395 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_396 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_396 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.5100 - acc: 0.7609 - val_loss: 0.4145 - val_acc: 0.8206\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.4239 - acc: 0.8181 - val_loss: 0.4147 - val_acc: 0.8242\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.4089 - acc: 0.8255 - val_loss: 0.4060 - val_acc: 0.8248\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3915 - acc: 0.8306 - val_loss: 0.3966 - val_acc: 0.8223\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3864 - acc: 0.8311 - val_loss: 0.3943 - val_acc: 0.8317\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 15s 77ms/step - loss: 0.3822 - acc: 0.8346 - val_loss: 0.3920 - val_acc: 0.8300\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 15s 77ms/step - loss: 0.3777 - acc: 0.8363 - val_loss: 0.3856 - val_acc: 0.8454\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3774 - acc: 0.8392 - val_loss: 0.4011 - val_acc: 0.8244\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3778 - acc: 0.8359 - val_loss: 0.4283 - val_acc: 0.8469\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3602 - acc: 0.8469 - val_loss: 0.3874 - val_acc: 0.8408\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3593 - acc: 0.8481 - val_loss: 0.3583 - val_acc: 0.8540\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3638 - acc: 0.8451 - val_loss: 0.4052 - val_acc: 0.8372\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3572 - acc: 0.8455 - val_loss: 0.3722 - val_acc: 0.8515\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3530 - acc: 0.8487 - val_loss: 0.3633 - val_acc: 0.8546\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3549 - acc: 0.8478 - val_loss: 0.3578 - val_acc: 0.8458\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3461 - acc: 0.8530 - val_loss: 0.3734 - val_acc: 0.8477\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3515 - acc: 0.8509 - val_loss: 0.3750 - val_acc: 0.8519\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3432 - acc: 0.8546 - val_loss: 0.3496 - val_acc: 0.8510\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3401 - acc: 0.8561 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3423 - acc: 0.8537 - val_loss: 0.3443 - val_acc: 0.8535\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3452 - acc: 0.8538 - val_loss: 0.3421 - val_acc: 0.8523\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3362 - acc: 0.8612 - val_loss: 0.3554 - val_acc: 0.8546\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3376 - acc: 0.8574 - val_loss: 0.3310 - val_acc: 0.8602\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 14s 76ms/step - loss: 0.3334 - acc: 0.8580 - val_loss: 0.3354 - val_acc: 0.8589\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3360 - acc: 0.8579 - val_loss: 0.3286 - val_acc: 0.8619\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3375 - acc: 0.8555 - val_loss: 0.3509 - val_acc: 0.8504\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3353 - acc: 0.8572 - val_loss: 0.3219 - val_acc: 0.8633\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3328 - acc: 0.8598 - val_loss: 0.3279 - val_acc: 0.8669\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3333 - acc: 0.8591 - val_loss: 0.3299 - val_acc: 0.8595\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3305 - acc: 0.8603 - val_loss: 0.3413 - val_acc: 0.8558\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3255 - acc: 0.8603 - val_loss: 0.3237 - val_acc: 0.8675\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3216 - acc: 0.8651 - val_loss: 0.3185 - val_acc: 0.8667\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3263 - acc: 0.8625 - val_loss: 0.3315 - val_acc: 0.8648\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3247 - acc: 0.8623 - val_loss: 0.3238 - val_acc: 0.8648\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3257 - acc: 0.8628 - val_loss: 0.3477 - val_acc: 0.8538\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3303 - acc: 0.8589 - val_loss: 0.3385 - val_acc: 0.8550\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3295 - acc: 0.8618 - val_loss: 0.3156 - val_acc: 0.8673\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3222 - acc: 0.8639 - val_loss: 0.3421 - val_acc: 0.8592\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3196 - acc: 0.8658 - val_loss: 0.3221 - val_acc: 0.8681\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3219 - acc: 0.8624 - val_loss: 0.3323 - val_acc: 0.8565\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3207 - acc: 0.8638 - val_loss: 0.3386 - val_acc: 0.8659\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3204 - acc: 0.8644 - val_loss: 0.3259 - val_acc: 0.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3159 - acc: 0.8683 - val_loss: 0.3320 - val_acc: 0.8763\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3196 - acc: 0.8646 - val_loss: 0.3331 - val_acc: 0.8629\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3168 - acc: 0.8668 - val_loss: 0.3542 - val_acc: 0.8531\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3200 - acc: 0.8665 - val_loss: 0.3353 - val_acc: 0.8660\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3198 - acc: 0.8644 - val_loss: 0.3352 - val_acc: 0.8652\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3100 - acc: 0.8697 - val_loss: 0.3264 - val_acc: 0.8706\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3132 - acc: 0.8683 - val_loss: 0.3222 - val_acc: 0.8665\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3184 - acc: 0.8652 - val_loss: 0.3215 - val_acc: 0.8725\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3088 - acc: 0.8707 - val_loss: 0.3522 - val_acc: 0.8469\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3134 - acc: 0.8687 - val_loss: 0.3265 - val_acc: 0.8704\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3102 - acc: 0.8711 - val_loss: 0.3442 - val_acc: 0.8614\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3093 - acc: 0.8697 - val_loss: 0.3572 - val_acc: 0.8421\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3124 - acc: 0.8695 - val_loss: 0.3162 - val_acc: 0.8663\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3109 - acc: 0.8687 - val_loss: 0.3329 - val_acc: 0.8640\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3130 - acc: 0.8682 - val_loss: 0.3147 - val_acc: 0.8654\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3044 - acc: 0.8726 - val_loss: 0.3236 - val_acc: 0.8739\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3103 - acc: 0.8666 - val_loss: 0.3101 - val_acc: 0.8708\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3072 - acc: 0.8704 - val_loss: 0.3291 - val_acc: 0.8652\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3059 - acc: 0.8722 - val_loss: 0.3180 - val_acc: 0.8652\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3125 - acc: 0.8685 - val_loss: 0.3211 - val_acc: 0.8663\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3079 - acc: 0.8722 - val_loss: 0.3192 - val_acc: 0.8675\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3092 - acc: 0.8693 - val_loss: 0.3327 - val_acc: 0.8631\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3078 - acc: 0.8716 - val_loss: 0.3219 - val_acc: 0.8673\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.2984 - acc: 0.8761 - val_loss: 0.3244 - val_acc: 0.8602\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3049 - acc: 0.8727 - val_loss: 0.3116 - val_acc: 0.8775\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3088 - acc: 0.8682 - val_loss: 0.3113 - val_acc: 0.8685\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3013 - acc: 0.8730 - val_loss: 0.3162 - val_acc: 0.8692\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3039 - acc: 0.8735 - val_loss: 0.3099 - val_acc: 0.8763\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.2963 - acc: 0.8777 - val_loss: 0.3298 - val_acc: 0.8692\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3062 - acc: 0.8704 - val_loss: 0.3183 - val_acc: 0.8687\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3011 - acc: 0.8737 - val_loss: 0.3097 - val_acc: 0.8731\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.3029 - acc: 0.8724 - val_loss: 0.3283 - val_acc: 0.8710\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 14s 75ms/step - loss: 0.2970 - acc: 0.8757 - val_loss: 0.3177 - val_acc: 0.8729\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3077 - acc: 0.8687 - val_loss: 0.3271 - val_acc: 0.8676\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.2981 - acc: 0.8741 - val_loss: 0.3039 - val_acc: 0.8785\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.2994 - acc: 0.8760 - val_loss: 0.3192 - val_acc: 0.8644\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3016 - acc: 0.8748 - val_loss: 0.3072 - val_acc: 0.8727\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 14s 74ms/step - loss: 0.3008 - acc: 0.8737 - val_loss: 0.3280 - val_acc: 0.8681\n",
      "\n",
      "Training process completed in: 0 h 19 m 2 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1258.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1260 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_397 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_397 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_398 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_398 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_399 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_399 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_400 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_400 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_100 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.5342 - acc: 0.7385 - val_loss: 0.4715 - val_acc: 0.7888\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 12s 66ms/step - loss: 0.4344 - acc: 0.8110 - val_loss: 0.4257 - val_acc: 0.8075\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4200 - acc: 0.8211 - val_loss: 0.3913 - val_acc: 0.8344\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4207 - acc: 0.8187 - val_loss: 0.4265 - val_acc: 0.8194\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4145 - acc: 0.8212 - val_loss: 0.4131 - val_acc: 0.8263\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4073 - acc: 0.8247 - val_loss: 0.4299 - val_acc: 0.8113\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.4035 - acc: 0.8281 - val_loss: 0.4236 - val_acc: 0.8138\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.4058 - acc: 0.8275 - val_loss: 0.4210 - val_acc: 0.8119\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.4001 - acc: 0.8303 - val_loss: 0.3746 - val_acc: 0.8394\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3996 - acc: 0.8290 - val_loss: 0.4074 - val_acc: 0.8269\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3902 - acc: 0.8315 - val_loss: 0.3874 - val_acc: 0.8288\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3943 - acc: 0.8308 - val_loss: 0.3663 - val_acc: 0.8481\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3899 - acc: 0.8321 - val_loss: 0.3779 - val_acc: 0.8331\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3869 - acc: 0.8341 - val_loss: 0.3886 - val_acc: 0.8300\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3829 - acc: 0.8358 - val_loss: 0.4194 - val_acc: 0.8144\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3776 - acc: 0.8383 - val_loss: 0.3878 - val_acc: 0.8325\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3755 - acc: 0.8399 - val_loss: 0.3697 - val_acc: 0.8450\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3755 - acc: 0.8407 - val_loss: 0.3788 - val_acc: 0.8327\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 13s 67ms/step - loss: 0.3718 - acc: 0.8403 - val_loss: 0.3823 - val_acc: 0.8344\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3804 - acc: 0.8368 - val_loss: 0.3858 - val_acc: 0.8281\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3787 - acc: 0.8379 - val_loss: 0.3923 - val_acc: 0.8219\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3667 - acc: 0.8425 - val_loss: 0.3764 - val_acc: 0.8338\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3630 - acc: 0.8452 - val_loss: 0.3466 - val_acc: 0.8619\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3649 - acc: 0.8453 - val_loss: 0.3791 - val_acc: 0.8387\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3648 - acc: 0.8442 - val_loss: 0.3532 - val_acc: 0.8550\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3621 - acc: 0.8451 - val_loss: 0.3333 - val_acc: 0.8675\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3601 - acc: 0.8473 - val_loss: 0.3611 - val_acc: 0.8438\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3582 - acc: 0.8466 - val_loss: 0.3344 - val_acc: 0.8600\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3587 - acc: 0.8472 - val_loss: 0.3548 - val_acc: 0.8394\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3525 - acc: 0.8518 - val_loss: 0.3367 - val_acc: 0.8537\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3565 - acc: 0.8491 - val_loss: 0.3581 - val_acc: 0.8519\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3492 - acc: 0.8527 - val_loss: 0.3760 - val_acc: 0.8456\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3464 - acc: 0.8532 - val_loss: 0.3517 - val_acc: 0.8525\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3501 - acc: 0.8498 - val_loss: 0.3361 - val_acc: 0.8625\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3492 - acc: 0.8537 - val_loss: 0.3583 - val_acc: 0.8472\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3516 - acc: 0.8513 - val_loss: 0.3475 - val_acc: 0.8531\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3480 - acc: 0.8535 - val_loss: 0.3494 - val_acc: 0.8556\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3467 - acc: 0.8532 - val_loss: 0.3668 - val_acc: 0.8369\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3396 - acc: 0.8559 - val_loss: 0.3682 - val_acc: 0.8456\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3470 - acc: 0.8525 - val_loss: 0.3302 - val_acc: 0.8625\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3399 - acc: 0.8565 - val_loss: 0.3417 - val_acc: 0.8569\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3401 - acc: 0.8565 - val_loss: 0.3333 - val_acc: 0.8587\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3404 - acc: 0.8549 - val_loss: 0.3577 - val_acc: 0.8438\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3458 - acc: 0.8523 - val_loss: 0.3214 - val_acc: 0.8712\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3336 - acc: 0.8595 - val_loss: 0.3379 - val_acc: 0.8594\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3359 - acc: 0.8562 - val_loss: 0.3332 - val_acc: 0.8575\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3339 - acc: 0.8601 - val_loss: 0.3035 - val_acc: 0.8700\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3325 - acc: 0.8610 - val_loss: 0.3384 - val_acc: 0.8550\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3350 - acc: 0.8565 - val_loss: 0.3394 - val_acc: 0.8525\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3383 - acc: 0.8562 - val_loss: 0.3640 - val_acc: 0.8481\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3330 - acc: 0.8587 - val_loss: 0.3366 - val_acc: 0.8581\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3313 - acc: 0.8587 - val_loss: 0.3168 - val_acc: 0.8644\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 14s 72ms/step - loss: 0.3337 - acc: 0.8615 - val_loss: 0.3120 - val_acc: 0.8750\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3298 - acc: 0.8591 - val_loss: 0.3400 - val_acc: 0.8556\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3301 - acc: 0.8599 - val_loss: 0.3566 - val_acc: 0.8438\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3283 - acc: 0.8635 - val_loss: 0.3450 - val_acc: 0.8531\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3289 - acc: 0.8611 - val_loss: 0.3493 - val_acc: 0.8506\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3283 - acc: 0.8618 - val_loss: 0.3288 - val_acc: 0.8519\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3291 - acc: 0.8603 - val_loss: 0.3325 - val_acc: 0.8606\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3248 - acc: 0.8625 - val_loss: 0.3317 - val_acc: 0.8637\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3275 - acc: 0.8621 - val_loss: 0.3586 - val_acc: 0.8338\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3307 - acc: 0.8600 - val_loss: 0.3198 - val_acc: 0.8606\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3242 - acc: 0.8603 - val_loss: 0.3220 - val_acc: 0.8656\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3259 - acc: 0.8628 - val_loss: 0.3021 - val_acc: 0.8744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3264 - acc: 0.8591 - val_loss: 0.3492 - val_acc: 0.8444\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3230 - acc: 0.8632 - val_loss: 0.3034 - val_acc: 0.8781\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3222 - acc: 0.8637 - val_loss: 0.3054 - val_acc: 0.8763\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3214 - acc: 0.8649 - val_loss: 0.3306 - val_acc: 0.8619\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3272 - acc: 0.8611 - val_loss: 0.3432 - val_acc: 0.8588\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 13s 70ms/step - loss: 0.3227 - acc: 0.8627 - val_loss: 0.3280 - val_acc: 0.8598\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.3206 - acc: 0.8650 - val_loss: 0.3219 - val_acc: 0.8644\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3203 - acc: 0.8647 - val_loss: 0.3143 - val_acc: 0.8694\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3198 - acc: 0.8646 - val_loss: 0.3329 - val_acc: 0.8588\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3119 - acc: 0.8707 - val_loss: 0.3222 - val_acc: 0.8656\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3174 - acc: 0.8660 - val_loss: 0.3375 - val_acc: 0.8481\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3134 - acc: 0.8672 - val_loss: 0.3103 - val_acc: 0.8681\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3167 - acc: 0.8667 - val_loss: 0.3277 - val_acc: 0.8519\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3163 - acc: 0.8648 - val_loss: 0.3023 - val_acc: 0.8713\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3203 - acc: 0.8622 - val_loss: 0.3400 - val_acc: 0.8475\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.3189 - acc: 0.8655 - val_loss: 0.3170 - val_acc: 0.8631\n",
      "\n",
      "Training process completed in: 0 h 17 m 35 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1259.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1261 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_401 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_401 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_402 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_402 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_403 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_403 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_404 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_404 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_101 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "190/190 [==============================] - 15s 78ms/step - loss: 0.5292 - acc: 0.7408 - val_loss: 0.4476 - val_acc: 0.7960\n",
      "Epoch 2/50\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.4363 - acc: 0.8126 - val_loss: 0.4206 - val_acc: 0.8230\n",
      "Epoch 3/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.4160 - acc: 0.8217 - val_loss: 0.3806 - val_acc: 0.8320\n",
      "Epoch 4/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.4156 - acc: 0.8190 - val_loss: 0.3987 - val_acc: 0.8290\n",
      "Epoch 5/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.4146 - acc: 0.8211 - val_loss: 0.4380 - val_acc: 0.8050\n",
      "Epoch 6/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.4081 - acc: 0.8259 - val_loss: 0.3832 - val_acc: 0.8420\n",
      "Epoch 7/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3991 - acc: 0.8294 - val_loss: 0.4063 - val_acc: 0.8210\n",
      "Epoch 8/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.4020 - acc: 0.8285 - val_loss: 0.4172 - val_acc: 0.8200\n",
      "Epoch 9/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3979 - acc: 0.8275 - val_loss: 0.4106 - val_acc: 0.8220\n",
      "Epoch 10/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3905 - acc: 0.8306 - val_loss: 0.4247 - val_acc: 0.8200\n",
      "Epoch 11/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3996 - acc: 0.8297 - val_loss: 0.4084 - val_acc: 0.8230\n",
      "Epoch 12/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3990 - acc: 0.8282 - val_loss: 0.3940 - val_acc: 0.8350\n",
      "Epoch 13/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3863 - acc: 0.8330 - val_loss: 0.3772 - val_acc: 0.8330\n",
      "Epoch 14/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3877 - acc: 0.8326 - val_loss: 0.4006 - val_acc: 0.8260\n",
      "Epoch 15/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3865 - acc: 0.8314 - val_loss: 0.4037 - val_acc: 0.8210\n",
      "Epoch 16/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3880 - acc: 0.8333 - val_loss: 0.3680 - val_acc: 0.8400\n",
      "Epoch 17/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3858 - acc: 0.8327 - val_loss: 0.4014 - val_acc: 0.8150\n",
      "Epoch 18/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3821 - acc: 0.8378 - val_loss: 0.3559 - val_acc: 0.8500\n",
      "Epoch 19/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3701 - acc: 0.8408 - val_loss: 0.3663 - val_acc: 0.8420\n",
      "Epoch 20/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3734 - acc: 0.8411 - val_loss: 0.4219 - val_acc: 0.8240\n",
      "Epoch 21/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3675 - acc: 0.8431 - val_loss: 0.3653 - val_acc: 0.8470\n",
      "Epoch 22/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3734 - acc: 0.8400 - val_loss: 0.3747 - val_acc: 0.8480\n",
      "Epoch 23/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3756 - acc: 0.8396 - val_loss: 0.3462 - val_acc: 0.8570\n",
      "Epoch 24/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3677 - acc: 0.8428 - val_loss: 0.3774 - val_acc: 0.8420\n",
      "Epoch 25/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3653 - acc: 0.8459 - val_loss: 0.3884 - val_acc: 0.8260\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3637 - acc: 0.8456 - val_loss: 0.3535 - val_acc: 0.8560\n",
      "Epoch 27/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3699 - acc: 0.8394 - val_loss: 0.3612 - val_acc: 0.8390\n",
      "Epoch 28/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3716 - acc: 0.8394 - val_loss: 0.3541 - val_acc: 0.8382\n",
      "Epoch 29/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3614 - acc: 0.8475 - val_loss: 0.3543 - val_acc: 0.8500\n",
      "Epoch 30/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3543 - acc: 0.8500 - val_loss: 0.3574 - val_acc: 0.8440\n",
      "Epoch 31/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3500 - acc: 0.8496 - val_loss: 0.3543 - val_acc: 0.8530\n",
      "Epoch 32/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3589 - acc: 0.8468 - val_loss: 0.3640 - val_acc: 0.8520\n",
      "Epoch 33/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3529 - acc: 0.8492 - val_loss: 0.3957 - val_acc: 0.8200\n",
      "Epoch 34/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3556 - acc: 0.8472 - val_loss: 0.3688 - val_acc: 0.8410\n",
      "Epoch 35/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3507 - acc: 0.8495 - val_loss: 0.3386 - val_acc: 0.8550\n",
      "Epoch 36/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3432 - acc: 0.8543 - val_loss: 0.3402 - val_acc: 0.8510\n",
      "Epoch 37/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3517 - acc: 0.8514 - val_loss: 0.3433 - val_acc: 0.8450\n",
      "Epoch 38/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3571 - acc: 0.8498 - val_loss: 0.3447 - val_acc: 0.8550\n",
      "Epoch 39/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3466 - acc: 0.8524 - val_loss: 0.3417 - val_acc: 0.8620\n",
      "Epoch 40/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3438 - acc: 0.8536 - val_loss: 0.3422 - val_acc: 0.8600\n",
      "Epoch 41/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3421 - acc: 0.8556 - val_loss: 0.3533 - val_acc: 0.8570\n",
      "Epoch 42/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3445 - acc: 0.8524 - val_loss: 0.3921 - val_acc: 0.8230\n",
      "Epoch 43/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3406 - acc: 0.8553 - val_loss: 0.3592 - val_acc: 0.8390\n",
      "Epoch 44/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3459 - acc: 0.8531 - val_loss: 0.3550 - val_acc: 0.8360\n",
      "Epoch 45/50\n",
      "190/190 [==============================] - 8s 45ms/step - loss: 0.3435 - acc: 0.8534 - val_loss: 0.3466 - val_acc: 0.8530\n",
      "Epoch 46/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3406 - acc: 0.8565 - val_loss: 0.3374 - val_acc: 0.8630\n",
      "Epoch 47/50\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.3523 - acc: 0.8489 - val_loss: 0.3359 - val_acc: 0.8600\n",
      "Epoch 48/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3417 - acc: 0.8537 - val_loss: 0.3519 - val_acc: 0.8560\n",
      "Epoch 49/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3344 - acc: 0.8581 - val_loss: 0.3261 - val_acc: 0.8670\n",
      "Epoch 50/50\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3474 - acc: 0.8499 - val_loss: 0.3221 - val_acc: 0.8700\n",
      "\n",
      "Training process completed in: 0 h 7 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1260.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1262 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_405 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_405 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_406 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_406 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_407 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_407 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_408 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_408 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_102 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 14s 80ms/step - loss: 0.4703 - acc: 0.7900 - val_loss: 0.4411 - val_acc: 0.8210\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 8s 43ms/step - loss: 0.4251 - acc: 0.8192 - val_loss: 0.4204 - val_acc: 0.8180\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4249 - acc: 0.8199 - val_loss: 0.4391 - val_acc: 0.8270\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4042 - acc: 0.8301 - val_loss: 0.3779 - val_acc: 0.8470\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3988 - acc: 0.8282 - val_loss: 0.4149 - val_acc: 0.8240\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3887 - acc: 0.8343 - val_loss: 0.3944 - val_acc: 0.8310\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3970 - acc: 0.8280 - val_loss: 0.4992 - val_acc: 0.7890\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3845 - acc: 0.8330 - val_loss: 0.3734 - val_acc: 0.8320\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3819 - acc: 0.8359 - val_loss: 0.4036 - val_acc: 0.8240\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3778 - acc: 0.8375 - val_loss: 0.3636 - val_acc: 0.8580\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3816 - acc: 0.8358 - val_loss: 0.3722 - val_acc: 0.8570\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3752 - acc: 0.8387 - val_loss: 0.3851 - val_acc: 0.8440\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3774 - acc: 0.8363 - val_loss: 0.3732 - val_acc: 0.8530\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3644 - acc: 0.8449 - val_loss: 0.3879 - val_acc: 0.8420\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3585 - acc: 0.8477 - val_loss: 0.3367 - val_acc: 0.8640\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3654 - acc: 0.8437 - val_loss: 0.3805 - val_acc: 0.8440\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3576 - acc: 0.8466 - val_loss: 0.3667 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3509 - acc: 0.8504 - val_loss: 0.3621 - val_acc: 0.8430\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3490 - acc: 0.8514 - val_loss: 0.3485 - val_acc: 0.8430\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3488 - acc: 0.8530 - val_loss: 0.3355 - val_acc: 0.8570\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3555 - acc: 0.8498 - val_loss: 0.3568 - val_acc: 0.8450\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3492 - acc: 0.8537 - val_loss: 0.3342 - val_acc: 0.8640\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3438 - acc: 0.8554 - val_loss: 0.3462 - val_acc: 0.8390\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3547 - acc: 0.8477 - val_loss: 0.3538 - val_acc: 0.8500\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3380 - acc: 0.8578 - val_loss: 0.3337 - val_acc: 0.8630\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3357 - acc: 0.8579 - val_loss: 0.3687 - val_acc: 0.8390\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3412 - acc: 0.8567 - val_loss: 0.3181 - val_acc: 0.8780\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3394 - acc: 0.8532 - val_loss: 0.3592 - val_acc: 0.8435\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3323 - acc: 0.8588 - val_loss: 0.3488 - val_acc: 0.8570\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3384 - acc: 0.8564 - val_loss: 0.3507 - val_acc: 0.8530\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3486 - acc: 0.8531 - val_loss: 0.3523 - val_acc: 0.8680\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3421 - acc: 0.8548 - val_loss: 0.3424 - val_acc: 0.8600\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3460 - acc: 0.8529 - val_loss: 0.3708 - val_acc: 0.8380\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3320 - acc: 0.8610 - val_loss: 0.3689 - val_acc: 0.8360\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3359 - acc: 0.8529 - val_loss: 0.3361 - val_acc: 0.8600\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3327 - acc: 0.8584 - val_loss: 0.3715 - val_acc: 0.8510\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3290 - acc: 0.8577 - val_loss: 0.3595 - val_acc: 0.8490\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3314 - acc: 0.8604 - val_loss: 0.3591 - val_acc: 0.8490\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3269 - acc: 0.8596 - val_loss: 0.3177 - val_acc: 0.8600\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3359 - acc: 0.8574 - val_loss: 0.3602 - val_acc: 0.8480\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3331 - acc: 0.8595 - val_loss: 0.3406 - val_acc: 0.8550\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3313 - acc: 0.8591 - val_loss: 0.3076 - val_acc: 0.8910\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3276 - acc: 0.8606 - val_loss: 0.3603 - val_acc: 0.8500\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3249 - acc: 0.8640 - val_loss: 0.3440 - val_acc: 0.8460\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3242 - acc: 0.8642 - val_loss: 0.3425 - val_acc: 0.8470\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3283 - acc: 0.8590 - val_loss: 0.3233 - val_acc: 0.8570\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3259 - acc: 0.8634 - val_loss: 0.3610 - val_acc: 0.8460\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3272 - acc: 0.8615 - val_loss: 0.3312 - val_acc: 0.8600\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3213 - acc: 0.8631 - val_loss: 0.3140 - val_acc: 0.8680\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3398 - acc: 0.8571 - val_loss: 0.3003 - val_acc: 0.8870\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3293 - acc: 0.8604 - val_loss: 0.3661 - val_acc: 0.8420\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3203 - acc: 0.8651 - val_loss: 0.3457 - val_acc: 0.8590\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3239 - acc: 0.8640 - val_loss: 0.3243 - val_acc: 0.8630\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3210 - acc: 0.8668 - val_loss: 0.3149 - val_acc: 0.8660\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3215 - acc: 0.8652 - val_loss: 0.3339 - val_acc: 0.8620\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3161 - acc: 0.8669 - val_loss: 0.3616 - val_acc: 0.8550 1s - loss\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3260 - acc: 0.8622 - val_loss: 0.3468 - val_acc: 0.8530\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3186 - acc: 0.8646 - val_loss: 0.3344 - val_acc: 0.8660\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3165 - acc: 0.8680 - val_loss: 0.3373 - val_acc: 0.8570\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3323 - acc: 0.8608 - val_loss: 0.3321 - val_acc: 0.8620\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3263 - acc: 0.8607 - val_loss: 0.3329 - val_acc: 0.8680\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3255 - acc: 0.8617 - val_loss: 0.3274 - val_acc: 0.8650\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3195 - acc: 0.8657 - val_loss: 0.3259 - val_acc: 0.8810\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3209 - acc: 0.8656 - val_loss: 0.3350 - val_acc: 0.8600\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3152 - acc: 0.8701 - val_loss: 0.3075 - val_acc: 0.8740\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3232 - acc: 0.8647 - val_loss: 0.3193 - val_acc: 0.8760\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3181 - acc: 0.8668 - val_loss: 0.3380 - val_acc: 0.8610\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3140 - acc: 0.8668 - val_loss: 0.3322 - val_acc: 0.8590\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3128 - acc: 0.8715 - val_loss: 0.3552 - val_acc: 0.8710\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3174 - acc: 0.8682 - val_loss: 0.3368 - val_acc: 0.8550\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3165 - acc: 0.8657 - val_loss: 0.3592 - val_acc: 0.8460\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3274 - acc: 0.8619 - val_loss: 0.3359 - val_acc: 0.8730\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3114 - acc: 0.8701 - val_loss: 0.3177 - val_acc: 0.8660\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3214 - acc: 0.8660 - val_loss: 0.3296 - val_acc: 0.8620\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3121 - acc: 0.8685 - val_loss: 0.3232 - val_acc: 0.8690\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3161 - acc: 0.8692 - val_loss: 0.3225 - val_acc: 0.8770\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3151 - acc: 0.8690 - val_loss: 0.3430 - val_acc: 0.8580\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3189 - acc: 0.8657 - val_loss: 0.3149 - val_acc: 0.8660\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 44ms/step - loss: 0.3153 - acc: 0.8670 - val_loss: 0.3010 - val_acc: 0.8760\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3140 - acc: 0.8670 - val_loss: 0.3287 - val_acc: 0.8550\n",
      "\n",
      "Training process completed in: 0 h 10 m 53 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1261.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1263 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_409 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_409 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_410 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_410 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_411 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_411 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_412 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_412 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_103 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 180\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 15s 83ms/step - loss: 0.4922 - acc: 0.7782 - val_loss: 0.4521 - val_acc: 0.8015\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4188 - acc: 0.8212 - val_loss: 0.4815 - val_acc: 0.7865\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4378 - acc: 0.8122 - val_loss: 0.4288 - val_acc: 0.8240\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4047 - acc: 0.8264 - val_loss: 0.4180 - val_acc: 0.8280\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3944 - acc: 0.8353 - val_loss: 0.3984 - val_acc: 0.8295\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3914 - acc: 0.8323 - val_loss: 0.4032 - val_acc: 0.8390\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4037 - acc: 0.8238 - val_loss: 0.3865 - val_acc: 0.8470\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3736 - acc: 0.8428 - val_loss: 0.3689 - val_acc: 0.8390\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3813 - acc: 0.8378 - val_loss: 0.3635 - val_acc: 0.8470\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3716 - acc: 0.8427 - val_loss: 0.3958 - val_acc: 0.8355\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3773 - acc: 0.8373 - val_loss: 0.3829 - val_acc: 0.8290\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3714 - acc: 0.8429 - val_loss: 0.3593 - val_acc: 0.8505\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3691 - acc: 0.8444 - val_loss: 0.3472 - val_acc: 0.8565\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3584 - acc: 0.8463 - val_loss: 0.3578 - val_acc: 0.8514\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3683 - acc: 0.8424 - val_loss: 0.3777 - val_acc: 0.8210\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3590 - acc: 0.8465 - val_loss: 0.3672 - val_acc: 0.8450\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3703 - acc: 0.8394 - val_loss: 0.3608 - val_acc: 0.8445\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3586 - acc: 0.8433 - val_loss: 0.3523 - val_acc: 0.8465\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3531 - acc: 0.8500 - val_loss: 0.3461 - val_acc: 0.8525\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3499 - acc: 0.8512 - val_loss: 0.3691 - val_acc: 0.8480\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3509 - acc: 0.8519 - val_loss: 0.3439 - val_acc: 0.8535\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3488 - acc: 0.8516 - val_loss: 0.3753 - val_acc: 0.8475\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3459 - acc: 0.8512 - val_loss: 0.3458 - val_acc: 0.8510\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.3503 - acc: 0.8494 - val_loss: 0.3346 - val_acc: 0.8560\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3446 - acc: 0.8544 - val_loss: 0.3778 - val_acc: 0.8535\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.3499 - acc: 0.8518 - val_loss: 0.3639 - val_acc: 0.8525\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3327 - acc: 0.8606 - val_loss: 0.3275 - val_acc: 0.8690\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3369 - acc: 0.8577 - val_loss: 0.3288 - val_acc: 0.8627\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3427 - acc: 0.8522 - val_loss: 0.3860 - val_acc: 0.8375\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3368 - acc: 0.8544 - val_loss: 0.3538 - val_acc: 0.8520\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3391 - acc: 0.8545 - val_loss: 0.3531 - val_acc: 0.8565\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3440 - acc: 0.8501 - val_loss: 0.3486 - val_acc: 0.8460\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3383 - acc: 0.8596 - val_loss: 0.3425 - val_acc: 0.8610\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3289 - acc: 0.8631 - val_loss: 0.3238 - val_acc: 0.8645\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3336 - acc: 0.8592 - val_loss: 0.3561 - val_acc: 0.8500\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3318 - acc: 0.8603 - val_loss: 0.3765 - val_acc: 0.8400\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3448 - acc: 0.8561 - val_loss: 0.3536 - val_acc: 0.8560\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 9s 49ms/step - loss: 0.3279 - acc: 0.8602 - val_loss: 0.3435 - val_acc: 0.8700\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.3293 - acc: 0.8596 - val_loss: 0.3288 - val_acc: 0.8630\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3317 - acc: 0.8586 - val_loss: 0.3363 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3395 - acc: 0.8560 - val_loss: 0.3754 - val_acc: 0.8420\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3338 - acc: 0.8588 - val_loss: 0.3913 - val_acc: 0.8443\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3359 - acc: 0.8566 - val_loss: 0.3204 - val_acc: 0.8690\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3293 - acc: 0.8628 - val_loss: 0.3231 - val_acc: 0.8615\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3241 - acc: 0.8629 - val_loss: 0.3588 - val_acc: 0.8475\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3267 - acc: 0.8627 - val_loss: 0.3489 - val_acc: 0.8660\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3290 - acc: 0.8597 - val_loss: 0.3234 - val_acc: 0.8625\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3251 - acc: 0.8631 - val_loss: 0.3157 - val_acc: 0.8755\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3284 - acc: 0.8608 - val_loss: 0.3527 - val_acc: 0.8515\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3272 - acc: 0.8628 - val_loss: 0.3318 - val_acc: 0.8635\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3247 - acc: 0.8627 - val_loss: 0.3201 - val_acc: 0.8755\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3247 - acc: 0.8644 - val_loss: 0.3440 - val_acc: 0.8615\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3207 - acc: 0.8647 - val_loss: 0.3656 - val_acc: 0.8595\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3114 - acc: 0.8700 - val_loss: 0.3327 - val_acc: 0.8540\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3234 - acc: 0.8620 - val_loss: 0.3442 - val_acc: 0.8560\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3189 - acc: 0.8650 - val_loss: 0.3490 - val_acc: 0.8519\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3297 - acc: 0.8606 - val_loss: 0.3500 - val_acc: 0.8580\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3168 - acc: 0.8661 - val_loss: 0.3187 - val_acc: 0.8770\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3274 - acc: 0.8607 - val_loss: 0.3332 - val_acc: 0.8640\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3236 - acc: 0.8644 - val_loss: 0.3312 - val_acc: 0.8630\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3238 - acc: 0.8643 - val_loss: 0.3326 - val_acc: 0.8640\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3280 - acc: 0.8618 - val_loss: 0.3277 - val_acc: 0.8710\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3232 - acc: 0.8646 - val_loss: 0.3208 - val_acc: 0.8775\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3185 - acc: 0.8669 - val_loss: 0.3147 - val_acc: 0.8640\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3204 - acc: 0.8639 - val_loss: 0.3227 - val_acc: 0.8695\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3285 - acc: 0.8607 - val_loss: 0.3477 - val_acc: 0.8600\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3080 - acc: 0.8714 - val_loss: 0.3400 - val_acc: 0.8670\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3225 - acc: 0.8643 - val_loss: 0.3324 - val_acc: 0.8630\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3216 - acc: 0.8633 - val_loss: 0.3254 - val_acc: 0.8685\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3173 - acc: 0.8666 - val_loss: 0.3451 - val_acc: 0.8576\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.3154 - acc: 0.8677 - val_loss: 0.3542 - val_acc: 0.8590\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3179 - acc: 0.8656 - val_loss: 0.3227 - val_acc: 0.8635\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3095 - acc: 0.8709 - val_loss: 0.3560 - val_acc: 0.8590\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.3213 - acc: 0.8623 - val_loss: 0.3197 - val_acc: 0.8650\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3242 - acc: 0.8631 - val_loss: 0.3250 - val_acc: 0.8540\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3077 - acc: 0.8712 - val_loss: 0.3361 - val_acc: 0.8665\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3092 - acc: 0.8714 - val_loss: 0.3696 - val_acc: 0.8505\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3122 - acc: 0.8677 - val_loss: 0.3146 - val_acc: 0.8710\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3167 - acc: 0.8655 - val_loss: 0.3063 - val_acc: 0.8710\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3198 - acc: 0.8668 - val_loss: 0.3459 - val_acc: 0.8555\n",
      "\n",
      "Training process completed in: 0 h 11 m 23 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1262.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1264 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_413 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_413 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_414 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_414 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_415 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_415 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_416 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_416 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_104 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.5753 - acc: 0.7112 - val_loss: 0.5036 - val_acc: 0.7246\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4473 - acc: 0.7998 - val_loss: 0.4370 - val_acc: 0.8114\n",
      "Epoch 3/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4197 - acc: 0.8205 - val_loss: 0.4098 - val_acc: 0.8232\n",
      "Epoch 4/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4092 - acc: 0.8257 - val_loss: 0.4051 - val_acc: 0.8229\n",
      "Epoch 5/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4025 - acc: 0.8265 - val_loss: 0.4011 - val_acc: 0.8254\n",
      "Epoch 6/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4110 - acc: 0.8226 - val_loss: 0.4204 - val_acc: 0.8121\n",
      "Epoch 7/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3955 - acc: 0.8297 - val_loss: 0.3976 - val_acc: 0.8318\n",
      "Epoch 8/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4071 - acc: 0.8227 - val_loss: 0.3944 - val_acc: 0.8279\n",
      "Epoch 9/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4014 - acc: 0.8284 - val_loss: 0.3957 - val_acc: 0.8321\n",
      "Epoch 10/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3917 - acc: 0.8289 - val_loss: 0.3782 - val_acc: 0.8295\n",
      "Epoch 11/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3908 - acc: 0.8317 - val_loss: 0.3978 - val_acc: 0.8161\n",
      "Epoch 12/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3964 - acc: 0.8271 - val_loss: 0.3872 - val_acc: 0.8407\n",
      "Epoch 13/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3856 - acc: 0.8328 - val_loss: 0.3898 - val_acc: 0.8261\n",
      "Epoch 14/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3833 - acc: 0.8350 - val_loss: 0.4062 - val_acc: 0.8218\n",
      "Epoch 15/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3846 - acc: 0.8340 - val_loss: 0.3747 - val_acc: 0.8379\n",
      "Epoch 16/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3851 - acc: 0.8314 - val_loss: 0.3875 - val_acc: 0.8346\n",
      "Epoch 17/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3746 - acc: 0.8401 - val_loss: 0.3728 - val_acc: 0.8468\n",
      "Epoch 18/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3820 - acc: 0.8351 - val_loss: 0.3805 - val_acc: 0.8325\n",
      "Epoch 19/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3740 - acc: 0.8392 - val_loss: 0.3700 - val_acc: 0.8375\n",
      "Epoch 20/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3792 - acc: 0.8343 - val_loss: 0.3834 - val_acc: 0.8447\n",
      "Epoch 21/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3704 - acc: 0.8423 - val_loss: 0.3734 - val_acc: 0.8379\n",
      "Epoch 22/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3739 - acc: 0.8376 - val_loss: 0.3702 - val_acc: 0.8375\n",
      "Epoch 23/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3692 - acc: 0.8419 - val_loss: 0.3677 - val_acc: 0.8518\n",
      "Epoch 24/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3707 - acc: 0.8397 - val_loss: 0.3728 - val_acc: 0.8371\n",
      "Epoch 25/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3704 - acc: 0.8380 - val_loss: 0.3567 - val_acc: 0.8518\n",
      "Epoch 26/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3644 - acc: 0.8427 - val_loss: 0.3684 - val_acc: 0.8400\n",
      "Epoch 27/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3652 - acc: 0.8423 - val_loss: 0.3661 - val_acc: 0.8421\n",
      "Epoch 28/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3643 - acc: 0.8456 - val_loss: 0.3620 - val_acc: 0.8339\n",
      "Epoch 29/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3660 - acc: 0.8414 - val_loss: 0.3497 - val_acc: 0.8539\n",
      "Epoch 30/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3662 - acc: 0.8423 - val_loss: 0.3696 - val_acc: 0.8421\n",
      "Epoch 31/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3578 - acc: 0.8484 - val_loss: 0.3684 - val_acc: 0.8457\n",
      "Epoch 32/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3560 - acc: 0.8475 - val_loss: 0.3543 - val_acc: 0.8418\n",
      "Epoch 33/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3645 - acc: 0.8445 - val_loss: 0.3576 - val_acc: 0.8482\n",
      "Epoch 34/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3597 - acc: 0.8460 - val_loss: 0.3634 - val_acc: 0.8461\n",
      "Epoch 35/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3655 - acc: 0.8435 - val_loss: 0.3426 - val_acc: 0.8579\n",
      "Epoch 36/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3487 - acc: 0.8526 - val_loss: 0.3521 - val_acc: 0.8493\n",
      "Epoch 37/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3522 - acc: 0.8500 - val_loss: 0.3438 - val_acc: 0.8536\n",
      "Epoch 38/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3397 - acc: 0.8563 - val_loss: 0.3390 - val_acc: 0.8493\n",
      "Epoch 39/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3591 - acc: 0.8469 - val_loss: 0.3588 - val_acc: 0.8496\n",
      "Epoch 40/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3564 - acc: 0.8467 - val_loss: 0.3561 - val_acc: 0.8477\n",
      "Epoch 41/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3518 - acc: 0.8489 - val_loss: 0.3543 - val_acc: 0.8429\n",
      "Epoch 42/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3446 - acc: 0.8520 - val_loss: 0.3685 - val_acc: 0.8425\n",
      "Epoch 43/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3524 - acc: 0.8471 - val_loss: 0.3406 - val_acc: 0.8589\n",
      "Epoch 44/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3438 - acc: 0.8523 - val_loss: 0.3360 - val_acc: 0.8600\n",
      "Epoch 45/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3441 - acc: 0.8521 - val_loss: 0.3471 - val_acc: 0.8579\n",
      "Epoch 46/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3463 - acc: 0.8536 - val_loss: 0.3309 - val_acc: 0.8614\n",
      "Epoch 47/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3450 - acc: 0.8539 - val_loss: 0.3379 - val_acc: 0.8604\n",
      "Epoch 48/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3524 - acc: 0.8474 - val_loss: 0.3621 - val_acc: 0.8386s:\n",
      "Epoch 49/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3374 - acc: 0.8549 - val_loss: 0.3375 - val_acc: 0.8536\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3367 - acc: 0.8584 - val_loss: 0.3491 - val_acc: 0.8507\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3389 - acc: 0.8561 - val_loss: 0.3538 - val_acc: 0.8579\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3422 - acc: 0.8553 - val_loss: 0.3538 - val_acc: 0.8514\n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3360 - acc: 0.8571 - val_loss: 0.3428 - val_acc: 0.8579\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3447 - acc: 0.8513 - val_loss: 0.3393 - val_acc: 0.8575\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3373 - acc: 0.8570 - val_loss: 0.3268 - val_acc: 0.8614\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3444 - acc: 0.8531 - val_loss: 0.3452 - val_acc: 0.8461\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3369 - acc: 0.8591 - val_loss: 0.3353 - val_acc: 0.8643\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3361 - acc: 0.8561 - val_loss: 0.3267 - val_acc: 0.8632\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3349 - acc: 0.8590 - val_loss: 0.3246 - val_acc: 0.8561\n",
      "Epoch 60/60\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3354 - acc: 0.8552 - val_loss: 0.3296 - val_acc: 0.8585\n",
      "\n",
      "Training process completed in: 0 h 9 m 51 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1263.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1265 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_417 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_417 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_418 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_418 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_419 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_419 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_420 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_420 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_105 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "150/150 [==============================] - 20s 136ms/step - loss: 0.5798 - acc: 0.7125 - val_loss: 0.5240 - val_acc: 0.7206\n",
      "Epoch 2/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.4591 - acc: 0.7913 - val_loss: 0.4281 - val_acc: 0.8136\n",
      "Epoch 3/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.4312 - acc: 0.8148 - val_loss: 0.4224 - val_acc: 0.8173\n",
      "Epoch 4/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.4184 - acc: 0.8218 - val_loss: 0.4202 - val_acc: 0.8186\n",
      "Epoch 5/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.4146 - acc: 0.8205 - val_loss: 0.4488 - val_acc: 0.8088\n",
      "Epoch 6/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.4121 - acc: 0.8237 - val_loss: 0.4041 - val_acc: 0.8233\n",
      "Epoch 7/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.4046 - acc: 0.8272 - val_loss: 0.4047 - val_acc: 0.8264\n",
      "Epoch 8/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.4161 - acc: 0.8213 - val_loss: 0.3974 - val_acc: 0.8299\n",
      "Epoch 9/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.4055 - acc: 0.8248 - val_loss: 0.4048 - val_acc: 0.8211\n",
      "Epoch 10/60\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.4067 - acc: 0.8255 - val_loss: 0.4011 - val_acc: 0.8252\n",
      "Epoch 11/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3982 - acc: 0.8275 - val_loss: 0.3998 - val_acc: 0.8296\n",
      "Epoch 12/60\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3899 - acc: 0.8316 - val_loss: 0.3873 - val_acc: 0.8296\n",
      "Epoch 13/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3960 - acc: 0.8298 - val_loss: 0.3906 - val_acc: 0.8306\n",
      "Epoch 14/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3952 - acc: 0.8299 - val_loss: 0.3914 - val_acc: 0.8255\n",
      "Epoch 15/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3887 - acc: 0.8331 - val_loss: 0.3857 - val_acc: 0.8325\n",
      "Epoch 16/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3908 - acc: 0.8326 - val_loss: 0.3906 - val_acc: 0.8314\n",
      "Epoch 17/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3913 - acc: 0.8300 - val_loss: 0.3890 - val_acc: 0.8294\n",
      "Epoch 18/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3800 - acc: 0.8366 - val_loss: 0.3872 - val_acc: 0.8296\n",
      "Epoch 19/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3814 - acc: 0.8340 - val_loss: 0.3784 - val_acc: 0.8341\n",
      "Epoch 20/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3848 - acc: 0.8364 - val_loss: 0.3947 - val_acc: 0.8358\n",
      "Epoch 21/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3807 - acc: 0.8376 - val_loss: 0.4105 - val_acc: 0.8272\n",
      "Epoch 22/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3792 - acc: 0.8340 - val_loss: 0.3800 - val_acc: 0.8344\n",
      "Epoch 23/60\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3792 - acc: 0.8361 - val_loss: 0.3727 - val_acc: 0.8414\n",
      "Epoch 24/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3664 - acc: 0.8414 - val_loss: 0.3764 - val_acc: 0.8378\n",
      "Epoch 25/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3702 - acc: 0.8432 - val_loss: 0.3794 - val_acc: 0.8342\n",
      "Epoch 26/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3732 - acc: 0.8400 - val_loss: 0.3676 - val_acc: 0.8398\n",
      "Epoch 27/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3751 - acc: 0.8407 - val_loss: 0.3852 - val_acc: 0.8387\n",
      "Epoch 28/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3738 - acc: 0.8410 - val_loss: 0.3840 - val_acc: 0.8302\n",
      "Epoch 29/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3714 - acc: 0.8404 - val_loss: 0.3839 - val_acc: 0.8423\n",
      "Epoch 30/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3593 - acc: 0.8442 - val_loss: 0.3775 - val_acc: 0.8357\n",
      "Epoch 31/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3720 - acc: 0.8410 - val_loss: 0.3599 - val_acc: 0.8437\n",
      "Epoch 32/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3587 - acc: 0.8460 - val_loss: 0.3579 - val_acc: 0.8459\n",
      "Epoch 33/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3607 - acc: 0.8477 - val_loss: 0.3589 - val_acc: 0.8447\n",
      "Epoch 34/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3585 - acc: 0.8475 - val_loss: 0.3723 - val_acc: 0.8414\n",
      "Epoch 35/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3549 - acc: 0.8470 - val_loss: 0.3520 - val_acc: 0.8519\n",
      "Epoch 36/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3510 - acc: 0.8509 - val_loss: 0.3541 - val_acc: 0.8421\n",
      "Epoch 37/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3537 - acc: 0.8504 - val_loss: 0.3727 - val_acc: 0.8365\n",
      "Epoch 38/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3549 - acc: 0.8494 - val_loss: 0.3558 - val_acc: 0.8433\n",
      "Epoch 39/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3614 - acc: 0.8465 - val_loss: 0.3594 - val_acc: 0.8503\n",
      "Epoch 40/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3620 - acc: 0.8431 - val_loss: 0.3476 - val_acc: 0.8522\n",
      "Epoch 41/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3593 - acc: 0.8435 - val_loss: 0.3523 - val_acc: 0.8486\n",
      "Epoch 42/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3446 - acc: 0.8553 - val_loss: 0.3491 - val_acc: 0.8490\n",
      "Epoch 43/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3548 - acc: 0.8477 - val_loss: 0.3423 - val_acc: 0.8571\n",
      "Epoch 44/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3488 - acc: 0.8527 - val_loss: 0.3571 - val_acc: 0.8441\n",
      "Epoch 45/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3494 - acc: 0.8500 - val_loss: 0.3406 - val_acc: 0.8563\n",
      "Epoch 46/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3495 - acc: 0.8490 - val_loss: 0.3479 - val_acc: 0.8507\n",
      "Epoch 47/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3535 - acc: 0.8462 - val_loss: 0.3588 - val_acc: 0.8473\n",
      "Epoch 48/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3473 - acc: 0.8518 - val_loss: 0.3590 - val_acc: 0.8454\n",
      "Epoch 49/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3437 - acc: 0.8560 - val_loss: 0.3434 - val_acc: 0.8569\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3503 - acc: 0.8512 - val_loss: 0.3533 - val_acc: 0.8502\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3469 - acc: 0.8534 - val_loss: 0.3405 - val_acc: 0.8548\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3419 - acc: 0.8545 - val_loss: 0.3425 - val_acc: 0.8530: 0.3402 - \n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3467 - acc: 0.8484 - val_loss: 0.3568 - val_acc: 0.8417\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3437 - acc: 0.8551 - val_loss: 0.3389 - val_acc: 0.8539\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3378 - acc: 0.8557 - val_loss: 0.3474 - val_acc: 0.8516\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3440 - acc: 0.8522 - val_loss: 0.3334 - val_acc: 0.8614\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3417 - acc: 0.8549 - val_loss: 0.3435 - val_acc: 0.8532\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3422 - acc: 0.8550 - val_loss: 0.3843 - val_acc: 0.8371\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3451 - acc: 0.8512 - val_loss: 0.3441 - val_acc: 0.8544\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3446 - acc: 0.8553 - val_loss: 0.3410 - val_acc: 0.8512\n",
      "\n",
      "Training process completed in: 0 h 13 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1264.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1266 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_421 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_421 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_422 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_422 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_423 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_423 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_424 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_424 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_106 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.5584 - acc: 0.7220 - val_loss: 0.4786 - val_acc: 0.8064\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.4391 - acc: 0.8073 - val_loss: 0.4315 - val_acc: 0.8189\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4200 - acc: 0.8208 - val_loss: 0.4334 - val_acc: 0.8082\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4184 - acc: 0.8204 - val_loss: 0.4122 - val_acc: 0.8207\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4177 - acc: 0.8214 - val_loss: 0.4351 - val_acc: 0.8171\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4129 - acc: 0.8240 - val_loss: 0.4015 - val_acc: 0.8243\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4057 - acc: 0.8259 - val_loss: 0.4035 - val_acc: 0.8225\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4075 - acc: 0.8236 - val_loss: 0.4231 - val_acc: 0.8207\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.4002 - acc: 0.8282 - val_loss: 0.3841 - val_acc: 0.8318\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3923 - acc: 0.8314 - val_loss: 0.3967 - val_acc: 0.8280\n",
      "Epoch 11/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.4071 - acc: 0.8259 - val_loss: 0.4041 - val_acc: 0.8318\n",
      "Epoch 12/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3932 - acc: 0.8315 - val_loss: 0.3975 - val_acc: 0.8318\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3909 - acc: 0.8320 - val_loss: 0.4062 - val_acc: 0.8257\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3959 - acc: 0.8305 - val_loss: 0.3891 - val_acc: 0.8350\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3881 - acc: 0.8344 - val_loss: 0.3700 - val_acc: 0.8329\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3881 - acc: 0.8348 - val_loss: 0.3892 - val_acc: 0.8318\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3921 - acc: 0.8284 - val_loss: 0.3955 - val_acc: 0.8257\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3776 - acc: 0.8385 - val_loss: 0.3916 - val_acc: 0.8325\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3857 - acc: 0.8331 - val_loss: 0.3855 - val_acc: 0.8289\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3782 - acc: 0.8360 - val_loss: 0.3781 - val_acc: 0.8388\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3813 - acc: 0.8358 - val_loss: 0.3724 - val_acc: 0.8421\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3824 - acc: 0.8396 - val_loss: 0.3757 - val_acc: 0.8371\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3773 - acc: 0.8385 - val_loss: 0.3721 - val_acc: 0.8354\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3739 - acc: 0.8390 - val_loss: 0.3737 - val_acc: 0.8382\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3676 - acc: 0.8429 - val_loss: 0.3731 - val_acc: 0.8393\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3779 - acc: 0.8407 - val_loss: 0.3951 - val_acc: 0.8289\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3672 - acc: 0.8434 - val_loss: 0.3786 - val_acc: 0.8332\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3635 - acc: 0.8431 - val_loss: 0.3739 - val_acc: 0.8457\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3740 - acc: 0.8376 - val_loss: 0.3657 - val_acc: 0.8425\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3645 - acc: 0.8441 - val_loss: 0.3718 - val_acc: 0.8444\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3655 - acc: 0.8445 - val_loss: 0.3754 - val_acc: 0.8357s: 0.3655 - acc: 0\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3668 - acc: 0.8407 - val_loss: 0.3668 - val_acc: 0.8443\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3670 - acc: 0.8410 - val_loss: 0.3984 - val_acc: 0.8318\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3643 - acc: 0.8439 - val_loss: 0.3713 - val_acc: 0.8400\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3540 - acc: 0.8489 - val_loss: 0.3583 - val_acc: 0.8418\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3594 - acc: 0.8462 - val_loss: 0.3426 - val_acc: 0.8614\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3566 - acc: 0.8479 - val_loss: 0.3565 - val_acc: 0.8546\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3572 - acc: 0.8476 - val_loss: 0.3469 - val_acc: 0.8507\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3546 - acc: 0.8460 - val_loss: 0.3403 - val_acc: 0.8571\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3510 - acc: 0.8489 - val_loss: 0.3562 - val_acc: 0.8503\n",
      "Epoch 41/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3540 - acc: 0.8499 - val_loss: 0.3592 - val_acc: 0.8479\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3525 - acc: 0.8526 - val_loss: 0.3330 - val_acc: 0.8607\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3465 - acc: 0.8508 - val_loss: 0.3547 - val_acc: 0.8550\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3458 - acc: 0.8527 - val_loss: 0.3402 - val_acc: 0.8593\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3441 - acc: 0.8552 - val_loss: 0.3506 - val_acc: 0.8468\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3468 - acc: 0.8516 - val_loss: 0.3608 - val_acc: 0.8493\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3487 - acc: 0.8540 - val_loss: 0.3409 - val_acc: 0.8596\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3530 - acc: 0.8510 - val_loss: 0.3561 - val_acc: 0.8443\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3504 - acc: 0.8503 - val_loss: 0.3522 - val_acc: 0.8443\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3445 - acc: 0.8535 - val_loss: 0.3596 - val_acc: 0.8418\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3505 - acc: 0.8501 - val_loss: 0.3514 - val_acc: 0.8550\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3452 - acc: 0.8527 - val_loss: 0.3743 - val_acc: 0.8421\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3440 - acc: 0.8530 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3403 - acc: 0.8559 - val_loss: 0.3296 - val_acc: 0.8650\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3457 - acc: 0.8507 - val_loss: 0.3535 - val_acc: 0.8525\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3407 - acc: 0.8563 - val_loss: 0.3423 - val_acc: 0.8554\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3388 - acc: 0.8556 - val_loss: 0.3591 - val_acc: 0.8471\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3412 - acc: 0.8567 - val_loss: 0.3317 - val_acc: 0.8575\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3397 - acc: 0.8550 - val_loss: 0.3513 - val_acc: 0.8568\n",
      "Epoch 60/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3414 - acc: 0.8555 - val_loss: 0.3278 - val_acc: 0.8622\n",
      "Epoch 61/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3391 - acc: 0.8576 - val_loss: 0.3445 - val_acc: 0.8571\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3366 - acc: 0.8577 - val_loss: 0.3397 - val_acc: 0.8586\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3420 - acc: 0.8565 - val_loss: 0.3148 - val_acc: 0.8664\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3279 - acc: 0.8621 - val_loss: 0.3328 - val_acc: 0.8611\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3432 - acc: 0.8545 - val_loss: 0.3815 - val_acc: 0.8336\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3345 - acc: 0.8590 - val_loss: 0.3241 - val_acc: 0.8693\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3391 - acc: 0.8527 - val_loss: 0.3397 - val_acc: 0.8529\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3337 - acc: 0.8598 - val_loss: 0.3454 - val_acc: 0.8561\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3333 - acc: 0.8580 - val_loss: 0.3434 - val_acc: 0.8586\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3244 - acc: 0.8613 - val_loss: 0.3478 - val_acc: 0.8536\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3267 - acc: 0.8620 - val_loss: 0.3089 - val_acc: 0.8682\n",
      "Epoch 72/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3322 - acc: 0.8599 - val_loss: 0.3305 - val_acc: 0.8614\n",
      "Epoch 73/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3255 - acc: 0.8622 - val_loss: 0.3210 - val_acc: 0.8636\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3299 - acc: 0.8581 - val_loss: 0.3357 - val_acc: 0.8568\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 0.3298 - acc: 0.8604 - val_loss: 0.3437 - val_acc: 0.8546\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3234 - acc: 0.8592 - val_loss: 0.3264 - val_acc: 0.8618\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3276 - acc: 0.8599 - val_loss: 0.3216 - val_acc: 0.8650\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3273 - acc: 0.8619 - val_loss: 0.3355 - val_acc: 0.8604\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3215 - acc: 0.8650 - val_loss: 0.3398 - val_acc: 0.8564\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3280 - acc: 0.8606 - val_loss: 0.3262 - val_acc: 0.8626\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3305 - acc: 0.8616 - val_loss: 0.3226 - val_acc: 0.8671: \n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3323 - acc: 0.8586 - val_loss: 0.3410 - val_acc: 0.8550\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3178 - acc: 0.8653 - val_loss: 0.3240 - val_acc: 0.8675\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3245 - acc: 0.8634 - val_loss: 0.3741 - val_acc: 0.8414\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3267 - acc: 0.8615 - val_loss: 0.3167 - val_acc: 0.8654\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3269 - acc: 0.8610 - val_loss: 0.3341 - val_acc: 0.8575\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3308 - acc: 0.8595 - val_loss: 0.3113 - val_acc: 0.8686\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3204 - acc: 0.8654 - val_loss: 0.3335 - val_acc: 0.8589: 5s - los - ETA: \n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.3211 - acc: 0.8654 - val_loss: 0.3374 - val_acc: 0.8529\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.3133 - acc: 0.8665 - val_loss: 0.3225 - val_acc: 0.8614\n",
      "\n",
      "Training process completed in: 0 h 14 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1265.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1267 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_425 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_425 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_426 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_426 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_427 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_427 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_428 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_428 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_107 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4676 - acc: 0.7901 - val_loss: 0.4162 - val_acc: 0.8222\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.4169 - acc: 0.8209 - val_loss: 0.4258 - val_acc: 0.8119\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.4081 - acc: 0.8246 - val_loss: 0.4202 - val_acc: 0.8103\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3980 - acc: 0.8285 - val_loss: 0.3969 - val_acc: 0.8394\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3921 - acc: 0.8314 - val_loss: 0.4234 - val_acc: 0.8256\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3821 - acc: 0.8327 - val_loss: 0.3823 - val_acc: 0.8419\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3772 - acc: 0.8374 - val_loss: 0.3817 - val_acc: 0.8403\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.3742 - acc: 0.8377 - val_loss: 0.3583 - val_acc: 0.8459\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3699 - acc: 0.8418 - val_loss: 0.3688 - val_acc: 0.8409\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3623 - acc: 0.8440 - val_loss: 0.4110 - val_acc: 0.8331\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3645 - acc: 0.8435 - val_loss: 0.3421 - val_acc: 0.8562\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3545 - acc: 0.8480 - val_loss: 0.3482 - val_acc: 0.8509\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3474 - acc: 0.8533 - val_loss: 0.3638 - val_acc: 0.8509\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3483 - acc: 0.8512 - val_loss: 0.3629 - val_acc: 0.8516\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3490 - acc: 0.8515 - val_loss: 0.3681 - val_acc: 0.8591\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3363 - acc: 0.8569 - val_loss: 0.3387 - val_acc: 0.8647\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3417 - acc: 0.8542 - val_loss: 0.3551 - val_acc: 0.8509\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3407 - acc: 0.8555 - val_loss: 0.3471 - val_acc: 0.8551\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3354 - acc: 0.8574 - val_loss: 0.3536 - val_acc: 0.8569\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3371 - acc: 0.8558 - val_loss: 0.3338 - val_acc: 0.8659\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3317 - acc: 0.8582 - val_loss: 0.3471 - val_acc: 0.8556\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3316 - acc: 0.8607 - val_loss: 0.3317 - val_acc: 0.8666\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3371 - acc: 0.8571 - val_loss: 0.3321 - val_acc: 0.8603\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3324 - acc: 0.8591 - val_loss: 0.3764 - val_acc: 0.8509\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3217 - acc: 0.8633 - val_loss: 0.3277 - val_acc: 0.8622\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3279 - acc: 0.8611 - val_loss: 0.3238 - val_acc: 0.8666\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3208 - acc: 0.8655 - val_loss: 0.3405 - val_acc: 0.8615\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3235 - acc: 0.8628 - val_loss: 0.3180 - val_acc: 0.8769\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3214 - acc: 0.8615 - val_loss: 0.3406 - val_acc: 0.8594\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3225 - acc: 0.8638 - val_loss: 0.3469 - val_acc: 0.8519\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3228 - acc: 0.8627 - val_loss: 0.3407 - val_acc: 0.8584\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3226 - acc: 0.8620 - val_loss: 0.3303 - val_acc: 0.8666\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3196 - acc: 0.8653 - val_loss: 0.3265 - val_acc: 0.8706\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3122 - acc: 0.8687 - val_loss: 0.3335 - val_acc: 0.8588\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3210 - acc: 0.8628 - val_loss: 0.3370 - val_acc: 0.8641\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3198 - acc: 0.8646 - val_loss: 0.3284 - val_acc: 0.8613\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3187 - acc: 0.8659 - val_loss: 0.3318 - val_acc: 0.8553\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3160 - acc: 0.8666 - val_loss: 0.3444 - val_acc: 0.8709\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3118 - acc: 0.8697 - val_loss: 0.3261 - val_acc: 0.8697\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3149 - acc: 0.8666 - val_loss: 0.3160 - val_acc: 0.8706\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3144 - acc: 0.8690 - val_loss: 0.3351 - val_acc: 0.8675\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3171 - acc: 0.8643 - val_loss: 0.3386 - val_acc: 0.8584\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3085 - acc: 0.8709 - val_loss: 0.3379 - val_acc: 0.8591\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3060 - acc: 0.8721 - val_loss: 0.2891 - val_acc: 0.8814\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3104 - acc: 0.8704 - val_loss: 0.3104 - val_acc: 0.8725\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3108 - acc: 0.8698 - val_loss: 0.3364 - val_acc: 0.8644\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3121 - acc: 0.8681 - val_loss: 0.3628 - val_acc: 0.8556\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3120 - acc: 0.8682 - val_loss: 0.3259 - val_acc: 0.8681\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3147 - acc: 0.8667 - val_loss: 0.3304 - val_acc: 0.8697\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3109 - acc: 0.8692 - val_loss: 0.3075 - val_acc: 0.8722\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3036 - acc: 0.8716 - val_loss: 0.3314 - val_acc: 0.8744\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3066 - acc: 0.8700 - val_loss: 0.3127 - val_acc: 0.8753\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.2979 - acc: 0.8759 - val_loss: 0.3105 - val_acc: 0.8776\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3140 - acc: 0.8666 - val_loss: 0.3340 - val_acc: 0.8638\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3031 - acc: 0.8730 - val_loss: 0.3246 - val_acc: 0.8719\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3020 - acc: 0.8737 - val_loss: 0.3423 - val_acc: 0.8600\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3024 - acc: 0.8738 - val_loss: 0.3108 - val_acc: 0.8744\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3038 - acc: 0.8722 - val_loss: 0.3192 - val_acc: 0.8781\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3048 - acc: 0.8710 - val_loss: 0.3495 - val_acc: 0.8594\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3082 - acc: 0.8678 - val_loss: 0.3037 - val_acc: 0.8722\n",
      "\n",
      "Training process completed in: 0 h 14 m 37 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1266.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1268 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_429 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_429 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_430 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_430 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_431 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_431 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_432 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_432 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_108 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "150/150 [==============================] - 20s 133ms/step - loss: 0.4974 - acc: 0.7679 - val_loss: 0.4110 - val_acc: 0.8235\n",
      "Epoch 2/60\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.4221 - acc: 0.8182 - val_loss: 0.4699 - val_acc: 0.8065\n",
      "Epoch 3/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.4118 - acc: 0.8224 - val_loss: 0.4051 - val_acc: 0.8287\n",
      "Epoch 4/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3911 - acc: 0.8336 - val_loss: 0.3898 - val_acc: 0.8300\n",
      "Epoch 5/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3906 - acc: 0.8328 - val_loss: 0.3980 - val_acc: 0.8408\n",
      "Epoch 6/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3832 - acc: 0.8357 - val_loss: 0.3650 - val_acc: 0.8420\n",
      "Epoch 7/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3861 - acc: 0.8343 - val_loss: 0.3887 - val_acc: 0.8353\n",
      "Epoch 8/60\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.3781 - acc: 0.8384 - val_loss: 0.3723 - val_acc: 0.8345\n",
      "Epoch 9/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3673 - acc: 0.8451 - val_loss: 0.3746 - val_acc: 0.8423\n",
      "Epoch 10/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3634 - acc: 0.8464 - val_loss: 0.3547 - val_acc: 0.8473\n",
      "Epoch 11/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3686 - acc: 0.8444 - val_loss: 0.3922 - val_acc: 0.8393\n",
      "Epoch 12/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3615 - acc: 0.8475 - val_loss: 0.3577 - val_acc: 0.8593\n",
      "Epoch 13/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3534 - acc: 0.8508 - val_loss: 0.3668 - val_acc: 0.8498\n",
      "Epoch 14/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3543 - acc: 0.8464 - val_loss: 0.3689 - val_acc: 0.8305\n",
      "Epoch 15/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3597 - acc: 0.8458 - val_loss: 0.3563 - val_acc: 0.8513\n",
      "Epoch 16/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3502 - acc: 0.8508 - val_loss: 0.3502 - val_acc: 0.8493\n",
      "Epoch 17/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3532 - acc: 0.8504 - val_loss: 0.3902 - val_acc: 0.8332\n",
      "Epoch 18/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3507 - acc: 0.8497 - val_loss: 0.3572 - val_acc: 0.8532\n",
      "Epoch 19/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3476 - acc: 0.8535 - val_loss: 0.3965 - val_acc: 0.8267\n",
      "Epoch 20/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3470 - acc: 0.8538 - val_loss: 0.3514 - val_acc: 0.8585\n",
      "Epoch 21/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3404 - acc: 0.8544 - val_loss: 0.3722 - val_acc: 0.8553\n",
      "Epoch 22/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3448 - acc: 0.8526 - val_loss: 0.3435 - val_acc: 0.8585\n",
      "Epoch 23/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3390 - acc: 0.8571 - val_loss: 0.3471 - val_acc: 0.8548\n",
      "Epoch 24/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3379 - acc: 0.8550 - val_loss: 0.3637 - val_acc: 0.8533\n",
      "Epoch 25/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3405 - acc: 0.8537 - val_loss: 0.3308 - val_acc: 0.8575\n",
      "Epoch 26/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3345 - acc: 0.8597 - val_loss: 0.3427 - val_acc: 0.8523\n",
      "Epoch 27/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3331 - acc: 0.8592 - val_loss: 0.3372 - val_acc: 0.8625\n",
      "Epoch 28/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3375 - acc: 0.8585 - val_loss: 0.3442 - val_acc: 0.8517\n",
      "Epoch 29/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3345 - acc: 0.8564 - val_loss: 0.3504 - val_acc: 0.8543\n",
      "Epoch 30/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3332 - acc: 0.8598 - val_loss: 0.3602 - val_acc: 0.8545\n",
      "Epoch 31/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3339 - acc: 0.8585 - val_loss: 0.3326 - val_acc: 0.8675\n",
      "Epoch 32/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3300 - acc: 0.8584 - val_loss: 0.3770 - val_acc: 0.8458\n",
      "Epoch 33/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3327 - acc: 0.8585 - val_loss: 0.3242 - val_acc: 0.8595\n",
      "Epoch 34/60\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3232 - acc: 0.8633 - val_loss: 0.3247 - val_acc: 0.8683\n",
      "Epoch 35/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3321 - acc: 0.8596 - val_loss: 0.3304 - val_acc: 0.8654\n",
      "Epoch 36/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3271 - acc: 0.8621 - val_loss: 0.3288 - val_acc: 0.8605\n",
      "Epoch 37/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3256 - acc: 0.8624 - val_loss: 0.3370 - val_acc: 0.8583\n",
      "Epoch 38/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3244 - acc: 0.8613 - val_loss: 0.3329 - val_acc: 0.8635\n",
      "Epoch 39/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3237 - acc: 0.8618 - val_loss: 0.3086 - val_acc: 0.8742\n",
      "Epoch 40/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3167 - acc: 0.8667 - val_loss: 0.3249 - val_acc: 0.8703\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3184 - acc: 0.8661 - val_loss: 0.3583 - val_acc: 0.8527\n",
      "Epoch 42/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3253 - acc: 0.8620 - val_loss: 0.3288 - val_acc: 0.8666\n",
      "Epoch 43/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3240 - acc: 0.8635 - val_loss: 0.3270 - val_acc: 0.8618\n",
      "Epoch 44/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3223 - acc: 0.8639 - val_loss: 0.3420 - val_acc: 0.8643\n",
      "Epoch 45/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3143 - acc: 0.8678 - val_loss: 0.3210 - val_acc: 0.8693\n",
      "Epoch 46/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3179 - acc: 0.8651 - val_loss: 0.3370 - val_acc: 0.8737\n",
      "Epoch 47/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3075 - acc: 0.8718 - val_loss: 0.3064 - val_acc: 0.8727\n",
      "Epoch 48/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3154 - acc: 0.8657 - val_loss: 0.3344 - val_acc: 0.8608\n",
      "Epoch 49/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3176 - acc: 0.8666 - val_loss: 0.3412 - val_acc: 0.8611\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3144 - acc: 0.8663 - val_loss: 0.3440 - val_acc: 0.8545\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3112 - acc: 0.8679 - val_loss: 0.3159 - val_acc: 0.8650\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3248 - acc: 0.8624 - val_loss: 0.3151 - val_acc: 0.8633\n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3077 - acc: 0.8688 - val_loss: 0.3211 - val_acc: 0.8623\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3079 - acc: 0.8705 - val_loss: 0.3105 - val_acc: 0.8752\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3141 - acc: 0.8668 - val_loss: 0.3292 - val_acc: 0.8670\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3135 - acc: 0.8660 - val_loss: 0.3313 - val_acc: 0.8666\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.3140 - acc: 0.8684 - val_loss: 0.3280 - val_acc: 0.8653\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.3153 - acc: 0.8662 - val_loss: 0.3282 - val_acc: 0.8660\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.3050 - acc: 0.8717 - val_loss: 0.3148 - val_acc: 0.8727\n",
      "Epoch 60/60\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3103 - acc: 0.8706 - val_loss: 0.2985 - val_acc: 0.8782\n",
      "\n",
      "Training process completed in: 0 h 13 m 40 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1267.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1269 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_433 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_433 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_434 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_434 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_435 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_435 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_436 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_436 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_109 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.5218 - acc: 0.7509 - val_loss: 0.4277 - val_acc: 0.8155\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.4233 - acc: 0.8177 - val_loss: 0.4260 - val_acc: 0.8138\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.4509 - val_acc: 0.8132\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.4085 - acc: 0.8232 - val_loss: 0.4039 - val_acc: 0.8282\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.4044 - acc: 0.8242 - val_loss: 0.4170 - val_acc: 0.8217\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3992 - acc: 0.8302 - val_loss: 0.3781 - val_acc: 0.8372\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3928 - acc: 0.8311 - val_loss: 0.3869 - val_acc: 0.8312\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3940 - acc: 0.8293 - val_loss: 0.3973 - val_acc: 0.8283\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3863 - acc: 0.8330 - val_loss: 0.3975 - val_acc: 0.8265\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3869 - acc: 0.8342 - val_loss: 0.3867 - val_acc: 0.8330\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3856 - acc: 0.8345 - val_loss: 0.3879 - val_acc: 0.8332\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3763 - acc: 0.8358 - val_loss: 0.3661 - val_acc: 0.8418\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3742 - acc: 0.8390 - val_loss: 0.3880 - val_acc: 0.8332\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3793 - acc: 0.8373 - val_loss: 0.3808 - val_acc: 0.8360\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3737 - acc: 0.8395 - val_loss: 0.3725 - val_acc: 0.8363\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3711 - acc: 0.8421 - val_loss: 0.3670 - val_acc: 0.8420\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3686 - acc: 0.8404 - val_loss: 0.3826 - val_acc: 0.8325\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3691 - acc: 0.8433 - val_loss: 0.3569 - val_acc: 0.8470\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3667 - acc: 0.8429 - val_loss: 0.3564 - val_acc: 0.8527\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3675 - acc: 0.8428 - val_loss: 0.3814 - val_acc: 0.8308\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3602 - acc: 0.8449 - val_loss: 0.3569 - val_acc: 0.8500\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3581 - acc: 0.8457 - val_loss: 0.3436 - val_acc: 0.8477\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3562 - acc: 0.8481 - val_loss: 0.3618 - val_acc: 0.8478\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3524 - acc: 0.8498 - val_loss: 0.3603 - val_acc: 0.8471\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3541 - acc: 0.8481 - val_loss: 0.3521 - val_acc: 0.8433\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3516 - acc: 0.8494 - val_loss: 0.3581 - val_acc: 0.8473\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3477 - acc: 0.8523 - val_loss: 0.3562 - val_acc: 0.8512\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3557 - acc: 0.8478 - val_loss: 0.3349 - val_acc: 0.8609\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3517 - acc: 0.8513 - val_loss: 0.3584 - val_acc: 0.8375\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3441 - acc: 0.8522 - val_loss: 0.3405 - val_acc: 0.8560\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3559 - acc: 0.8471 - val_loss: 0.3560 - val_acc: 0.8470\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3473 - acc: 0.8523 - val_loss: 0.3515 - val_acc: 0.8530\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3400 - acc: 0.8558 - val_loss: 0.3410 - val_acc: 0.8567\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3373 - acc: 0.8561 - val_loss: 0.3578 - val_acc: 0.8503\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3421 - acc: 0.8538 - val_loss: 0.3355 - val_acc: 0.8542\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3456 - acc: 0.8520 - val_loss: 0.3466 - val_acc: 0.8538\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3391 - acc: 0.8553 - val_loss: 0.3510 - val_acc: 0.8562\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3405 - acc: 0.8539 - val_loss: 0.3458 - val_acc: 0.8564\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3369 - acc: 0.8573 - val_loss: 0.3507 - val_acc: 0.8567\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3344 - acc: 0.8579 - val_loss: 0.3474 - val_acc: 0.8478\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3390 - acc: 0.8549 - val_loss: 0.3324 - val_acc: 0.8617\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3349 - acc: 0.8582 - val_loss: 0.3314 - val_acc: 0.8567\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3394 - acc: 0.8553 - val_loss: 0.3317 - val_acc: 0.8598\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3338 - acc: 0.8585 - val_loss: 0.3292 - val_acc: 0.8627\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3359 - acc: 0.8586 - val_loss: 0.3451 - val_acc: 0.8493\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3341 - acc: 0.8567 - val_loss: 0.3606 - val_acc: 0.8470\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3344 - acc: 0.8586 - val_loss: 0.3456 - val_acc: 0.8575\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3292 - acc: 0.8626 - val_loss: 0.3371 - val_acc: 0.8522\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3323 - acc: 0.8593 - val_loss: 0.3129 - val_acc: 0.8700\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3291 - acc: 0.8598 - val_loss: 0.3572 - val_acc: 0.8483\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3321 - acc: 0.8592 - val_loss: 0.3367 - val_acc: 0.8570\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3283 - acc: 0.8596 - val_loss: 0.3357 - val_acc: 0.8603\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3321 - acc: 0.8580 - val_loss: 0.3165 - val_acc: 0.8693\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3300 - acc: 0.8594 - val_loss: 0.3610 - val_acc: 0.8442\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3274 - acc: 0.8605 - val_loss: 0.3337 - val_acc: 0.8590\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3276 - acc: 0.8609 - val_loss: 0.3238 - val_acc: 0.8639\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3284 - acc: 0.8600 - val_loss: 0.3307 - val_acc: 0.8547\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3265 - acc: 0.8626 - val_loss: 0.3267 - val_acc: 0.8670\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3275 - acc: 0.8626 - val_loss: 0.3205 - val_acc: 0.8642\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3270 - acc: 0.8599 - val_loss: 0.3346 - val_acc: 0.8570\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3197 - acc: 0.8621 - val_loss: 0.3497 - val_acc: 0.8513\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3245 - acc: 0.8632 - val_loss: 0.3274 - val_acc: 0.8597\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3273 - acc: 0.8613 - val_loss: 0.3262 - val_acc: 0.8612\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3236 - acc: 0.8640 - val_loss: 0.3272 - val_acc: 0.8623\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3209 - acc: 0.8625 - val_loss: 0.3386 - val_acc: 0.8579\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3190 - acc: 0.8656 - val_loss: 0.3294 - val_acc: 0.8592\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3289 - acc: 0.8613 - val_loss: 0.3205 - val_acc: 0.8632\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3165 - acc: 0.8661 - val_loss: 0.3254 - val_acc: 0.8632\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3212 - acc: 0.8642 - val_loss: 0.3169 - val_acc: 0.8667\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3279 - acc: 0.8595 - val_loss: 0.3129 - val_acc: 0.8656\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3165 - acc: 0.8646 - val_loss: 0.3138 - val_acc: 0.8667\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3162 - acc: 0.8657 - val_loss: 0.3161 - val_acc: 0.8703\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3203 - acc: 0.8641 - val_loss: 0.3266 - val_acc: 0.8547\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3218 - acc: 0.8635 - val_loss: 0.3190 - val_acc: 0.8660\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3181 - acc: 0.8652 - val_loss: 0.3520 - val_acc: 0.8486\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3152 - acc: 0.8670 - val_loss: 0.3238 - val_acc: 0.8668\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3139 - acc: 0.8664 - val_loss: 0.3158 - val_acc: 0.8640\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3181 - acc: 0.8648 - val_loss: 0.3247 - val_acc: 0.8668\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3168 - acc: 0.8661 - val_loss: 0.3120 - val_acc: 0.8666\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3130 - acc: 0.8685 - val_loss: 0.3058 - val_acc: 0.8700\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3123 - acc: 0.8677 - val_loss: 0.3145 - val_acc: 0.8687\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3129 - acc: 0.8655 - val_loss: 0.3279 - val_acc: 0.8625\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3151 - acc: 0.8646 - val_loss: 0.3184 - val_acc: 0.8642\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3114 - acc: 0.8675 - val_loss: 0.3187 - val_acc: 0.8641\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3150 - acc: 0.8652 - val_loss: 0.3202 - val_acc: 0.8625\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3084 - acc: 0.8706 - val_loss: 0.3377 - val_acc: 0.8593\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3178 - acc: 0.8642 - val_loss: 0.3210 - val_acc: 0.8660\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3076 - acc: 0.8700 - val_loss: 0.3142 - val_acc: 0.8702\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3056 - acc: 0.8703 - val_loss: 0.3077 - val_acc: 0.8695\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3090 - acc: 0.8693 - val_loss: 0.3046 - val_acc: 0.8722\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3135 - acc: 0.8651 - val_loss: 0.3223 - val_acc: 0.8598\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3045 - acc: 0.8697 - val_loss: 0.3216 - val_acc: 0.8590\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3095 - acc: 0.8686 - val_loss: 0.3157 - val_acc: 0.8642\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3079 - acc: 0.8689 - val_loss: 0.3147 - val_acc: 0.8667\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3075 - acc: 0.8683 - val_loss: 0.3294 - val_acc: 0.8535\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3079 - acc: 0.8693 - val_loss: 0.3160 - val_acc: 0.8668\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3061 - acc: 0.8701 - val_loss: 0.3089 - val_acc: 0.8698\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3041 - acc: 0.8714 - val_loss: 0.2916 - val_acc: 0.8784\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3076 - acc: 0.8684 - val_loss: 0.3003 - val_acc: 0.8718\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3019 - acc: 0.8721 - val_loss: 0.3279 - val_acc: 0.8617\n",
      "\n",
      "Training process completed in: 0 h 29 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1268.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1270 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_437 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_437 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_438 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_438 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_439 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_439 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_440 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_440 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_110 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.5403 - acc: 0.7311 - val_loss: 0.4512 - val_acc: 0.7947\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4425 - acc: 0.8065 - val_loss: 0.4217 - val_acc: 0.8200\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4226 - acc: 0.8182 - val_loss: 0.4185 - val_acc: 0.8219\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4241 - acc: 0.8191 - val_loss: 0.4139 - val_acc: 0.8162\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4242 - acc: 0.8181 - val_loss: 0.4239 - val_acc: 0.8112\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4046 - acc: 0.8261 - val_loss: 0.4124 - val_acc: 0.8231\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4036 - acc: 0.8278 - val_loss: 0.4048 - val_acc: 0.8213\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4091 - acc: 0.8230 - val_loss: 0.4046 - val_acc: 0.8269\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4103 - acc: 0.8245 - val_loss: 0.4451 - val_acc: 0.8023\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4066 - acc: 0.8228 - val_loss: 0.4142 - val_acc: 0.8219\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3977 - acc: 0.8303 - val_loss: 0.4184 - val_acc: 0.8200\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.4009 - acc: 0.8287 - val_loss: 0.3959 - val_acc: 0.8337\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.4021 - acc: 0.8234 - val_loss: 0.3940 - val_acc: 0.8359\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3994 - acc: 0.8280 - val_loss: 0.4061 - val_acc: 0.8234\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3939 - acc: 0.8299 - val_loss: 0.3931 - val_acc: 0.8322\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3890 - acc: 0.8332 - val_loss: 0.3971 - val_acc: 0.8306\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3955 - acc: 0.8288 - val_loss: 0.3797 - val_acc: 0.8369\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3944 - acc: 0.8297 - val_loss: 0.3966 - val_acc: 0.8205\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3883 - acc: 0.8318 - val_loss: 0.3825 - val_acc: 0.8356\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3866 - acc: 0.8332 - val_loss: 0.3918 - val_acc: 0.8278\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3825 - acc: 0.8330 - val_loss: 0.3802 - val_acc: 0.8356\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3820 - acc: 0.8331 - val_loss: 0.3827 - val_acc: 0.8413\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3800 - acc: 0.8371 - val_loss: 0.3918 - val_acc: 0.8294\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3817 - acc: 0.8386 - val_loss: 0.3985 - val_acc: 0.8300\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3839 - acc: 0.8323 - val_loss: 0.3836 - val_acc: 0.8341\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3791 - acc: 0.8360 - val_loss: 0.3876 - val_acc: 0.8412\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3843 - acc: 0.8327 - val_loss: 0.3827 - val_acc: 0.8371\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3742 - acc: 0.8421 - val_loss: 0.3868 - val_acc: 0.8316\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3680 - acc: 0.8413 - val_loss: 0.3726 - val_acc: 0.8338\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3738 - acc: 0.8397 - val_loss: 0.3719 - val_acc: 0.8434\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3657 - acc: 0.8448 - val_loss: 0.3685 - val_acc: 0.8450\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3728 - acc: 0.8424 - val_loss: 0.3658 - val_acc: 0.8378\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3670 - acc: 0.8432 - val_loss: 0.3727 - val_acc: 0.8422\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3678 - acc: 0.8423 - val_loss: 0.3651 - val_acc: 0.8422\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3624 - acc: 0.8438 - val_loss: 0.3858 - val_acc: 0.8452\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3620 - acc: 0.8471 - val_loss: 0.3629 - val_acc: 0.8497\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3741 - acc: 0.8389 - val_loss: 0.3611 - val_acc: 0.8450\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3673 - acc: 0.8430 - val_loss: 0.3788 - val_acc: 0.8403\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3681 - acc: 0.8421 - val_loss: 0.3735 - val_acc: 0.8422\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3603 - acc: 0.8489 - val_loss: 0.3626 - val_acc: 0.8431\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3637 - acc: 0.8433 - val_loss: 0.3524 - val_acc: 0.8428\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3615 - acc: 0.8444 - val_loss: 0.3590 - val_acc: 0.8434\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3548 - acc: 0.8482 - val_loss: 0.3419 - val_acc: 0.8622\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3533 - acc: 0.8478 - val_loss: 0.3384 - val_acc: 0.8603\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3685 - acc: 0.8420 - val_loss: 0.3723 - val_acc: 0.8491\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3523 - acc: 0.8480 - val_loss: 0.3573 - val_acc: 0.8491\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3435 - acc: 0.8578 - val_loss: 0.3696 - val_acc: 0.8478\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3517 - acc: 0.8489 - val_loss: 0.3622 - val_acc: 0.8509\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3474 - acc: 0.8552 - val_loss: 0.3493 - val_acc: 0.8512\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3506 - acc: 0.8519 - val_loss: 0.3460 - val_acc: 0.8559\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3527 - acc: 0.8514 - val_loss: 0.3462 - val_acc: 0.8556\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3587 - acc: 0.8472 - val_loss: 0.3466 - val_acc: 0.8472\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3516 - acc: 0.8492 - val_loss: 0.3496 - val_acc: 0.8477\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3551 - acc: 0.8475 - val_loss: 0.3457 - val_acc: 0.8534\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3386 - acc: 0.8576 - val_loss: 0.3392 - val_acc: 0.8581\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3487 - acc: 0.8496 - val_loss: 0.3544 - val_acc: 0.8431\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3539 - acc: 0.8492 - val_loss: 0.3376 - val_acc: 0.8628\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 8s 41ms/step - loss: 0.3501 - acc: 0.8528 - val_loss: 0.3494 - val_acc: 0.8519\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3449 - acc: 0.8549 - val_loss: 0.3415 - val_acc: 0.8569\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3438 - acc: 0.8522 - val_loss: 0.3481 - val_acc: 0.8566\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3416 - acc: 0.8560 - val_loss: 0.3503 - val_acc: 0.8537\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3517 - acc: 0.8491 - val_loss: 0.3496 - val_acc: 0.8534\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3473 - acc: 0.8534 - val_loss: 0.3828 - val_acc: 0.8347\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3428 - acc: 0.8538 - val_loss: 0.3458 - val_acc: 0.8531\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3408 - acc: 0.8557 - val_loss: 0.3354 - val_acc: 0.8547\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3364 - acc: 0.8549 - val_loss: 0.3532 - val_acc: 0.8612\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3411 - acc: 0.8556 - val_loss: 0.3216 - val_acc: 0.8666\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3412 - acc: 0.8544 - val_loss: 0.3352 - val_acc: 0.8566\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3429 - acc: 0.8564 - val_loss: 0.3430 - val_acc: 0.8572\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3398 - acc: 0.8559 - val_loss: 0.3567 - val_acc: 0.8471\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3344 - acc: 0.8576 - val_loss: 0.3152 - val_acc: 0.8669\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3383 - acc: 0.8553 - val_loss: 0.3499 - val_acc: 0.8553\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3330 - acc: 0.8564 - val_loss: 0.3371 - val_acc: 0.8522\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3419 - acc: 0.8568 - val_loss: 0.3203 - val_acc: 0.8672\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3338 - acc: 0.8614 - val_loss: 0.3500 - val_acc: 0.8544\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3331 - acc: 0.8564 - val_loss: 0.3314 - val_acc: 0.8650\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3331 - acc: 0.8562 - val_loss: 0.3356 - val_acc: 0.8584\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3323 - acc: 0.8588 - val_loss: 0.3243 - val_acc: 0.8650\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3447 - acc: 0.8541 - val_loss: 0.3505 - val_acc: 0.8493\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3428 - acc: 0.8546 - val_loss: 0.3381 - val_acc: 0.8597\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3303 - acc: 0.8607 - val_loss: 0.3308 - val_acc: 0.8631\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3325 - acc: 0.8590 - val_loss: 0.3391 - val_acc: 0.8569\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3248 - acc: 0.8645 - val_loss: 0.3234 - val_acc: 0.8678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3307 - acc: 0.8609 - val_loss: 0.3030 - val_acc: 0.8731\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3212 - acc: 0.8624 - val_loss: 0.3626 - val_acc: 0.8425\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3338 - acc: 0.8578 - val_loss: 0.3443 - val_acc: 0.8497\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3305 - acc: 0.8605 - val_loss: 0.3254 - val_acc: 0.8643\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3199 - acc: 0.8657 - val_loss: 0.3166 - val_acc: 0.8697\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3275 - acc: 0.8611 - val_loss: 0.3255 - val_acc: 0.8578\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3272 - acc: 0.8589 - val_loss: 0.3425 - val_acc: 0.8606\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3309 - acc: 0.8620 - val_loss: 0.3337 - val_acc: 0.8606\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3371 - acc: 0.8541 - val_loss: 0.3287 - val_acc: 0.8631\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3211 - acc: 0.8649 - val_loss: 0.3330 - val_acc: 0.8597\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3169 - acc: 0.8647 - val_loss: 0.3230 - val_acc: 0.8709\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3175 - acc: 0.8655 - val_loss: 0.3232 - val_acc: 0.8700\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3252 - acc: 0.8619 - val_loss: 0.3336 - val_acc: 0.8578\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3200 - acc: 0.8656 - val_loss: 0.3315 - val_acc: 0.8566\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3199 - acc: 0.8655 - val_loss: 0.3248 - val_acc: 0.8663\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3284 - acc: 0.8638 - val_loss: 0.3150 - val_acc: 0.8681\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3227 - acc: 0.8627 - val_loss: 0.3246 - val_acc: 0.8603\n",
      "\n",
      "Training process completed in: 0 h 13 m 30 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1269.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1271 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_441 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_441 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_442 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_442 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_443 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_443 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_444 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_444 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_111 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4892 - acc: 0.7808 - val_loss: 0.4450 - val_acc: 0.8069\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4354 - acc: 0.8161 - val_loss: 0.4246 - val_acc: 0.8172\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4064 - acc: 0.8260 - val_loss: 0.3964 - val_acc: 0.8297\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4077 - acc: 0.8306 - val_loss: 0.4175 - val_acc: 0.8194\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4123 - acc: 0.8237 - val_loss: 0.4295 - val_acc: 0.8094\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.4054 - acc: 0.8253 - val_loss: 0.3853 - val_acc: 0.8328\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3916 - acc: 0.8289 - val_loss: 0.3812 - val_acc: 0.8394\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3978 - acc: 0.8295 - val_loss: 0.4043 - val_acc: 0.8303\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3847 - acc: 0.8355 - val_loss: 0.4085 - val_acc: 0.8195\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3861 - acc: 0.8326 - val_loss: 0.3785 - val_acc: 0.8356\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3724 - acc: 0.8369 - val_loss: 0.3910 - val_acc: 0.8359\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3865 - acc: 0.8330 - val_loss: 0.3824 - val_acc: 0.8313\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3843 - acc: 0.8351 - val_loss: 0.4470 - val_acc: 0.8313\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3867 - acc: 0.8336 - val_loss: 0.4247 - val_acc: 0.8372\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3778 - acc: 0.8386 - val_loss: 0.3788 - val_acc: 0.8419\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3776 - acc: 0.8376 - val_loss: 0.4193 - val_acc: 0.8422\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3753 - acc: 0.8397 - val_loss: 0.3706 - val_acc: 0.8409\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3736 - acc: 0.8370 - val_loss: 0.3942 - val_acc: 0.8402\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3744 - acc: 0.8376 - val_loss: 0.3953 - val_acc: 0.8312\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3726 - acc: 0.8388 - val_loss: 0.3828 - val_acc: 0.8459\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3637 - acc: 0.8482 - val_loss: 0.3984 - val_acc: 0.8381\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3593 - acc: 0.8432 - val_loss: 0.3567 - val_acc: 0.8525\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3654 - acc: 0.8434 - val_loss: 0.3546 - val_acc: 0.8531\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3631 - acc: 0.8446 - val_loss: 0.3645 - val_acc: 0.8488\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3605 - acc: 0.8482 - val_loss: 0.3758 - val_acc: 0.8509\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3511 - acc: 0.8499 - val_loss: 0.3763 - val_acc: 0.8456\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3605 - acc: 0.8448 - val_loss: 0.3669 - val_acc: 0.8456\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3569 - acc: 0.8487 - val_loss: 0.3528 - val_acc: 0.8534\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3533 - acc: 0.8500 - val_loss: 0.3547 - val_acc: 0.8528\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3480 - acc: 0.8495 - val_loss: 0.3617 - val_acc: 0.8600\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3433 - acc: 0.8545 - val_loss: 0.3621 - val_acc: 0.8462\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3474 - acc: 0.8558 - val_loss: 0.3697 - val_acc: 0.8459\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3473 - acc: 0.8528 - val_loss: 0.3628 - val_acc: 0.8591\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3545 - acc: 0.8497 - val_loss: 0.3598 - val_acc: 0.8509\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3615 - acc: 0.8449 - val_loss: 0.3532 - val_acc: 0.8462\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3488 - acc: 0.8524 - val_loss: 0.3658 - val_acc: 0.8484\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3399 - acc: 0.8570 - val_loss: 0.3465 - val_acc: 0.8500\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3373 - acc: 0.8594 - val_loss: 0.3882 - val_acc: 0.8331\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3529 - acc: 0.8528 - val_loss: 0.3804 - val_acc: 0.8519\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3412 - acc: 0.8595 - val_loss: 0.3445 - val_acc: 0.8544\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3547 - acc: 0.8501 - val_loss: 0.3672 - val_acc: 0.8528\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3439 - acc: 0.8526 - val_loss: 0.3505 - val_acc: 0.8528\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3397 - acc: 0.8549 - val_loss: 0.3503 - val_acc: 0.8534\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3414 - acc: 0.8566 - val_loss: 0.3456 - val_acc: 0.8600\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3319 - acc: 0.8586 - val_loss: 0.3539 - val_acc: 0.8634\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3450 - acc: 0.8541 - val_loss: 0.3681 - val_acc: 0.8447\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3352 - acc: 0.8599 - val_loss: 0.3291 - val_acc: 0.8606\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3336 - acc: 0.8583 - val_loss: 0.3234 - val_acc: 0.8700\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3333 - acc: 0.8585 - val_loss: 0.3452 - val_acc: 0.8597\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3258 - acc: 0.8644 - val_loss: 0.3402 - val_acc: 0.8547\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3381 - acc: 0.8597 - val_loss: 0.3499 - val_acc: 0.8584\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3425 - acc: 0.8539 - val_loss: 0.3552 - val_acc: 0.8603\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 8s 44ms/step - loss: 0.3524 - acc: 0.8471 - val_loss: 0.3418 - val_acc: 0.8559\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3310 - acc: 0.8600 - val_loss: 0.3399 - val_acc: 0.8563\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3358 - acc: 0.8561 - val_loss: 0.3401 - val_acc: 0.8591\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3266 - acc: 0.8599 - val_loss: 0.3531 - val_acc: 0.8559\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3366 - acc: 0.8562 - val_loss: 0.3565 - val_acc: 0.8394\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3328 - acc: 0.8593 - val_loss: 0.3353 - val_acc: 0.8703\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3361 - acc: 0.8605 - val_loss: 0.3276 - val_acc: 0.8647\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3231 - acc: 0.8670 - val_loss: 0.3341 - val_acc: 0.8666\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3238 - acc: 0.8632 - val_loss: 0.3551 - val_acc: 0.8540\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3345 - acc: 0.8563 - val_loss: 0.3391 - val_acc: 0.8609\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3339 - acc: 0.8589 - val_loss: 0.3434 - val_acc: 0.8531\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3325 - acc: 0.8562 - val_loss: 0.3329 - val_acc: 0.8603\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3222 - acc: 0.8659 - val_loss: 0.3119 - val_acc: 0.8672\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3337 - acc: 0.8600 - val_loss: 0.3412 - val_acc: 0.8634\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3329 - acc: 0.8616 - val_loss: 0.3377 - val_acc: 0.8619\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3302 - acc: 0.8586 - val_loss: 0.3751 - val_acc: 0.8478\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3287 - acc: 0.8620 - val_loss: 0.3358 - val_acc: 0.8522\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3236 - acc: 0.8642 - val_loss: 0.3466 - val_acc: 0.8515\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3225 - acc: 0.8634 - val_loss: 0.3461 - val_acc: 0.8641\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3294 - acc: 0.8618 - val_loss: 0.3335 - val_acc: 0.8628\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3236 - acc: 0.8618 - val_loss: 0.3382 - val_acc: 0.8609\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3279 - acc: 0.8587 - val_loss: 0.3313 - val_acc: 0.8600\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3326 - acc: 0.8579 - val_loss: 0.3268 - val_acc: 0.8578\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3271 - acc: 0.8605 - val_loss: 0.3628 - val_acc: 0.8519\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3205 - acc: 0.8669 - val_loss: 0.3705 - val_acc: 0.8491\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3187 - acc: 0.8666 - val_loss: 0.3175 - val_acc: 0.8738\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3218 - acc: 0.8659 - val_loss: 0.3394 - val_acc: 0.8512\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3253 - acc: 0.8645 - val_loss: 0.3450 - val_acc: 0.8644\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3253 - acc: 0.8660 - val_loss: 0.3308 - val_acc: 0.8691\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3234 - acc: 0.8651 - val_loss: 0.3227 - val_acc: 0.8656\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3279 - acc: 0.8626 - val_loss: 0.3436 - val_acc: 0.8494\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3183 - acc: 0.8653 - val_loss: 0.3280 - val_acc: 0.8641\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3289 - acc: 0.8609 - val_loss: 0.3435 - val_acc: 0.8703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3177 - acc: 0.8664 - val_loss: 0.3376 - val_acc: 0.8603\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3205 - acc: 0.8656 - val_loss: 0.3546 - val_acc: 0.8587\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3316 - acc: 0.8570 - val_loss: 0.3260 - val_acc: 0.8666\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3262 - acc: 0.8591 - val_loss: 0.3453 - val_acc: 0.8541\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3212 - acc: 0.8644 - val_loss: 0.3143 - val_acc: 0.8644\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3202 - acc: 0.8615 - val_loss: 0.3359 - val_acc: 0.8734\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3181 - acc: 0.8650 - val_loss: 0.3385 - val_acc: 0.8566\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3207 - acc: 0.8647 - val_loss: 0.3237 - val_acc: 0.8722\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3158 - acc: 0.8682 - val_loss: 0.3468 - val_acc: 0.8600\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3218 - acc: 0.8652 - val_loss: 0.3256 - val_acc: 0.8641\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3188 - acc: 0.8679 - val_loss: 0.3285 - val_acc: 0.8694\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3149 - acc: 0.8686 - val_loss: 0.3189 - val_acc: 0.8703\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3178 - acc: 0.8661 - val_loss: 0.3190 - val_acc: 0.8688\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3202 - acc: 0.8630 - val_loss: 0.3446 - val_acc: 0.8572\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 8s 42ms/step - loss: 0.3162 - acc: 0.8689 - val_loss: 0.3487 - val_acc: 0.8616\n",
      "\n",
      "Training process completed in: 0 h 13 m 39 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1270.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1272 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_445 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_445 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_446 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_446 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_447 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_447 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_448 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_448 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_112 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 26s 135ms/step - loss: 0.5733 - acc: 0.7088 - val_loss: 0.4644 - val_acc: 0.7732\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.4213 - acc: 0.8212 - val_loss: 0.4238 - val_acc: 0.8153\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.4077 - acc: 0.8259 - val_loss: 0.3998 - val_acc: 0.8259\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.4088 - acc: 0.8238 - val_loss: 0.3973 - val_acc: 0.8267\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4002 - acc: 0.8275 - val_loss: 0.4035 - val_acc: 0.8231\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3987 - acc: 0.8314 - val_loss: 0.4030 - val_acc: 0.8281\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.4007 - acc: 0.8288 - val_loss: 0.3965 - val_acc: 0.8290\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3947 - acc: 0.8316 - val_loss: 0.4201 - val_acc: 0.8191\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3914 - acc: 0.8327 - val_loss: 0.3866 - val_acc: 0.8308\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3865 - acc: 0.8343 - val_loss: 0.3812 - val_acc: 0.8379\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3866 - acc: 0.8326 - val_loss: 0.3929 - val_acc: 0.8306\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3791 - acc: 0.8391 - val_loss: 0.3834 - val_acc: 0.8347\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3851 - acc: 0.8347 - val_loss: 0.3749 - val_acc: 0.8403\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3758 - acc: 0.8398 - val_loss: 0.3828 - val_acc: 0.8346\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3760 - acc: 0.8399 - val_loss: 0.3922 - val_acc: 0.8320\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3769 - acc: 0.8390 - val_loss: 0.3703 - val_acc: 0.8381\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3735 - acc: 0.8415 - val_loss: 0.3694 - val_acc: 0.8437\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3693 - acc: 0.8418 - val_loss: 0.3702 - val_acc: 0.8387\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3708 - acc: 0.8408 - val_loss: 0.3667 - val_acc: 0.8446\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3671 - acc: 0.8431 - val_loss: 0.3614 - val_acc: 0.8457\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3640 - acc: 0.8458 - val_loss: 0.3660 - val_acc: 0.8444\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3650 - acc: 0.8447 - val_loss: 0.3600 - val_acc: 0.8408\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3625 - acc: 0.8462 - val_loss: 0.3717 - val_acc: 0.8461\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3564 - acc: 0.8483 - val_loss: 0.3547 - val_acc: 0.8509\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3563 - acc: 0.8501 - val_loss: 0.3664 - val_acc: 0.8402\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3517 - acc: 0.8499 - val_loss: 0.3456 - val_acc: 0.8544\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3544 - acc: 0.8484 - val_loss: 0.3527 - val_acc: 0.8511\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3585 - acc: 0.8474 - val_loss: 0.3523 - val_acc: 0.8522\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3545 - acc: 0.8487 - val_loss: 0.3466 - val_acc: 0.8518\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3496 - acc: 0.8528 - val_loss: 0.3464 - val_acc: 0.8531\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3525 - acc: 0.8511 - val_loss: 0.3691 - val_acc: 0.8384\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3524 - acc: 0.8516 - val_loss: 0.3604 - val_acc: 0.8477\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3420 - acc: 0.8563 - val_loss: 0.3609 - val_acc: 0.8483\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3420 - acc: 0.8541 - val_loss: 0.3394 - val_acc: 0.8544\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3494 - acc: 0.8502 - val_loss: 0.3398 - val_acc: 0.8638\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3437 - acc: 0.8535 - val_loss: 0.3455 - val_acc: 0.8521\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3390 - acc: 0.8556 - val_loss: 0.3436 - val_acc: 0.8534\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3380 - acc: 0.8584 - val_loss: 0.3364 - val_acc: 0.8588\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3370 - acc: 0.8583 - val_loss: 0.3281 - val_acc: 0.8602\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3431 - acc: 0.8551 - val_loss: 0.3372 - val_acc: 0.8549\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3410 - acc: 0.8563 - val_loss: 0.3338 - val_acc: 0.8619\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3378 - acc: 0.8565 - val_loss: 0.3486 - val_acc: 0.8510\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3368 - acc: 0.8570 - val_loss: 0.3343 - val_acc: 0.8544\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3323 - acc: 0.8598 - val_loss: 0.3294 - val_acc: 0.8628\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3293 - acc: 0.8628 - val_loss: 0.3363 - val_acc: 0.8578\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3320 - acc: 0.8598 - val_loss: 0.3458 - val_acc: 0.8563\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3310 - acc: 0.8591 - val_loss: 0.3291 - val_acc: 0.8604\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3240 - acc: 0.8649 - val_loss: 0.3253 - val_acc: 0.8645\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3349 - acc: 0.8578 - val_loss: 0.3337 - val_acc: 0.8554\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3263 - acc: 0.8618 - val_loss: 0.3346 - val_acc: 0.8588\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3318 - acc: 0.8595 - val_loss: 0.3232 - val_acc: 0.8629\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3269 - acc: 0.8617 - val_loss: 0.3334 - val_acc: 0.8600\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3261 - acc: 0.8627 - val_loss: 0.3328 - val_acc: 0.8637\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3208 - acc: 0.8655 - val_loss: 0.3336 - val_acc: 0.8604\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3246 - acc: 0.8627 - val_loss: 0.3263 - val_acc: 0.8568\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3267 - acc: 0.8609 - val_loss: 0.3242 - val_acc: 0.8633\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3231 - acc: 0.8614 - val_loss: 0.3259 - val_acc: 0.8631\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3227 - acc: 0.8632 - val_loss: 0.3135 - val_acc: 0.8676\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3203 - acc: 0.8629 - val_loss: 0.3232 - val_acc: 0.8629\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3181 - acc: 0.8644 - val_loss: 0.3306 - val_acc: 0.8612\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3184 - acc: 0.8655 - val_loss: 0.3145 - val_acc: 0.8697\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3149 - acc: 0.8657 - val_loss: 0.3181 - val_acc: 0.8679\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3209 - acc: 0.8637 - val_loss: 0.3261 - val_acc: 0.8618\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3223 - acc: 0.8636 - val_loss: 0.3205 - val_acc: 0.8635\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3197 - acc: 0.8644 - val_loss: 0.3084 - val_acc: 0.8680\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3140 - acc: 0.8670 - val_loss: 0.3193 - val_acc: 0.8631\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3129 - acc: 0.8666 - val_loss: 0.3080 - val_acc: 0.8730\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3099 - acc: 0.8688 - val_loss: 0.3137 - val_acc: 0.8666\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3140 - acc: 0.8685 - val_loss: 0.3233 - val_acc: 0.8642\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3199 - acc: 0.8645 - val_loss: 0.3169 - val_acc: 0.8686\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3141 - acc: 0.8670 - val_loss: 0.3161 - val_acc: 0.8655\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3174 - acc: 0.8644 - val_loss: 0.3255 - val_acc: 0.8630\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3141 - acc: 0.8669 - val_loss: 0.3185 - val_acc: 0.8661\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3091 - acc: 0.8696 - val_loss: 0.3284 - val_acc: 0.8569\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3104 - acc: 0.8680 - val_loss: 0.3071 - val_acc: 0.8680\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3103 - acc: 0.8684 - val_loss: 0.3144 - val_acc: 0.8689\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 20s 103ms/step - loss: 0.3113 - acc: 0.8681 - val_loss: 0.3155 - val_acc: 0.8701\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3089 - acc: 0.8690 - val_loss: 0.3189 - val_acc: 0.8662\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3091 - acc: 0.8710 - val_loss: 0.3136 - val_acc: 0.8690\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3124 - acc: 0.8675 - val_loss: 0.3081 - val_acc: 0.8681\n",
      "\n",
      "Training process completed in: 0 h 24 m 53 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1271.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1273 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_449 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_449 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_450 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_450 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_451 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_451 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_452 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_452 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_113 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 24s 198ms/step - loss: 0.5253 - acc: 0.7477 - val_loss: 0.4352 - val_acc: 0.8147\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.4208 - acc: 0.8232 - val_loss: 0.4255 - val_acc: 0.8087\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.4162 - acc: 0.8234 - val_loss: 0.4279 - val_acc: 0.8239\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.4095 - acc: 0.8264 - val_loss: 0.4085 - val_acc: 0.8284\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.4001 - acc: 0.8271 - val_loss: 0.4086 - val_acc: 0.8334\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3950 - acc: 0.8317 - val_loss: 0.4184 - val_acc: 0.8271\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3873 - acc: 0.8351 - val_loss: 0.3917 - val_acc: 0.8333\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3899 - acc: 0.8337 - val_loss: 0.4176 - val_acc: 0.8310\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3840 - acc: 0.8349 - val_loss: 0.3959 - val_acc: 0.8345\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3703 - acc: 0.8433 - val_loss: 0.4006 - val_acc: 0.8380\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3746 - acc: 0.8415 - val_loss: 0.3737 - val_acc: 0.8427\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.3693 - acc: 0.8441 - val_loss: 0.3913 - val_acc: 0.8383\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.3734 - acc: 0.8393 - val_loss: 0.3880 - val_acc: 0.8432\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3684 - acc: 0.8439 - val_loss: 0.4538 - val_acc: 0.8195\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3691 - acc: 0.8440 - val_loss: 0.3954 - val_acc: 0.8458\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3630 - acc: 0.8452 - val_loss: 0.3763 - val_acc: 0.8435\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3640 - acc: 0.8448 - val_loss: 0.3745 - val_acc: 0.8500\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3585 - acc: 0.8464 - val_loss: 0.3895 - val_acc: 0.8453\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3566 - acc: 0.8493 - val_loss: 0.3707 - val_acc: 0.8504\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3518 - acc: 0.8515 - val_loss: 0.3584 - val_acc: 0.8477\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3605 - acc: 0.8474 - val_loss: 0.3576 - val_acc: 0.8527\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.3512 - acc: 0.8493 - val_loss: 0.3532 - val_acc: 0.8542\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3471 - acc: 0.8533 - val_loss: 0.3831 - val_acc: 0.8543\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3525 - acc: 0.8508 - val_loss: 0.3625 - val_acc: 0.8531\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3457 - acc: 0.8541 - val_loss: 0.3614 - val_acc: 0.8584\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3588 - acc: 0.8479 - val_loss: 0.4087 - val_acc: 0.8562\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3473 - acc: 0.8524 - val_loss: 0.4016 - val_acc: 0.8507\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3449 - acc: 0.8500 - val_loss: 0.3678 - val_acc: 0.8527\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3429 - acc: 0.8525 - val_loss: 0.4125 - val_acc: 0.8418\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3412 - acc: 0.8563 - val_loss: 0.3727 - val_acc: 0.8562\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3362 - acc: 0.8563 - val_loss: 0.3634 - val_acc: 0.8563\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3418 - acc: 0.8542 - val_loss: 0.3473 - val_acc: 0.8632\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3450 - acc: 0.8547 - val_loss: 0.3603 - val_acc: 0.8553\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3315 - acc: 0.8615 - val_loss: 0.3455 - val_acc: 0.8522\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3378 - acc: 0.8580 - val_loss: 0.3449 - val_acc: 0.8604\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3342 - acc: 0.8600 - val_loss: 0.3545 - val_acc: 0.8495\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 16s 135ms/step - loss: 0.3393 - acc: 0.8560 - val_loss: 0.3667 - val_acc: 0.8591\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 18s 147ms/step - loss: 0.3348 - acc: 0.8595 - val_loss: 0.3543 - val_acc: 0.8566\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3272 - acc: 0.8615 - val_loss: 0.3433 - val_acc: 0.8629\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3375 - acc: 0.8584 - val_loss: 0.3663 - val_acc: 0.8594\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3260 - acc: 0.8632 - val_loss: 0.4156 - val_acc: 0.8296\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3340 - acc: 0.8563 - val_loss: 0.3488 - val_acc: 0.8615\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3318 - acc: 0.8593 - val_loss: 0.3643 - val_acc: 0.8590\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3259 - acc: 0.8645 - val_loss: 0.3534 - val_acc: 0.8533\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3285 - acc: 0.8610 - val_loss: 0.3497 - val_acc: 0.8610\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3325 - acc: 0.8566 - val_loss: 0.3427 - val_acc: 0.8649\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3244 - acc: 0.8617 - val_loss: 0.3717 - val_acc: 0.8560\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3263 - acc: 0.8614 - val_loss: 0.3575 - val_acc: 0.8670\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3233 - acc: 0.8639 - val_loss: 0.3522 - val_acc: 0.8624\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3264 - acc: 0.8621 - val_loss: 0.3417 - val_acc: 0.8633\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3169 - acc: 0.8685 - val_loss: 0.3405 - val_acc: 0.8641\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3133 - acc: 0.8676 - val_loss: 0.3332 - val_acc: 0.8647\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3225 - acc: 0.8637 - val_loss: 0.3195 - val_acc: 0.8688\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3222 - acc: 0.8657 - val_loss: 0.3623 - val_acc: 0.8575\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3229 - acc: 0.8654 - val_loss: 0.3534 - val_acc: 0.8522\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3212 - acc: 0.8640 - val_loss: 0.3310 - val_acc: 0.8612\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3146 - acc: 0.8692 - val_loss: 0.3434 - val_acc: 0.8671\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3239 - acc: 0.8646 - val_loss: 0.3594 - val_acc: 0.8549\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3246 - acc: 0.8615 - val_loss: 0.3672 - val_acc: 0.8559\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3117 - acc: 0.8682 - val_loss: 0.3271 - val_acc: 0.8672\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3090 - acc: 0.8698 - val_loss: 0.3309 - val_acc: 0.8700\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3178 - acc: 0.8647 - val_loss: 0.3595 - val_acc: 0.8619\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3208 - acc: 0.8663 - val_loss: 0.3579 - val_acc: 0.8639\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3134 - acc: 0.8686 - val_loss: 0.3295 - val_acc: 0.8668\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3077 - acc: 0.8713 - val_loss: 0.3402 - val_acc: 0.8632\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3147 - acc: 0.8677 - val_loss: 0.3407 - val_acc: 0.8707\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3129 - acc: 0.8683 - val_loss: 0.3755 - val_acc: 0.8595\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.3196 - acc: 0.8641 - val_loss: 0.3543 - val_acc: 0.8675\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3145 - acc: 0.8656 - val_loss: 0.3370 - val_acc: 0.8657\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3114 - acc: 0.8697 - val_loss: 0.3653 - val_acc: 0.8559\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3170 - acc: 0.8656 - val_loss: 0.3455 - val_acc: 0.8657\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 17s 143ms/step - loss: 0.3115 - acc: 0.8672 - val_loss: 0.3719 - val_acc: 0.8497\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3057 - acc: 0.8718 - val_loss: 0.3341 - val_acc: 0.8681\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.3143 - acc: 0.8666 - val_loss: 0.3346 - val_acc: 0.8654\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 17s 143ms/step - loss: 0.3031 - acc: 0.8719 - val_loss: 0.3343 - val_acc: 0.8633\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3114 - acc: 0.8682 - val_loss: 0.3294 - val_acc: 0.8722\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3113 - acc: 0.8698 - val_loss: 0.3568 - val_acc: 0.8661\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3088 - acc: 0.8707 - val_loss: 0.3350 - val_acc: 0.8622\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3121 - acc: 0.8698 - val_loss: 0.3981 - val_acc: 0.8453\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3070 - acc: 0.8697 - val_loss: 0.3250 - val_acc: 0.8687\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3135 - acc: 0.8680 - val_loss: 0.3412 - val_acc: 0.8646\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3060 - acc: 0.8737 - val_loss: 0.3309 - val_acc: 0.8677\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3114 - acc: 0.8690 - val_loss: 0.3250 - val_acc: 0.8664\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3106 - acc: 0.8693 - val_loss: 0.3272 - val_acc: 0.8685\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3092 - acc: 0.8702 - val_loss: 0.3334 - val_acc: 0.8657\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3069 - acc: 0.8717 - val_loss: 0.3501 - val_acc: 0.8632\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3092 - acc: 0.8683 - val_loss: 0.3503 - val_acc: 0.8587\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3021 - acc: 0.8731 - val_loss: 0.3236 - val_acc: 0.8712\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3095 - acc: 0.8687 - val_loss: 0.3216 - val_acc: 0.8684\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 0.3065 - acc: 0.8713 - val_loss: 0.3174 - val_acc: 0.8673\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 17s 141ms/step - loss: 0.3045 - acc: 0.8707 - val_loss: 0.3124 - val_acc: 0.8741\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3026 - acc: 0.8709 - val_loss: 0.3309 - val_acc: 0.8668\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.3036 - acc: 0.8730 - val_loss: 0.3264 - val_acc: 0.8676\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3058 - acc: 0.8719 - val_loss: 0.3255 - val_acc: 0.8672\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3004 - acc: 0.8720 - val_loss: 0.3383 - val_acc: 0.8614\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.2990 - acc: 0.8747 - val_loss: 0.3204 - val_acc: 0.8708\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 0.3045 - acc: 0.8708 - val_loss: 0.3331 - val_acc: 0.8687\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.2936 - acc: 0.8767 - val_loss: 0.3118 - val_acc: 0.8725\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.2974 - acc: 0.8761 - val_loss: 0.3241 - val_acc: 0.8724\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.3049 - acc: 0.8700 - val_loss: 0.3412 - val_acc: 0.8677\n",
      "\n",
      "Training process completed in: 0 h 27 m 54 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1272.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1274 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_453 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_453 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_454 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_454 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_455 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_455 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_456 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_456 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_114 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "120/120 [==============================] - 17s 146ms/step - loss: 0.5015 - acc: 0.7684 - val_loss: 0.4979 - val_acc: 0.7845\n",
      "Epoch 2/80\n",
      "120/120 [==============================] - 10s 83ms/step - loss: 0.4215 - acc: 0.8191 - val_loss: 0.3965 - val_acc: 0.8205\n",
      "Epoch 3/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.4090 - acc: 0.8242 - val_loss: 0.4190 - val_acc: 0.8265\n",
      "Epoch 4/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.4072 - acc: 0.8254 - val_loss: 0.3995 - val_acc: 0.8255\n",
      "Epoch 5/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3945 - acc: 0.8290 - val_loss: 0.4565 - val_acc: 0.8100\n",
      "Epoch 6/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3871 - acc: 0.8321 - val_loss: 0.3785 - val_acc: 0.8390\n",
      "Epoch 7/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3937 - acc: 0.8280 - val_loss: 0.4101 - val_acc: 0.8415\n",
      "Epoch 8/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3752 - acc: 0.8409 - val_loss: 0.3825 - val_acc: 0.8310\n",
      "Epoch 9/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3770 - acc: 0.8376 - val_loss: 0.3771 - val_acc: 0.8440\n",
      "Epoch 10/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3720 - acc: 0.8408 - val_loss: 0.3554 - val_acc: 0.8440\n",
      "Epoch 11/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3757 - acc: 0.8402 - val_loss: 0.3701 - val_acc: 0.8405\n",
      "Epoch 12/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3670 - acc: 0.8399 - val_loss: 0.3345 - val_acc: 0.8570\n",
      "Epoch 13/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3635 - acc: 0.8443 - val_loss: 0.3821 - val_acc: 0.8390\n",
      "Epoch 14/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3595 - acc: 0.8432 - val_loss: 0.3428 - val_acc: 0.8642\n",
      "Epoch 15/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3592 - acc: 0.8464 - val_loss: 0.3558 - val_acc: 0.8475\n",
      "Epoch 16/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3653 - acc: 0.8441 - val_loss: 0.3444 - val_acc: 0.8555\n",
      "Epoch 17/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3490 - acc: 0.8513 - val_loss: 0.3795 - val_acc: 0.8420\n",
      "Epoch 18/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3490 - acc: 0.8527 - val_loss: 0.3446 - val_acc: 0.8515\n",
      "Epoch 19/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3465 - acc: 0.8536 - val_loss: 0.3448 - val_acc: 0.8565\n",
      "Epoch 20/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3518 - acc: 0.8474 - val_loss: 0.3515 - val_acc: 0.8540\n",
      "Epoch 21/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3507 - acc: 0.8529 - val_loss: 0.3481 - val_acc: 0.8625\n",
      "Epoch 22/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3459 - acc: 0.8505 - val_loss: 0.3497 - val_acc: 0.8405\n",
      "Epoch 23/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3431 - acc: 0.8537 - val_loss: 0.3529 - val_acc: 0.8515\n",
      "Epoch 24/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3456 - acc: 0.8495 - val_loss: 0.3347 - val_acc: 0.8600\n",
      "Epoch 25/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3424 - acc: 0.8565 - val_loss: 0.3566 - val_acc: 0.8510\n",
      "Epoch 26/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3404 - acc: 0.8560 - val_loss: 0.3504 - val_acc: 0.8495\n",
      "Epoch 27/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3504 - acc: 0.8500 - val_loss: 0.3403 - val_acc: 0.8630\n",
      "Epoch 28/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3366 - acc: 0.8563 - val_loss: 0.3320 - val_acc: 0.8678\n",
      "Epoch 29/80\n",
      "120/120 [==============================] - 10s 87ms/step - loss: 0.3374 - acc: 0.8559 - val_loss: 0.3345 - val_acc: 0.8635\n",
      "Epoch 30/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3409 - acc: 0.8530 - val_loss: 0.3973 - val_acc: 0.8420\n",
      "Epoch 31/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3364 - acc: 0.8555 - val_loss: 0.3269 - val_acc: 0.8645\n",
      "Epoch 32/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3339 - acc: 0.8599 - val_loss: 0.3217 - val_acc: 0.8620\n",
      "Epoch 33/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3324 - acc: 0.8605 - val_loss: 0.3270 - val_acc: 0.8690\n",
      "Epoch 34/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3288 - acc: 0.8596 - val_loss: 0.3398 - val_acc: 0.8600\n",
      "Epoch 35/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3384 - acc: 0.8570 - val_loss: 0.3376 - val_acc: 0.8595\n",
      "Epoch 36/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3310 - acc: 0.8590 - val_loss: 0.3134 - val_acc: 0.8680\n",
      "Epoch 37/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3321 - acc: 0.8615 - val_loss: 0.3682 - val_acc: 0.8475\n",
      "Epoch 38/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3258 - acc: 0.8609 - val_loss: 0.3249 - val_acc: 0.8625\n",
      "Epoch 39/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3299 - acc: 0.8591 - val_loss: 0.3201 - val_acc: 0.8700\n",
      "Epoch 40/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3252 - acc: 0.8632 - val_loss: 0.3410 - val_acc: 0.8555\n",
      "Epoch 41/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3278 - acc: 0.8587 - val_loss: 0.3558 - val_acc: 0.8470\n",
      "Epoch 42/80\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.3249 - acc: 0.8642 - val_loss: 0.3151 - val_acc: 0.8689\n",
      "Epoch 43/80\n",
      "120/120 [==============================] - 10s 86ms/step - loss: 0.3338 - acc: 0.8581 - val_loss: 0.3408 - val_acc: 0.8615\n",
      "Epoch 44/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3293 - acc: 0.8591 - val_loss: 0.3229 - val_acc: 0.8725\n",
      "Epoch 45/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3270 - acc: 0.8638 - val_loss: 0.3305 - val_acc: 0.8625\n",
      "Epoch 46/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3304 - acc: 0.8600 - val_loss: 0.3321 - val_acc: 0.8675\n",
      "Epoch 47/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3181 - acc: 0.8682 - val_loss: 0.3183 - val_acc: 0.8605\n",
      "Epoch 48/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3221 - acc: 0.8622 - val_loss: 0.3523 - val_acc: 0.8580\n",
      "Epoch 49/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3219 - acc: 0.8647 - val_loss: 0.3239 - val_acc: 0.8640\n",
      "Epoch 50/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3271 - acc: 0.8611 - val_loss: 0.3283 - val_acc: 0.8675\n",
      "Epoch 51/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3194 - acc: 0.8651 - val_loss: 0.3156 - val_acc: 0.8715\n",
      "Epoch 52/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3288 - acc: 0.8644 - val_loss: 0.3383 - val_acc: 0.8570\n",
      "Epoch 53/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3224 - acc: 0.8629 - val_loss: 0.3402 - val_acc: 0.8545\n",
      "Epoch 54/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3222 - acc: 0.8623 - val_loss: 0.3220 - val_acc: 0.8700\n",
      "Epoch 55/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3207 - acc: 0.8672 - val_loss: 0.3361 - val_acc: 0.8570\n",
      "Epoch 56/80\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.3245 - acc: 0.8619 - val_loss: 0.3342 - val_acc: 0.8596\n",
      "Epoch 57/80\n",
      "120/120 [==============================] - 10s 87ms/step - loss: 0.3194 - acc: 0.8626 - val_loss: 0.3231 - val_acc: 0.8645\n",
      "Epoch 58/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3142 - acc: 0.8644 - val_loss: 0.3200 - val_acc: 0.8720\n",
      "Epoch 59/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3161 - acc: 0.8680 - val_loss: 0.3319 - val_acc: 0.8635\n",
      "Epoch 60/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3138 - acc: 0.8685 - val_loss: 0.3188 - val_acc: 0.8655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3192 - acc: 0.8642 - val_loss: 0.3252 - val_acc: 0.8595\n",
      "Epoch 62/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3115 - acc: 0.8679 - val_loss: 0.3149 - val_acc: 0.8645\n",
      "Epoch 63/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3175 - acc: 0.8662 - val_loss: 0.3310 - val_acc: 0.8620\n",
      "Epoch 64/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3181 - acc: 0.8699 - val_loss: 0.3458 - val_acc: 0.8570\n",
      "Epoch 65/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3200 - acc: 0.8661 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "Epoch 66/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3147 - acc: 0.8687 - val_loss: 0.3099 - val_acc: 0.8770\n",
      "Epoch 67/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3227 - acc: 0.8629 - val_loss: 0.3108 - val_acc: 0.8760\n",
      "Epoch 68/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3138 - acc: 0.8669 - val_loss: 0.3383 - val_acc: 0.8555\n",
      "Epoch 69/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3129 - acc: 0.8691 - val_loss: 0.3252 - val_acc: 0.8710\n",
      "Epoch 70/80\n",
      "120/120 [==============================] - 11s 93ms/step - loss: 0.3086 - acc: 0.8685 - val_loss: 0.3144 - val_acc: 0.8637\n",
      "Epoch 71/80\n",
      "120/120 [==============================] - 10s 87ms/step - loss: 0.3022 - acc: 0.8728 - val_loss: 0.3132 - val_acc: 0.8650\n",
      "Epoch 72/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3152 - acc: 0.8648 - val_loss: 0.3128 - val_acc: 0.8825\n",
      "Epoch 73/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3095 - acc: 0.8688 - val_loss: 0.3470 - val_acc: 0.8550\n",
      "Epoch 74/80\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.3140 - acc: 0.8671 - val_loss: 0.3295 - val_acc: 0.8655\n",
      "Epoch 75/80\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 0.3129 - acc: 0.8680 - val_loss: 0.3100 - val_acc: 0.8725\n",
      "Epoch 76/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3131 - acc: 0.8667 - val_loss: 0.3203 - val_acc: 0.8645\n",
      "Epoch 77/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3084 - acc: 0.8699 - val_loss: 0.3099 - val_acc: 0.8705\n",
      "Epoch 78/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3054 - acc: 0.8702 - val_loss: 0.3357 - val_acc: 0.8655\n",
      "Epoch 79/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3072 - acc: 0.8709 - val_loss: 0.3198 - val_acc: 0.8630\n",
      "Epoch 80/80\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.3118 - acc: 0.8678 - val_loss: 0.3501 - val_acc: 0.8525\n",
      "\n",
      "Training process completed in: 0 h 14 m 20 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1273.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1275 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_457 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_457 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_458 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_458 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_459 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_459 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_460 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_460 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_115 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 90\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.5379 - acc: 0.7360 - val_loss: 0.4549 - val_acc: 0.8068\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.4440 - acc: 0.8123 - val_loss: 0.4298 - val_acc: 0.8147\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.4366 - acc: 0.8165 - val_loss: 0.4501 - val_acc: 0.8237\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.4210 - acc: 0.8227 - val_loss: 0.4456 - val_acc: 0.8095\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.4278 - acc: 0.8210 - val_loss: 0.4591 - val_acc: 0.8007\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3989 - acc: 0.8314 - val_loss: 0.4041 - val_acc: 0.8237\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.4025 - acc: 0.8307 - val_loss: 0.3916 - val_acc: 0.8324\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.4028 - acc: 0.8269 - val_loss: 0.3942 - val_acc: 0.8281\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.4048 - acc: 0.8268 - val_loss: 0.4057 - val_acc: 0.8242\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3990 - acc: 0.8249 - val_loss: 0.4080 - val_acc: 0.8342\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.4044 - acc: 0.8299 - val_loss: 0.4238 - val_acc: 0.8319\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3896 - acc: 0.8298 - val_loss: 0.3900 - val_acc: 0.8354\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3906 - acc: 0.8283 - val_loss: 0.4002 - val_acc: 0.8342\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3979 - acc: 0.8299 - val_loss: 0.3917 - val_acc: 0.8371\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3872 - acc: 0.8343 - val_loss: 0.3841 - val_acc: 0.8325\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3791 - acc: 0.8372 - val_loss: 0.4139 - val_acc: 0.8211\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3907 - acc: 0.8311 - val_loss: 0.3986 - val_acc: 0.8271\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3830 - acc: 0.8386 - val_loss: 0.3988 - val_acc: 0.8311\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3785 - acc: 0.8392 - val_loss: 0.3999 - val_acc: 0.8356\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3771 - acc: 0.8386 - val_loss: 0.3676 - val_acc: 0.8416\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3721 - acc: 0.8436 - val_loss: 0.3970 - val_acc: 0.8210\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3770 - acc: 0.8414 - val_loss: 0.3770 - val_acc: 0.8404\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3592 - acc: 0.8521 - val_loss: 0.3689 - val_acc: 0.8432\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3814 - acc: 0.8415 - val_loss: 0.3772 - val_acc: 0.8401\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3655 - acc: 0.8453 - val_loss: 0.3594 - val_acc: 0.8490\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3624 - acc: 0.8486 - val_loss: 0.3658 - val_acc: 0.8390\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3745 - acc: 0.8399 - val_loss: 0.3744 - val_acc: 0.8409\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3765 - acc: 0.8409 - val_loss: 0.3753 - val_acc: 0.8382\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3693 - acc: 0.8439 - val_loss: 0.3487 - val_acc: 0.8572\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3637 - acc: 0.8447 - val_loss: 0.3699 - val_acc: 0.8503\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3644 - acc: 0.8443 - val_loss: 0.3645 - val_acc: 0.8411\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3672 - acc: 0.8418 - val_loss: 0.3760 - val_acc: 0.8539\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3602 - acc: 0.8471 - val_loss: 0.3825 - val_acc: 0.8415\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3657 - acc: 0.8428 - val_loss: 0.3822 - val_acc: 0.8482\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3595 - acc: 0.8427 - val_loss: 0.3891 - val_acc: 0.8350\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3408 - acc: 0.8584 - val_loss: 0.3592 - val_acc: 0.8529\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3477 - acc: 0.8521 - val_loss: 0.3354 - val_acc: 0.8601\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3458 - acc: 0.8520 - val_loss: 0.3639 - val_acc: 0.8442\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3567 - acc: 0.8470 - val_loss: 0.3525 - val_acc: 0.8555\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3565 - acc: 0.8522 - val_loss: 0.3776 - val_acc: 0.8408\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3511 - acc: 0.8471 - val_loss: 0.3504 - val_acc: 0.8587\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3436 - acc: 0.8538 - val_loss: 0.3739 - val_acc: 0.8378\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3578 - acc: 0.8456 - val_loss: 0.3420 - val_acc: 0.8551\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3494 - acc: 0.8539 - val_loss: 0.3523 - val_acc: 0.8501\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3564 - acc: 0.8439 - val_loss: 0.3510 - val_acc: 0.8538\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3435 - acc: 0.8572 - val_loss: 0.3570 - val_acc: 0.8465\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3437 - acc: 0.8536 - val_loss: 0.3395 - val_acc: 0.8575\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3575 - acc: 0.8474 - val_loss: 0.3728 - val_acc: 0.8361\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3516 - acc: 0.8484 - val_loss: 0.3441 - val_acc: 0.8524\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3474 - acc: 0.8506 - val_loss: 0.3581 - val_acc: 0.8507\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3491 - acc: 0.8495 - val_loss: 0.3461 - val_acc: 0.8589\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3317 - acc: 0.8601 - val_loss: 0.3458 - val_acc: 0.8565\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3396 - acc: 0.8518 - val_loss: 0.3463 - val_acc: 0.8556\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3367 - acc: 0.8585 - val_loss: 0.3444 - val_acc: 0.8550\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3532 - acc: 0.8519 - val_loss: 0.3499 - val_acc: 0.8560\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3449 - acc: 0.8564 - val_loss: 0.3522 - val_acc: 0.8511\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3447 - acc: 0.8569 - val_loss: 0.3704 - val_acc: 0.8511\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3448 - acc: 0.8539 - val_loss: 0.3412 - val_acc: 0.8530\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3345 - acc: 0.8609 - val_loss: 0.3307 - val_acc: 0.8628\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3496 - acc: 0.8518 - val_loss: 0.3469 - val_acc: 0.8586\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3484 - acc: 0.8515 - val_loss: 0.3365 - val_acc: 0.8572\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3334 - acc: 0.8547 - val_loss: 0.3560 - val_acc: 0.8532\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3581 - acc: 0.8489 - val_loss: 0.3617 - val_acc: 0.8521\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3469 - acc: 0.8516 - val_loss: 0.3738 - val_acc: 0.8453\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3328 - acc: 0.8614 - val_loss: 0.3684 - val_acc: 0.8590\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3359 - acc: 0.8580 - val_loss: 0.3524 - val_acc: 0.8618\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3377 - acc: 0.8576 - val_loss: 0.3673 - val_acc: 0.8410\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3320 - acc: 0.8646 - val_loss: 0.3385 - val_acc: 0.8649\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3456 - acc: 0.8506 - val_loss: 0.3376 - val_acc: 0.8567\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3335 - acc: 0.8590 - val_loss: 0.3534 - val_acc: 0.8521\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3323 - acc: 0.8554 - val_loss: 0.3439 - val_acc: 0.8565\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3291 - acc: 0.8621 - val_loss: 0.3375 - val_acc: 0.8614\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3394 - acc: 0.8584 - val_loss: 0.3363 - val_acc: 0.8592\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3389 - acc: 0.8557 - val_loss: 0.3573 - val_acc: 0.8509\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3310 - acc: 0.8595 - val_loss: 0.3424 - val_acc: 0.8551\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3337 - acc: 0.8623 - val_loss: 0.3537 - val_acc: 0.8579\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3332 - acc: 0.8626 - val_loss: 0.3681 - val_acc: 0.8532\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3348 - acc: 0.8595 - val_loss: 0.3409 - val_acc: 0.8632\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3373 - acc: 0.8562 - val_loss: 0.3307 - val_acc: 0.8625\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3300 - acc: 0.8638 - val_loss: 0.3554 - val_acc: 0.8508\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3388 - acc: 0.8574 - val_loss: 0.3658 - val_acc: 0.8578\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3354 - acc: 0.8561 - val_loss: 0.3543 - val_acc: 0.8482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.3280 - acc: 0.8609 - val_loss: 0.3363 - val_acc: 0.8612\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.3343 - acc: 0.8570 - val_loss: 0.3472 - val_acc: 0.8611\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3399 - acc: 0.8541 - val_loss: 0.3359 - val_acc: 0.8564\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3265 - acc: 0.8621 - val_loss: 0.3224 - val_acc: 0.8644\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3337 - acc: 0.8580 - val_loss: 0.3636 - val_acc: 0.8543\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3268 - acc: 0.8656 - val_loss: 0.3536 - val_acc: 0.8590\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3352 - acc: 0.8565 - val_loss: 0.3375 - val_acc: 0.8582\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3285 - acc: 0.8597 - val_loss: 0.3636 - val_acc: 0.8481\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3365 - acc: 0.8576 - val_loss: 0.3506 - val_acc: 0.8579\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3329 - acc: 0.8580 - val_loss: 0.3435 - val_acc: 0.8657\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.3350 - acc: 0.8590 - val_loss: 0.3448 - val_acc: 0.8635\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3334 - acc: 0.8610 - val_loss: 0.3417 - val_acc: 0.8661\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.3253 - acc: 0.8632 - val_loss: 0.3608 - val_acc: 0.8486\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3302 - acc: 0.8613 - val_loss: 0.3521 - val_acc: 0.8585\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3299 - acc: 0.8587 - val_loss: 0.3316 - val_acc: 0.8615\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3319 - acc: 0.8583 - val_loss: 0.3346 - val_acc: 0.8647\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3316 - acc: 0.8601 - val_loss: 0.3558 - val_acc: 0.8615\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3296 - acc: 0.8632 - val_loss: 0.3374 - val_acc: 0.8679\n",
      "\n",
      "Training process completed in: 0 h 12 m 37 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1274.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1276 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_461 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_461 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_462 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_462 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_463 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_463 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_464 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_464 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_116 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 20\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.5408 - acc: 0.7370 - val_loss: 0.5104 - val_acc: 0.7662\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.4471 - acc: 0.8109 - val_loss: 0.4173 - val_acc: 0.8312\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.4281 - acc: 0.8209 - val_loss: 0.4202 - val_acc: 0.8338\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.4252 - acc: 0.8195 - val_loss: 0.4419 - val_acc: 0.8438\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.4157 - acc: 0.8227 - val_loss: 0.4423 - val_acc: 0.8112\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.4130 - acc: 0.8208 - val_loss: 0.4081 - val_acc: 0.8338\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3947 - acc: 0.8322 - val_loss: 0.4007 - val_acc: 0.8325\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3994 - acc: 0.8268 - val_loss: 0.3784 - val_acc: 0.8388\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.3954 - acc: 0.8258 - val_loss: 0.3908 - val_acc: 0.8562\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.4042 - acc: 0.8267 - val_loss: 0.4150 - val_acc: 0.8125\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3906 - acc: 0.8325 - val_loss: 0.3863 - val_acc: 0.8412\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3803 - acc: 0.8370 - val_loss: 0.3863 - val_acc: 0.8275\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3878 - acc: 0.8374 - val_loss: 0.3992 - val_acc: 0.8238\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3672 - acc: 0.8419 - val_loss: 0.4479 - val_acc: 0.7988\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3803 - acc: 0.8397 - val_loss: 0.4275 - val_acc: 0.8075\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3790 - acc: 0.8370 - val_loss: 0.3627 - val_acc: 0.8500\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3791 - acc: 0.8335 - val_loss: 0.3687 - val_acc: 0.8475\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3756 - acc: 0.8345 - val_loss: 0.3960 - val_acc: 0.8262\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3848 - acc: 0.8340 - val_loss: 0.3784 - val_acc: 0.8312\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3723 - acc: 0.8381 - val_loss: 0.3568 - val_acc: 0.8450\n",
      "\n",
      "Training process completed in: 0 h 1 m 41 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1275.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1277 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_465 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_465 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_466 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_466 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_467 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_467 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_468 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_468 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_117 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 24s 126ms/step - loss: 0.4815 - acc: 0.7797 - val_loss: 0.4551 - val_acc: 0.7975\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.4155 - acc: 0.8214 - val_loss: 0.3914 - val_acc: 0.8335\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3986 - acc: 0.8309 - val_loss: 0.3712 - val_acc: 0.8385\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3926 - acc: 0.8319 - val_loss: 0.4422 - val_acc: 0.8220\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3860 - acc: 0.8328 - val_loss: 0.3760 - val_acc: 0.8405\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3763 - acc: 0.8403 - val_loss: 0.3657 - val_acc: 0.8485\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3722 - acc: 0.8408 - val_loss: 0.3714 - val_acc: 0.8395\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3750 - acc: 0.8392 - val_loss: 0.4025 - val_acc: 0.8425\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3724 - acc: 0.8392 - val_loss: 0.3650 - val_acc: 0.8505\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3607 - acc: 0.8486 - val_loss: 0.4415 - val_acc: 0.8245\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3654 - acc: 0.8426 - val_loss: 0.4076 - val_acc: 0.8315\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3573 - acc: 0.8482 - val_loss: 0.3622 - val_acc: 0.8570\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3529 - acc: 0.8502 - val_loss: 0.3610 - val_acc: 0.8520\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3540 - acc: 0.8502 - val_loss: 0.3746 - val_acc: 0.8412\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3498 - acc: 0.8511 - val_loss: 0.3813 - val_acc: 0.8555\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3404 - acc: 0.8563 - val_loss: 0.3451 - val_acc: 0.8600\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3461 - acc: 0.8504 - val_loss: 0.3497 - val_acc: 0.8565\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3421 - acc: 0.8548 - val_loss: 0.3672 - val_acc: 0.8495\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3399 - acc: 0.8567 - val_loss: 0.3464 - val_acc: 0.8470\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3369 - acc: 0.8559 - val_loss: 0.3545 - val_acc: 0.8495\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3337 - acc: 0.8589 - val_loss: 0.3237 - val_acc: 0.8675\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3303 - acc: 0.8602 - val_loss: 0.3474 - val_acc: 0.8450\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3322 - acc: 0.8591 - val_loss: 0.3266 - val_acc: 0.8710\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3275 - acc: 0.8613 - val_loss: 0.3602 - val_acc: 0.8595\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3250 - acc: 0.8634 - val_loss: 0.3297 - val_acc: 0.8635\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3259 - acc: 0.8623 - val_loss: 0.3494 - val_acc: 0.8575\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3283 - acc: 0.8621 - val_loss: 0.3500 - val_acc: 0.8720\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3315 - acc: 0.8601 - val_loss: 0.3481 - val_acc: 0.8581\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3233 - acc: 0.8646 - val_loss: 0.3539 - val_acc: 0.8640\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3269 - acc: 0.8613 - val_loss: 0.3660 - val_acc: 0.8530\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3208 - acc: 0.8636 - val_loss: 0.3362 - val_acc: 0.8685\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3241 - acc: 0.8621 - val_loss: 0.3362 - val_acc: 0.8640\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3192 - acc: 0.8646 - val_loss: 0.3136 - val_acc: 0.8765\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3159 - acc: 0.8664 - val_loss: 0.3268 - val_acc: 0.8645\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3170 - acc: 0.8666 - val_loss: 0.3155 - val_acc: 0.8720\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3137 - acc: 0.8686 - val_loss: 0.3297 - val_acc: 0.8680\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3172 - acc: 0.8653 - val_loss: 0.3791 - val_acc: 0.8495\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3159 - acc: 0.8676 - val_loss: 0.3578 - val_acc: 0.8465\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3172 - acc: 0.8661 - val_loss: 0.3506 - val_acc: 0.8620\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3111 - acc: 0.8692 - val_loss: 0.3179 - val_acc: 0.8750\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3128 - acc: 0.8681 - val_loss: 0.3103 - val_acc: 0.8760\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.3067 - acc: 0.8738 - val_loss: 0.3161 - val_acc: 0.8730\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3101 - acc: 0.8699 - val_loss: 0.3266 - val_acc: 0.8615\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3039 - acc: 0.8711 - val_loss: 0.3341 - val_acc: 0.8570\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3144 - acc: 0.8673 - val_loss: 0.3070 - val_acc: 0.8800\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3089 - acc: 0.8700 - val_loss: 0.3324 - val_acc: 0.8700\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3102 - acc: 0.8710 - val_loss: 0.3446 - val_acc: 0.8545\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3051 - acc: 0.8717 - val_loss: 0.3246 - val_acc: 0.8595\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3033 - acc: 0.8736 - val_loss: 0.3300 - val_acc: 0.8805\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3073 - acc: 0.8703 - val_loss: 0.2984 - val_acc: 0.8860\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3066 - acc: 0.8724 - val_loss: 0.3205 - val_acc: 0.8690\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3028 - acc: 0.8743 - val_loss: 0.3257 - val_acc: 0.8770\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3080 - acc: 0.8701 - val_loss: 0.3428 - val_acc: 0.8670\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3035 - acc: 0.8745 - val_loss: 0.3002 - val_acc: 0.8790\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3034 - acc: 0.8723 - val_loss: 0.3164 - val_acc: 0.8670\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3052 - acc: 0.8691 - val_loss: 0.3204 - val_acc: 0.8781\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2996 - acc: 0.8741 - val_loss: 0.3230 - val_acc: 0.8750\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2979 - acc: 0.8762 - val_loss: 0.3014 - val_acc: 0.8810\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.3002 - acc: 0.8764 - val_loss: 0.3301 - val_acc: 0.8655\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3025 - acc: 0.8720 - val_loss: 0.3228 - val_acc: 0.8640\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3048 - acc: 0.8722 - val_loss: 0.3061 - val_acc: 0.8820\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3040 - acc: 0.8713 - val_loss: 0.3059 - val_acc: 0.8795\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2988 - acc: 0.8751 - val_loss: 0.3219 - val_acc: 0.8650\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2989 - acc: 0.8751 - val_loss: 0.3290 - val_acc: 0.8625\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2911 - acc: 0.8779 - val_loss: 0.3148 - val_acc: 0.8665\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2939 - acc: 0.8769 - val_loss: 0.3519 - val_acc: 0.8475\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2984 - acc: 0.8759 - val_loss: 0.3026 - val_acc: 0.8695\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2975 - acc: 0.8746 - val_loss: 0.3428 - val_acc: 0.8635\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2939 - acc: 0.8771 - val_loss: 0.3064 - val_acc: 0.8695\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 17s 90ms/step - loss: 0.2980 - acc: 0.8749 - val_loss: 0.3208 - val_acc: 0.8735\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2964 - acc: 0.8750 - val_loss: 0.3089 - val_acc: 0.8645\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2943 - acc: 0.8753 - val_loss: 0.3057 - val_acc: 0.8705\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2884 - acc: 0.8800 - val_loss: 0.3019 - val_acc: 0.8780\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2970 - acc: 0.8750 - val_loss: 0.3065 - val_acc: 0.8760\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2931 - acc: 0.8791 - val_loss: 0.3145 - val_acc: 0.8755\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2889 - acc: 0.8789 - val_loss: 0.3132 - val_acc: 0.8770\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2810 - acc: 0.8818 - val_loss: 0.3075 - val_acc: 0.8760\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2854 - acc: 0.8808 - val_loss: 0.3245 - val_acc: 0.8655\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.2936 - acc: 0.8784 - val_loss: 0.3148 - val_acc: 0.8755\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3006 - acc: 0.8736 - val_loss: 0.3058 - val_acc: 0.8745\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.2962 - acc: 0.8769 - val_loss: 0.3269 - val_acc: 0.8700\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2854 - acc: 0.8796 - val_loss: 0.2990 - val_acc: 0.8700\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2924 - acc: 0.8767 - val_loss: 0.3239 - val_acc: 0.8660\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2834 - acc: 0.8809 - val_loss: 0.3079 - val_acc: 0.8704\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2866 - acc: 0.8810 - val_loss: 0.3044 - val_acc: 0.8695\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2887 - acc: 0.8792 - val_loss: 0.2941 - val_acc: 0.8910\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2910 - acc: 0.8782 - val_loss: 0.3213 - val_acc: 0.8630\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.2901 - acc: 0.8792 - val_loss: 0.2914 - val_acc: 0.8805\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3401 - val_acc: 0.8635\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.2882 - acc: 0.8779 - val_loss: 0.3446 - val_acc: 0.8720\n",
      "\n",
      "Training process completed in: 0 h 25 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1276.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1278 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_469 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_469 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_470 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_470 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_471 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_471 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_472 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_472 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_118 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "130/130 [==============================] - 17s 133ms/step - loss: 0.5067 - acc: 0.7611 - val_loss: 0.4553 - val_acc: 0.7963\n",
      "Epoch 2/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4422 - acc: 0.8065 - val_loss: 0.4450 - val_acc: 0.8078\n",
      "Epoch 3/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4251 - acc: 0.8191 - val_loss: 0.4245 - val_acc: 0.8356\n",
      "Epoch 4/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4056 - acc: 0.8280 - val_loss: 0.4056 - val_acc: 0.8312\n",
      "Epoch 5/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3995 - acc: 0.8317 - val_loss: 0.4005 - val_acc: 0.8316\n",
      "Epoch 6/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3961 - acc: 0.8295 - val_loss: 0.3866 - val_acc: 0.8309\n",
      "Epoch 7/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3982 - acc: 0.8301 - val_loss: 0.4654 - val_acc: 0.8175\n",
      "Epoch 8/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3901 - acc: 0.8339 - val_loss: 0.4008 - val_acc: 0.8387\n",
      "Epoch 9/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3965 - acc: 0.8274 - val_loss: 0.3998 - val_acc: 0.8438\n",
      "Epoch 10/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3803 - acc: 0.8374 - val_loss: 0.3789 - val_acc: 0.8347\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3735 - acc: 0.8397 - val_loss: 0.3603 - val_acc: 0.8450\n",
      "Epoch 12/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3747 - acc: 0.8362 - val_loss: 0.4004 - val_acc: 0.8394\n",
      "Epoch 13/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3664 - acc: 0.8419 - val_loss: 0.3832 - val_acc: 0.8500\n",
      "Epoch 14/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3623 - acc: 0.8450 - val_loss: 0.3507 - val_acc: 0.8497\n",
      "Epoch 15/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3620 - acc: 0.8464 - val_loss: 0.3773 - val_acc: 0.8322\n",
      "Epoch 16/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3664 - acc: 0.8444 - val_loss: 0.3897 - val_acc: 0.8450\n",
      "Epoch 17/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3667 - acc: 0.8415 - val_loss: 0.3758 - val_acc: 0.8372\n",
      "Epoch 18/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3638 - acc: 0.8439 - val_loss: 0.3617 - val_acc: 0.8570\n",
      "Epoch 19/80\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3637 - acc: 0.8460 - val_loss: 0.3768 - val_acc: 0.8459\n",
      "Epoch 20/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3543 - acc: 0.8476 - val_loss: 0.3636 - val_acc: 0.8587\n",
      "Epoch 21/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3526 - acc: 0.8493 - val_loss: 0.3916 - val_acc: 0.8459\n",
      "Epoch 22/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3451 - acc: 0.8562 - val_loss: 0.3483 - val_acc: 0.8506\n",
      "Epoch 23/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3476 - acc: 0.8533 - val_loss: 0.4123 - val_acc: 0.8284\n",
      "Epoch 24/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3435 - acc: 0.8503 - val_loss: 0.3651 - val_acc: 0.8500\n",
      "Epoch 25/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3432 - acc: 0.8555 - val_loss: 0.3472 - val_acc: 0.8441\n",
      "Epoch 26/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3479 - acc: 0.8511 - val_loss: 0.3772 - val_acc: 0.8344\n",
      "Epoch 27/80\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3470 - acc: 0.8524 - val_loss: 0.3518 - val_acc: 0.8586\n",
      "Epoch 28/80\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3459 - acc: 0.8539 - val_loss: 0.3612 - val_acc: 0.8525\n",
      "Epoch 29/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3403 - acc: 0.8552 - val_loss: 0.3465 - val_acc: 0.8506\n",
      "Epoch 30/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3456 - acc: 0.8484 - val_loss: 0.3596 - val_acc: 0.8506\n",
      "Epoch 31/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3397 - acc: 0.8555 - val_loss: 0.3623 - val_acc: 0.8466\n",
      "Epoch 32/80\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.3400 - acc: 0.8571 - val_loss: 0.3557 - val_acc: 0.8584\n",
      "Epoch 33/80\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 0.3282 - acc: 0.8616 - val_loss: 0.3594 - val_acc: 0.8538\n",
      "Epoch 34/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3402 - acc: 0.8553 - val_loss: 0.3761 - val_acc: 0.8378\n",
      "Epoch 35/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3325 - acc: 0.8610 - val_loss: 0.3377 - val_acc: 0.8573\n",
      "Epoch 36/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3342 - acc: 0.8553 - val_loss: 0.3289 - val_acc: 0.8672\n",
      "Epoch 37/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3360 - acc: 0.8573 - val_loss: 0.3381 - val_acc: 0.8534\n",
      "Epoch 38/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3497 - acc: 0.8513 - val_loss: 0.3441 - val_acc: 0.8647\n",
      "Epoch 39/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3312 - acc: 0.8589 - val_loss: 0.3438 - val_acc: 0.8562\n",
      "Epoch 40/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3308 - acc: 0.8579 - val_loss: 0.3393 - val_acc: 0.8700\n",
      "Epoch 41/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3359 - acc: 0.8565 - val_loss: 0.3497 - val_acc: 0.8425\n",
      "Epoch 42/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3306 - acc: 0.8601 - val_loss: 0.3377 - val_acc: 0.8578\n",
      "Epoch 43/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3302 - acc: 0.8580 - val_loss: 0.4173 - val_acc: 0.8109\n",
      "Epoch 44/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3344 - acc: 0.8563 - val_loss: 0.3461 - val_acc: 0.8493\n",
      "Epoch 45/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3242 - acc: 0.8626 - val_loss: 0.3304 - val_acc: 0.8631\n",
      "Epoch 46/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3276 - acc: 0.8580 - val_loss: 0.3471 - val_acc: 0.8600\n",
      "Epoch 47/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3264 - acc: 0.8621 - val_loss: 0.3388 - val_acc: 0.8575\n",
      "Epoch 48/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3259 - acc: 0.8614 - val_loss: 0.3532 - val_acc: 0.8600\n",
      "Epoch 49/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3293 - acc: 0.8600 - val_loss: 0.3289 - val_acc: 0.8609\n",
      "Epoch 50/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3266 - acc: 0.8610 - val_loss: 0.3338 - val_acc: 0.8587\n",
      "Epoch 51/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3291 - acc: 0.8577 - val_loss: 0.3548 - val_acc: 0.8531\n",
      "Epoch 52/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3210 - acc: 0.8660 - val_loss: 0.3139 - val_acc: 0.8684\n",
      "Epoch 53/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3274 - acc: 0.8593 - val_loss: 0.3555 - val_acc: 0.8467\n",
      "Epoch 54/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3170 - acc: 0.8640 - val_loss: 0.3058 - val_acc: 0.8731\n",
      "Epoch 55/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3232 - acc: 0.8625 - val_loss: 0.3238 - val_acc: 0.8613\n",
      "Epoch 56/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3245 - acc: 0.8625 - val_loss: 0.3323 - val_acc: 0.8628\n",
      "Epoch 57/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3210 - acc: 0.8667 - val_loss: 0.3380 - val_acc: 0.8597\n",
      "Epoch 58/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3206 - acc: 0.8642 - val_loss: 0.3357 - val_acc: 0.8547\n",
      "Epoch 59/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3206 - acc: 0.8646 - val_loss: 0.3432 - val_acc: 0.8563\n",
      "Epoch 60/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3263 - acc: 0.8602 - val_loss: 0.3545 - val_acc: 0.8600\n",
      "Epoch 61/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3126 - acc: 0.8672 - val_loss: 0.3331 - val_acc: 0.8689\n",
      "Epoch 62/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3197 - acc: 0.8609 - val_loss: 0.3259 - val_acc: 0.8625\n",
      "Epoch 63/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3148 - acc: 0.8646 - val_loss: 0.3333 - val_acc: 0.8528\n",
      "Epoch 64/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3313 - acc: 0.8581 - val_loss: 0.3363 - val_acc: 0.8697\n",
      "Epoch 65/80\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.3256 - acc: 0.8635 - val_loss: 0.3300 - val_acc: 0.8659\n",
      "Epoch 66/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3248 - acc: 0.8602 - val_loss: 0.3554 - val_acc: 0.8547\n",
      "Epoch 67/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3160 - acc: 0.8656 - val_loss: 0.3232 - val_acc: 0.8525\n",
      "Epoch 68/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3179 - acc: 0.8658 - val_loss: 0.3534 - val_acc: 0.8509\n",
      "Epoch 69/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3164 - acc: 0.8673 - val_loss: 0.3138 - val_acc: 0.8672\n",
      "Epoch 70/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3151 - acc: 0.8680 - val_loss: 0.3252 - val_acc: 0.8618\n",
      "Epoch 71/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3153 - acc: 0.8687 - val_loss: 0.3248 - val_acc: 0.8678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3155 - acc: 0.8664 - val_loss: 0.3281 - val_acc: 0.8675\n",
      "Epoch 73/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3075 - acc: 0.8717 - val_loss: 0.3460 - val_acc: 0.8578\n",
      "Epoch 74/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3162 - acc: 0.8663 - val_loss: 0.3287 - val_acc: 0.8600\n",
      "Epoch 75/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3210 - acc: 0.8639 - val_loss: 0.3239 - val_acc: 0.8622\n",
      "Epoch 76/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3135 - acc: 0.8659 - val_loss: 0.3187 - val_acc: 0.8656\n",
      "Epoch 77/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3147 - acc: 0.8672 - val_loss: 0.3261 - val_acc: 0.8634\n",
      "Epoch 78/80\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.3143 - acc: 0.8654 - val_loss: 0.3305 - val_acc: 0.8647\n",
      "Epoch 79/80\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.3110 - acc: 0.8682 - val_loss: 0.3356 - val_acc: 0.8634\n",
      "Epoch 80/80\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.3145 - acc: 0.8649 - val_loss: 0.3163 - val_acc: 0.8709\n",
      "\n",
      "Training process completed in: 0 h 13 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1277.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1279 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_473 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_473 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_474 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_474 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_475 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_475 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_476 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_476 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_119 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "130/130 [==============================] - 19s 145ms/step - loss: 0.4881 - acc: 0.7747 - val_loss: 0.4468 - val_acc: 0.8005\n",
      "Epoch 2/90\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.4244 - acc: 0.8200 - val_loss: 0.4019 - val_acc: 0.8255\n",
      "Epoch 3/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.4059 - acc: 0.8250 - val_loss: 0.4372 - val_acc: 0.8150\n",
      "Epoch 4/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.4015 - acc: 0.8292 - val_loss: 0.4081 - val_acc: 0.8285\n",
      "Epoch 5/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3842 - acc: 0.8360 - val_loss: 0.3832 - val_acc: 0.8340\n",
      "Epoch 6/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3850 - acc: 0.8355 - val_loss: 0.3710 - val_acc: 0.8525\n",
      "Epoch 7/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3909 - acc: 0.8327 - val_loss: 0.3949 - val_acc: 0.8350\n",
      "Epoch 8/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3828 - acc: 0.8353 - val_loss: 0.3958 - val_acc: 0.8245\n",
      "Epoch 9/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3785 - acc: 0.8383 - val_loss: 0.3788 - val_acc: 0.8485\n",
      "Epoch 10/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3671 - acc: 0.8433 - val_loss: 0.3751 - val_acc: 0.8440\n",
      "Epoch 11/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3739 - acc: 0.8393 - val_loss: 0.3560 - val_acc: 0.8500\n",
      "Epoch 12/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3680 - acc: 0.8421 - val_loss: 0.3634 - val_acc: 0.8430\n",
      "Epoch 13/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3665 - acc: 0.8434 - val_loss: 0.3760 - val_acc: 0.8380\n",
      "Epoch 14/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3629 - acc: 0.8449 - val_loss: 0.3739 - val_acc: 0.8407\n",
      "Epoch 15/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3621 - acc: 0.8445 - val_loss: 0.4187 - val_acc: 0.8170\n",
      "Epoch 16/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3582 - acc: 0.8463 - val_loss: 0.3671 - val_acc: 0.8460\n",
      "Epoch 17/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3523 - acc: 0.8520 - val_loss: 0.3805 - val_acc: 0.8485\n",
      "Epoch 18/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3492 - acc: 0.8523 - val_loss: 0.3356 - val_acc: 0.8550\n",
      "Epoch 19/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3432 - acc: 0.8538 - val_loss: 0.3458 - val_acc: 0.8465\n",
      "Epoch 20/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3584 - acc: 0.8470 - val_loss: 0.3292 - val_acc: 0.8755\n",
      "Epoch 21/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3459 - acc: 0.8522 - val_loss: 0.3775 - val_acc: 0.8375\n",
      "Epoch 22/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3381 - acc: 0.8575 - val_loss: 0.3372 - val_acc: 0.8520\n",
      "Epoch 23/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3430 - acc: 0.8534 - val_loss: 0.3348 - val_acc: 0.8600\n",
      "Epoch 24/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3415 - acc: 0.8545 - val_loss: 0.3493 - val_acc: 0.8445\n",
      "Epoch 25/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3459 - acc: 0.8529 - val_loss: 0.3543 - val_acc: 0.8590\n",
      "Epoch 26/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3458 - acc: 0.8499 - val_loss: 0.3402 - val_acc: 0.8590\n",
      "Epoch 27/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3356 - acc: 0.8573 - val_loss: 0.3820 - val_acc: 0.8360\n",
      "Epoch 28/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3395 - acc: 0.8538 - val_loss: 0.3278 - val_acc: 0.8535\n",
      "Epoch 29/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3325 - acc: 0.8572 - val_loss: 0.3351 - val_acc: 0.8615\n",
      "Epoch 30/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3288 - acc: 0.8599 - val_loss: 0.3397 - val_acc: 0.8585\n",
      "Epoch 31/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3344 - acc: 0.8570 - val_loss: 0.3481 - val_acc: 0.8460\n",
      "Epoch 32/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3331 - acc: 0.8568 - val_loss: 0.3306 - val_acc: 0.8660\n",
      "Epoch 33/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3392 - acc: 0.8540 - val_loss: 0.3337 - val_acc: 0.8630\n",
      "Epoch 34/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3324 - acc: 0.8566 - val_loss: 0.3427 - val_acc: 0.8505\n",
      "Epoch 35/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3193 - acc: 0.8665 - val_loss: 0.3222 - val_acc: 0.8650\n",
      "Epoch 36/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3211 - acc: 0.8650 - val_loss: 0.3427 - val_acc: 0.8585\n",
      "Epoch 37/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3297 - acc: 0.8608 - val_loss: 0.3271 - val_acc: 0.8640\n",
      "Epoch 38/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3297 - acc: 0.8613 - val_loss: 0.3214 - val_acc: 0.8630\n",
      "Epoch 39/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3258 - acc: 0.8632 - val_loss: 0.3474 - val_acc: 0.8575\n",
      "Epoch 40/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3302 - acc: 0.8579 - val_loss: 0.3174 - val_acc: 0.8675\n",
      "Epoch 41/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3234 - acc: 0.8617 - val_loss: 0.3490 - val_acc: 0.8540\n",
      "Epoch 42/90\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3260 - acc: 0.8614 - val_loss: 0.3197 - val_acc: 0.8776\n",
      "Epoch 43/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3226 - acc: 0.8623 - val_loss: 0.3289 - val_acc: 0.8700\n",
      "Epoch 44/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3167 - acc: 0.8656 - val_loss: 0.3259 - val_acc: 0.8655\n",
      "Epoch 45/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3206 - acc: 0.8639 - val_loss: 0.3378 - val_acc: 0.8555\n",
      "Epoch 46/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3274 - acc: 0.8634 - val_loss: 0.3206 - val_acc: 0.8675\n",
      "Epoch 47/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3123 - acc: 0.8662 - val_loss: 0.3331 - val_acc: 0.8580\n",
      "Epoch 48/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3247 - acc: 0.8633 - val_loss: 0.3313 - val_acc: 0.8610\n",
      "Epoch 49/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3198 - acc: 0.8659 - val_loss: 0.3181 - val_acc: 0.8695\n",
      "Epoch 50/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3190 - acc: 0.8654 - val_loss: 0.3277 - val_acc: 0.8620\n",
      "Epoch 51/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3194 - acc: 0.8647 - val_loss: 0.3381 - val_acc: 0.8585\n",
      "Epoch 52/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3146 - acc: 0.8669 - val_loss: 0.3145 - val_acc: 0.8770\n",
      "Epoch 53/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3188 - acc: 0.8654 - val_loss: 0.3054 - val_acc: 0.8750\n",
      "Epoch 54/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3126 - acc: 0.8672 - val_loss: 0.3202 - val_acc: 0.8600\n",
      "Epoch 55/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3124 - acc: 0.8659 - val_loss: 0.3308 - val_acc: 0.8590\n",
      "Epoch 56/90\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3117 - acc: 0.8680 - val_loss: 0.3162 - val_acc: 0.8709\n",
      "Epoch 57/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3082 - acc: 0.8687 - val_loss: 0.3555 - val_acc: 0.8515\n",
      "Epoch 58/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3211 - acc: 0.8642 - val_loss: 0.3385 - val_acc: 0.8560\n",
      "Epoch 59/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3180 - acc: 0.8665 - val_loss: 0.2971 - val_acc: 0.8755\n",
      "Epoch 60/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3125 - acc: 0.8690 - val_loss: 0.3179 - val_acc: 0.8605\n",
      "Epoch 61/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3110 - acc: 0.8667 - val_loss: 0.3207 - val_acc: 0.8605\n",
      "Epoch 62/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3038 - acc: 0.8728 - val_loss: 0.2938 - val_acc: 0.8785\n",
      "Epoch 63/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3167 - acc: 0.8648 - val_loss: 0.3079 - val_acc: 0.8745\n",
      "Epoch 64/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3079 - acc: 0.8725 - val_loss: 0.3049 - val_acc: 0.86651s - loss: 0.3108\n",
      "Epoch 65/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3106 - acc: 0.8675 - val_loss: 0.3029 - val_acc: 0.8725\n",
      "Epoch 66/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3115 - acc: 0.8673 - val_loss: 0.3310 - val_acc: 0.8585\n",
      "Epoch 67/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3091 - acc: 0.8702 - val_loss: 0.3288 - val_acc: 0.8675: 0.3088 - acc: 0.\n",
      "Epoch 68/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3126 - acc: 0.8686 - val_loss: 0.3135 - val_acc: 0.8760\n",
      "Epoch 69/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3053 - acc: 0.8710 - val_loss: 0.3303 - val_acc: 0.8680\n",
      "Epoch 70/90\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3033 - acc: 0.8729 - val_loss: 0.3342 - val_acc: 0.8694\n",
      "Epoch 71/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3043 - acc: 0.8710 - val_loss: 0.3328 - val_acc: 0.8580\n",
      "Epoch 72/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3023 - acc: 0.8734 - val_loss: 0.3112 - val_acc: 0.8755\n",
      "Epoch 73/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3070 - acc: 0.8715 - val_loss: 0.3221 - val_acc: 0.8645\n",
      "Epoch 74/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3148 - acc: 0.8683 - val_loss: 0.3017 - val_acc: 0.8780\n",
      "Epoch 75/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3025 - acc: 0.8692 - val_loss: 0.3091 - val_acc: 0.8675\n",
      "Epoch 76/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3023 - acc: 0.8720 - val_loss: 0.3222 - val_acc: 0.8545\n",
      "Epoch 77/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3070 - acc: 0.8706 - val_loss: 0.3114 - val_acc: 0.8710\n",
      "Epoch 78/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3096 - acc: 0.8697 - val_loss: 0.3331 - val_acc: 0.8610\n",
      "Epoch 79/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3050 - acc: 0.8702 - val_loss: 0.3081 - val_acc: 0.8675\n",
      "Epoch 80/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3075 - acc: 0.8708 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 81/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3012 - acc: 0.8720 - val_loss: 0.3271 - val_acc: 0.8620\n",
      "Epoch 82/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.2950 - acc: 0.8759 - val_loss: 0.2948 - val_acc: 0.8745\n",
      "Epoch 83/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3021 - acc: 0.8731 - val_loss: 0.3240 - val_acc: 0.8695\n",
      "Epoch 84/90\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3030 - acc: 0.8735 - val_loss: 0.2886 - val_acc: 0.8842\n",
      "Epoch 85/90\n",
      "130/130 [==============================] - 11s 88ms/step - loss: 0.3006 - acc: 0.8734 - val_loss: 0.3343 - val_acc: 0.8615\n",
      "Epoch 86/90\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.3052 - acc: 0.8720 - val_loss: 0.3059 - val_acc: 0.8725\n",
      "Epoch 87/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.2950 - acc: 0.8762 - val_loss: 0.3115 - val_acc: 0.8675\n",
      "Epoch 88/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.2987 - acc: 0.8757 - val_loss: 0.3368 - val_acc: 0.8575\n",
      "Epoch 89/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.2978 - acc: 0.8754 - val_loss: 0.3210 - val_acc: 0.8635\n",
      "Epoch 90/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3029 - acc: 0.8732 - val_loss: 0.2962 - val_acc: 0.8820\n",
      "\n",
      "Training process completed in: 0 h 17 m 44 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1278.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1280 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_477 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_477 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_478 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_478 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_479 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_479 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_480 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_480 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_120 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 40\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "130/130 [==============================] - 19s 145ms/step - loss: 0.5020 - acc: 0.7662 - val_loss: 0.4909 - val_acc: 0.7869\n",
      "Epoch 2/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.4263 - acc: 0.8170 - val_loss: 0.4621 - val_acc: 0.8198\n",
      "Epoch 3/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.4144 - acc: 0.8231 - val_loss: 0.3992 - val_acc: 0.8284\n",
      "Epoch 4/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.4081 - acc: 0.8260 - val_loss: 0.4234 - val_acc: 0.8298\n",
      "Epoch 5/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3957 - acc: 0.8300 - val_loss: 0.3956 - val_acc: 0.8218\n",
      "Epoch 6/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3962 - acc: 0.8296 - val_loss: 0.4199 - val_acc: 0.8359\n",
      "Epoch 7/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3964 - acc: 0.8291 - val_loss: 0.3968 - val_acc: 0.8352\n",
      "Epoch 8/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3853 - acc: 0.8362 - val_loss: 0.3989 - val_acc: 0.8256\n",
      "Epoch 9/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3834 - acc: 0.8302 - val_loss: 0.4116 - val_acc: 0.8365\n",
      "Epoch 10/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3787 - acc: 0.8408 - val_loss: 0.4174 - val_acc: 0.8416\n",
      "Epoch 11/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3753 - acc: 0.8377 - val_loss: 0.3917 - val_acc: 0.8450\n",
      "Epoch 12/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3687 - acc: 0.8429 - val_loss: 0.3863 - val_acc: 0.8361\n",
      "Epoch 13/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3616 - acc: 0.8444 - val_loss: 0.3706 - val_acc: 0.8445\n",
      "Epoch 14/90\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.3856 - acc: 0.8340 - val_loss: 0.3704 - val_acc: 0.8395\n",
      "Epoch 15/90\n",
      "130/130 [==============================] - 11s 88ms/step - loss: 0.3668 - acc: 0.8435 - val_loss: 0.3811 - val_acc: 0.8431\n",
      "Epoch 16/90\n",
      "130/130 [==============================] - 11s 88ms/step - loss: 0.3635 - acc: 0.8448 - val_loss: 0.4137 - val_acc: 0.8327\n",
      "Epoch 17/90\n",
      "130/130 [==============================] - 11s 88ms/step - loss: 0.3672 - acc: 0.8452 - val_loss: 0.4075 - val_acc: 0.8472\n",
      "Epoch 18/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3639 - acc: 0.8451 - val_loss: 0.3627 - val_acc: 0.8400\n",
      "Epoch 19/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3580 - acc: 0.8468 - val_loss: 0.3587 - val_acc: 0.8522\n",
      "Epoch 20/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3583 - acc: 0.8469 - val_loss: 0.3901 - val_acc: 0.8198\n",
      "Epoch 21/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3626 - acc: 0.8452 - val_loss: 0.3920 - val_acc: 0.8395\n",
      "Epoch 22/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3569 - acc: 0.8470 - val_loss: 0.3759 - val_acc: 0.8501\n",
      "Epoch 23/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3565 - acc: 0.8466 - val_loss: 0.3922 - val_acc: 0.8491\n",
      "Epoch 24/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3481 - acc: 0.8517 - val_loss: 0.3652 - val_acc: 0.8537\n",
      "Epoch 25/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3500 - acc: 0.8512 - val_loss: 0.3575 - val_acc: 0.8569\n",
      "Epoch 26/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3428 - acc: 0.8531 - val_loss: 0.3616 - val_acc: 0.8495\n",
      "Epoch 27/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3411 - acc: 0.8542 - val_loss: 0.3479 - val_acc: 0.8607\n",
      "Epoch 28/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3434 - acc: 0.8521 - val_loss: 0.3470 - val_acc: 0.8578\n",
      "Epoch 29/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3463 - acc: 0.8515 - val_loss: 0.3674 - val_acc: 0.8491\n",
      "Epoch 30/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3360 - acc: 0.8600 - val_loss: 0.3476 - val_acc: 0.8553\n",
      "Epoch 31/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3343 - acc: 0.8544 - val_loss: 0.3318 - val_acc: 0.8536\n",
      "Epoch 32/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3355 - acc: 0.8586 - val_loss: 0.3476 - val_acc: 0.8589\n",
      "Epoch 33/90\n",
      "130/130 [==============================] - 12s 89ms/step - loss: 0.3309 - acc: 0.8579 - val_loss: 0.3474 - val_acc: 0.8558\n",
      "Epoch 34/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3363 - acc: 0.8584 - val_loss: 0.3984 - val_acc: 0.8245\n",
      "Epoch 35/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3376 - acc: 0.8586 - val_loss: 0.3407 - val_acc: 0.8603\n",
      "Epoch 36/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3349 - acc: 0.8583 - val_loss: 0.3400 - val_acc: 0.8567\n",
      "Epoch 37/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3349 - acc: 0.8587 - val_loss: 0.3652 - val_acc: 0.8477\n",
      "Epoch 38/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3336 - acc: 0.8568 - val_loss: 0.3461 - val_acc: 0.8581\n",
      "Epoch 39/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3382 - acc: 0.8554 - val_loss: 0.3433 - val_acc: 0.8534\n",
      "Epoch 40/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3319 - acc: 0.8591 - val_loss: 0.3521 - val_acc: 0.8527\n",
      "Epoch 41/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3376 - acc: 0.8563 - val_loss: 0.3893 - val_acc: 0.8369\n",
      "Epoch 42/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3343 - acc: 0.8582 - val_loss: 0.3416 - val_acc: 0.8627\n",
      "Epoch 43/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3270 - acc: 0.8594 - val_loss: 0.3435 - val_acc: 0.8516\n",
      "Epoch 44/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3281 - acc: 0.8626 - val_loss: 0.3214 - val_acc: 0.8683\n",
      "Epoch 45/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3301 - acc: 0.8603 - val_loss: 0.3390 - val_acc: 0.8652\n",
      "Epoch 46/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3252 - acc: 0.8623 - val_loss: 0.3401 - val_acc: 0.8558\n",
      "Epoch 47/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3285 - acc: 0.8604 - val_loss: 0.3262 - val_acc: 0.8688\n",
      "Epoch 48/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3207 - acc: 0.8638 - val_loss: 0.3389 - val_acc: 0.8612\n",
      "Epoch 49/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3214 - acc: 0.8658 - val_loss: 0.3458 - val_acc: 0.8555\n",
      "Epoch 50/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3287 - acc: 0.8610 - val_loss: 0.3169 - val_acc: 0.8695\n",
      "Epoch 51/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3299 - acc: 0.8591 - val_loss: 0.3165 - val_acc: 0.8669\n",
      "Epoch 52/90\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.3253 - acc: 0.8617 - val_loss: 0.3473 - val_acc: 0.8525\n",
      "Epoch 53/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3172 - acc: 0.8649 - val_loss: 0.3304 - val_acc: 0.8574\n",
      "Epoch 54/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3285 - acc: 0.8601 - val_loss: 0.3196 - val_acc: 0.8680\n",
      "Epoch 55/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3174 - acc: 0.8643 - val_loss: 0.3134 - val_acc: 0.8706\n",
      "Epoch 56/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3235 - acc: 0.8626 - val_loss: 0.3347 - val_acc: 0.8611\n",
      "Epoch 57/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3277 - acc: 0.8616 - val_loss: 0.3337 - val_acc: 0.8617\n",
      "Epoch 58/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3208 - acc: 0.8619 - val_loss: 0.3197 - val_acc: 0.8653\n",
      "Epoch 59/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3199 - acc: 0.8639 - val_loss: 0.3358 - val_acc: 0.8569\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3211 - acc: 0.8649 - val_loss: 0.3250 - val_acc: 0.8650\n",
      "Epoch 61/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3211 - acc: 0.8648 - val_loss: 0.3367 - val_acc: 0.8579\n",
      "Epoch 62/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3151 - acc: 0.8673 - val_loss: 0.3189 - val_acc: 0.8675\n",
      "Epoch 63/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3151 - acc: 0.8660 - val_loss: 0.3300 - val_acc: 0.8583\n",
      "Epoch 64/90\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.3169 - acc: 0.8649 - val_loss: 0.3215 - val_acc: 0.8623\n",
      "Epoch 65/90\n",
      "130/130 [==============================] - 11s 88ms/step - loss: 0.3139 - acc: 0.8638 - val_loss: 0.3328 - val_acc: 0.8608\n",
      "Epoch 66/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3101 - acc: 0.8670 - val_loss: 0.3194 - val_acc: 0.8676\n",
      "Epoch 67/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3247 - acc: 0.8625 - val_loss: 0.3247 - val_acc: 0.8642\n",
      "Epoch 68/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3192 - acc: 0.8665 - val_loss: 0.3310 - val_acc: 0.8520\n",
      "Epoch 69/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3138 - acc: 0.8673 - val_loss: 0.3297 - val_acc: 0.8614\n",
      "Epoch 70/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3134 - acc: 0.8681 - val_loss: 0.3173 - val_acc: 0.8671\n",
      "Epoch 71/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3161 - acc: 0.8659 - val_loss: 0.3571 - val_acc: 0.8473\n",
      "Epoch 72/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3108 - acc: 0.8700 - val_loss: 0.3205 - val_acc: 0.8631\n",
      "Epoch 73/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3145 - acc: 0.8667 - val_loss: 0.3383 - val_acc: 0.8625\n",
      "Epoch 74/90\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.3086 - acc: 0.8704 - val_loss: 0.3360 - val_acc: 0.8609\n",
      "Epoch 75/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3140 - acc: 0.8669 - val_loss: 0.3252 - val_acc: 0.8653\n",
      "Epoch 76/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3046 - acc: 0.8700 - val_loss: 0.3251 - val_acc: 0.8700\n",
      "Epoch 77/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3021 - acc: 0.8716 - val_loss: 0.3286 - val_acc: 0.8597\n",
      "Epoch 78/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3134 - acc: 0.8686 - val_loss: 0.3264 - val_acc: 0.8583\n",
      "Epoch 79/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3119 - acc: 0.8698 - val_loss: 0.3194 - val_acc: 0.8638\n",
      "Epoch 80/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3121 - acc: 0.8659 - val_loss: 0.3431 - val_acc: 0.8611\n",
      "Epoch 81/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3032 - acc: 0.8713 - val_loss: 0.3110 - val_acc: 0.8744\n",
      "Epoch 82/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3154 - acc: 0.8670 - val_loss: 0.3385 - val_acc: 0.8608\n",
      "Epoch 83/90\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.3125 - acc: 0.8677 - val_loss: 0.3257 - val_acc: 0.8593\n",
      "Epoch 84/90\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.3166 - acc: 0.8648 - val_loss: 0.3293 - val_acc: 0.8623\n",
      "Epoch 85/90\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.3077 - acc: 0.8719 - val_loss: 0.3232 - val_acc: 0.8636\n",
      "Epoch 86/90\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.3068 - acc: 0.8710 - val_loss: 0.3122 - val_acc: 0.8687\n",
      "Epoch 87/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3092 - acc: 0.8710 - val_loss: 0.3209 - val_acc: 0.8742\n",
      "Epoch 88/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3054 - acc: 0.8715 - val_loss: 0.3330 - val_acc: 0.8662\n",
      "Epoch 89/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3074 - acc: 0.8684 - val_loss: 0.3251 - val_acc: 0.8609\n",
      "Epoch 90/90\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.3079 - acc: 0.8700 - val_loss: 0.3021 - val_acc: 0.8755\n",
      "\n",
      "Training process completed in: 0 h 16 m 49 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1279.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1281 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_481 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_481 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_482 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_482 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_483 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_483 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_484 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_484 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_121 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.4607 - acc: 0.7922 - val_loss: 0.4176 - val_acc: 0.8144\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.4213 - acc: 0.8203 - val_loss: 0.4144 - val_acc: 0.8228\n",
      "Epoch 3/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.4037 - acc: 0.8267 - val_loss: 0.3988 - val_acc: 0.8200\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3905 - acc: 0.8320 - val_loss: 0.3885 - val_acc: 0.8350\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3844 - acc: 0.8340 - val_loss: 0.3748 - val_acc: 0.8364\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3735 - acc: 0.8421 - val_loss: 0.3726 - val_acc: 0.8412\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3706 - acc: 0.8419 - val_loss: 0.3624 - val_acc: 0.8444\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3629 - acc: 0.8460 - val_loss: 0.3646 - val_acc: 0.8488\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3591 - acc: 0.8465 - val_loss: 0.3534 - val_acc: 0.8480\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3541 - acc: 0.8499 - val_loss: 0.3477 - val_acc: 0.8516\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3605 - acc: 0.8460 - val_loss: 0.3583 - val_acc: 0.8441\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3460 - acc: 0.8542 - val_loss: 0.3490 - val_acc: 0.8569\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3537 - acc: 0.8493 - val_loss: 0.3590 - val_acc: 0.8466\n",
      "Epoch 14/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3466 - acc: 0.8516 - val_loss: 0.3516 - val_acc: 0.8486\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3450 - acc: 0.8538 - val_loss: 0.3568 - val_acc: 0.8585\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3377 - acc: 0.8557 - val_loss: 0.3472 - val_acc: 0.8613\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3410 - acc: 0.8569 - val_loss: 0.3442 - val_acc: 0.8589\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3337 - acc: 0.8579 - val_loss: 0.3517 - val_acc: 0.8565\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3303 - acc: 0.8604 - val_loss: 0.3478 - val_acc: 0.8564\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3323 - acc: 0.8582 - val_loss: 0.3447 - val_acc: 0.8613\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3291 - acc: 0.8596 - val_loss: 0.3337 - val_acc: 0.8586\n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3286 - acc: 0.8604 - val_loss: 0.3535 - val_acc: 0.8626\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3318 - acc: 0.8607 - val_loss: 0.3564 - val_acc: 0.8588\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3250 - acc: 0.8614 - val_loss: 0.3433 - val_acc: 0.8524\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3273 - acc: 0.8618 - val_loss: 0.3408 - val_acc: 0.8589\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3235 - acc: 0.8615 - val_loss: 0.3409 - val_acc: 0.8539\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3239 - acc: 0.8625 - val_loss: 0.3329 - val_acc: 0.8651\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3194 - acc: 0.8631 - val_loss: 0.3641 - val_acc: 0.8583\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3194 - acc: 0.8665 - val_loss: 0.3409 - val_acc: 0.8656\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3222 - acc: 0.8620 - val_loss: 0.3252 - val_acc: 0.8664\n",
      "Epoch 31/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3196 - acc: 0.8654 - val_loss: 0.3445 - val_acc: 0.8662\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3188 - acc: 0.8666 - val_loss: 0.3343 - val_acc: 0.8623\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3182 - acc: 0.8670 - val_loss: 0.3277 - val_acc: 0.8665\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3129 - acc: 0.8679 - val_loss: 0.3254 - val_acc: 0.8713\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3152 - acc: 0.8666 - val_loss: 0.3337 - val_acc: 0.8639\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3148 - acc: 0.8661 - val_loss: 0.3241 - val_acc: 0.8630\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3120 - acc: 0.8686 - val_loss: 0.3154 - val_acc: 0.8706\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3099 - acc: 0.8697 - val_loss: 0.3285 - val_acc: 0.8608\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3074 - acc: 0.8714 - val_loss: 0.3183 - val_acc: 0.8663\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3131 - acc: 0.8683 - val_loss: 0.3207 - val_acc: 0.8646\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3068 - acc: 0.8712 - val_loss: 0.3225 - val_acc: 0.8642\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3090 - acc: 0.8699 - val_loss: 0.3223 - val_acc: 0.8708\n",
      "Epoch 43/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3112 - acc: 0.8682 - val_loss: 0.3096 - val_acc: 0.8703\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3103 - acc: 0.8692 - val_loss: 0.3237 - val_acc: 0.8670\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3136 - acc: 0.8680 - val_loss: 0.3412 - val_acc: 0.8659\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3065 - acc: 0.8724 - val_loss: 0.3205 - val_acc: 0.8688\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3041 - acc: 0.8720 - val_loss: 0.3188 - val_acc: 0.8721\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3048 - acc: 0.8705 - val_loss: 0.3223 - val_acc: 0.8697\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3074 - acc: 0.8698 - val_loss: 0.3228 - val_acc: 0.8706\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3071 - acc: 0.8707 - val_loss: 0.3167 - val_acc: 0.8701\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3042 - acc: 0.8722 - val_loss: 0.3157 - val_acc: 0.8716\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3003 - acc: 0.8722 - val_loss: 0.3196 - val_acc: 0.8728\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.3051 - acc: 0.8735 - val_loss: 0.3176 - val_acc: 0.8689\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.3039 - acc: 0.8719 - val_loss: 0.3176 - val_acc: 0.8655\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3057 - acc: 0.8728 - val_loss: 0.3294 - val_acc: 0.8691\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3001 - acc: 0.8731 - val_loss: 0.3207 - val_acc: 0.8696\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3041 - acc: 0.8717 - val_loss: 0.3228 - val_acc: 0.8703\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.3016 - acc: 0.8737 - val_loss: 0.3179 - val_acc: 0.8737\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.2998 - acc: 0.8739 - val_loss: 0.3213 - val_acc: 0.8711\n",
      "Epoch 60/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.2994 - acc: 0.8739 - val_loss: 0.3094 - val_acc: 0.8734\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.2979 - acc: 0.8753 - val_loss: 0.3466 - val_acc: 0.8636\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.2974 - acc: 0.8751 - val_loss: 0.3263 - val_acc: 0.8662\n",
      "Epoch 63/70\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.2923 - acc: 0.8788 - val_loss: 0.3272 - val_acc: 0.8719\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.2979 - acc: 0.8745 - val_loss: 0.3120 - val_acc: 0.8753\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.2970 - acc: 0.8764 - val_loss: 0.3132 - val_acc: 0.8701\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.2945 - acc: 0.8755 - val_loss: 0.3343 - val_acc: 0.8589\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.2961 - acc: 0.8734 - val_loss: 0.3088 - val_acc: 0.8781\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.2921 - acc: 0.8774 - val_loss: 0.3083 - val_acc: 0.8731\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.2934 - acc: 0.8777 - val_loss: 0.3031 - val_acc: 0.8761\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.2974 - acc: 0.8750 - val_loss: 0.3221 - val_acc: 0.8692\n",
      "\n",
      "Training process completed in: 0 h 25 m 49 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: \" MODELS / model_breast_cancer_1280.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1282 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_485 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_485 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_486 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_486 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_487 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_487 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_488 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_488 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_122 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 0.4868 - acc: 0.7739 - val_loss: 0.4317 - val_acc: 0.8178\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.4217 - acc: 0.8167 - val_loss: 0.4198 - val_acc: 0.8203\n",
      "Epoch 3/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.4085 - acc: 0.8273 - val_loss: 0.4772 - val_acc: 0.8225\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3942 - acc: 0.8332 - val_loss: 0.4000 - val_acc: 0.8372\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3908 - acc: 0.8334 - val_loss: 0.4022 - val_acc: 0.8344\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3815 - acc: 0.8373 - val_loss: 0.3702 - val_acc: 0.8381\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3817 - acc: 0.8360 - val_loss: 0.4287 - val_acc: 0.8347\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3800 - acc: 0.8378 - val_loss: 0.3882 - val_acc: 0.8306\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3717 - acc: 0.8413 - val_loss: 0.3863 - val_acc: 0.8474\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3669 - acc: 0.8426 - val_loss: 0.3841 - val_acc: 0.8547\n",
      "Epoch 11/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3806 - acc: 0.8365 - val_loss: 0.3884 - val_acc: 0.8416\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3698 - acc: 0.8410 - val_loss: 0.3758 - val_acc: 0.8422\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3666 - acc: 0.8427 - val_loss: 0.4073 - val_acc: 0.8291\n",
      "Epoch 14/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3633 - acc: 0.8454 - val_loss: 0.3884 - val_acc: 0.8525\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3617 - acc: 0.8450 - val_loss: 0.3971 - val_acc: 0.8487\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3551 - acc: 0.8473 - val_loss: 0.3714 - val_acc: 0.8306\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3560 - acc: 0.8488 - val_loss: 0.3884 - val_acc: 0.8434\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3546 - acc: 0.8484 - val_loss: 0.3724 - val_acc: 0.8602\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3503 - acc: 0.8502 - val_loss: 0.3598 - val_acc: 0.8519\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3538 - acc: 0.8489 - val_loss: 0.3549 - val_acc: 0.8487\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3506 - acc: 0.8510 - val_loss: 0.3388 - val_acc: 0.8469\n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3413 - acc: 0.8555 - val_loss: 0.3622 - val_acc: 0.8438\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3481 - acc: 0.8496 - val_loss: 0.3800 - val_acc: 0.8569\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3405 - acc: 0.8560 - val_loss: 0.3300 - val_acc: 0.8678\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3440 - acc: 0.8540 - val_loss: 0.3519 - val_acc: 0.8466\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3429 - acc: 0.8541 - val_loss: 0.3467 - val_acc: 0.8550\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.3353 - acc: 0.8563 - val_loss: 0.3388 - val_acc: 0.8564\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3370 - acc: 0.8558 - val_loss: 0.3444 - val_acc: 0.8566\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3367 - acc: 0.8569 - val_loss: 0.3474 - val_acc: 0.8681\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3367 - acc: 0.8563 - val_loss: 0.3393 - val_acc: 0.8556\n",
      "Epoch 31/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3242 - acc: 0.8613 - val_loss: 0.3499 - val_acc: 0.8463\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3338 - acc: 0.8580 - val_loss: 0.3361 - val_acc: 0.8606\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3270 - acc: 0.8625 - val_loss: 0.3432 - val_acc: 0.8634\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3330 - acc: 0.8597 - val_loss: 0.3475 - val_acc: 0.8572\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3311 - acc: 0.8595 - val_loss: 0.3258 - val_acc: 0.8641\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3220 - acc: 0.8629 - val_loss: 0.3337 - val_acc: 0.8637\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3304 - acc: 0.8596 - val_loss: 0.3470 - val_acc: 0.8534\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3279 - acc: 0.8602 - val_loss: 0.3356 - val_acc: 0.8634\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3191 - acc: 0.8639 - val_loss: 0.3402 - val_acc: 0.8481\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3285 - acc: 0.8608 - val_loss: 0.3485 - val_acc: 0.8591\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3222 - acc: 0.8618 - val_loss: 0.3368 - val_acc: 0.8628\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3253 - acc: 0.8634 - val_loss: 0.3251 - val_acc: 0.8672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3238 - acc: 0.8627 - val_loss: 0.3390 - val_acc: 0.8631\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3154 - acc: 0.8692 - val_loss: 0.3299 - val_acc: 0.8673\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3192 - acc: 0.8662 - val_loss: 0.3115 - val_acc: 0.8744\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3168 - acc: 0.8647 - val_loss: 0.3418 - val_acc: 0.8556\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3125 - acc: 0.8696 - val_loss: 0.3296 - val_acc: 0.8631\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3198 - acc: 0.8642 - val_loss: 0.3407 - val_acc: 0.8562\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3189 - acc: 0.8635 - val_loss: 0.3220 - val_acc: 0.8675\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3174 - acc: 0.8641 - val_loss: 0.3191 - val_acc: 0.8678\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3171 - acc: 0.8647 - val_loss: 0.3290 - val_acc: 0.8597\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3137 - acc: 0.8671 - val_loss: 0.3325 - val_acc: 0.8684\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.3113 - acc: 0.8680 - val_loss: 0.3594 - val_acc: 0.8519\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3168 - acc: 0.8660 - val_loss: 0.3452 - val_acc: 0.8544\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3187 - acc: 0.8656 - val_loss: 0.3180 - val_acc: 0.8700\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3126 - acc: 0.8675 - val_loss: 0.3571 - val_acc: 0.8600\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3155 - acc: 0.8649 - val_loss: 0.3220 - val_acc: 0.8716\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3095 - acc: 0.8702 - val_loss: 0.3199 - val_acc: 0.8722\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3114 - acc: 0.8687 - val_loss: 0.3236 - val_acc: 0.8725\n",
      "Epoch 60/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3068 - acc: 0.8692 - val_loss: 0.3187 - val_acc: 0.8663\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3118 - acc: 0.8681 - val_loss: 0.3132 - val_acc: 0.8792\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3057 - acc: 0.8705 - val_loss: 0.3140 - val_acc: 0.8769\n",
      "Epoch 63/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3107 - acc: 0.8670 - val_loss: 0.3229 - val_acc: 0.8659\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3047 - acc: 0.8716 - val_loss: 0.3180 - val_acc: 0.8706\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.3074 - acc: 0.8706 - val_loss: 0.3219 - val_acc: 0.8609\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3087 - acc: 0.8718 - val_loss: 0.3118 - val_acc: 0.8716\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3105 - acc: 0.8682 - val_loss: 0.3209 - val_acc: 0.8625\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3062 - acc: 0.8712 - val_loss: 0.3348 - val_acc: 0.8653\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3101 - acc: 0.8682 - val_loss: 0.3222 - val_acc: 0.8691\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.2986 - acc: 0.8735 - val_loss: 0.3051 - val_acc: 0.8676\n",
      "\n",
      "Training process completed in: 0 h 17 m 21 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1281.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1283 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_489 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_489 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_490 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_490 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_491 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_491 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_492 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_492 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_123 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 70\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4585 - acc: 0.7942 - val_loss: 0.4140 - val_acc: 0.8238\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4162 - acc: 0.8226 - val_loss: 0.4241 - val_acc: 0.8227\n",
      "Epoch 3/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.4035 - acc: 0.8255 - val_loss: 0.4055 - val_acc: 0.8224\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.4026 - acc: 0.8273 - val_loss: 0.4141 - val_acc: 0.8238\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3858 - acc: 0.8331 - val_loss: 0.4040 - val_acc: 0.8341\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.3890 - acc: 0.8315 - val_loss: 0.3762 - val_acc: 0.8344\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3852 - acc: 0.8340 - val_loss: 0.3768 - val_acc: 0.8390\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3785 - acc: 0.8372 - val_loss: 0.3695 - val_acc: 0.8465\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3730 - acc: 0.8416 - val_loss: 0.4032 - val_acc: 0.8337\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3724 - acc: 0.8414 - val_loss: 0.3748 - val_acc: 0.8414\n",
      "Epoch 11/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3578 - acc: 0.8502 - val_loss: 0.3828 - val_acc: 0.8498\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3616 - acc: 0.8467 - val_loss: 0.3599 - val_acc: 0.8548\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3655 - acc: 0.8435 - val_loss: 0.3931 - val_acc: 0.8486\n",
      "Epoch 14/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3505 - acc: 0.8508 - val_loss: 0.3702 - val_acc: 0.8356\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3448 - acc: 0.8543 - val_loss: 0.3593 - val_acc: 0.8500\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3536 - acc: 0.8490 - val_loss: 0.3526 - val_acc: 0.8551\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3485 - acc: 0.8507 - val_loss: 0.3478 - val_acc: 0.8538\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3443 - acc: 0.8546 - val_loss: 0.3582 - val_acc: 0.8431\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3456 - acc: 0.8531 - val_loss: 0.3432 - val_acc: 0.8554\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3406 - acc: 0.8551 - val_loss: 0.3413 - val_acc: 0.8523\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3421 - acc: 0.8523 - val_loss: 0.3738 - val_acc: 0.8387\n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3382 - acc: 0.8569 - val_loss: 0.3283 - val_acc: 0.8611\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3340 - acc: 0.8573 - val_loss: 0.3729 - val_acc: 0.8548\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3330 - acc: 0.8594 - val_loss: 0.3378 - val_acc: 0.8589\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3258 - acc: 0.8620 - val_loss: 0.3401 - val_acc: 0.8495\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3320 - acc: 0.8593 - val_loss: 0.3286 - val_acc: 0.8659\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3371 - acc: 0.8577 - val_loss: 0.3372 - val_acc: 0.8613\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3315 - acc: 0.8592 - val_loss: 0.3260 - val_acc: 0.8636\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3292 - acc: 0.8596 - val_loss: 0.3551 - val_acc: 0.8486\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3254 - acc: 0.8635 - val_loss: 0.3280 - val_acc: 0.8620\n",
      "Epoch 31/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3228 - acc: 0.8641 - val_loss: 0.3209 - val_acc: 0.8678\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3238 - acc: 0.8613 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3241 - acc: 0.8620 - val_loss: 0.3296 - val_acc: 0.8658\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3218 - acc: 0.8630 - val_loss: 0.3241 - val_acc: 0.8639\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3198 - acc: 0.8665 - val_loss: 0.3186 - val_acc: 0.8668\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3181 - acc: 0.8664 - val_loss: 0.3225 - val_acc: 0.8673\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3196 - acc: 0.8658 - val_loss: 0.3342 - val_acc: 0.8582\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3137 - acc: 0.8661 - val_loss: 0.3228 - val_acc: 0.8690\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3208 - acc: 0.8638 - val_loss: 0.3181 - val_acc: 0.8709\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3198 - acc: 0.8647 - val_loss: 0.3317 - val_acc: 0.8564\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3194 - acc: 0.8656 - val_loss: 0.3107 - val_acc: 0.8711\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3159 - acc: 0.8677 - val_loss: 0.3256 - val_acc: 0.8671\n",
      "Epoch 43/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3214 - acc: 0.8658 - val_loss: 0.3181 - val_acc: 0.8657\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3079 - acc: 0.8692 - val_loss: 0.3152 - val_acc: 0.8705\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3102 - acc: 0.8692 - val_loss: 0.3292 - val_acc: 0.8673\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3117 - acc: 0.8673 - val_loss: 0.3181 - val_acc: 0.8671\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3150 - acc: 0.8691 - val_loss: 0.3174 - val_acc: 0.8703\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3130 - acc: 0.8667 - val_loss: 0.3230 - val_acc: 0.8686\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3117 - acc: 0.8679 - val_loss: 0.3184 - val_acc: 0.8707\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3073 - acc: 0.8710 - val_loss: 0.3301 - val_acc: 0.8639\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3058 - acc: 0.8726 - val_loss: 0.3137 - val_acc: 0.8693\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3065 - acc: 0.8697 - val_loss: 0.3087 - val_acc: 0.8737\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3122 - acc: 0.8688 - val_loss: 0.3093 - val_acc: 0.8706\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3075 - acc: 0.8695 - val_loss: 0.3274 - val_acc: 0.8661\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3068 - acc: 0.8714 - val_loss: 0.3186 - val_acc: 0.8747\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3120 - acc: 0.8688 - val_loss: 0.3096 - val_acc: 0.8696\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3056 - acc: 0.8722 - val_loss: 0.3180 - val_acc: 0.8658\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3070 - acc: 0.8712 - val_loss: 0.3264 - val_acc: 0.8655\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3000 - acc: 0.8742 - val_loss: 0.3063 - val_acc: 0.8716\n",
      "Epoch 60/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3015 - acc: 0.8743 - val_loss: 0.3184 - val_acc: 0.8644\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3023 - acc: 0.8739 - val_loss: 0.3261 - val_acc: 0.8710\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3096 - acc: 0.8694 - val_loss: 0.3020 - val_acc: 0.8737\n",
      "Epoch 63/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3097 - acc: 0.8706 - val_loss: 0.3243 - val_acc: 0.8648\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3039 - acc: 0.8717 - val_loss: 0.3097 - val_acc: 0.8717\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2975 - acc: 0.8758 - val_loss: 0.3104 - val_acc: 0.8746\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2994 - acc: 0.8745 - val_loss: 0.3000 - val_acc: 0.8757\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3029 - acc: 0.8740 - val_loss: 0.3200 - val_acc: 0.8669\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.2967 - acc: 0.8753 - val_loss: 0.3052 - val_acc: 0.8750\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3034 - acc: 0.8716 - val_loss: 0.3081 - val_acc: 0.8737\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.2912 - acc: 0.8790 - val_loss: 0.3121 - val_acc: 0.8703\n",
      "\n",
      "Training process completed in: 0 h 21 m 20 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1282.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1284 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_493 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_493 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_494 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_494 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_495 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_495 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_496 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_496 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_124 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 0.5004 - acc: 0.7640 - val_loss: 0.4308 - val_acc: 0.8115\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.4280 - acc: 0.8179 - val_loss: 0.3902 - val_acc: 0.8275\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.4182 - acc: 0.8200 - val_loss: 0.4177 - val_acc: 0.8165\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3946 - acc: 0.8333 - val_loss: 0.3837 - val_acc: 0.8403\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3884 - acc: 0.8333 - val_loss: 0.3978 - val_acc: 0.8210\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3928 - acc: 0.8333 - val_loss: 0.3942 - val_acc: 0.8320\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3845 - acc: 0.8349 - val_loss: 0.3924 - val_acc: 0.8360\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.3799 - acc: 0.8365 - val_loss: 0.3851 - val_acc: 0.8308\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3698 - acc: 0.8418 - val_loss: 0.3980 - val_acc: 0.8305\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3705 - acc: 0.8418 - val_loss: 0.3865 - val_acc: 0.8458\n",
      "Epoch 11/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3592 - acc: 0.8446 - val_loss: 0.3665 - val_acc: 0.8432\n",
      "Epoch 12/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3658 - acc: 0.8431 - val_loss: 0.3650 - val_acc: 0.8595\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3624 - acc: 0.8451 - val_loss: 0.3935 - val_acc: 0.8450\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3638 - acc: 0.8465 - val_loss: 0.3954 - val_acc: 0.8431\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3635 - acc: 0.8429 - val_loss: 0.3781 - val_acc: 0.8377\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3552 - acc: 0.8477 - val_loss: 0.4058 - val_acc: 0.8537\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3498 - acc: 0.8526 - val_loss: 0.3675 - val_acc: 0.8442\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3510 - acc: 0.8473 - val_loss: 0.4022 - val_acc: 0.8525\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3537 - acc: 0.8468 - val_loss: 0.4006 - val_acc: 0.8540\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3513 - acc: 0.8499 - val_loss: 0.3511 - val_acc: 0.8565\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3485 - acc: 0.8504 - val_loss: 0.3701 - val_acc: 0.8580\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3487 - acc: 0.8492 - val_loss: 0.4228 - val_acc: 0.8290\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3414 - acc: 0.8536 - val_loss: 0.3522 - val_acc: 0.8600\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3460 - acc: 0.8541 - val_loss: 0.3426 - val_acc: 0.8592\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3418 - acc: 0.8555 - val_loss: 0.3494 - val_acc: 0.8608\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3457 - acc: 0.8525 - val_loss: 0.3755 - val_acc: 0.8502\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3375 - acc: 0.8584 - val_loss: 0.3499 - val_acc: 0.8688\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3426 - acc: 0.8540 - val_loss: 0.3500 - val_acc: 0.8535\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3322 - acc: 0.8591 - val_loss: 0.3506 - val_acc: 0.8675\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3394 - acc: 0.8553 - val_loss: 0.3362 - val_acc: 0.8580\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3329 - acc: 0.8581 - val_loss: 0.3887 - val_acc: 0.8528\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3333 - acc: 0.8587 - val_loss: 0.3411 - val_acc: 0.8635\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3343 - acc: 0.8562 - val_loss: 0.3521 - val_acc: 0.8570\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3279 - acc: 0.8608 - val_loss: 0.3576 - val_acc: 0.8632\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3235 - acc: 0.8620 - val_loss: 0.3483 - val_acc: 0.8606\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3266 - acc: 0.8601 - val_loss: 0.4015 - val_acc: 0.8425\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3378 - acc: 0.8557 - val_loss: 0.3516 - val_acc: 0.8680\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3308 - acc: 0.8589 - val_loss: 0.3505 - val_acc: 0.8615\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3287 - acc: 0.8606 - val_loss: 0.3348 - val_acc: 0.8580\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3272 - acc: 0.8600 - val_loss: 0.3626 - val_acc: 0.8517\n",
      "Epoch 41/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3281 - acc: 0.8599 - val_loss: 0.3595 - val_acc: 0.8605\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3263 - acc: 0.8610 - val_loss: 0.3547 - val_acc: 0.8626\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3209 - acc: 0.8626 - val_loss: 0.3480 - val_acc: 0.8638\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3203 - acc: 0.8642 - val_loss: 0.3741 - val_acc: 0.8465\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3273 - acc: 0.8626 - val_loss: 0.3619 - val_acc: 0.8545\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3245 - acc: 0.8611 - val_loss: 0.3473 - val_acc: 0.8627\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3206 - acc: 0.8619 - val_loss: 0.3435 - val_acc: 0.8635\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3177 - acc: 0.8651 - val_loss: 0.3384 - val_acc: 0.8588\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3259 - acc: 0.8610 - val_loss: 0.3361 - val_acc: 0.8611\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3171 - acc: 0.8652 - val_loss: 0.3524 - val_acc: 0.8590\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3199 - acc: 0.8650 - val_loss: 0.3550 - val_acc: 0.8650\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3243 - acc: 0.8635 - val_loss: 0.3307 - val_acc: 0.8590\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3171 - acc: 0.8659 - val_loss: 0.3234 - val_acc: 0.8698\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3195 - acc: 0.8651 - val_loss: 0.3228 - val_acc: 0.8700\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3121 - acc: 0.8693 - val_loss: 0.3490 - val_acc: 0.8580\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3182 - acc: 0.8639 - val_loss: 0.3292 - val_acc: 0.8644\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3162 - acc: 0.8668 - val_loss: 0.3401 - val_acc: 0.8627\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3148 - acc: 0.8681 - val_loss: 0.3655 - val_acc: 0.8642\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3125 - acc: 0.8672 - val_loss: 0.3360 - val_acc: 0.8577\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3121 - acc: 0.8681 - val_loss: 0.3447 - val_acc: 0.8662\n",
      "Epoch 61/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3186 - acc: 0.8655 - val_loss: 0.3299 - val_acc: 0.8727\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3083 - acc: 0.8692 - val_loss: 0.3472 - val_acc: 0.8575\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3091 - acc: 0.8716 - val_loss: 0.3292 - val_acc: 0.8634\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3190 - acc: 0.8630 - val_loss: 0.3278 - val_acc: 0.8687\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3104 - acc: 0.8685 - val_loss: 0.3435 - val_acc: 0.8528\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3167 - acc: 0.8649 - val_loss: 0.3722 - val_acc: 0.8582\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3116 - acc: 0.8671 - val_loss: 0.3231 - val_acc: 0.8690\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3105 - acc: 0.8683 - val_loss: 0.3526 - val_acc: 0.8567\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3100 - acc: 0.8677 - val_loss: 0.3532 - val_acc: 0.8662\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3056 - acc: 0.8702 - val_loss: 0.3227 - val_acc: 0.8634\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3059 - acc: 0.8692 - val_loss: 0.3328 - val_acc: 0.8715\n",
      "Epoch 72/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3122 - acc: 0.8688 - val_loss: 0.3280 - val_acc: 0.8650\n",
      "Epoch 73/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3132 - acc: 0.8686 - val_loss: 0.3363 - val_acc: 0.8658\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3120 - acc: 0.8678 - val_loss: 0.3418 - val_acc: 0.8662\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3018 - acc: 0.8708 - val_loss: 0.3328 - val_acc: 0.8620 - loss: 0.3024 - acc: 0\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.2994 - acc: 0.8731 - val_loss: 0.3107 - val_acc: 0.8705\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3079 - acc: 0.8712 - val_loss: 0.3262 - val_acc: 0.8659\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3019 - acc: 0.8735 - val_loss: 0.3254 - val_acc: 0.8718\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3087 - acc: 0.8691 - val_loss: 0.3264 - val_acc: 0.8703\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.3048 - acc: 0.8717 - val_loss: 0.3269 - val_acc: 0.8680\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3070 - acc: 0.8694 - val_loss: 0.3260 - val_acc: 0.8700\n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3042 - acc: 0.8721 - val_loss: 0.3342 - val_acc: 0.8710\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3069 - acc: 0.8698 - val_loss: 0.3360 - val_acc: 0.8633\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.2949 - acc: 0.8763 - val_loss: 0.3249 - val_acc: 0.8651\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.2926 - acc: 0.8763 - val_loss: 0.3216 - val_acc: 0.8710\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3056 - acc: 0.8709 - val_loss: 0.3269 - val_acc: 0.8750\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3088 - acc: 0.8696 - val_loss: 0.3509 - val_acc: 0.8585\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3012 - acc: 0.8706 - val_loss: 0.3360 - val_acc: 0.8645\n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3037 - acc: 0.8705 - val_loss: 0.3208 - val_acc: 0.8718\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.2941 - acc: 0.8744 - val_loss: 0.3184 - val_acc: 0.8690\n",
      "\n",
      "Training process completed in: 0 h 21 m 5 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1283.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1285 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_497 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_497 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_498 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_498 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_499 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_499 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_500 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_500 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_125 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 20\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.5787 - acc: 0.7117 - val_loss: 0.4998 - val_acc: 0.7425\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4970 - acc: 0.7753 - val_loss: 0.3936 - val_acc: 0.8250\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4979 - acc: 0.7763 - val_loss: 0.4952 - val_acc: 0.7650\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4596 - acc: 0.8060 - val_loss: 0.4383 - val_acc: 0.8075\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4358 - acc: 0.8230 - val_loss: 0.4522 - val_acc: 0.8025\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4678 - acc: 0.7977 - val_loss: 0.5109 - val_acc: 0.7250\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4524 - acc: 0.8133 - val_loss: 0.6125 - val_acc: 0.7375\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4488 - acc: 0.8093 - val_loss: 0.4825 - val_acc: 0.7500\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4385 - acc: 0.8137 - val_loss: 0.4514 - val_acc: 0.8000\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4307 - acc: 0.8147 - val_loss: 0.4515 - val_acc: 0.8125\n",
      "Epoch 11/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4334 - acc: 0.8100 - val_loss: 0.4156 - val_acc: 0.8500\n",
      "Epoch 12/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4300 - acc: 0.8183 - val_loss: 0.4102 - val_acc: 0.8500\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4262 - acc: 0.8150 - val_loss: 0.5094 - val_acc: 0.8050\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4312 - acc: 0.8127 - val_loss: 0.4787 - val_acc: 0.8075\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4410 - acc: 0.8067 - val_loss: 0.4178 - val_acc: 0.8100\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4197 - acc: 0.8127 - val_loss: 0.4146 - val_acc: 0.8300\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4240 - acc: 0.8170 - val_loss: 0.4128 - val_acc: 0.8475\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4167 - acc: 0.8227 - val_loss: 0.4107 - val_acc: 0.8075\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4285 - acc: 0.8163 - val_loss: 0.3788 - val_acc: 0.8250\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4109 - acc: 0.8250 - val_loss: 0.4057 - val_acc: 0.8500\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3999 - acc: 0.8400 - val_loss: 0.3922 - val_acc: 0.8325\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3981 - acc: 0.8300 - val_loss: 0.4249 - val_acc: 0.8100\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4116 - acc: 0.8143 - val_loss: 0.4955 - val_acc: 0.8050\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4232 - acc: 0.8207 - val_loss: 0.4186 - val_acc: 0.8325\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4050 - acc: 0.8257 - val_loss: 0.4055 - val_acc: 0.8075\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4192 - acc: 0.8170 - val_loss: 0.4122 - val_acc: 0.8275\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4072 - acc: 0.8207 - val_loss: 0.3891 - val_acc: 0.8250\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3970 - acc: 0.8380 - val_loss: 0.3560 - val_acc: 0.8550\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4203 - acc: 0.8223 - val_loss: 0.4154 - val_acc: 0.8350\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3686 - acc: 0.8390 - val_loss: 0.4147 - val_acc: 0.8100\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4011 - acc: 0.8243 - val_loss: 0.4034 - val_acc: 0.8275\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4126 - acc: 0.8220 - val_loss: 0.4333 - val_acc: 0.8425\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3900 - acc: 0.8323 - val_loss: 0.3818 - val_acc: 0.8375\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3845 - acc: 0.8383 - val_loss: 0.3993 - val_acc: 0.8200\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3892 - acc: 0.8353 - val_loss: 0.4194 - val_acc: 0.8250\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4048 - acc: 0.8273 - val_loss: 0.3593 - val_acc: 0.8600\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3978 - acc: 0.8267 - val_loss: 0.4292 - val_acc: 0.8275\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4002 - acc: 0.8293 - val_loss: 0.3777 - val_acc: 0.8300\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3795 - acc: 0.8337 - val_loss: 0.3779 - val_acc: 0.8425\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3810 - acc: 0.8353 - val_loss: 0.3949 - val_acc: 0.8400\n",
      "Epoch 41/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3893 - acc: 0.8317 - val_loss: 0.4152 - val_acc: 0.8225\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3898 - acc: 0.8310 - val_loss: 0.4540 - val_acc: 0.8225\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4079 - acc: 0.8293 - val_loss: 0.4023 - val_acc: 0.8325\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3695 - acc: 0.8447 - val_loss: 0.3649 - val_acc: 0.8350\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3878 - acc: 0.8350 - val_loss: 0.4128 - val_acc: 0.8325\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3963 - acc: 0.8323 - val_loss: 0.4159 - val_acc: 0.8175\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3691 - acc: 0.8430 - val_loss: 0.4544 - val_acc: 0.8175\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3868 - acc: 0.8347 - val_loss: 0.4352 - val_acc: 0.8175\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3886 - acc: 0.8297 - val_loss: 0.3434 - val_acc: 0.8650\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3968 - acc: 0.8277 - val_loss: 0.4236 - val_acc: 0.8425\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3814 - acc: 0.8373 - val_loss: 0.4238 - val_acc: 0.8400\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3961 - acc: 0.8333 - val_loss: 0.4171 - val_acc: 0.7950\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3750 - acc: 0.8417 - val_loss: 0.4122 - val_acc: 0.8425\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3937 - acc: 0.8287 - val_loss: 0.3886 - val_acc: 0.8750\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3819 - acc: 0.8297 - val_loss: 0.3583 - val_acc: 0.8525\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3654 - acc: 0.8447 - val_loss: 0.3913 - val_acc: 0.8175\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3808 - acc: 0.8347 - val_loss: 0.4186 - val_acc: 0.8500\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3763 - acc: 0.8367 - val_loss: 0.4110 - val_acc: 0.8175\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3848 - acc: 0.8357 - val_loss: 0.4162 - val_acc: 0.8350\n",
      "Epoch 60/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3868 - acc: 0.8347 - val_loss: 0.3915 - val_acc: 0.8275\n",
      "Epoch 61/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.4114 - acc: 0.8270 - val_loss: 0.4065 - val_acc: 0.8200\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3870 - acc: 0.8353 - val_loss: 0.3564 - val_acc: 0.8500\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3853 - acc: 0.8353 - val_loss: 0.3572 - val_acc: 0.8550\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3933 - acc: 0.8387 - val_loss: 0.3797 - val_acc: 0.8375\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3797 - acc: 0.8340 - val_loss: 0.4375 - val_acc: 0.8375\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3811 - acc: 0.8353 - val_loss: 0.4329 - val_acc: 0.8350\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3639 - acc: 0.8467 - val_loss: 0.3564 - val_acc: 0.8600\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3590 - acc: 0.8470 - val_loss: 0.3920 - val_acc: 0.8175\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3690 - acc: 0.8457 - val_loss: 0.4160 - val_acc: 0.8150\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3712 - acc: 0.8387 - val_loss: 0.3939 - val_acc: 0.8367\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3875 - acc: 0.8370 - val_loss: 0.3948 - val_acc: 0.8600\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3783 - acc: 0.8390 - val_loss: 0.4111 - val_acc: 0.8200\n",
      "Epoch 73/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3552 - acc: 0.8510 - val_loss: 0.3636 - val_acc: 0.8350\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3623 - acc: 0.8510 - val_loss: 0.4095 - val_acc: 0.8050\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.3655 - acc: 0.8417 - val_loss: 0.3789 - val_acc: 0.8225\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3842 - acc: 0.8313 - val_loss: 0.3303 - val_acc: 0.8850\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3806 - acc: 0.8400 - val_loss: 0.3985 - val_acc: 0.8425\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3718 - acc: 0.8387 - val_loss: 0.4099 - val_acc: 0.8375\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3811 - acc: 0.8330 - val_loss: 0.4169 - val_acc: 0.8050\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3818 - acc: 0.8417 - val_loss: 0.3579 - val_acc: 0.8625\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3579 - acc: 0.8507 - val_loss: 0.3719 - val_acc: 0.8275\n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3698 - acc: 0.8410 - val_loss: 0.3907 - val_acc: 0.8625\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3799 - acc: 0.8440 - val_loss: 0.3735 - val_acc: 0.8550\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3611 - acc: 0.8533 - val_loss: 0.3730 - val_acc: 0.8375\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3870 - acc: 0.8300 - val_loss: 0.3882 - val_acc: 0.8375\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3811 - acc: 0.8393 - val_loss: 0.3853 - val_acc: 0.8225\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3797 - acc: 0.8383 - val_loss: 0.3924 - val_acc: 0.8325\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3523 - acc: 0.8527 - val_loss: 0.3898 - val_acc: 0.8325\n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3856 - acc: 0.8367 - val_loss: 0.4288 - val_acc: 0.8250\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3813 - acc: 0.8380 - val_loss: 0.3908 - val_acc: 0.8450\n",
      "\n",
      "Training process completed in: 0 h 3 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1284.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1286 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_501 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_501 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_502 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_502 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_503 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_503 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_504 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_504 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_126 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.4763 - acc: 0.7788 - val_loss: 0.4406 - val_acc: 0.8071\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.4218 - acc: 0.8192 - val_loss: 0.4144 - val_acc: 0.8153\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.4100 - acc: 0.8245 - val_loss: 0.3964 - val_acc: 0.8257\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3997 - acc: 0.8266 - val_loss: 0.4007 - val_acc: 0.8233\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.4075 - acc: 0.8239 - val_loss: 0.4269 - val_acc: 0.8372\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3879 - acc: 0.8319 - val_loss: 0.4315 - val_acc: 0.8023\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3975 - acc: 0.8292 - val_loss: 0.3815 - val_acc: 0.8446\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3758 - acc: 0.8376 - val_loss: 0.3931 - val_acc: 0.8369\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3747 - acc: 0.8388 - val_loss: 0.4198 - val_acc: 0.8414\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3645 - acc: 0.8451 - val_loss: 0.3628 - val_acc: 0.8419\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3635 - acc: 0.8455 - val_loss: 0.3570 - val_acc: 0.8428\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3645 - acc: 0.8442 - val_loss: 0.3643 - val_acc: 0.8469\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3559 - acc: 0.8491 - val_loss: 0.3653 - val_acc: 0.8470\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3644 - acc: 0.8417 - val_loss: 0.3543 - val_acc: 0.8404\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3610 - acc: 0.8434 - val_loss: 0.3965 - val_acc: 0.8352\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3479 - acc: 0.8498 - val_loss: 0.3617 - val_acc: 0.8555\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3538 - acc: 0.8468 - val_loss: 0.3571 - val_acc: 0.8518\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3513 - acc: 0.8489 - val_loss: 0.3502 - val_acc: 0.8563\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3472 - acc: 0.8539 - val_loss: 0.3643 - val_acc: 0.8525\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3470 - acc: 0.8521 - val_loss: 0.3579 - val_acc: 0.8574\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3444 - acc: 0.8550 - val_loss: 0.3363 - val_acc: 0.8536\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3428 - acc: 0.8545 - val_loss: 0.3374 - val_acc: 0.8604\n",
      "Epoch 23/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3466 - acc: 0.8517 - val_loss: 0.3364 - val_acc: 0.8568\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3384 - acc: 0.8564 - val_loss: 0.3357 - val_acc: 0.8587\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3384 - acc: 0.8542 - val_loss: 0.3370 - val_acc: 0.8552\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3318 - acc: 0.8590 - val_loss: 0.3565 - val_acc: 0.8425\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3448 - acc: 0.8526 - val_loss: 0.3350 - val_acc: 0.8630\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3342 - acc: 0.8583 - val_loss: 0.3482 - val_acc: 0.8467\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3308 - acc: 0.8576 - val_loss: 0.3474 - val_acc: 0.8581\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3367 - acc: 0.8569 - val_loss: 0.3345 - val_acc: 0.8580\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3274 - acc: 0.8603 - val_loss: 0.3506 - val_acc: 0.8594\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3278 - acc: 0.8615 - val_loss: 0.3408 - val_acc: 0.8568\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3270 - acc: 0.8624 - val_loss: 0.3167 - val_acc: 0.8654\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3301 - acc: 0.8590 - val_loss: 0.3457 - val_acc: 0.8611\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3301 - acc: 0.8605 - val_loss: 0.3346 - val_acc: 0.8573\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3255 - acc: 0.8614 - val_loss: 0.3278 - val_acc: 0.8631\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3193 - acc: 0.8664 - val_loss: 0.3304 - val_acc: 0.8649\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3281 - acc: 0.8609 - val_loss: 0.3228 - val_acc: 0.8633\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3250 - acc: 0.8615 - val_loss: 0.3185 - val_acc: 0.8679\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3145 - acc: 0.8681 - val_loss: 0.3230 - val_acc: 0.8686\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3250 - acc: 0.8636 - val_loss: 0.3190 - val_acc: 0.8640\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3171 - acc: 0.8668 - val_loss: 0.3257 - val_acc: 0.8646\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3121 - acc: 0.8669 - val_loss: 0.3266 - val_acc: 0.8638\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3214 - acc: 0.8647 - val_loss: 0.3204 - val_acc: 0.8681\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3228 - acc: 0.8629 - val_loss: 0.3214 - val_acc: 0.8625\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3217 - acc: 0.8646 - val_loss: 0.3254 - val_acc: 0.8671\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3127 - acc: 0.8697 - val_loss: 0.3429 - val_acc: 0.8640\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3224 - acc: 0.8630 - val_loss: 0.3474 - val_acc: 0.8587\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3164 - acc: 0.8652 - val_loss: 0.3302 - val_acc: 0.8586\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3232 - acc: 0.8637 - val_loss: 0.3100 - val_acc: 0.8694\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3145 - acc: 0.8642 - val_loss: 0.3213 - val_acc: 0.8667\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3177 - acc: 0.8662 - val_loss: 0.3231 - val_acc: 0.8642\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3095 - acc: 0.8695 - val_loss: 0.3130 - val_acc: 0.8723\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3162 - acc: 0.8656 - val_loss: 0.3263 - val_acc: 0.8683\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3119 - acc: 0.8674 - val_loss: 0.3235 - val_acc: 0.8683\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3183 - acc: 0.8662 - val_loss: 0.3186 - val_acc: 0.8654\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3113 - acc: 0.8701 - val_loss: 0.3220 - val_acc: 0.8703\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3161 - acc: 0.8654 - val_loss: 0.3264 - val_acc: 0.8618\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3119 - acc: 0.8675 - val_loss: 0.3177 - val_acc: 0.8701\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3083 - acc: 0.8715 - val_loss: 0.3184 - val_acc: 0.8737\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3117 - acc: 0.8662 - val_loss: 0.3197 - val_acc: 0.8704\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3171 - acc: 0.8673 - val_loss: 0.3391 - val_acc: 0.8632\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3076 - acc: 0.8697 - val_loss: 0.3137 - val_acc: 0.8718\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3102 - acc: 0.8673 - val_loss: 0.3146 - val_acc: 0.8704\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3118 - acc: 0.8683 - val_loss: 0.3108 - val_acc: 0.8678\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3063 - acc: 0.8708 - val_loss: 0.3081 - val_acc: 0.8701\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3141 - acc: 0.8681 - val_loss: 0.3182 - val_acc: 0.8672\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3081 - acc: 0.8694 - val_loss: 0.3191 - val_acc: 0.8693\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3131 - acc: 0.8684 - val_loss: 0.3167 - val_acc: 0.8652\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3116 - acc: 0.8678 - val_loss: 0.3077 - val_acc: 0.8730\n",
      "\n",
      "Training process completed in: 0 h 19 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1285.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1287 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_505 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_505 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_506 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_506 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_507 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_507 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_508 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_508 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_127 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 32s 170ms/step - loss: 0.4649 - acc: 0.7903 - val_loss: 0.4380 - val_acc: 0.8112\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.4124 - acc: 0.8233 - val_loss: 0.4136 - val_acc: 0.8187\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3887 - acc: 0.8323 - val_loss: 0.4240 - val_acc: 0.8250\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 24s 126ms/step - loss: 0.3861 - acc: 0.8333 - val_loss: 0.4396 - val_acc: 0.8202\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3837 - acc: 0.8353 - val_loss: 0.3859 - val_acc: 0.8301\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 25s 131ms/step - loss: 0.3805 - acc: 0.8367 - val_loss: 0.3788 - val_acc: 0.8443\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3748 - acc: 0.8395 - val_loss: 0.3939 - val_acc: 0.8385\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3686 - acc: 0.8422 - val_loss: 0.3603 - val_acc: 0.8436\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3582 - acc: 0.8451 - val_loss: 0.3767 - val_acc: 0.8422\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3606 - acc: 0.8474 - val_loss: 0.3658 - val_acc: 0.8442\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3592 - acc: 0.8464 - val_loss: 0.3663 - val_acc: 0.8485\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3575 - acc: 0.8462 - val_loss: 0.3600 - val_acc: 0.8439\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3488 - acc: 0.8514 - val_loss: 0.3533 - val_acc: 0.8501\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3525 - acc: 0.8477 - val_loss: 0.3432 - val_acc: 0.8561\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3488 - acc: 0.8526 - val_loss: 0.3574 - val_acc: 0.8465\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3486 - acc: 0.8515 - val_loss: 0.3488 - val_acc: 0.8497\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3458 - acc: 0.8537 - val_loss: 0.3901 - val_acc: 0.8323\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3464 - acc: 0.8523 - val_loss: 0.3443 - val_acc: 0.8512\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3394 - acc: 0.8561 - val_loss: 0.3753 - val_acc: 0.8460\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3377 - acc: 0.8560 - val_loss: 0.3419 - val_acc: 0.8565\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3393 - acc: 0.8560 - val_loss: 0.3572 - val_acc: 0.8550\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3387 - acc: 0.8556 - val_loss: 0.3499 - val_acc: 0.8592\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3363 - acc: 0.8564 - val_loss: 0.3356 - val_acc: 0.8635\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3339 - acc: 0.8586 - val_loss: 0.3309 - val_acc: 0.8614\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3331 - acc: 0.8578 - val_loss: 0.3418 - val_acc: 0.8610\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 25s 132ms/step - loss: 0.3315 - acc: 0.8598 - val_loss: 0.3357 - val_acc: 0.8577\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3267 - acc: 0.8603 - val_loss: 0.3276 - val_acc: 0.8629\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3254 - acc: 0.8599 - val_loss: 0.3319 - val_acc: 0.8569\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3309 - acc: 0.8590 - val_loss: 0.3447 - val_acc: 0.8605\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3232 - acc: 0.8627 - val_loss: 0.3238 - val_acc: 0.8659\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3223 - acc: 0.8637 - val_loss: 0.3263 - val_acc: 0.8613\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3216 - acc: 0.8633 - val_loss: 0.3290 - val_acc: 0.8622\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.3233 - acc: 0.8625 - val_loss: 0.3325 - val_acc: 0.8614\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3230 - acc: 0.8622 - val_loss: 0.3320 - val_acc: 0.8594\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3219 - acc: 0.8628 - val_loss: 0.3260 - val_acc: 0.8664\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3210 - acc: 0.8642 - val_loss: 0.3230 - val_acc: 0.8637\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3175 - acc: 0.8656 - val_loss: 0.3237 - val_acc: 0.8656\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3119 - acc: 0.8664 - val_loss: 0.3274 - val_acc: 0.8638\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3128 - acc: 0.8690 - val_loss: 0.3227 - val_acc: 0.8659\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3114 - acc: 0.8680 - val_loss: 0.3246 - val_acc: 0.8631\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3244 - acc: 0.8624 - val_loss: 0.3453 - val_acc: 0.8555\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3125 - acc: 0.8671 - val_loss: 0.3157 - val_acc: 0.8690\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3135 - acc: 0.8676 - val_loss: 0.3187 - val_acc: 0.8654\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3110 - acc: 0.8678 - val_loss: 0.3155 - val_acc: 0.8668\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3082 - acc: 0.8710 - val_loss: 0.3172 - val_acc: 0.8647\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3121 - acc: 0.8684 - val_loss: 0.3263 - val_acc: 0.8679\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3168 - acc: 0.8658 - val_loss: 0.3206 - val_acc: 0.8715 ETA: 3s - loss: 0. - ETA: 1s - loss: 0\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3012 - acc: 0.8735 - val_loss: 0.3124 - val_acc: 0.87102  - ETA: 4s - loss: 0.3017 - a\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3124 - acc: 0.8670 - val_loss: 0.3301 - val_acc: 0.8643\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3044 - acc: 0.8712 - val_loss: 0.3261 - val_acc: 0.8679\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3090 - acc: 0.8692 - val_loss: 0.3143 - val_acc: 0.8718\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3118 - acc: 0.8679 - val_loss: 0.3242 - val_acc: 0.8687\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3081 - acc: 0.8684 - val_loss: 0.3349 - val_acc: 0.8658\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3051 - acc: 0.8709 - val_loss: 0.3208 - val_acc: 0.8662\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2992 - acc: 0.8733 - val_loss: 0.3117 - val_acc: 0.8699\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3067 - acc: 0.8704 - val_loss: 0.3292 - val_acc: 0.8664\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3090 - acc: 0.8698 - val_loss: 0.3289 - val_acc: 0.8653\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3049 - acc: 0.8723 - val_loss: 0.3273 - val_acc: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "190/190 [==============================] - 25s 131ms/step - loss: 0.3034 - acc: 0.8733 - val_loss: 0.3189 - val_acc: 0.8673\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2995 - acc: 0.8741 - val_loss: 0.3044 - val_acc: 0.8719\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2996 - acc: 0.8740 - val_loss: 0.3109 - val_acc: 0.8697\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3044 - acc: 0.8712 - val_loss: 0.3124 - val_acc: 0.8664\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3067 - acc: 0.8700 - val_loss: 0.3164 - val_acc: 0.8718\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3050 - acc: 0.8728 - val_loss: 0.3188 - val_acc: 0.8703\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.3022 - acc: 0.8738 - val_loss: 0.3145 - val_acc: 0.8674\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2965 - acc: 0.8752 - val_loss: 0.3109 - val_acc: 0.8723\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2957 - acc: 0.8760 - val_loss: 0.3087 - val_acc: 0.8721 loss: 0\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.3022 - acc: 0.8731 - val_loss: 0.3385 - val_acc: 0.8633\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.3049 - acc: 0.8712 - val_loss: 0.3209 - val_acc: 0.8717\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.2974 - acc: 0.8755 - val_loss: 0.3104 - val_acc: 0.8698\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2968 - acc: 0.8766 - val_loss: 0.3070 - val_acc: 0.8712\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2998 - acc: 0.8734 - val_loss: 0.3030 - val_acc: 0.8713\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2939 - acc: 0.8764 - val_loss: 0.3230 - val_acc: 0.8645\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2918 - acc: 0.8774 - val_loss: 0.3200 - val_acc: 0.8677\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2918 - acc: 0.8785 - val_loss: 0.3121 - val_acc: 0.8686\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2980 - acc: 0.8745 - val_loss: 0.3080 - val_acc: 0.8728\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 26s 135ms/step - loss: 0.2911 - acc: 0.8792 - val_loss: 0.3094 - val_acc: 0.8713\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2884 - acc: 0.8786 - val_loss: 0.3003 - val_acc: 0.8748\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 25s 131ms/step - loss: 0.2929 - acc: 0.8768 - val_loss: 0.3187 - val_acc: 0.8724\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2933 - acc: 0.8762 - val_loss: 0.3175 - val_acc: 0.8699\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2965 - acc: 0.8756 - val_loss: 0.3181 - val_acc: 0.8737\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2992 - acc: 0.8745 - val_loss: 0.2990 - val_acc: 0.8756\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 25s 132ms/step - loss: 0.2878 - acc: 0.8794 - val_loss: 0.3024 - val_acc: 0.8729\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 24s 128ms/step - loss: 0.2921 - acc: 0.8785 - val_loss: 0.3064 - val_acc: 0.8738\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 24s 129ms/step - loss: 0.2940 - acc: 0.8766 - val_loss: 0.3121 - val_acc: 0.8688\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2870 - acc: 0.8803 - val_loss: 0.3069 - val_acc: 0.8710\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2896 - acc: 0.8795 - val_loss: 0.3162 - val_acc: 0.8681\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2877 - acc: 0.8804 - val_loss: 0.3000 - val_acc: 0.8774\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2857 - acc: 0.8803 - val_loss: 0.3096 - val_acc: 0.8717\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2963 - acc: 0.8751 - val_loss: 0.3030 - val_acc: 0.8750\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2888 - acc: 0.8791 - val_loss: 0.3038 - val_acc: 0.8746\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2891 - acc: 0.8771 - val_loss: 0.3040 - val_acc: 0.8746\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2882 - acc: 0.8793 - val_loss: 0.3151 - val_acc: 0.8719\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2895 - acc: 0.8774 - val_loss: 0.2988 - val_acc: 0.8764\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2870 - acc: 0.8790 - val_loss: 0.3016 - val_acc: 0.8751\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2891 - acc: 0.8765 - val_loss: 0.3090 - val_acc: 0.8714\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2835 - acc: 0.8827 - val_loss: 0.3009 - val_acc: 0.8780\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2808 - acc: 0.8831 - val_loss: 0.3012 - val_acc: 0.8743\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 25s 129ms/step - loss: 0.2871 - acc: 0.8806 - val_loss: 0.3059 - val_acc: 0.8767\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 25s 130ms/step - loss: 0.2812 - acc: 0.8818 - val_loss: 0.3144 - val_acc: 0.8722\n",
      "\n",
      "Training process completed in: 0 h 41 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1286.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1288 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_509 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_509 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_510 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_510 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_511 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_511 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_512 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_512 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_128 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 100\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 26s 138ms/step - loss: 0.5141 - acc: 0.7527 - val_loss: 0.4407 - val_acc: 0.8134\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4206 - acc: 0.8232 - val_loss: 0.4281 - val_acc: 0.8078\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.4125 - acc: 0.8235 - val_loss: 0.3928 - val_acc: 0.8299\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3974 - acc: 0.8300 - val_loss: 0.4081 - val_acc: 0.8276\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.4025 - acc: 0.8290 - val_loss: 0.3895 - val_acc: 0.8335\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3872 - acc: 0.8334 - val_loss: 0.3878 - val_acc: 0.8290\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3894 - acc: 0.8324 - val_loss: 0.3880 - val_acc: 0.8357\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3768 - acc: 0.8373 - val_loss: 0.3930 - val_acc: 0.8386\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3776 - acc: 0.8364 - val_loss: 0.3756 - val_acc: 0.8419\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3717 - acc: 0.8416 - val_loss: 0.4127 - val_acc: 0.8302\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3816 - acc: 0.8360 - val_loss: 0.4041 - val_acc: 0.8343\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3688 - acc: 0.8420 - val_loss: 0.3792 - val_acc: 0.8508\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3676 - acc: 0.8435 - val_loss: 0.3963 - val_acc: 0.8481\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3644 - acc: 0.8447 - val_loss: 0.3798 - val_acc: 0.8493\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3634 - acc: 0.8441 - val_loss: 0.4304 - val_acc: 0.8372\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3588 - acc: 0.8488 - val_loss: 0.3827 - val_acc: 0.8458\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3561 - acc: 0.8500 - val_loss: 0.3935 - val_acc: 0.8456\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3567 - acc: 0.8475 - val_loss: 0.3759 - val_acc: 0.8519\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3503 - acc: 0.8511 - val_loss: 0.3884 - val_acc: 0.8409\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3564 - acc: 0.8522 - val_loss: 0.3843 - val_acc: 0.8473\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3521 - acc: 0.8501 - val_loss: 0.3697 - val_acc: 0.8509\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3494 - acc: 0.8518 - val_loss: 0.3701 - val_acc: 0.8503\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3496 - acc: 0.8510 - val_loss: 0.3569 - val_acc: 0.8534\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3430 - acc: 0.8535 - val_loss: 0.3626 - val_acc: 0.8525\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3495 - acc: 0.8525 - val_loss: 0.3813 - val_acc: 0.8418\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3518 - acc: 0.8510 - val_loss: 0.3622 - val_acc: 0.8507\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3522 - acc: 0.8508 - val_loss: 0.3409 - val_acc: 0.8588\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3455 - acc: 0.8560 - val_loss: 0.3983 - val_acc: 0.8400\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3519 - acc: 0.8514 - val_loss: 0.3523 - val_acc: 0.8555\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3507 - acc: 0.8511 - val_loss: 0.4051 - val_acc: 0.8361\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3394 - acc: 0.8576 - val_loss: 0.3580 - val_acc: 0.8561\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3372 - acc: 0.8582 - val_loss: 0.3551 - val_acc: 0.8528\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3426 - acc: 0.8549 - val_loss: 0.3589 - val_acc: 0.8497\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3375 - acc: 0.8569 - val_loss: 0.3580 - val_acc: 0.8574\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3310 - acc: 0.8577 - val_loss: 0.3448 - val_acc: 0.8529\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3372 - acc: 0.8566 - val_loss: 0.3647 - val_acc: 0.8493\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3312 - acc: 0.8600 - val_loss: 0.3609 - val_acc: 0.8604\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3349 - acc: 0.8597 - val_loss: 0.3957 - val_acc: 0.8488\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3428 - acc: 0.8544 - val_loss: 0.3644 - val_acc: 0.8534\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3419 - acc: 0.8545 - val_loss: 0.4093 - val_acc: 0.8299\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3370 - acc: 0.8566 - val_loss: 0.3276 - val_acc: 0.8656\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3345 - acc: 0.8588 - val_loss: 0.3591 - val_acc: 0.8550\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3273 - acc: 0.8602 - val_loss: 0.3434 - val_acc: 0.8631\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3273 - acc: 0.8639 - val_loss: 0.3536 - val_acc: 0.8550\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3388 - acc: 0.8548 - val_loss: 0.3604 - val_acc: 0.8573\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3352 - acc: 0.8555 - val_loss: 0.3359 - val_acc: 0.8663\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3245 - acc: 0.8637 - val_loss: 0.4131 - val_acc: 0.8159\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3300 - acc: 0.8612 - val_loss: 0.3481 - val_acc: 0.8616\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3322 - acc: 0.8602 - val_loss: 0.3556 - val_acc: 0.8594\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3306 - acc: 0.8574 - val_loss: 0.3637 - val_acc: 0.8453\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3200 - acc: 0.8640 - val_loss: 0.3376 - val_acc: 0.8591\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3300 - acc: 0.8602 - val_loss: 0.3499 - val_acc: 0.8555\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3187 - acc: 0.8647 - val_loss: 0.3288 - val_acc: 0.8609\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3301 - acc: 0.8600 - val_loss: 0.3537 - val_acc: 0.8574\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3287 - acc: 0.8621 - val_loss: 0.3479 - val_acc: 0.8619\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3211 - acc: 0.8638 - val_loss: 0.3303 - val_acc: 0.8645\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3222 - acc: 0.8644 - val_loss: 0.3386 - val_acc: 0.8576\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3234 - acc: 0.8629 - val_loss: 0.3339 - val_acc: 0.8596\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3230 - acc: 0.8612 - val_loss: 0.3272 - val_acc: 0.8639\n",
      "Epoch 60/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3209 - acc: 0.8624 - val_loss: 0.3400 - val_acc: 0.8609\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3296 - acc: 0.8617 - val_loss: 0.3383 - val_acc: 0.8659\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3157 - acc: 0.8668 - val_loss: 0.3377 - val_acc: 0.8608\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3212 - acc: 0.8644 - val_loss: 0.3366 - val_acc: 0.8637\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3181 - acc: 0.8655 - val_loss: 0.3310 - val_acc: 0.8611\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3261 - acc: 0.8629 - val_loss: 0.3382 - val_acc: 0.8654\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3189 - acc: 0.8647 - val_loss: 0.3368 - val_acc: 0.8700\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3134 - acc: 0.8684 - val_loss: 0.3322 - val_acc: 0.8656\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3157 - acc: 0.8642 - val_loss: 0.3476 - val_acc: 0.8585\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3179 - acc: 0.8634 - val_loss: 0.3527 - val_acc: 0.8594\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3214 - acc: 0.8638 - val_loss: 0.3405 - val_acc: 0.8641\n",
      "\n",
      "Training process completed in: 0 h 20 m 44 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1287.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1289 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_513 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_513 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_514 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_514 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_515 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_515 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_516 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_516 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_129 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 31s 163ms/step - loss: 0.4916 - acc: 0.7747 - val_loss: 0.4329 - val_acc: 0.8015\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.4146 - acc: 0.8222 - val_loss: 0.4306 - val_acc: 0.8039\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.4037 - acc: 0.8271 - val_loss: 0.4001 - val_acc: 0.8224\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3871 - acc: 0.8336 - val_loss: 0.4151 - val_acc: 0.8381\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3890 - acc: 0.8318 - val_loss: 0.3866 - val_acc: 0.8399\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3756 - acc: 0.8382 - val_loss: 0.3778 - val_acc: 0.8339\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3708 - acc: 0.8417 - val_loss: 0.3696 - val_acc: 0.8401\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3753 - acc: 0.8408 - val_loss: 0.3724 - val_acc: 0.8368\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3606 - acc: 0.8444 - val_loss: 0.3653 - val_acc: 0.8442\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3567 - acc: 0.8475 - val_loss: 0.3805 - val_acc: 0.8484\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3591 - acc: 0.8476 - val_loss: 0.3600 - val_acc: 0.8554\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3528 - acc: 0.8494 - val_loss: 0.3657 - val_acc: 0.8493\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3485 - acc: 0.8514 - val_loss: 0.3702 - val_acc: 0.8548\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3450 - acc: 0.8548 - val_loss: 0.3560 - val_acc: 0.8544\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 22s 117ms/step - loss: 0.3460 - acc: 0.8511 - val_loss: 0.3459 - val_acc: 0.8511\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 22s 117ms/step - loss: 0.3430 - acc: 0.8543 - val_loss: 0.3407 - val_acc: 0.8557\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3487 - acc: 0.8489 - val_loss: 0.3528 - val_acc: 0.8581\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3397 - acc: 0.8566 - val_loss: 0.3392 - val_acc: 0.8620\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3372 - acc: 0.8565 - val_loss: 0.3634 - val_acc: 0.8536\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3327 - acc: 0.8585 - val_loss: 0.3512 - val_acc: 0.8545\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3372 - acc: 0.8571 - val_loss: 0.3648 - val_acc: 0.8414\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3359 - acc: 0.8564 - val_loss: 0.3328 - val_acc: 0.8604\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3337 - acc: 0.8559 - val_loss: 0.3433 - val_acc: 0.8644\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3357 - acc: 0.8586 - val_loss: 0.3313 - val_acc: 0.8609\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3335 - acc: 0.8576 - val_loss: 0.3302 - val_acc: 0.8631\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3281 - acc: 0.8612 - val_loss: 0.3545 - val_acc: 0.8576\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3316 - acc: 0.8591 - val_loss: 0.3269 - val_acc: 0.8610\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3272 - acc: 0.8615 - val_loss: 0.3451 - val_acc: 0.8610\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3261 - acc: 0.8622 - val_loss: 0.3336 - val_acc: 0.8648\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3218 - acc: 0.8630 - val_loss: 0.3381 - val_acc: 0.8647\n",
      "Epoch 31/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3255 - acc: 0.8626 - val_loss: 0.3264 - val_acc: 0.8644\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3231 - acc: 0.8621 - val_loss: 0.3206 - val_acc: 0.8650\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3189 - acc: 0.8652 - val_loss: 0.3254 - val_acc: 0.8689\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 23s 122ms/step - loss: 0.3217 - acc: 0.8648 - val_loss: 0.3314 - val_acc: 0.8615\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3179 - acc: 0.8659 - val_loss: 0.3462 - val_acc: 0.8583\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3157 - acc: 0.8678 - val_loss: 0.3327 - val_acc: 0.8647\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3197 - acc: 0.8664 - val_loss: 0.3242 - val_acc: 0.8638\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3173 - acc: 0.8652 - val_loss: 0.3245 - val_acc: 0.8634\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3197 - acc: 0.8629 - val_loss: 0.3251 - val_acc: 0.8678\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 22s 117ms/step - loss: 0.3181 - acc: 0.8658 - val_loss: 0.3405 - val_acc: 0.8622\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3168 - acc: 0.8671 - val_loss: 0.3227 - val_acc: 0.8654\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3160 - acc: 0.8669 - val_loss: 0.3293 - val_acc: 0.8746\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3149 - acc: 0.8655 - val_loss: 0.3269 - val_acc: 0.8658A: 0s - loss: 0.3150 - acc:\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3090 - acc: 0.8699 - val_loss: 0.3372 - val_acc: 0.8688\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3111 - acc: 0.8697 - val_loss: 0.3217 - val_acc: 0.8656\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3148 - acc: 0.8672 - val_loss: 0.3228 - val_acc: 0.8707\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3090 - acc: 0.8698 - val_loss: 0.3246 - val_acc: 0.8663\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3083 - acc: 0.8708 - val_loss: 0.3168 - val_acc: 0.8669\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3102 - acc: 0.8697 - val_loss: 0.3272 - val_acc: 0.86959\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3070 - acc: 0.8711 - val_loss: 0.3157 - val_acc: 0.8680\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3140 - acc: 0.8667 - val_loss: 0.3041 - val_acc: 0.8745\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3050 - acc: 0.8729 - val_loss: 0.3140 - val_acc: 0.8680\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3121 - acc: 0.8682 - val_loss: 0.3165 - val_acc: 0.8704\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3030 - acc: 0.8723 - val_loss: 0.3168 - val_acc: 0.8670\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.3046 - acc: 0.8739 - val_loss: 0.3633 - val_acc: 0.8593\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 23s 118ms/step - loss: 0.3115 - acc: 0.8697 - val_loss: 0.3292 - val_acc: 0.8690\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3042 - acc: 0.8701 - val_loss: 0.3410 - val_acc: 0.8676\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.3086 - acc: 0.8707 - val_loss: 0.3158 - val_acc: 0.8677\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3032 - acc: 0.8714 - val_loss: 0.3086 - val_acc: 0.8716\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3041 - acc: 0.8722 - val_loss: 0.3558 - val_acc: 0.8579\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3015 - acc: 0.8727 - val_loss: 0.3066 - val_acc: 0.8727\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3034 - acc: 0.8727 - val_loss: 0.3187 - val_acc: 0.8719\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3035 - acc: 0.8726 - val_loss: 0.3303 - val_acc: 0.8699\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3053 - acc: 0.8731 - val_loss: 0.3105 - val_acc: 0.8711\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3082 - acc: 0.8708 - val_loss: 0.3082 - val_acc: 0.8677\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.3002 - acc: 0.8737 - val_loss: 0.3231 - val_acc: 0.8709\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 23s 121ms/step - loss: 0.2985 - acc: 0.8744 - val_loss: 0.3329 - val_acc: 0.8618\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 22s 118ms/step - loss: 0.3019 - acc: 0.8719 - val_loss: 0.3080 - val_acc: 0.8736\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.2922 - acc: 0.8770 - val_loss: 0.3168 - val_acc: 0.8709\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 23s 120ms/step - loss: 0.2995 - acc: 0.8739 - val_loss: 0.3287 - val_acc: 0.8652\n",
      "\n",
      "Training process completed in: 0 h 26 m 38 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1288.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1290 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_517 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_517 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_518 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_518 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_519 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_519 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_520 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_520 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_130 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 140\n",
      "Learning Rate: 0.001\n",
      "Epochs: 40\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 80\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/40\n",
      "190/190 [==============================] - 25s 133ms/step - loss: 0.4788 - acc: 0.7828 - val_loss: 0.4220 - val_acc: 0.8146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.4260 - acc: 0.8174 - val_loss: 0.4535 - val_acc: 0.8278\n",
      "Epoch 3/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3987 - acc: 0.8281 - val_loss: 0.4438 - val_acc: 0.8265\n",
      "Epoch 4/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.4007 - acc: 0.8302 - val_loss: 0.4176 - val_acc: 0.8098\n",
      "Epoch 5/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3938 - acc: 0.8321 - val_loss: 0.3934 - val_acc: 0.8308\n",
      "Epoch 6/40\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3870 - acc: 0.8336 - val_loss: 0.4257 - val_acc: 0.8386\n",
      "Epoch 7/40\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3808 - acc: 0.8374 - val_loss: 0.3838 - val_acc: 0.8365\n",
      "Epoch 8/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3739 - acc: 0.8418 - val_loss: 0.3946 - val_acc: 0.8366\n",
      "Epoch 9/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3802 - acc: 0.8386 - val_loss: 0.3821 - val_acc: 0.8399\n",
      "Epoch 10/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3718 - acc: 0.8420 - val_loss: 0.3752 - val_acc: 0.8434\n",
      "Epoch 11/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3695 - acc: 0.8430 - val_loss: 0.3669 - val_acc: 0.8465\n",
      "Epoch 12/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3669 - acc: 0.8441 - val_loss: 0.4595 - val_acc: 0.8397\n",
      "Epoch 13/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3655 - acc: 0.8455 - val_loss: 0.3793 - val_acc: 0.8433\n",
      "Epoch 14/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3649 - acc: 0.8452 - val_loss: 0.3758 - val_acc: 0.8501\n",
      "Epoch 15/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3636 - acc: 0.8447 - val_loss: 0.3770 - val_acc: 0.8356\n",
      "Epoch 16/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3544 - acc: 0.8472 - val_loss: 0.3730 - val_acc: 0.8503\n",
      "Epoch 17/40\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3536 - acc: 0.8509 - val_loss: 0.3521 - val_acc: 0.8548\n",
      "Epoch 18/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3532 - acc: 0.8496 - val_loss: 0.3655 - val_acc: 0.8533\n",
      "Epoch 19/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3570 - acc: 0.8485 - val_loss: 0.3678 - val_acc: 0.8536\n",
      "Epoch 20/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3500 - acc: 0.8512 - val_loss: 0.3701 - val_acc: 0.8497\n",
      "Epoch 21/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3484 - acc: 0.8520 - val_loss: 0.3887 - val_acc: 0.8364\n",
      "Epoch 22/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3437 - acc: 0.8550 - val_loss: 0.3429 - val_acc: 0.8607\n",
      "Epoch 23/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3403 - acc: 0.8564 - val_loss: 0.3775 - val_acc: 0.8505\n",
      "Epoch 24/40\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3389 - acc: 0.8535 - val_loss: 0.3933 - val_acc: 0.8415\n",
      "Epoch 25/40\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3392 - acc: 0.8585 - val_loss: 0.3488 - val_acc: 0.8523\n",
      "Epoch 26/40\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3398 - acc: 0.8571 - val_loss: 0.3563 - val_acc: 0.8598\n",
      "Epoch 27/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3421 - acc: 0.8552 - val_loss: 0.3464 - val_acc: 0.8480\n",
      "Epoch 28/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3327 - acc: 0.8597 - val_loss: 0.3616 - val_acc: 0.8601\n",
      "Epoch 29/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3316 - acc: 0.8618 - val_loss: 0.3454 - val_acc: 0.8560\n",
      "Epoch 30/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3317 - acc: 0.8616 - val_loss: 0.3627 - val_acc: 0.8475\n",
      "Epoch 31/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3413 - acc: 0.8556 - val_loss: 0.3446 - val_acc: 0.8533\n",
      "Epoch 32/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3383 - acc: 0.8567 - val_loss: 0.3474 - val_acc: 0.8488\n",
      "Epoch 33/40\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3325 - acc: 0.8604 - val_loss: 0.4236 - val_acc: 0.8210\n",
      "Epoch 34/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3368 - acc: 0.8568 - val_loss: 0.3388 - val_acc: 0.8670\n",
      "Epoch 35/40\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3375 - acc: 0.8565 - val_loss: 0.3482 - val_acc: 0.8567\n",
      "Epoch 36/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3316 - acc: 0.8601 - val_loss: 0.3557 - val_acc: 0.8465\n",
      "Epoch 37/40\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3266 - acc: 0.8615 - val_loss: 0.3424 - val_acc: 0.8484\n",
      "Epoch 38/40\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.3326 - acc: 0.8595 - val_loss: 0.3437 - val_acc: 0.8628\n",
      "Epoch 39/40\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3252 - acc: 0.8621 - val_loss: 0.3400 - val_acc: 0.8649\n",
      "Epoch 40/40\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3227 - acc: 0.8642 - val_loss: 0.3454 - val_acc: 0.8573\n",
      "\n",
      "Training process completed in: 0 h 11 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1289.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1291 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_521 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_521 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_522 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_522 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_523 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_523 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_524 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_524 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_131 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 0.5325 - acc: 0.7439 - val_loss: 0.4469 - val_acc: 0.8060\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.4245 - acc: 0.8180 - val_loss: 0.4292 - val_acc: 0.8155\n",
      "Epoch 3/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 92ms/step - loss: 0.4145 - acc: 0.8220 - val_loss: 0.4096 - val_acc: 0.8190\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4116 - acc: 0.8214 - val_loss: 0.4080 - val_acc: 0.8285\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3985 - acc: 0.8288 - val_loss: 0.4083 - val_acc: 0.8095\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3995 - acc: 0.8278 - val_loss: 0.3771 - val_acc: 0.8400\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3981 - acc: 0.8263 - val_loss: 0.3999 - val_acc: 0.8345\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3895 - acc: 0.8310 - val_loss: 0.3915 - val_acc: 0.8245\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3892 - acc: 0.8337 - val_loss: 0.3837 - val_acc: 0.8355\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3883 - acc: 0.8298 - val_loss: 0.3871 - val_acc: 0.8285\n",
      "Epoch 11/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3819 - acc: 0.8350 - val_loss: 0.3607 - val_acc: 0.8440\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3772 - acc: 0.8378 - val_loss: 0.3766 - val_acc: 0.8430\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3732 - acc: 0.8390 - val_loss: 0.3878 - val_acc: 0.8380\n",
      "Epoch 14/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3711 - acc: 0.8393 - val_loss: 0.3612 - val_acc: 0.8412\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3715 - acc: 0.8414 - val_loss: 0.3740 - val_acc: 0.8400\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3709 - acc: 0.8380 - val_loss: 0.3846 - val_acc: 0.8345\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3666 - acc: 0.8441 - val_loss: 0.3803 - val_acc: 0.8410\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3622 - acc: 0.8463 - val_loss: 0.3650 - val_acc: 0.8385\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3617 - acc: 0.8435 - val_loss: 0.3678 - val_acc: 0.8465\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3608 - acc: 0.8445 - val_loss: 0.3511 - val_acc: 0.8440\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3557 - acc: 0.8488 - val_loss: 0.3602 - val_acc: 0.8380\n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3603 - acc: 0.8456 - val_loss: 0.3664 - val_acc: 0.8515\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3547 - acc: 0.8497 - val_loss: 0.3382 - val_acc: 0.8595\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3595 - acc: 0.8439 - val_loss: 0.3389 - val_acc: 0.8525\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3456 - acc: 0.8507 - val_loss: 0.3594 - val_acc: 0.8470\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3424 - acc: 0.8547 - val_loss: 0.3545 - val_acc: 0.8380\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3544 - acc: 0.8501 - val_loss: 0.3321 - val_acc: 0.8640\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3444 - acc: 0.8534 - val_loss: 0.3434 - val_acc: 0.8622\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3474 - acc: 0.8520 - val_loss: 0.3551 - val_acc: 0.8460\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3472 - acc: 0.8537 - val_loss: 0.3265 - val_acc: 0.8600\n",
      "Epoch 31/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3410 - acc: 0.8552 - val_loss: 0.3288 - val_acc: 0.8655\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3394 - acc: 0.8563 - val_loss: 0.3169 - val_acc: 0.8635\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3398 - acc: 0.8560 - val_loss: 0.3297 - val_acc: 0.8590\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3435 - acc: 0.8521 - val_loss: 0.3495 - val_acc: 0.8570\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3388 - acc: 0.8559 - val_loss: 0.3532 - val_acc: 0.8510\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3440 - acc: 0.8529 - val_loss: 0.3624 - val_acc: 0.8465\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3409 - acc: 0.8552 - val_loss: 0.3561 - val_acc: 0.8475\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3394 - acc: 0.8553 - val_loss: 0.3260 - val_acc: 0.8615\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3324 - acc: 0.8585 - val_loss: 0.3283 - val_acc: 0.8650\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3353 - acc: 0.8566 - val_loss: 0.3349 - val_acc: 0.8605\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3333 - acc: 0.8585 - val_loss: 0.3361 - val_acc: 0.8515\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3370 - acc: 0.8564 - val_loss: 0.3351 - val_acc: 0.8586\n",
      "Epoch 43/70\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.3348 - acc: 0.8576 - val_loss: 0.3304 - val_acc: 0.8555\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3280 - acc: 0.8625 - val_loss: 0.3092 - val_acc: 0.8670\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3350 - acc: 0.8575 - val_loss: 0.3212 - val_acc: 0.8655\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3279 - acc: 0.8626 - val_loss: 0.3378 - val_acc: 0.8645\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3315 - acc: 0.8575 - val_loss: 0.3321 - val_acc: 0.8625\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3303 - acc: 0.8594 - val_loss: 0.3546 - val_acc: 0.8460\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3277 - acc: 0.8616 - val_loss: 0.3302 - val_acc: 0.8545\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3277 - acc: 0.8619 - val_loss: 0.3279 - val_acc: 0.8610\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3219 - acc: 0.8625 - val_loss: 0.2967 - val_acc: 0.8740\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3273 - acc: 0.8601 - val_loss: 0.3259 - val_acc: 0.8555\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3284 - acc: 0.8591 - val_loss: 0.3109 - val_acc: 0.8665\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3246 - acc: 0.8606 - val_loss: 0.3272 - val_acc: 0.8610\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3232 - acc: 0.8632 - val_loss: 0.3304 - val_acc: 0.8585\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3216 - acc: 0.8636 - val_loss: 0.3486 - val_acc: 0.8509\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.3262 - acc: 0.8615 - val_loss: 0.3108 - val_acc: 0.8725\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3192 - acc: 0.8651 - val_loss: 0.3546 - val_acc: 0.8485\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3165 - acc: 0.8643 - val_loss: 0.3182 - val_acc: 0.8580\n",
      "Epoch 60/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3202 - acc: 0.8631 - val_loss: 0.3004 - val_acc: 0.8750\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3243 - acc: 0.8637 - val_loss: 0.3300 - val_acc: 0.8710\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3202 - acc: 0.8641 - val_loss: 0.3179 - val_acc: 0.8685\n",
      "Epoch 63/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3214 - acc: 0.8640 - val_loss: 0.3660 - val_acc: 0.8535\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3159 - acc: 0.8667 - val_loss: 0.3149 - val_acc: 0.8675\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3211 - acc: 0.8628 - val_loss: 0.3267 - val_acc: 0.8635\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3157 - acc: 0.8665 - val_loss: 0.3083 - val_acc: 0.8710\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3194 - acc: 0.8654 - val_loss: 0.3087 - val_acc: 0.8675\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3209 - acc: 0.8636 - val_loss: 0.3356 - val_acc: 0.8605\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.3139 - acc: 0.8667 - val_loss: 0.3125 - val_acc: 0.8675\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3099 - acc: 0.8690 - val_loss: 0.3594 - val_acc: 0.8499\n",
      "\n",
      "Training process completed in: 0 h 21 m 40 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1290.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1292 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_525 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_525 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_526 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_526 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_527 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_527 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_528 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_528 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_132 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 0.4781 - acc: 0.7812 - val_loss: 0.4472 - val_acc: 0.8128\n",
      "Epoch 2/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4128 - acc: 0.8246 - val_loss: 0.4201 - val_acc: 0.8232\n",
      "Epoch 3/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3998 - acc: 0.8285 - val_loss: 0.3855 - val_acc: 0.8375\n",
      "Epoch 4/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3933 - acc: 0.8288 - val_loss: 0.3830 - val_acc: 0.8285\n",
      "Epoch 5/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3783 - acc: 0.8371 - val_loss: 0.3812 - val_acc: 0.8343\n",
      "Epoch 6/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3824 - acc: 0.8358 - val_loss: 0.4046 - val_acc: 0.8273\n",
      "Epoch 7/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3746 - acc: 0.8408 - val_loss: 0.4383 - val_acc: 0.8355\n",
      "Epoch 8/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3689 - acc: 0.8404 - val_loss: 0.3774 - val_acc: 0.8485\n",
      "Epoch 9/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3639 - acc: 0.8427 - val_loss: 0.3512 - val_acc: 0.8510\n",
      "Epoch 10/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3645 - acc: 0.8407 - val_loss: 0.4003 - val_acc: 0.8478\n",
      "Epoch 11/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3598 - acc: 0.8452 - val_loss: 0.3988 - val_acc: 0.8407\n",
      "Epoch 12/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3572 - acc: 0.8461 - val_loss: 0.3890 - val_acc: 0.8520\n",
      "Epoch 13/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3456 - acc: 0.8529 - val_loss: 0.3651 - val_acc: 0.8558\n",
      "Epoch 14/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3482 - acc: 0.8521 - val_loss: 0.3636 - val_acc: 0.8515\n",
      "Epoch 15/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3482 - acc: 0.8508 - val_loss: 0.3535 - val_acc: 0.8548\n",
      "Epoch 16/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3469 - acc: 0.8527 - val_loss: 0.3490 - val_acc: 0.8507\n",
      "Epoch 17/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3403 - acc: 0.8552 - val_loss: 0.3480 - val_acc: 0.8598\n",
      "Epoch 18/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3406 - acc: 0.8544 - val_loss: 0.3975 - val_acc: 0.8380\n",
      "Epoch 19/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3463 - acc: 0.8537 - val_loss: 0.3761 - val_acc: 0.8580\n",
      "Epoch 20/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3329 - acc: 0.8585 - val_loss: 0.3441 - val_acc: 0.8575\n",
      "Epoch 21/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3400 - acc: 0.8564 - val_loss: 0.3470 - val_acc: 0.8565\n",
      "Epoch 22/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3375 - acc: 0.8549 - val_loss: 0.3355 - val_acc: 0.8622\n",
      "Epoch 23/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3317 - acc: 0.8581 - val_loss: 0.3780 - val_acc: 0.8435\n",
      "Epoch 24/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3228 - acc: 0.8616 - val_loss: 0.3243 - val_acc: 0.8635\n",
      "Epoch 25/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3307 - acc: 0.8592 - val_loss: 0.3371 - val_acc: 0.8552\n",
      "Epoch 26/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3259 - acc: 0.8631 - val_loss: 0.3660 - val_acc: 0.8598\n",
      "Epoch 27/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3300 - acc: 0.8602 - val_loss: 0.3483 - val_acc: 0.8457\n",
      "Epoch 28/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3308 - acc: 0.8612 - val_loss: 0.3315 - val_acc: 0.8699\n",
      "Epoch 29/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3214 - acc: 0.8640 - val_loss: 0.3438 - val_acc: 0.8608\n",
      "Epoch 30/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3248 - acc: 0.8613 - val_loss: 0.3531 - val_acc: 0.8580\n",
      "Epoch 31/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3258 - acc: 0.8614 - val_loss: 0.3466 - val_acc: 0.8548\n",
      "Epoch 32/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3221 - acc: 0.8635 - val_loss: 0.3476 - val_acc: 0.8575\n",
      "Epoch 33/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3243 - acc: 0.8621 - val_loss: 0.3362 - val_acc: 0.8508\n",
      "Epoch 34/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3182 - acc: 0.8649 - val_loss: 0.3381 - val_acc: 0.8640\n",
      "Epoch 35/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3211 - acc: 0.8633 - val_loss: 0.3274 - val_acc: 0.8808\n",
      "Epoch 36/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3154 - acc: 0.8659 - val_loss: 0.3151 - val_acc: 0.8698\n",
      "Epoch 37/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3139 - acc: 0.8668 - val_loss: 0.3132 - val_acc: 0.8713\n",
      "Epoch 38/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3176 - acc: 0.8668 - val_loss: 0.3439 - val_acc: 0.8637\n",
      "Epoch 39/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3142 - acc: 0.8692 - val_loss: 0.3354 - val_acc: 0.8623\n",
      "Epoch 40/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3138 - acc: 0.8680 - val_loss: 0.3313 - val_acc: 0.8567\n",
      "Epoch 41/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3107 - acc: 0.8665 - val_loss: 0.3323 - val_acc: 0.8585\n",
      "Epoch 42/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3146 - acc: 0.8664 - val_loss: 0.3036 - val_acc: 0.8821\n",
      "Epoch 43/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3060 - acc: 0.8722 - val_loss: 0.3259 - val_acc: 0.8698\n",
      "Epoch 44/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3115 - acc: 0.8689 - val_loss: 0.3195 - val_acc: 0.8713\n",
      "Epoch 45/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3040 - acc: 0.8724 - val_loss: 0.3270 - val_acc: 0.8638\n",
      "Epoch 46/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3101 - acc: 0.8685 - val_loss: 0.3205 - val_acc: 0.8692\n",
      "Epoch 47/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3085 - acc: 0.8679 - val_loss: 0.3238 - val_acc: 0.8695\n",
      "Epoch 48/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3071 - acc: 0.8721 - val_loss: 0.3312 - val_acc: 0.8733\n",
      "Epoch 49/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3114 - acc: 0.8670 - val_loss: 0.3381 - val_acc: 0.8555\n",
      "Epoch 50/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3029 - acc: 0.8723 - val_loss: 0.3158 - val_acc: 0.8677\n",
      "Epoch 51/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2984 - acc: 0.8733 - val_loss: 0.3161 - val_acc: 0.8712\n",
      "Epoch 52/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3064 - acc: 0.8713 - val_loss: 0.3247 - val_acc: 0.8702\n",
      "Epoch 53/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3036 - acc: 0.8731 - val_loss: 0.3220 - val_acc: 0.8678\n",
      "Epoch 54/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3064 - acc: 0.8697 - val_loss: 0.3243 - val_acc: 0.8590\n",
      "Epoch 55/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3052 - acc: 0.8703 - val_loss: 0.3327 - val_acc: 0.8578\n",
      "Epoch 56/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3069 - acc: 0.8707 - val_loss: 0.3158 - val_acc: 0.8730\n",
      "Epoch 57/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2996 - acc: 0.8752 - val_loss: 0.3086 - val_acc: 0.8770\n",
      "Epoch 58/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2982 - acc: 0.8752 - val_loss: 0.3017 - val_acc: 0.8770\n",
      "Epoch 59/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3000 - acc: 0.8733 - val_loss: 0.3255 - val_acc: 0.8672\n",
      "Epoch 60/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3018 - acc: 0.8719 - val_loss: 0.3214 - val_acc: 0.8645\n",
      "Epoch 61/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3022 - acc: 0.8729 - val_loss: 0.3120 - val_acc: 0.8703\n",
      "Epoch 62/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2987 - acc: 0.8753 - val_loss: 0.3142 - val_acc: 0.8745\n",
      "Epoch 63/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2964 - acc: 0.8747 - val_loss: 0.3033 - val_acc: 0.8783\n",
      "Epoch 64/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2989 - acc: 0.8744 - val_loss: 0.3097 - val_acc: 0.8758\n",
      "Epoch 65/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3051 - acc: 0.8709 - val_loss: 0.2944 - val_acc: 0.8815\n",
      "Epoch 66/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3004 - acc: 0.8728 - val_loss: 0.3177 - val_acc: 0.8718\n",
      "Epoch 67/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2968 - acc: 0.8751 - val_loss: 0.3136 - val_acc: 0.8698\n",
      "Epoch 68/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2917 - acc: 0.8769 - val_loss: 0.3124 - val_acc: 0.8718\n",
      "Epoch 69/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2974 - acc: 0.8759 - val_loss: 0.3316 - val_acc: 0.8608\n",
      "Epoch 70/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3002 - acc: 0.8737 - val_loss: 0.3159 - val_acc: 0.8679\n",
      "Epoch 71/90\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.2908 - acc: 0.8788 - val_loss: 0.3125 - val_acc: 0.8735\n",
      "Epoch 72/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2957 - acc: 0.8763 - val_loss: 0.3074 - val_acc: 0.8773\n",
      "Epoch 73/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2944 - acc: 0.8753 - val_loss: 0.3195 - val_acc: 0.8680\n",
      "Epoch 74/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2892 - acc: 0.8787 - val_loss: 0.3164 - val_acc: 0.8688\n",
      "Epoch 75/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2932 - acc: 0.8760 - val_loss: 0.3086 - val_acc: 0.8722\n",
      "Epoch 76/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2921 - acc: 0.8782 - val_loss: 0.3162 - val_acc: 0.8723\n",
      "Epoch 77/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2942 - acc: 0.8744 - val_loss: 0.3252 - val_acc: 0.8697\n",
      "Epoch 78/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2965 - acc: 0.8749 - val_loss: 0.3225 - val_acc: 0.8693\n",
      "Epoch 79/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2898 - acc: 0.8786 - val_loss: 0.3000 - val_acc: 0.8738\n",
      "Epoch 80/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2947 - acc: 0.8748 - val_loss: 0.3128 - val_acc: 0.8737\n",
      "Epoch 81/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2868 - acc: 0.8799 - val_loss: 0.3070 - val_acc: 0.8702\n",
      "Epoch 82/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2944 - acc: 0.8748 - val_loss: 0.3053 - val_acc: 0.8792\n",
      "Epoch 83/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2916 - acc: 0.8781 - val_loss: 0.2989 - val_acc: 0.8780\n",
      "Epoch 84/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2913 - acc: 0.8764 - val_loss: 0.3082 - val_acc: 0.8707\n",
      "Epoch 85/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2910 - acc: 0.8791 - val_loss: 0.3085 - val_acc: 0.8813\n",
      "Epoch 86/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2876 - acc: 0.8786 - val_loss: 0.3180 - val_acc: 0.8660\n",
      "Epoch 87/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2858 - acc: 0.8797 - val_loss: 0.2995 - val_acc: 0.8697\n",
      "Epoch 88/90\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.2899 - acc: 0.8764 - val_loss: 0.2898 - val_acc: 0.8822\n",
      "Epoch 89/90\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2885 - acc: 0.8789 - val_loss: 0.3254 - val_acc: 0.8695\n",
      "Epoch 90/90\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2820 - acc: 0.8825 - val_loss: 0.3218 - val_acc: 0.8595\n",
      "\n",
      "Training process completed in: 0 h 28 m 15 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1291.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1293 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_529 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_529 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_530 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_530 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_531 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_531 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_532 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_532 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_133 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4854 - acc: 0.7822 - val_loss: 0.4543 - val_acc: 0.7930\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.4184 - acc: 0.8232 - val_loss: 0.3853 - val_acc: 0.8290\n",
      "Epoch 3/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.4106 - acc: 0.8247 - val_loss: 0.4398 - val_acc: 0.8080\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3986 - acc: 0.8285 - val_loss: 0.4335 - val_acc: 0.8290\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3967 - acc: 0.8294 - val_loss: 0.4011 - val_acc: 0.8320\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3967 - acc: 0.8298 - val_loss: 0.4081 - val_acc: 0.8350\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3815 - acc: 0.8370 - val_loss: 0.3918 - val_acc: 0.8240\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3778 - acc: 0.8356 - val_loss: 0.3835 - val_acc: 0.8510\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3820 - acc: 0.8354 - val_loss: 0.4155 - val_acc: 0.8250\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3764 - acc: 0.8371 - val_loss: 0.3958 - val_acc: 0.8260\n",
      "Epoch 11/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3826 - acc: 0.8339 - val_loss: 0.3832 - val_acc: 0.8410\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3725 - acc: 0.8378 - val_loss: 0.3663 - val_acc: 0.8490\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3621 - acc: 0.8452 - val_loss: 0.3517 - val_acc: 0.8440\n",
      "Epoch 14/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3658 - acc: 0.8414 - val_loss: 0.3837 - val_acc: 0.8490\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3611 - acc: 0.8467 - val_loss: 0.4002 - val_acc: 0.8400\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3552 - acc: 0.8499 - val_loss: 0.3662 - val_acc: 0.8410\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3540 - acc: 0.8518 - val_loss: 0.3232 - val_acc: 0.8810\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3562 - acc: 0.8472 - val_loss: 0.3411 - val_acc: 0.8680\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3560 - acc: 0.8482 - val_loss: 0.3806 - val_acc: 0.8550\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3484 - acc: 0.8529 - val_loss: 0.3631 - val_acc: 0.8470\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3491 - acc: 0.8515 - val_loss: 0.3741 - val_acc: 0.8360\n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3474 - acc: 0.8530 - val_loss: 0.3477 - val_acc: 0.8480\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3429 - acc: 0.8574 - val_loss: 0.3518 - val_acc: 0.8540\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3430 - acc: 0.8547 - val_loss: 0.3388 - val_acc: 0.8520\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3449 - acc: 0.8527 - val_loss: 0.3678 - val_acc: 0.8390\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3442 - acc: 0.8518 - val_loss: 0.3636 - val_acc: 0.8390\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3349 - acc: 0.8583 - val_loss: 0.3604 - val_acc: 0.8440\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3364 - acc: 0.8579 - val_loss: 0.3866 - val_acc: 0.8214\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3445 - acc: 0.8552 - val_loss: 0.3552 - val_acc: 0.8550\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3291 - acc: 0.8625 - val_loss: 0.3508 - val_acc: 0.8520\n",
      "Epoch 31/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3406 - acc: 0.8573 - val_loss: 0.3321 - val_acc: 0.8690\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3420 - acc: 0.8548 - val_loss: 0.3164 - val_acc: 0.8730\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3351 - acc: 0.8588 - val_loss: 0.3423 - val_acc: 0.8530\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3294 - acc: 0.8606 - val_loss: 0.3179 - val_acc: 0.8580\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3273 - acc: 0.8628 - val_loss: 0.3285 - val_acc: 0.8590\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3348 - acc: 0.8578 - val_loss: 0.3165 - val_acc: 0.8740\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3297 - acc: 0.8605 - val_loss: 0.3327 - val_acc: 0.8610\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3259 - acc: 0.8627 - val_loss: 0.3403 - val_acc: 0.8720\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3273 - acc: 0.8595 - val_loss: 0.3310 - val_acc: 0.8460\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3337 - acc: 0.8576 - val_loss: 0.3296 - val_acc: 0.8600\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3226 - acc: 0.8682 - val_loss: 0.3456 - val_acc: 0.8510\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3250 - acc: 0.8631 - val_loss: 0.3718 - val_acc: 0.8380\n",
      "Epoch 43/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3258 - acc: 0.8619 - val_loss: 0.3370 - val_acc: 0.8560\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3242 - acc: 0.8641 - val_loss: 0.3665 - val_acc: 0.8510\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3269 - acc: 0.8616 - val_loss: 0.3106 - val_acc: 0.8680\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3203 - acc: 0.8626 - val_loss: 0.3496 - val_acc: 0.8410\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3253 - acc: 0.8610 - val_loss: 0.3417 - val_acc: 0.8590\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3243 - acc: 0.8645 - val_loss: 0.3401 - val_acc: 0.8590\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3313 - acc: 0.8588 - val_loss: 0.3363 - val_acc: 0.8660\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3241 - acc: 0.8634 - val_loss: 0.3627 - val_acc: 0.8400\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3258 - acc: 0.8631 - val_loss: 0.3041 - val_acc: 0.8730\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3147 - acc: 0.8667 - val_loss: 0.2908 - val_acc: 0.8800\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3209 - acc: 0.8652 - val_loss: 0.3126 - val_acc: 0.8780\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3228 - acc: 0.8639 - val_loss: 0.3237 - val_acc: 0.8760\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3148 - acc: 0.8687 - val_loss: 0.3436 - val_acc: 0.8480\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3157 - acc: 0.8675 - val_loss: 0.3146 - val_acc: 0.8687\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3184 - acc: 0.8648 - val_loss: 0.3113 - val_acc: 0.8800\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3170 - acc: 0.8660 - val_loss: 0.3244 - val_acc: 0.8720\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3238 - acc: 0.8618 - val_loss: 0.3086 - val_acc: 0.8710\n",
      "Epoch 60/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3168 - acc: 0.8660 - val_loss: 0.3197 - val_acc: 0.8510\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3118 - acc: 0.8690 - val_loss: 0.3292 - val_acc: 0.8570\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3161 - acc: 0.8686 - val_loss: 0.3260 - val_acc: 0.8660\n",
      "Epoch 63/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3148 - acc: 0.8674 - val_loss: 0.3160 - val_acc: 0.8730\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3147 - acc: 0.8667 - val_loss: 0.3284 - val_acc: 0.8650\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3115 - acc: 0.8686 - val_loss: 0.3314 - val_acc: 0.8600\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3234 - acc: 0.8653 - val_loss: 0.3192 - val_acc: 0.8700\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3242 - acc: 0.8639 - val_loss: 0.3098 - val_acc: 0.8670\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3160 - acc: 0.8663 - val_loss: 0.3404 - val_acc: 0.8630\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3123 - acc: 0.8698 - val_loss: 0.2967 - val_acc: 0.8760\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3118 - acc: 0.8678 - val_loss: 0.3429 - val_acc: 0.8580\n",
      "\n",
      "Training process completed in: 0 h 11 m 33 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1292.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1294 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_533 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_533 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_534 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_534 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_535 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_535 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_536 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_536 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_134 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 1e-05\n",
      "Epochs: 70\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 0.6144 - acc: 0.7183 - val_loss: 0.5671 - val_acc: 0.7260\n",
      "Epoch 2/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.5755 - acc: 0.7146 - val_loss: 0.5745 - val_acc: 0.7058\n",
      "Epoch 3/70\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.5573 - acc: 0.7150 - val_loss: 0.5418 - val_acc: 0.7088\n",
      "Epoch 4/70\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.5032 - acc: 0.7363 - val_loss: 0.4662 - val_acc: 0.7817\n",
      "Epoch 5/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4532 - acc: 0.7910 - val_loss: 0.4229 - val_acc: 0.8135\n",
      "Epoch 6/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4345 - acc: 0.8081 - val_loss: 0.4298 - val_acc: 0.8095\n",
      "Epoch 7/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4243 - acc: 0.8157 - val_loss: 0.4150 - val_acc: 0.8196\n",
      "Epoch 8/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4183 - acc: 0.8165 - val_loss: 0.4200 - val_acc: 0.8200\n",
      "Epoch 9/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4111 - acc: 0.8248 - val_loss: 0.4257 - val_acc: 0.8085\n",
      "Epoch 10/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4168 - acc: 0.8194 - val_loss: 0.4265 - val_acc: 0.8085\n",
      "Epoch 11/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4148 - acc: 0.8216 - val_loss: 0.4068 - val_acc: 0.8180\n",
      "Epoch 12/70\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.4107 - acc: 0.8226 - val_loss: 0.4106 - val_acc: 0.8225\n",
      "Epoch 13/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4110 - acc: 0.8228 - val_loss: 0.4199 - val_acc: 0.8173\n",
      "Epoch 14/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4133 - acc: 0.8220 - val_loss: 0.4046 - val_acc: 0.8249\n",
      "Epoch 15/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4116 - acc: 0.8216 - val_loss: 0.4150 - val_acc: 0.8153\n",
      "Epoch 16/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4093 - acc: 0.8226 - val_loss: 0.4213 - val_acc: 0.8095\n",
      "Epoch 17/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4080 - acc: 0.8250 - val_loss: 0.3991 - val_acc: 0.8258\n",
      "Epoch 18/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4070 - acc: 0.8253 - val_loss: 0.4112 - val_acc: 0.8200\n",
      "Epoch 19/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4033 - acc: 0.8282 - val_loss: 0.4162 - val_acc: 0.8153\n",
      "Epoch 20/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4046 - acc: 0.8259 - val_loss: 0.4048 - val_acc: 0.8198\n",
      "Epoch 21/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4053 - acc: 0.8262 - val_loss: 0.4071 - val_acc: 0.8234 ETA: 1s - loss: \n",
      "Epoch 22/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4119 - acc: 0.8225 - val_loss: 0.4146 - val_acc: 0.8145\n",
      "Epoch 23/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4084 - acc: 0.8242 - val_loss: 0.3964 - val_acc: 0.8295\n",
      "Epoch 24/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4044 - acc: 0.8264 - val_loss: 0.4096 - val_acc: 0.8212\n",
      "Epoch 25/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4070 - acc: 0.8248 - val_loss: 0.3951 - val_acc: 0.8283\n",
      "Epoch 26/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4028 - acc: 0.8258 - val_loss: 0.4181 - val_acc: 0.8105\n",
      "Epoch 27/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3980 - acc: 0.8290 - val_loss: 0.4059 - val_acc: 0.8247\n",
      "Epoch 28/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.4009 - acc: 0.8273 - val_loss: 0.3957 - val_acc: 0.8277\n",
      "Epoch 29/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3986 - acc: 0.8309 - val_loss: 0.4141 - val_acc: 0.8200\n",
      "Epoch 30/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3971 - acc: 0.8292 - val_loss: 0.4184 - val_acc: 0.8140\n",
      "Epoch 31/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4014 - acc: 0.8266 - val_loss: 0.4031 - val_acc: 0.8208\n",
      "Epoch 32/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3989 - acc: 0.8276 - val_loss: 0.3962 - val_acc: 0.8308\n",
      "Epoch 33/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4016 - acc: 0.8264 - val_loss: 0.3931 - val_acc: 0.8245\n",
      "Epoch 34/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3996 - acc: 0.8254 - val_loss: 0.3843 - val_acc: 0.8313\n",
      "Epoch 35/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.4019 - acc: 0.8286 - val_loss: 0.4004 - val_acc: 0.8269\n",
      "Epoch 36/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3989 - acc: 0.8280 - val_loss: 0.4052 - val_acc: 0.8195\n",
      "Epoch 37/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3984 - acc: 0.8262 - val_loss: 0.4032 - val_acc: 0.8225\n",
      "Epoch 38/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3940 - acc: 0.8315 - val_loss: 0.4158 - val_acc: 0.8205\n",
      "Epoch 39/70\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3937 - acc: 0.8306 - val_loss: 0.3916 - val_acc: 0.8315\n",
      "Epoch 40/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3971 - acc: 0.8279 - val_loss: 0.3856 - val_acc: 0.8295\n",
      "Epoch 41/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3967 - acc: 0.8281 - val_loss: 0.4016 - val_acc: 0.8252\n",
      "Epoch 42/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3915 - acc: 0.8331 - val_loss: 0.3911 - val_acc: 0.8267\n",
      "Epoch 43/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3926 - acc: 0.8320 - val_loss: 0.3961 - val_acc: 0.8245\n",
      "Epoch 44/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3986 - acc: 0.8269 - val_loss: 0.3968 - val_acc: 0.8317\n",
      "Epoch 45/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3937 - acc: 0.8313 - val_loss: 0.3863 - val_acc: 0.8347\n",
      "Epoch 46/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3969 - acc: 0.8286 - val_loss: 0.4053 - val_acc: 0.8195\n",
      "Epoch 47/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3931 - acc: 0.8296 - val_loss: 0.3833 - val_acc: 0.8338\n",
      "Epoch 48/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3881 - acc: 0.8324 - val_loss: 0.4004 - val_acc: 0.8255\n",
      "Epoch 49/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3920 - acc: 0.8297 - val_loss: 0.3935 - val_acc: 0.8239\n",
      "Epoch 50/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3856 - acc: 0.8367 - val_loss: 0.3800 - val_acc: 0.8388\n",
      "Epoch 51/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3906 - acc: 0.8318 - val_loss: 0.3928 - val_acc: 0.8262\n",
      "Epoch 52/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3871 - acc: 0.8326 - val_loss: 0.3947 - val_acc: 0.8272\n",
      "Epoch 53/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3909 - acc: 0.8316 - val_loss: 0.3898 - val_acc: 0.8280\n",
      "Epoch 54/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3864 - acc: 0.8338 - val_loss: 0.3912 - val_acc: 0.8250\n",
      "Epoch 55/70\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3896 - acc: 0.8326 - val_loss: 0.4031 - val_acc: 0.8203\n",
      "Epoch 56/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3904 - acc: 0.8326 - val_loss: 0.3747 - val_acc: 0.8421\n",
      "Epoch 57/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3845 - acc: 0.8338 - val_loss: 0.3977 - val_acc: 0.8285\n",
      "Epoch 58/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3907 - acc: 0.8316 - val_loss: 0.3989 - val_acc: 0.8240\n",
      "Epoch 59/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3826 - acc: 0.8355 - val_loss: 0.3872 - val_acc: 0.8340\n",
      "Epoch 60/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3901 - acc: 0.8316 - val_loss: 0.3860 - val_acc: 0.8290\n",
      "Epoch 61/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3869 - acc: 0.8327 - val_loss: 0.3852 - val_acc: 0.8325\n",
      "Epoch 62/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3831 - acc: 0.8359 - val_loss: 0.3891 - val_acc: 0.8342\n",
      "Epoch 63/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3842 - acc: 0.8346 - val_loss: 0.3831 - val_acc: 0.8315- acc:\n",
      "Epoch 64/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3838 - acc: 0.8354 - val_loss: 0.3891 - val_acc: 0.8248\n",
      "Epoch 65/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3847 - acc: 0.8328 - val_loss: 0.3918 - val_acc: 0.8218\n",
      "Epoch 66/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3824 - acc: 0.8339 - val_loss: 0.3959 - val_acc: 0.8243\n",
      "Epoch 67/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3836 - acc: 0.8369 - val_loss: 0.3558 - val_acc: 0.84620.836\n",
      "Epoch 68/70\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.3837 - acc: 0.8351 - val_loss: 0.3728 - val_acc: 0.8412\n",
      "Epoch 69/70\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3814 - acc: 0.8374 - val_loss: 0.3946 - val_acc: 0.8325\n",
      "Epoch 70/70\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.3845 - acc: 0.8327 - val_loss: 0.3768 - val_acc: 0.8353\n",
      "\n",
      "Training process completed in: 0 h 22 m 14 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1293.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1295 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_537 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_537 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_538 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_538 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_539 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_539 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_540 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_540 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_135 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 26s 152ms/step - loss: 0.5677 - acc: 0.7184 - val_loss: 0.5104 - val_acc: 0.7554\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 17s 99ms/step - loss: 0.4478 - acc: 0.8024 - val_loss: 0.4150 - val_acc: 0.8211\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.4223 - acc: 0.8179 - val_loss: 0.4185 - val_acc: 0.8178\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.4155 - acc: 0.8233 - val_loss: 0.4095 - val_acc: 0.8230\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.4133 - acc: 0.8238 - val_loss: 0.4061 - val_acc: 0.8250\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.4021 - acc: 0.8297 - val_loss: 0.4074 - val_acc: 0.8209\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.4091 - acc: 0.8258 - val_loss: 0.4360 - val_acc: 0.8100\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.4014 - acc: 0.8298 - val_loss: 0.4032 - val_acc: 0.8269\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3984 - acc: 0.8299 - val_loss: 0.4007 - val_acc: 0.8248\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3968 - acc: 0.8283 - val_loss: 0.3941 - val_acc: 0.8283\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3920 - acc: 0.8320 - val_loss: 0.3926 - val_acc: 0.8261\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3955 - acc: 0.8312 - val_loss: 0.3932 - val_acc: 0.8343\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3927 - acc: 0.8315 - val_loss: 0.4100 - val_acc: 0.8232\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3933 - acc: 0.8327 - val_loss: 0.3929 - val_acc: 0.8306\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3889 - acc: 0.8339 - val_loss: 0.3833 - val_acc: 0.8362\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3862 - acc: 0.8357 - val_loss: 0.3831 - val_acc: 0.8322\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3790 - acc: 0.8414 - val_loss: 0.3823 - val_acc: 0.8330\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3826 - acc: 0.8352 - val_loss: 0.3836 - val_acc: 0.8354\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3782 - acc: 0.8381 - val_loss: 0.3792 - val_acc: 0.8359\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3768 - acc: 0.8391 - val_loss: 0.3813 - val_acc: 0.8357\n",
      "Epoch 21/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3808 - acc: 0.8389 - val_loss: 0.3849 - val_acc: 0.8348\n",
      "Epoch 22/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3775 - acc: 0.8375 - val_loss: 0.3883 - val_acc: 0.8355\n",
      "Epoch 23/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3736 - acc: 0.8390 - val_loss: 0.3658 - val_acc: 0.8399\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3755 - acc: 0.8390 - val_loss: 0.3668 - val_acc: 0.8432\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3752 - acc: 0.8406 - val_loss: 0.3672 - val_acc: 0.8403\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3633 - acc: 0.8448 - val_loss: 0.3645 - val_acc: 0.8409\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3677 - acc: 0.8452 - val_loss: 0.3692 - val_acc: 0.8414\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3675 - acc: 0.8429 - val_loss: 0.3750 - val_acc: 0.8406\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3618 - acc: 0.8468 - val_loss: 0.3595 - val_acc: 0.8486\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3713 - acc: 0.8429 - val_loss: 0.3686 - val_acc: 0.8450\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3615 - acc: 0.8480 - val_loss: 0.3634 - val_acc: 0.8406\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3583 - acc: 0.8481 - val_loss: 0.3549 - val_acc: 0.8517\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3610 - acc: 0.8493 - val_loss: 0.3697 - val_acc: 0.8420\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3587 - acc: 0.8484 - val_loss: 0.3685 - val_acc: 0.8403\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3584 - acc: 0.8470 - val_loss: 0.3598 - val_acc: 0.8437\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3572 - acc: 0.8514 - val_loss: 0.3601 - val_acc: 0.8459\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3541 - acc: 0.8501 - val_loss: 0.3524 - val_acc: 0.8576\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3556 - acc: 0.8492 - val_loss: 0.3565 - val_acc: 0.8516\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3492 - acc: 0.8513 - val_loss: 0.3487 - val_acc: 0.8557\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3513 - acc: 0.8502 - val_loss: 0.3559 - val_acc: 0.8540\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3527 - acc: 0.8519 - val_loss: 0.3510 - val_acc: 0.8510\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3525 - acc: 0.8505 - val_loss: 0.3547 - val_acc: 0.8499\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3463 - acc: 0.8560 - val_loss: 0.3568 - val_acc: 0.8459\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3503 - acc: 0.8516 - val_loss: 0.3473 - val_acc: 0.8562\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3486 - acc: 0.8520 - val_loss: 0.3534 - val_acc: 0.8520\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3448 - acc: 0.8536 - val_loss: 0.3407 - val_acc: 0.8546\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3461 - acc: 0.8529 - val_loss: 0.3474 - val_acc: 0.8511\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3403 - acc: 0.8567 - val_loss: 0.3477 - val_acc: 0.8539\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3445 - acc: 0.8529 - val_loss: 0.3426 - val_acc: 0.8582\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3370 - acc: 0.8597 - val_loss: 0.3380 - val_acc: 0.8583\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3513 - acc: 0.8496 - val_loss: 0.3515 - val_acc: 0.8528\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3426 - acc: 0.8553 - val_loss: 0.3381 - val_acc: 0.8609\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3405 - acc: 0.8550 - val_loss: 0.3503 - val_acc: 0.8484\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3392 - acc: 0.8585 - val_loss: 0.3377 - val_acc: 0.8578\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3410 - acc: 0.8549 - val_loss: 0.3425 - val_acc: 0.8564\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3356 - acc: 0.8585 - val_loss: 0.3425 - val_acc: 0.8547\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3385 - acc: 0.8555 - val_loss: 0.3365 - val_acc: 0.8576\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3369 - acc: 0.8573 - val_loss: 0.3457 - val_acc: 0.8530\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3437 - acc: 0.8550 - val_loss: 0.3498 - val_acc: 0.8546\n",
      "Epoch 60/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3380 - acc: 0.8563 - val_loss: 0.3334 - val_acc: 0.8576\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3277 - acc: 0.8625 - val_loss: 0.3344 - val_acc: 0.8598\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3342 - acc: 0.8583 - val_loss: 0.3356 - val_acc: 0.8635\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3361 - acc: 0.8581 - val_loss: 0.3253 - val_acc: 0.8623\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3325 - acc: 0.8592 - val_loss: 0.3617 - val_acc: 0.8467\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3342 - acc: 0.8597 - val_loss: 0.3390 - val_acc: 0.8588\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3207 - acc: 0.8657 - val_loss: 0.3410 - val_acc: 0.8548\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3321 - acc: 0.8601 - val_loss: 0.3331 - val_acc: 0.8567\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3376 - acc: 0.8551 - val_loss: 0.3289 - val_acc: 0.8644\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3323 - acc: 0.8592 - val_loss: 0.3410 - val_acc: 0.8560\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3327 - acc: 0.8592 - val_loss: 0.3293 - val_acc: 0.8617\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3270 - acc: 0.8632 - val_loss: 0.3259 - val_acc: 0.8616\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3248 - acc: 0.8630 - val_loss: 0.3370 - val_acc: 0.8569\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3263 - acc: 0.8632 - val_loss: 0.3262 - val_acc: 0.8657\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3252 - acc: 0.8617 - val_loss: 0.3238 - val_acc: 0.8622\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3271 - acc: 0.8601 - val_loss: 0.3326 - val_acc: 0.8585\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3307 - acc: 0.8591 - val_loss: 0.3314 - val_acc: 0.8587\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3160 - acc: 0.8678 - val_loss: 0.3256 - val_acc: 0.8624\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.3274 - acc: 0.8609 - val_loss: 0.3319 - val_acc: 0.8625\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3264 - acc: 0.8637 - val_loss: 0.3350 - val_acc: 0.8623\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.3211 - acc: 0.8643 - val_loss: 0.3251 - val_acc: 0.8649\n",
      "\n",
      "Training process completed in: 0 h 22 m 58 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1294.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1296 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_541 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_541 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_542 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_542 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_543 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_543 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_544 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_544 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_136 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 170\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "170/170 [==============================] - 27s 157ms/step - loss: 0.4842 - acc: 0.7750 - val_loss: 0.4230 - val_acc: 0.8154\n",
      "Epoch 2/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.4173 - acc: 0.8200 - val_loss: 0.4109 - val_acc: 0.8269\n",
      "Epoch 3/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.4044 - acc: 0.8260 - val_loss: 0.4304 - val_acc: 0.8272\n",
      "Epoch 4/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3962 - acc: 0.8313 - val_loss: 0.4058 - val_acc: 0.8332\n",
      "Epoch 5/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3942 - acc: 0.8336 - val_loss: 0.4506 - val_acc: 0.8300\n",
      "Epoch 6/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3835 - acc: 0.8358 - val_loss: 0.4448 - val_acc: 0.8298\n",
      "Epoch 7/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.3836 - acc: 0.8340 - val_loss: 0.3746 - val_acc: 0.8433\n",
      "Epoch 8/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3775 - acc: 0.8401 - val_loss: 0.4350 - val_acc: 0.8367\n",
      "Epoch 9/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3702 - acc: 0.8425 - val_loss: 0.3998 - val_acc: 0.8365\n",
      "Epoch 10/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3667 - acc: 0.8412 - val_loss: 0.3678 - val_acc: 0.8397\n",
      "Epoch 11/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3635 - acc: 0.8438 - val_loss: 0.3863 - val_acc: 0.8509\n",
      "Epoch 12/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3621 - acc: 0.8456 - val_loss: 0.3696 - val_acc: 0.8497\n",
      "Epoch 13/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3643 - acc: 0.8439 - val_loss: 0.3621 - val_acc: 0.8490\n",
      "Epoch 14/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3599 - acc: 0.8459 - val_loss: 0.3616 - val_acc: 0.8481\n",
      "Epoch 15/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3534 - acc: 0.8503 - val_loss: 0.3734 - val_acc: 0.8493\n",
      "Epoch 16/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3508 - acc: 0.8515 - val_loss: 0.3728 - val_acc: 0.8431\n",
      "Epoch 17/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3473 - acc: 0.8524 - val_loss: 0.3712 - val_acc: 0.8418\n",
      "Epoch 18/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3501 - acc: 0.8511 - val_loss: 0.3880 - val_acc: 0.8420\n",
      "Epoch 19/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3464 - acc: 0.8530 - val_loss: 0.4267 - val_acc: 0.8199\n",
      "Epoch 20/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3407 - acc: 0.8543 - val_loss: 0.3445 - val_acc: 0.8614\n",
      "Epoch 21/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3410 - acc: 0.8536 - val_loss: 0.3497 - val_acc: 0.8520\n",
      "Epoch 22/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3429 - acc: 0.8541 - val_loss: 0.3529 - val_acc: 0.8574\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3437 - acc: 0.8536 - val_loss: 0.3531 - val_acc: 0.8606\n",
      "Epoch 24/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3351 - acc: 0.8586 - val_loss: 0.3539 - val_acc: 0.8571\n",
      "Epoch 25/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3374 - acc: 0.8564 - val_loss: 0.3546 - val_acc: 0.8604\n",
      "Epoch 26/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3312 - acc: 0.8599 - val_loss: 0.3424 - val_acc: 0.8628\n",
      "Epoch 27/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3281 - acc: 0.8614 - val_loss: 0.3513 - val_acc: 0.8545\n",
      "Epoch 28/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3290 - acc: 0.8614 - val_loss: 0.3283 - val_acc: 0.8704\n",
      "Epoch 29/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3342 - acc: 0.8585 - val_loss: 0.3737 - val_acc: 0.8646\n",
      "Epoch 30/80\n",
      "170/170 [==============================] - 18s 107ms/step - loss: 0.3290 - acc: 0.8616 - val_loss: 0.3441 - val_acc: 0.8637\n",
      "Epoch 31/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3244 - acc: 0.8617 - val_loss: 0.3660 - val_acc: 0.8609\n",
      "Epoch 32/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.3269 - acc: 0.8625 - val_loss: 0.3357 - val_acc: 0.8583\n",
      "Epoch 33/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3281 - acc: 0.8599 - val_loss: 0.3712 - val_acc: 0.8592\n",
      "Epoch 34/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3281 - acc: 0.8593 - val_loss: 0.3724 - val_acc: 0.8551\n",
      "Epoch 35/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3200 - acc: 0.8660 - val_loss: 0.3476 - val_acc: 0.8631\n",
      "Epoch 36/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3258 - acc: 0.8625 - val_loss: 0.3444 - val_acc: 0.8711\n",
      "Epoch 37/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3331 - acc: 0.8603 - val_loss: 0.3501 - val_acc: 0.8643\n",
      "Epoch 38/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3217 - acc: 0.8614 - val_loss: 0.3616 - val_acc: 0.8584\n",
      "Epoch 39/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3182 - acc: 0.8647 - val_loss: 0.3545 - val_acc: 0.8643\n",
      "Epoch 40/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3223 - acc: 0.8648 - val_loss: 0.3377 - val_acc: 0.8630\n",
      "Epoch 41/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3158 - acc: 0.8643 - val_loss: 0.3291 - val_acc: 0.8678\n",
      "Epoch 42/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3113 - acc: 0.8713 - val_loss: 0.3261 - val_acc: 0.8682\n",
      "Epoch 43/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3271 - acc: 0.8605 - val_loss: 0.3473 - val_acc: 0.8640\n",
      "Epoch 44/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3173 - acc: 0.8656 - val_loss: 0.3394 - val_acc: 0.8680\n",
      "Epoch 45/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3123 - acc: 0.8675 - val_loss: 0.3645 - val_acc: 0.8631\n",
      "Epoch 46/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3123 - acc: 0.8699 - val_loss: 0.3598 - val_acc: 0.8564\n",
      "Epoch 47/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3198 - acc: 0.8636 - val_loss: 0.3312 - val_acc: 0.8671\n",
      "Epoch 48/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3181 - acc: 0.8651 - val_loss: 0.3305 - val_acc: 0.8675\n",
      "Epoch 49/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3099 - acc: 0.8689 - val_loss: 0.3246 - val_acc: 0.8678\n",
      "Epoch 50/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3153 - acc: 0.8672 - val_loss: 0.3267 - val_acc: 0.8656\n",
      "Epoch 51/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3084 - acc: 0.8698 - val_loss: 0.3249 - val_acc: 0.8657\n",
      "Epoch 52/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3042 - acc: 0.8702 - val_loss: 0.3244 - val_acc: 0.8681\n",
      "Epoch 53/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3091 - acc: 0.8721 - val_loss: 0.3240 - val_acc: 0.8702\n",
      "Epoch 54/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3164 - acc: 0.8660 - val_loss: 0.3296 - val_acc: 0.8741\n",
      "Epoch 55/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3107 - acc: 0.8706 - val_loss: 0.3330 - val_acc: 0.8725\n",
      "Epoch 56/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3105 - acc: 0.8698 - val_loss: 0.3335 - val_acc: 0.8699\n",
      "Epoch 57/80\n",
      "170/170 [==============================] - 17s 103ms/step - loss: 0.3074 - acc: 0.8686 - val_loss: 0.3393 - val_acc: 0.8604\n",
      "Epoch 58/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3132 - acc: 0.8686 - val_loss: 0.3485 - val_acc: 0.8610\n",
      "Epoch 59/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3087 - acc: 0.8680 - val_loss: 0.3341 - val_acc: 0.8692\n",
      "Epoch 60/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3059 - acc: 0.8721 - val_loss: 0.3394 - val_acc: 0.8649\n",
      "Epoch 61/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3097 - acc: 0.8682 - val_loss: 0.3254 - val_acc: 0.8596\n",
      "Epoch 62/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3019 - acc: 0.8742 - val_loss: 0.3255 - val_acc: 0.8719\n",
      "Epoch 63/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3070 - acc: 0.8708 - val_loss: 0.3360 - val_acc: 0.8644\n",
      "Epoch 64/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3094 - acc: 0.8701 - val_loss: 0.3274 - val_acc: 0.8687\n",
      "Epoch 65/80\n",
      "170/170 [==============================] - 18s 103ms/step - loss: 0.3057 - acc: 0.8712 - val_loss: 0.3361 - val_acc: 0.8688\n",
      "Epoch 66/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3105 - acc: 0.8697 - val_loss: 0.3272 - val_acc: 0.8622\n",
      "Epoch 67/80\n",
      "170/170 [==============================] - 18s 105ms/step - loss: 0.3018 - acc: 0.8732 - val_loss: 0.3105 - val_acc: 0.8690\n",
      "Epoch 68/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3070 - acc: 0.8721 - val_loss: 0.3199 - val_acc: 0.8714\n",
      "Epoch 69/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.2952 - acc: 0.8762 - val_loss: 0.3452 - val_acc: 0.8611\n",
      "Epoch 70/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3088 - acc: 0.8720 - val_loss: 0.3377 - val_acc: 0.8652\n",
      "Epoch 71/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3033 - acc: 0.8714 - val_loss: 0.3249 - val_acc: 0.8741\n",
      "Epoch 72/80\n",
      "170/170 [==============================] - 17s 102ms/step - loss: 0.3028 - acc: 0.8733 - val_loss: 0.3445 - val_acc: 0.8588\n",
      "Epoch 73/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3031 - acc: 0.8729 - val_loss: 0.3047 - val_acc: 0.8727\n",
      "Epoch 74/80\n",
      "170/170 [==============================] - 18s 107ms/step - loss: 0.3061 - acc: 0.8703 - val_loss: 0.3441 - val_acc: 0.8581\n",
      "Epoch 75/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.3016 - acc: 0.8732 - val_loss: 0.3231 - val_acc: 0.8713\n",
      "Epoch 76/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3025 - acc: 0.8726 - val_loss: 0.3273 - val_acc: 0.8649\n",
      "Epoch 77/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.2978 - acc: 0.8745 - val_loss: 0.3281 - val_acc: 0.8656\n",
      "Epoch 78/80\n",
      "170/170 [==============================] - 18s 104ms/step - loss: 0.3017 - acc: 0.8725 - val_loss: 0.3771 - val_acc: 0.8350\n",
      "Epoch 79/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.3044 - acc: 0.8723 - val_loss: 0.3240 - val_acc: 0.8727\n",
      "Epoch 80/80\n",
      "170/170 [==============================] - 18s 106ms/step - loss: 0.2962 - acc: 0.8767 - val_loss: 0.3419 - val_acc: 0.8596\n",
      "\n",
      "Training process completed in: 0 h 23 m 46 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1295.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1297 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_545 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_545 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_546 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_546 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_547 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_547 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_548 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_548 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_137 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 25s 159ms/step - loss: 0.4713 - acc: 0.7869 - val_loss: 0.4252 - val_acc: 0.8280\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.4167 - acc: 0.8252 - val_loss: 0.4157 - val_acc: 0.8136\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.4060 - acc: 0.8283 - val_loss: 0.4216 - val_acc: 0.8157\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.4004 - acc: 0.8283 - val_loss: 0.3886 - val_acc: 0.8293\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3886 - acc: 0.8346 - val_loss: 0.3705 - val_acc: 0.8412\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3837 - acc: 0.8327 - val_loss: 0.3747 - val_acc: 0.8393\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3836 - acc: 0.8367 - val_loss: 0.3828 - val_acc: 0.8310\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3790 - acc: 0.8380 - val_loss: 0.4005 - val_acc: 0.8231\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3694 - acc: 0.8414 - val_loss: 0.3696 - val_acc: 0.8373\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3737 - acc: 0.8402 - val_loss: 0.3642 - val_acc: 0.8464\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3648 - acc: 0.8436 - val_loss: 0.3645 - val_acc: 0.8442\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3605 - acc: 0.8442 - val_loss: 0.3505 - val_acc: 0.8540\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3553 - acc: 0.8474 - val_loss: 0.3569 - val_acc: 0.8523\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3544 - acc: 0.8503 - val_loss: 0.3807 - val_acc: 0.8433\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.3591 - acc: 0.8479 - val_loss: 0.3627 - val_acc: 0.8386\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3532 - acc: 0.8504 - val_loss: 0.3674 - val_acc: 0.8485\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3485 - acc: 0.8505 - val_loss: 0.3454 - val_acc: 0.8551\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3447 - acc: 0.8547 - val_loss: 0.3549 - val_acc: 0.8446\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3503 - acc: 0.8523 - val_loss: 0.3516 - val_acc: 0.8458\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3416 - acc: 0.8543 - val_loss: 0.3486 - val_acc: 0.8548\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3445 - acc: 0.8534 - val_loss: 0.3361 - val_acc: 0.8571\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.3495 - acc: 0.8502 - val_loss: 0.3530 - val_acc: 0.8423\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3389 - acc: 0.8551 - val_loss: 0.3318 - val_acc: 0.8609\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3450 - acc: 0.8516 - val_loss: 0.3452 - val_acc: 0.8579\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3389 - acc: 0.8557 - val_loss: 0.3391 - val_acc: 0.8528\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3355 - acc: 0.8589 - val_loss: 0.3318 - val_acc: 0.8644\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3384 - acc: 0.8562 - val_loss: 0.3437 - val_acc: 0.8604\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3324 - acc: 0.8594 - val_loss: 0.3879 - val_acc: 0.8373\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3347 - acc: 0.8550 - val_loss: 0.3563 - val_acc: 0.8547\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.3323 - acc: 0.8601 - val_loss: 0.3818 - val_acc: 0.8343\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3322 - acc: 0.8595 - val_loss: 0.3574 - val_acc: 0.8568\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3280 - acc: 0.8621 - val_loss: 0.3558 - val_acc: 0.8536\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3194 - acc: 0.8645 - val_loss: 0.3306 - val_acc: 0.8626\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3240 - acc: 0.8645 - val_loss: 0.3399 - val_acc: 0.8624\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3258 - acc: 0.8628 - val_loss: 0.3464 - val_acc: 0.8557\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3257 - acc: 0.8614 - val_loss: 0.3210 - val_acc: 0.8617\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3275 - acc: 0.8627 - val_loss: 0.3359 - val_acc: 0.8628\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3262 - acc: 0.8630 - val_loss: 0.3387 - val_acc: 0.8623\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3224 - acc: 0.8652 - val_loss: 0.3193 - val_acc: 0.8632\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3198 - acc: 0.8661 - val_loss: 0.3373 - val_acc: 0.8566\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3234 - acc: 0.8647 - val_loss: 0.3393 - val_acc: 0.8563\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3242 - acc: 0.8645 - val_loss: 0.3630 - val_acc: 0.8562\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3196 - acc: 0.8650 - val_loss: 0.3202 - val_acc: 0.8682\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3195 - acc: 0.8645 - val_loss: 0.3312 - val_acc: 0.8583\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3230 - acc: 0.8635 - val_loss: 0.3481 - val_acc: 0.8518\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3198 - acc: 0.8660 - val_loss: 0.3277 - val_acc: 0.8678\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3199 - acc: 0.8655 - val_loss: 0.3204 - val_acc: 0.8662\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3203 - acc: 0.8647 - val_loss: 0.3402 - val_acc: 0.8573\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3163 - acc: 0.8657 - val_loss: 0.3320 - val_acc: 0.8627\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3059 - acc: 0.8707 - val_loss: 0.3146 - val_acc: 0.8691\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3179 - acc: 0.8678 - val_loss: 0.3230 - val_acc: 0.8630\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3202 - acc: 0.8647 - val_loss: 0.3151 - val_acc: 0.8714\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3139 - acc: 0.8681 - val_loss: 0.3327 - val_acc: 0.8656\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3170 - acc: 0.8651 - val_loss: 0.3242 - val_acc: 0.8686\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3199 - acc: 0.8657 - val_loss: 0.3211 - val_acc: 0.8680\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3111 - acc: 0.8703 - val_loss: 0.3184 - val_acc: 0.8718\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3174 - acc: 0.8679 - val_loss: 0.3262 - val_acc: 0.8612\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3097 - acc: 0.8683 - val_loss: 0.3288 - val_acc: 0.8684\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3074 - acc: 0.8714 - val_loss: 0.3295 - val_acc: 0.8651\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3024 - acc: 0.8722 - val_loss: 0.3130 - val_acc: 0.8678\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3147 - acc: 0.8685 - val_loss: 0.3294 - val_acc: 0.8648\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3128 - acc: 0.8664 - val_loss: 0.3104 - val_acc: 0.8718\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 16s 103ms/step - loss: 0.3006 - acc: 0.8742 - val_loss: 0.3278 - val_acc: 0.8641\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3078 - acc: 0.8691 - val_loss: 0.3240 - val_acc: 0.8683\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3111 - acc: 0.8687 - val_loss: 0.3301 - val_acc: 0.8631\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 17s 103ms/step - loss: 0.3029 - acc: 0.8722 - val_loss: 0.3109 - val_acc: 0.8751\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3097 - acc: 0.8689 - val_loss: 0.3317 - val_acc: 0.8583\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3070 - acc: 0.8719 - val_loss: 0.3209 - val_acc: 0.8600\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3100 - acc: 0.8696 - val_loss: 0.3225 - val_acc: 0.8699\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3069 - acc: 0.8662 - val_loss: 0.3311 - val_acc: 0.8648\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2972 - acc: 0.8766 - val_loss: 0.3213 - val_acc: 0.8654\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3058 - acc: 0.8726 - val_loss: 0.3101 - val_acc: 0.8694\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3078 - acc: 0.8726 - val_loss: 0.3486 - val_acc: 0.8616\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3045 - acc: 0.8719 - val_loss: 0.3139 - val_acc: 0.8674\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2971 - acc: 0.8770 - val_loss: 0.3187 - val_acc: 0.8699\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.3060 - acc: 0.8701 - val_loss: 0.3130 - val_acc: 0.8704\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3055 - acc: 0.8718 - val_loss: 0.3185 - val_acc: 0.8708\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2970 - acc: 0.8753 - val_loss: 0.3335 - val_acc: 0.8686\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2993 - acc: 0.8749 - val_loss: 0.3293 - val_acc: 0.8657\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3114 - val_acc: 0.8786\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3026 - acc: 0.8726 - val_loss: 0.3113 - val_acc: 0.8702\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.3002 - acc: 0.8714 - val_loss: 0.3160 - val_acc: 0.8723\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3257 - val_acc: 0.8658\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.3042 - acc: 0.8730 - val_loss: 0.3196 - val_acc: 0.8725\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3011 - acc: 0.8724 - val_loss: 0.3104 - val_acc: 0.8712\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2966 - acc: 0.8764 - val_loss: 0.3046 - val_acc: 0.8757\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.3045 - acc: 0.8731 - val_loss: 0.3240 - val_acc: 0.8712\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2930 - acc: 0.8785 - val_loss: 0.3020 - val_acc: 0.8778\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.2899 - acc: 0.8789 - val_loss: 0.3076 - val_acc: 0.8706\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2983 - acc: 0.8745 - val_loss: 0.3117 - val_acc: 0.8674\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.2989 - acc: 0.8752 - val_loss: 0.3201 - val_acc: 0.8688\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.2949 - acc: 0.8775 - val_loss: 0.3122 - val_acc: 0.8780\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.3032 - acc: 0.8729 - val_loss: 0.3038 - val_acc: 0.8745\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2928 - acc: 0.8787 - val_loss: 0.3143 - val_acc: 0.8683\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2956 - acc: 0.8767 - val_loss: 0.3004 - val_acc: 0.8744\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2998 - acc: 0.8734 - val_loss: 0.3254 - val_acc: 0.8693\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2956 - acc: 0.8746 - val_loss: 0.3080 - val_acc: 0.8695\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.2955 - acc: 0.8774 - val_loss: 0.3145 - val_acc: 0.8729\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.2967 - acc: 0.8739 - val_loss: 0.3161 - val_acc: 0.8710\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.2939 - acc: 0.8774 - val_loss: 0.2984 - val_acc: 0.8769\n",
      "\n",
      "Training process completed in: 0 h 27 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1296.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1298 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_549 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_549 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_550 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_550 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_551 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_551 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_552 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_552 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_138 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 160\n",
      "Validation Steps: 60\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "160/160 [==============================] - 20s 123ms/step - loss: 0.4935 - acc: 0.7744 - val_loss: 0.4456 - val_acc: 0.8197\n",
      "Epoch 2/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4277 - acc: 0.8184 - val_loss: 0.4266 - val_acc: 0.8097\n",
      "Epoch 3/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.4105 - acc: 0.8276 - val_loss: 0.4142 - val_acc: 0.8235\n",
      "Epoch 4/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4124 - acc: 0.8234 - val_loss: 0.4222 - val_acc: 0.8232\n",
      "Epoch 5/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3975 - acc: 0.8331 - val_loss: 0.3935 - val_acc: 0.8303\n",
      "Epoch 6/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.4005 - acc: 0.8259 - val_loss: 0.3835 - val_acc: 0.8295\n",
      "Epoch 7/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3857 - acc: 0.8331 - val_loss: 0.3933 - val_acc: 0.8298\n",
      "Epoch 8/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3930 - acc: 0.8298 - val_loss: 0.3962 - val_acc: 0.8330\n",
      "Epoch 9/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3964 - acc: 0.8302 - val_loss: 0.4139 - val_acc: 0.8338\n",
      "Epoch 10/80\n",
      "160/160 [==============================] - 10s 65ms/step - loss: 0.3835 - acc: 0.8353 - val_loss: 0.3964 - val_acc: 0.8343\n",
      "Epoch 11/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3847 - acc: 0.8306 - val_loss: 0.3783 - val_acc: 0.8387\n",
      "Epoch 12/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3784 - acc: 0.8394 - val_loss: 0.3916 - val_acc: 0.8340\n",
      "Epoch 13/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3848 - acc: 0.8357 - val_loss: 0.4331 - val_acc: 0.8305\n",
      "Epoch 14/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3779 - acc: 0.8369 - val_loss: 0.3979 - val_acc: 0.8424\n",
      "Epoch 15/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3805 - acc: 0.8397 - val_loss: 0.3960 - val_acc: 0.8422\n",
      "Epoch 16/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3739 - acc: 0.8379 - val_loss: 0.3626 - val_acc: 0.8405\n",
      "Epoch 17/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3694 - acc: 0.8439 - val_loss: 0.3606 - val_acc: 0.8475\n",
      "Epoch 18/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3706 - acc: 0.8408 - val_loss: 0.4266 - val_acc: 0.8290\n",
      "Epoch 19/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3655 - acc: 0.8469 - val_loss: 0.3878 - val_acc: 0.8397\n",
      "Epoch 20/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3649 - acc: 0.8452 - val_loss: 0.3700 - val_acc: 0.8453\n",
      "Epoch 21/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3620 - acc: 0.8451 - val_loss: 0.3633 - val_acc: 0.8492\n",
      "Epoch 22/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3650 - acc: 0.8437 - val_loss: 0.3607 - val_acc: 0.8472\n",
      "Epoch 23/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3498 - acc: 0.8468 - val_loss: 0.3604 - val_acc: 0.8542\n",
      "Epoch 24/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3566 - acc: 0.8454 - val_loss: 0.3546 - val_acc: 0.8557\n",
      "Epoch 25/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3435 - acc: 0.8526 - val_loss: 0.3845 - val_acc: 0.8385\n",
      "Epoch 26/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3569 - acc: 0.8456 - val_loss: 0.3671 - val_acc: 0.8543\n",
      "Epoch 27/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3477 - acc: 0.8528 - val_loss: 0.3472 - val_acc: 0.8488\n",
      "Epoch 28/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3554 - acc: 0.8510 - val_loss: 0.3583 - val_acc: 0.8538\n",
      "Epoch 29/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3434 - acc: 0.8533 - val_loss: 0.3678 - val_acc: 0.8400\n",
      "Epoch 30/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3448 - acc: 0.8533 - val_loss: 0.3493 - val_acc: 0.8505\n",
      "Epoch 31/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3522 - acc: 0.8499 - val_loss: 0.3779 - val_acc: 0.8525\n",
      "Epoch 32/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3416 - acc: 0.8553 - val_loss: 0.3536 - val_acc: 0.8575\n",
      "Epoch 33/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3425 - acc: 0.8547 - val_loss: 0.3430 - val_acc: 0.8612\n",
      "Epoch 34/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3515 - acc: 0.8478 - val_loss: 0.3795 - val_acc: 0.8542\n",
      "Epoch 35/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3375 - acc: 0.8559 - val_loss: 0.3438 - val_acc: 0.8648\n",
      "Epoch 36/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3450 - acc: 0.8536 - val_loss: 0.3543 - val_acc: 0.8505\n",
      "Epoch 37/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3481 - acc: 0.8517 - val_loss: 0.3399 - val_acc: 0.8595\n",
      "Epoch 38/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3357 - acc: 0.8560 - val_loss: 0.3499 - val_acc: 0.8481\n",
      "Epoch 39/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3351 - acc: 0.8574 - val_loss: 0.3466 - val_acc: 0.8620\n",
      "Epoch 40/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3312 - acc: 0.8592 - val_loss: 0.3428 - val_acc: 0.8552\n",
      "Epoch 41/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3376 - acc: 0.8583 - val_loss: 0.3578 - val_acc: 0.8465\n",
      "Epoch 42/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3306 - acc: 0.8599 - val_loss: 0.3421 - val_acc: 0.8513\n",
      "Epoch 43/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3336 - acc: 0.8581 - val_loss: 0.3374 - val_acc: 0.8550\n",
      "Epoch 44/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3346 - acc: 0.8576 - val_loss: 0.3339 - val_acc: 0.8623\n",
      "Epoch 45/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3324 - acc: 0.8588 - val_loss: 0.3329 - val_acc: 0.8655\n",
      "Epoch 46/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3380 - acc: 0.8574 - val_loss: 0.3533 - val_acc: 0.8542\n",
      "Epoch 47/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3303 - acc: 0.8612 - val_loss: 0.3286 - val_acc: 0.8589\n",
      "Epoch 48/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3311 - acc: 0.8594 - val_loss: 0.3392 - val_acc: 0.8642\n",
      "Epoch 49/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3317 - acc: 0.8556 - val_loss: 0.3396 - val_acc: 0.8567\n",
      "Epoch 50/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3285 - acc: 0.8631 - val_loss: 0.3252 - val_acc: 0.8663\n",
      "Epoch 51/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3360 - acc: 0.8614 - val_loss: 0.3518 - val_acc: 0.8632\n",
      "Epoch 52/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3268 - acc: 0.8648 - val_loss: 0.3337 - val_acc: 0.8663\n",
      "Epoch 53/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3360 - acc: 0.8550 - val_loss: 0.3357 - val_acc: 0.8617\n",
      "Epoch 54/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3294 - acc: 0.8605 - val_loss: 0.3484 - val_acc: 0.8548\n",
      "Epoch 55/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3252 - acc: 0.8597 - val_loss: 0.3391 - val_acc: 0.8557\n",
      "Epoch 56/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3265 - acc: 0.8603 - val_loss: 0.3197 - val_acc: 0.8627\n",
      "Epoch 57/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3232 - acc: 0.8630 - val_loss: 0.3227 - val_acc: 0.8608\n",
      "Epoch 58/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3315 - acc: 0.8604 - val_loss: 0.3299 - val_acc: 0.8612\n",
      "Epoch 59/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3367 - acc: 0.8572 - val_loss: 0.3504 - val_acc: 0.8482\n",
      "Epoch 60/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3172 - acc: 0.8658 - val_loss: 0.3307 - val_acc: 0.8642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3203 - acc: 0.8629 - val_loss: 0.3780 - val_acc: 0.8345\n",
      "Epoch 62/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3361 - acc: 0.8579 - val_loss: 0.3483 - val_acc: 0.8603\n",
      "Epoch 63/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3303 - acc: 0.8602 - val_loss: 0.3319 - val_acc: 0.8632\n",
      "Epoch 64/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3215 - acc: 0.8642 - val_loss: 0.3282 - val_acc: 0.8633\n",
      "Epoch 65/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3197 - acc: 0.8633 - val_loss: 0.3224 - val_acc: 0.8683\n",
      "Epoch 66/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3289 - acc: 0.8619 - val_loss: 0.3368 - val_acc: 0.8618\n",
      "Epoch 67/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3178 - acc: 0.8634 - val_loss: 0.3119 - val_acc: 0.8750\n",
      "Epoch 68/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3231 - acc: 0.8631 - val_loss: 0.3500 - val_acc: 0.8600\n",
      "Epoch 69/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3277 - acc: 0.8604 - val_loss: 0.3365 - val_acc: 0.8577\n",
      "Epoch 70/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3174 - acc: 0.8659 - val_loss: 0.3347 - val_acc: 0.8584\n",
      "Epoch 71/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3237 - acc: 0.8611 - val_loss: 0.3637 - val_acc: 0.8517\n",
      "Epoch 72/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3261 - acc: 0.8584 - val_loss: 0.3483 - val_acc: 0.8463\n",
      "Epoch 73/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3172 - acc: 0.8684 - val_loss: 0.3253 - val_acc: 0.8653\n",
      "Epoch 74/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3164 - acc: 0.8681 - val_loss: 0.3437 - val_acc: 0.8562\n",
      "Epoch 75/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3204 - acc: 0.8652 - val_loss: 0.3199 - val_acc: 0.8695\n",
      "Epoch 76/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3205 - acc: 0.8661 - val_loss: 0.3289 - val_acc: 0.8672\n",
      "Epoch 77/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3244 - acc: 0.8646 - val_loss: 0.3286 - val_acc: 0.8608\n",
      "Epoch 78/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3232 - acc: 0.8640 - val_loss: 0.3211 - val_acc: 0.8668\n",
      "Epoch 79/80\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.3136 - acc: 0.8648 - val_loss: 0.3374 - val_acc: 0.8488\n",
      "Epoch 80/80\n",
      "160/160 [==============================] - 10s 64ms/step - loss: 0.3194 - acc: 0.8669 - val_loss: 0.3417 - val_acc: 0.8578\n",
      "\n",
      "Training process completed in: 0 h 13 m 42 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1297.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1299 of 1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_553 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_553 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_554 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_554 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_555 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_555 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_556 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_556 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_139 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 180\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 10\n",
      "Validation Steps: 50\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5897 - acc: 0.7067 - val_loss: 0.5665 - val_acc: 0.7243\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.5714 - acc: 0.7150 - val_loss: 0.5632 - val_acc: 0.7123\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.5668 - acc: 0.7061 - val_loss: 0.5649 - val_acc: 0.7118\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.5558 - acc: 0.7056 - val_loss: 0.5170 - val_acc: 0.7098\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.5071 - acc: 0.7400 - val_loss: 0.4670 - val_acc: 0.7768\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.4901 - acc: 0.7917 - val_loss: 0.4676 - val_acc: 0.7886\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.4310 - acc: 0.8300 - val_loss: 0.4630 - val_acc: 0.7959\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.4416 - acc: 0.8117 - val_loss: 0.4231 - val_acc: 0.8136\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.4546 - acc: 0.7994 - val_loss: 0.4397 - val_acc: 0.8188\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.4529 - acc: 0.7900 - val_loss: 0.4275 - val_acc: 0.8222\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4203 - acc: 0.8250 - val_loss: 0.4271 - val_acc: 0.8099\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.4096 - acc: 0.8244 - val_loss: 0.4368 - val_acc: 0.8164\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 5s 450ms/step - loss: 0.4628 - acc: 0.8033 - val_loss: 0.4287 - val_acc: 0.8137\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 4s 433ms/step - loss: 0.4213 - acc: 0.8189 - val_loss: 0.4233 - val_acc: 0.8148\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.4387 - acc: 0.8056 - val_loss: 0.4351 - val_acc: 0.8136\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.4060 - acc: 0.8356 - val_loss: 0.4454 - val_acc: 0.8089\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3969 - acc: 0.8383 - val_loss: 0.4077 - val_acc: 0.8254\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.4337 - acc: 0.8183 - val_loss: 0.4135 - val_acc: 0.8199\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.4190 - acc: 0.8250 - val_loss: 0.4175 - val_acc: 0.8176\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.4253 - acc: 0.8144 - val_loss: 0.4138 - val_acc: 0.8246\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.4195 - acc: 0.8117 - val_loss: 0.4076 - val_acc: 0.8237\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 432ms/step - loss: 0.4316 - acc: 0.8128 - val_loss: 0.4168 - val_acc: 0.8209\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4014 - acc: 0.8300 - val_loss: 0.4036 - val_acc: 0.8277\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3798 - acc: 0.8339 - val_loss: 0.4128 - val_acc: 0.8130\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.4178 - acc: 0.8183 - val_loss: 0.4118 - val_acc: 0.8232\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.3935 - acc: 0.8339 - val_loss: 0.4426 - val_acc: 0.8017\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.4095 - acc: 0.8372 - val_loss: 0.4708 - val_acc: 0.8074\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.4278 - acc: 0.8200 - val_loss: 0.4403 - val_acc: 0.8251\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.3910 - acc: 0.8350 - val_loss: 0.4463 - val_acc: 0.8097\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4066 - acc: 0.8239 - val_loss: 0.4628 - val_acc: 0.7938\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.4512 - acc: 0.8017 - val_loss: 0.4432 - val_acc: 0.8281\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 4s 432ms/step - loss: 0.4191 - acc: 0.8261 - val_loss: 0.4104 - val_acc: 0.8207\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.4184 - acc: 0.8261 - val_loss: 0.4064 - val_acc: 0.8229\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.4294 - acc: 0.8178 - val_loss: 0.4194 - val_acc: 0.8261\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3989 - acc: 0.8278 - val_loss: 0.4089 - val_acc: 0.8206\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.4202 - acc: 0.8139 - val_loss: 0.4165 - val_acc: 0.8237\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3975 - acc: 0.8322 - val_loss: 0.4117 - val_acc: 0.8258\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.3866 - acc: 0.8306 - val_loss: 0.3940 - val_acc: 0.8322\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 0.3912 - acc: 0.8222 - val_loss: 0.4133 - val_acc: 0.8192\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 0.3940 - acc: 0.8356 - val_loss: 0.3957 - val_acc: 0.8258\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.4037 - acc: 0.8133 - val_loss: 0.3894 - val_acc: 0.8309\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.4288 - acc: 0.8167 - val_loss: 0.4098 - val_acc: 0.8182\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.3971 - acc: 0.8233 - val_loss: 0.4014 - val_acc: 0.8268\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4144 - acc: 0.8222 - val_loss: 0.3948 - val_acc: 0.8299\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.3924 - acc: 0.8322 - val_loss: 0.4192 - val_acc: 0.8230\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.4108 - acc: 0.8150 - val_loss: 0.4063 - val_acc: 0.8290\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.3926 - acc: 0.8356 - val_loss: 0.3992 - val_acc: 0.8322\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4199 - acc: 0.8339 - val_loss: 0.4030 - val_acc: 0.8243\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3786 - acc: 0.8433 - val_loss: 0.3990 - val_acc: 0.8227\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.3680 - acc: 0.8411 - val_loss: 0.3939 - val_acc: 0.8260\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3776 - acc: 0.8444 - val_loss: 0.4021 - val_acc: 0.8247\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.3942 - acc: 0.8389 - val_loss: 0.4080 - val_acc: 0.8338\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 4s 435ms/step - loss: 0.4077 - acc: 0.8183 - val_loss: 0.4048 - val_acc: 0.8265\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.3664 - acc: 0.8489 - val_loss: 0.3918 - val_acc: 0.8314\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.3937 - acc: 0.8378 - val_loss: 0.3824 - val_acc: 0.8334\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 0.3902 - acc: 0.8428 - val_loss: 0.4095 - val_acc: 0.8225\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.3983 - acc: 0.8289 - val_loss: 0.3970 - val_acc: 0.8328\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.4148 - acc: 0.8244 - val_loss: 0.3969 - val_acc: 0.8306\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.4073 - acc: 0.8311 - val_loss: 0.3911 - val_acc: 0.8326\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.3870 - acc: 0.8372 - val_loss: 0.3864 - val_acc: 0.8341\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.3714 - acc: 0.8372 - val_loss: 0.3828 - val_acc: 0.8347\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.3842 - acc: 0.8267 - val_loss: 0.3826 - val_acc: 0.8301\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.3766 - acc: 0.8428 - val_loss: 0.3979 - val_acc: 0.8279\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3956 - acc: 0.8256 - val_loss: 0.3755 - val_acc: 0.8391\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 4s 433ms/step - loss: 0.4078 - acc: 0.8256 - val_loss: 0.4009 - val_acc: 0.8222\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.4179 - acc: 0.8217 - val_loss: 0.4347 - val_acc: 0.8238\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.4047 - acc: 0.8283 - val_loss: 0.4149 - val_acc: 0.8308\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 5s 450ms/step - loss: 0.3821 - acc: 0.8400 - val_loss: 0.3856 - val_acc: 0.8338\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.3877 - acc: 0.8367 - val_loss: 0.3946 - val_acc: 0.8247\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.4251 - acc: 0.8222 - val_loss: 0.4139 - val_acc: 0.8364\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.3990 - acc: 0.8306 - val_loss: 0.4127 - val_acc: 0.8258\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.3919 - acc: 0.8267 - val_loss: 0.3903 - val_acc: 0.8308\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.3930 - acc: 0.8322 - val_loss: 0.3879 - val_acc: 0.8327\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.3857 - acc: 0.8278 - val_loss: 0.3876 - val_acc: 0.8324\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.3943 - acc: 0.8289 - val_loss: 0.3966 - val_acc: 0.8322\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 4s 435ms/step - loss: 0.3949 - acc: 0.8278 - val_loss: 0.3875 - val_acc: 0.8346\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 4s 435ms/step - loss: 0.3703 - acc: 0.8389 - val_loss: 0.3937 - val_acc: 0.8314\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.3779 - acc: 0.8411 - val_loss: 0.4036 - val_acc: 0.8325\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.3722 - acc: 0.8500 - val_loss: 0.4357 - val_acc: 0.8107\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.4048 - acc: 0.8267 - val_loss: 0.3862 - val_acc: 0.8339\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 0.4124 - acc: 0.8228 - val_loss: 0.3789 - val_acc: 0.8399\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.3794 - acc: 0.8383 - val_loss: 0.3941 - val_acc: 0.8309\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 429ms/step - loss: 0.3987 - acc: 0.8367 - val_loss: 0.3889 - val_acc: 0.8243\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3874 - acc: 0.8367 - val_loss: 0.3909 - val_acc: 0.8251\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.3880 - acc: 0.8222 - val_loss: 0.3993 - val_acc: 0.8193\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.3884 - acc: 0.8272 - val_loss: 0.3868 - val_acc: 0.8356\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.3525 - acc: 0.8550 - val_loss: 0.3791 - val_acc: 0.8369\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.3648 - acc: 0.8406 - val_loss: 0.3884 - val_acc: 0.8316\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3852 - acc: 0.8350 - val_loss: 0.3778 - val_acc: 0.8442\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.3961 - acc: 0.8333 - val_loss: 0.4090 - val_acc: 0.8177\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3781 - acc: 0.8428 - val_loss: 0.3985 - val_acc: 0.8199\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.3935 - acc: 0.8272 - val_loss: 0.4570 - val_acc: 0.8077\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.4087 - acc: 0.8194 - val_loss: 0.4008 - val_acc: 0.8241\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.3878 - acc: 0.8194 - val_loss: 0.3860 - val_acc: 0.8370\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 4s 432ms/step - loss: 0.4039 - acc: 0.8200 - val_loss: 0.3871 - val_acc: 0.8268\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.3799 - acc: 0.8344 - val_loss: 0.4205 - val_acc: 0.8029\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.4027 - acc: 0.8294 - val_loss: 0.3897 - val_acc: 0.8411\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4070 - acc: 0.8278 - val_loss: 0.3907 - val_acc: 0.8400\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.3840 - acc: 0.8367 - val_loss: 0.4019 - val_acc: 0.8331\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.3804 - acc: 0.8372 - val_loss: 0.3869 - val_acc: 0.8281\n",
      "\n",
      "Training process completed in: 0 h 7 m 27 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1298.h5 \"\n",
      "######################################################################################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596284</td>\n",
       "      <td>0.717086</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.424821</td>\n",
       "      <td>0.824666</td>\n",
       "      <td>0:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.400397</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.821459</td>\n",
       "      <td>0:02:56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.342393</td>\n",
       "      <td>0.854934</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0:03:59</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.61192</td>\n",
       "      <td>0.713867</td>\n",
       "      <td>4.51508</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0:11:35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.57984</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>4.66014</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>0:04:34</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.414818</td>\n",
       "      <td>0.818889</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.355077</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0:11:37</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.598234</td>\n",
       "      <td>0.714492</td>\n",
       "      <td>0.587283</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0:11:21</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.415619</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.415587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0:03:26</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355923</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.340781</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0:04:54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.386344</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>0.38406</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0:01:19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.578921</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.572354</td>\n",
       "      <td>0.707286</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.386086</td>\n",
       "      <td>0.829286</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.406065</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.821349</td>\n",
       "      <td>0:09:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.343212</td>\n",
       "      <td>0.854563</td>\n",
       "      <td>0.333918</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0:11:05</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.366198</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.378055</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0:02:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.36458</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>0.842172</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.398393</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.593772</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.418344</td>\n",
       "      <td>0.815605</td>\n",
       "      <td>0:06:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.369263</td>\n",
       "      <td>0.838594</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.846597</td>\n",
       "      <td>0:05:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.720147</td>\n",
       "      <td>0.593732</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0:03:39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.481815</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.503438</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0:01:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.60906</td>\n",
       "      <td>0.714044</td>\n",
       "      <td>4.5453</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0:20:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.63599</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>4.53844</td>\n",
       "      <td>0.718426</td>\n",
       "      <td>0:01:44</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.66619</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>4.60252</td>\n",
       "      <td>0.71445</td>\n",
       "      <td>0:06:20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.401561</td>\n",
       "      <td>0.824792</td>\n",
       "      <td>0.387844</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0:03:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.602757</td>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.592917</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0:07:09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.485893</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>0.79175</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.32273</td>\n",
       "      <td>0.862697</td>\n",
       "      <td>0.324586</td>\n",
       "      <td>0.860313</td>\n",
       "      <td>0:13:30</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.316215</td>\n",
       "      <td>0.868882</td>\n",
       "      <td>0.348692</td>\n",
       "      <td>0.861562</td>\n",
       "      <td>0:13:39</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.312403</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.308084</td>\n",
       "      <td>0.868083</td>\n",
       "      <td>0:24:53</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.304879</td>\n",
       "      <td>0.870042</td>\n",
       "      <td>0.341189</td>\n",
       "      <td>0.867667</td>\n",
       "      <td>0:27:54</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311753</td>\n",
       "      <td>0.867792</td>\n",
       "      <td>0.350141</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0:14:20</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.32962</td>\n",
       "      <td>0.863229</td>\n",
       "      <td>0.337369</td>\n",
       "      <td>0.867917</td>\n",
       "      <td>0:12:37</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.372294</td>\n",
       "      <td>0.838125</td>\n",
       "      <td>0.356806</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0:01:41</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>0.344556</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0:25:08</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.31455</td>\n",
       "      <td>0.864904</td>\n",
       "      <td>0.31632</td>\n",
       "      <td>0.870937</td>\n",
       "      <td>0:13:16</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.302942</td>\n",
       "      <td>0.873192</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0:17:44</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.307891</td>\n",
       "      <td>0.870048</td>\n",
       "      <td>0.302075</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>0:16:49</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.297431</td>\n",
       "      <td>0.874975</td>\n",
       "      <td>0.322068</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0:25:49</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.298593</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.305138</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0:17:21</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.291219</td>\n",
       "      <td>0.879031</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.87032</td>\n",
       "      <td>0:21:20</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.294142</td>\n",
       "      <td>0.874367</td>\n",
       "      <td>0.318399</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0:21:05</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.381282</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.390819</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0:03:27</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>140</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311605</td>\n",
       "      <td>0.867782</td>\n",
       "      <td>0.30766</td>\n",
       "      <td>0.872972</td>\n",
       "      <td>0:19:16</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.281195</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>0:41:08</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>140</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>0.863759</td>\n",
       "      <td>0.340524</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>0:20:44</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.299469</td>\n",
       "      <td>0.873921</td>\n",
       "      <td>0.32866</td>\n",
       "      <td>0.865221</td>\n",
       "      <td>0:26:38</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>140</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.322656</td>\n",
       "      <td>0.864211</td>\n",
       "      <td>0.345417</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0:11:08</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.309414</td>\n",
       "      <td>0.869061</td>\n",
       "      <td>0.359405</td>\n",
       "      <td>0.849898</td>\n",
       "      <td>0:21:40</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.321814</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>0:28:15</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311804</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.342944</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0:11:33</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.376809</td>\n",
       "      <td>0.835273</td>\n",
       "      <td>0:22:14</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.321127</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.325096</td>\n",
       "      <td>0.864889</td>\n",
       "      <td>0:22:58</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.296176</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.341947</td>\n",
       "      <td>0.85963</td>\n",
       "      <td>0:23:46</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.293916</td>\n",
       "      <td>0.877396</td>\n",
       "      <td>0.298404</td>\n",
       "      <td>0.876864</td>\n",
       "      <td>0:27:08</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.319407</td>\n",
       "      <td>0.866937</td>\n",
       "      <td>0.341723</td>\n",
       "      <td>0.857833</td>\n",
       "      <td>0:13:42</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.380374</td>\n",
       "      <td>0.837222</td>\n",
       "      <td>0.386942</td>\n",
       "      <td>0.828061</td>\n",
       "      <td>0:07:27</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc  val_loss   val_acc     time  gen  alive\n",
       "0            160               60                50      30        0.01000   0.596284  0.717086  0.602438  0.710375  0:02:47    1  False\n",
       "1            140              200                20      80        0.01000   0.419026  0.819964  0.424821  0.824666  0:14:00    1  False\n",
       "2            200               30                70      30        0.00010   0.400397  0.828667  0.407492  0.821459  0:02:56    1  False\n",
       "3             80              190                30      40        0.00100   0.342393  0.854934    0.3493     0.855  0:03:59    1  False\n",
       "4            100              150                80      90        0.10000    4.61192  0.713867   4.51508  0.719875  0:11:35    1  False\n",
       "5            200               70                40      40        0.10000    4.57984  0.715857   4.66014  0.710875  0:04:34    1  False\n",
       "6             60               30                80      40        0.00010   0.414818  0.818889  0.516359  0.784375  0:01:24    1  False\n",
       "7            200              110                70      60        0.00010   0.351962  0.852273  0.355077  0.848624  0:11:37    1  False\n",
       "8            160              160                20      70        0.01000   0.598234  0.714492  0.587283  0.726542  0:11:21    1  False\n",
       "9            120              110                20      40        0.00001   0.415619  0.823788  0.415587  0.819167  0:03:26    1  False\n",
       "10            40              130               100      90        0.00100   0.355923  0.847692  0.340781     0.862  0:04:54    1  False\n",
       "11           140              120                50      10        0.00100   0.386344   0.83375   0.38406  0.837714  0:01:19    1  False\n",
       "12           140               10                50      10        0.00010   0.578921  0.707143  0.572354  0.707286  0:00:27    1  False\n",
       "13            20              130                70      30        0.00100   0.396505  0.838462  0.386086  0.829286  0:00:46    1  False\n",
       "14           140              160                90      50        0.00001   0.406065  0.825893  0.408935  0.821349  0:09:57    1  False\n",
       "15           160              100                80      70        0.00010   0.343212  0.854563  0.333918  0.855412  0:11:05    1  False\n",
       "16           140               90                10      30        0.00100   0.366198  0.840635  0.378055  0.837143  0:02:27    1  False\n",
       "17            80               80                10      70        0.00100    0.36458  0.840156   0.34817  0.842172  0:03:00    1  False\n",
       "18           120               30                20      40        0.00100   0.398393  0.832778  0.461081  0.833333  0:01:07    1  False\n",
       "19            60              120                40      40        0.01000   0.596109  0.716944  0.593772  0.719167  0:02:15    1  False\n",
       "20           160               10                70     100        0.00010   0.409997    0.8225  0.418344  0.815605  0:06:57    1  False\n",
       "21           160              120                90      30        0.00010   0.369263  0.838594  0.359941  0.846597  0:05:47    1  False\n",
       "22           120              170                90      20        0.01000   0.593047  0.720147  0.593732  0.719444  0:03:39    1  False\n",
       "23            40               70                20      60        0.01000   0.481815      0.79  0.503438    0.7525  0:01:15    1  False\n",
       "24           160              170                50     100        0.10000    4.60906  0.714044    4.5453     0.718  0:20:24    1  False\n",
       "25           180              110                60      10        0.10000    4.63599  0.712374   4.53844  0.718426  0:01:44    1  False\n",
       "26           200               20               100      50        0.10000    4.66619    0.7105   4.60252   0.71445  0:06:20    1  False\n",
       "27            60               80                30      90        0.00001   0.401561  0.824792  0.387844     0.835  0:03:24    1  False\n",
       "28            80              120                30     100        0.01000   0.602757  0.709479  0.592917  0.720833  0:07:09    1  False\n",
       "29            80               70                50      20        0.00001   0.485893  0.765714  0.457634   0.79175  0:01:06    1  False\n",
       "...          ...              ...               ...     ...            ...        ...       ...       ...       ...      ...  ...    ...\n",
       "1269          80              190                40     100        0.00010    0.32273  0.862697  0.324586  0.860313  0:13:30    3   True\n",
       "1270          80              190                40     100        0.00100   0.316215  0.868882  0.348692  0.861562  0:13:39    3   True\n",
       "1271         200              190                40      80        0.00010   0.312403    0.8675  0.308084  0.868083  0:24:53    3   True\n",
       "1272         200              120                90     100        0.00100   0.304879  0.870042  0.341189  0.867667  0:27:54    3   True\n",
       "1273         200              120                10      80        0.00100   0.311753  0.867792  0.350141    0.8525  0:14:20    3   True\n",
       "1274          80              120                90     100        0.00100    0.32962  0.863229  0.337369  0.867917  0:12:37    3   True\n",
       "1275          80              120                10      20        0.00100   0.372294  0.838125  0.356806     0.845  0:01:41    3   True\n",
       "1276         200              190                10      90        0.00100   0.288244  0.877947  0.344556     0.872  0:25:08    3   True\n",
       "1277         160              130                20      80        0.00100    0.31455  0.864904   0.31632  0.870937  0:13:16    3   True\n",
       "1278         200              130                10      90        0.00100   0.302942  0.873192  0.296192     0.882  0:17:44    3   True\n",
       "1279         160              130                40      90        0.00100   0.307891  0.870048  0.302075  0.875469  0:16:49    3   True\n",
       "1280         200              200                70      70        0.00100   0.297431  0.874975  0.322068  0.869194  0:25:49    3   True\n",
       "1281         160              200                20      70        0.00100   0.298593  0.873469  0.305138  0.867609  0:17:21    3   True\n",
       "1282         160              200                70      70        0.00100   0.291219  0.879031  0.312112   0.87032  0:21:20    3   True\n",
       "1283         200              150                20      90        0.00100   0.294142  0.874367  0.318399     0.869  0:21:05    3   True\n",
       "1284          20              150                20      90        0.00100   0.381282     0.838  0.390819     0.845  0:03:27    3   True\n",
       "1285         140              190                80      70        0.00100   0.311605  0.867782   0.30766  0.872972  0:19:16    3   True\n",
       "1286         200              190               100     100        0.00100   0.281195  0.881789  0.314381    0.8722  0:41:08    3   True\n",
       "1287         140              190               100      70        0.00100   0.321365  0.863759  0.340524  0.864094  0:20:44    3   True\n",
       "1288         200              190                80      70        0.00100   0.299469  0.873921   0.32866  0.865221  0:26:38    3   True\n",
       "1289         140              190                80      40        0.00100   0.322656  0.864211  0.345417  0.857285  0:11:08    3   True\n",
       "1290         200              200                10      70        0.00010   0.309414  0.869061  0.359405  0.849898  0:21:40    3   True\n",
       "1291         200              200                20      90        0.00100   0.281991    0.8825  0.321814    0.8595  0:28:15    3   True\n",
       "1292         100              200                10      70        0.00100   0.311804    0.8678  0.342944     0.858  0:11:33    3   True\n",
       "1293         200              200                20      70        0.00001   0.384464    0.8327  0.376809  0.835273  0:22:14    3   True\n",
       "1294         180              170                50      80        0.00010   0.321127  0.864346  0.325096  0.864889  0:22:58    3   True\n",
       "1295         180              170                60      80        0.00100   0.296176  0.876667  0.341947   0.85963  0:23:46    3   True\n",
       "1296         180              160                50     100        0.00100   0.293916  0.877396  0.298404  0.876864  0:27:08    3   True\n",
       "1297         100              160                60      80        0.00100   0.319407  0.866937  0.341723  0.857833  0:13:42    3   True\n",
       "1298         180               10                50     100        0.00100   0.380374  0.837222  0.386942  0.828061  0:07:27    3   True\n",
       "\n",
       "[1299 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate\n",
    "train_generation(model=model_7, image_size=(50,50), gen=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.865789</td>\n",
       "      <td>0.292571</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0:11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0:12:35</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.333464</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>0:05:13</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.302942</td>\n",
       "      <td>0.873192</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0:17:44</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.311461</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.295427</td>\n",
       "      <td>0.881832</td>\n",
       "      <td>0:29:50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.321133</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0:10:42</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.306632</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0:14:31</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.284835</td>\n",
       "      <td>0.881026</td>\n",
       "      <td>0.298489</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0:28:42</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.310335</td>\n",
       "      <td>0.870633</td>\n",
       "      <td>0.298475</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>0:13:40</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.344512</td>\n",
       "      <td>0.852526</td>\n",
       "      <td>0.317177</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0:07:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "653          100              190                10      90         0.0001    0.317655   0.865789  0.292571  0.894000  0:11:41    1   True\n",
       "1240         160              140                10      80         0.0010    0.309508   0.870714  0.298903  0.886250  0:12:35    3   True\n",
       "1178          80              190                30      50         0.0010    0.333464   0.858750  0.292957  0.884583  0:05:13    2   True\n",
       "1278         200              130                10      90         0.0010    0.302942   0.873192  0.296192  0.882000  0:17:44    3   True\n",
       "1129         200              200                20      70         0.0001    0.311461   0.867375  0.295427  0.881832  0:29:50    2   True\n",
       "1107          80              160                10      80         0.0010    0.321133   0.866250  0.336637  0.881250  0:10:42    2   True\n",
       "1038         100              200                10      90         0.0010    0.306632   0.870800  0.317246  0.881000  0:14:31    2   True\n",
       "1250         200              190                30     100         0.0010    0.284835   0.881026  0.298489  0.878500  0:28:42    3   True\n",
       "1267         200              150                20      60         0.0010    0.310335   0.870633  0.298475  0.878250  0:13:40    3   True\n",
       "1039         100              190                10      50         0.0001    0.344512   0.852526  0.317177  0.878000  0:07:40    2   True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep top performing algorithms\n",
    "df_fittest = select_fittest(top_percent=10)\n",
    "df_fittest.nlargest(10, 'val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th GENERATION ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1039, 1278), (1250, 1129), (1107, 1267), (653, 1029), (1178, 1240)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = create_parents()\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read generations file\n",
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "    \n",
    "for pair in parents:\n",
    "    df_parents = df_generations.iloc[[pair[0], pair[1]]]\n",
    "    \n",
    "    # make children\n",
    "    df_child_1 = create_child(df_parents, generation=4)\n",
    "    df_child_2 = create_child(df_parents, generation=4)\n",
    "    df_child_3 = create_child(df_parents, generation=4)\n",
    "    df_child_4 = create_child(df_parents, generation=4)\n",
    "    df_child_5 = create_child(df_parents, generation=4, mutate=True)\n",
    "\n",
    "    df_children = df_child_1.append([df_child_2, df_child_3, df_child_4, df_child_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.333464</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>0:05:13</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0:12:35</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "1178          80              190                30      50          0.001    0.333464   0.858750  0.292957  0.884583  0:05:13    2   True\n",
       "1240         160              140                10      80          0.001    0.309508   0.870714  0.298903  0.886250  0:12:35    3   True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc val_loss val_acc time  gen  alive\n",
       "0         160              190                30      80          0.001                                               4   True\n",
       "1          80              140                10      80          0.001                                               4   True\n",
       "2          80              190                30      80          0.001                                               4   True\n",
       "3         160              190                10      50          0.001                                               4   True\n",
       "4          80              120                30      80          0.001                                               4   True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 1300 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_557 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_557 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_558 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_558 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_559 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_559 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_560 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_560 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_140 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "130/130 [==============================] - 18s 138ms/step - loss: 0.5827 - acc: 0.7098 - val_loss: 0.5560 - val_acc: 0.7090\n",
      "Epoch 2/90\n",
      "130/130 [==============================] - 7s 55ms/step - loss: 0.4991 - acc: 0.7552 - val_loss: 0.4788 - val_acc: 0.7850\n",
      "Epoch 3/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4316 - acc: 0.8130 - val_loss: 0.4192 - val_acc: 0.8250\n",
      "Epoch 4/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.4300 - acc: 0.8138 - val_loss: 0.3905 - val_acc: 0.8310\n",
      "Epoch 5/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4131 - acc: 0.8240 - val_loss: 0.4210 - val_acc: 0.8200\n",
      "Epoch 6/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.4154 - acc: 0.8214 - val_loss: 0.4268 - val_acc: 0.8150\n",
      "Epoch 7/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4120 - acc: 0.8250 - val_loss: 0.4229 - val_acc: 0.8070\n",
      "Epoch 8/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4174 - acc: 0.8205 - val_loss: 0.4221 - val_acc: 0.8180\n",
      "Epoch 9/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4062 - acc: 0.8248 - val_loss: 0.3702 - val_acc: 0.8340\n",
      "Epoch 10/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4110 - acc: 0.8265 - val_loss: 0.3756 - val_acc: 0.8420\n",
      "Epoch 11/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4066 - acc: 0.8248 - val_loss: 0.4019 - val_acc: 0.8270\n",
      "Epoch 12/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3988 - acc: 0.8302 - val_loss: 0.4351 - val_acc: 0.8020\n",
      "Epoch 13/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4108 - acc: 0.8242 - val_loss: 0.3949 - val_acc: 0.8280\n",
      "Epoch 14/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4109 - acc: 0.8212 - val_loss: 0.4339 - val_acc: 0.8080\n",
      "Epoch 15/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3987 - acc: 0.8262 - val_loss: 0.4085 - val_acc: 0.8220\n",
      "Epoch 16/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3956 - acc: 0.8292 - val_loss: 0.3767 - val_acc: 0.8440\n",
      "Epoch 17/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3938 - acc: 0.8300 - val_loss: 0.3915 - val_acc: 0.8290\n",
      "Epoch 18/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3959 - acc: 0.8300 - val_loss: 0.4051 - val_acc: 0.8340\n",
      "Epoch 19/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3967 - acc: 0.8322 - val_loss: 0.3905 - val_acc: 0.8320\n",
      "Epoch 20/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3915 - acc: 0.8322 - val_loss: 0.3792 - val_acc: 0.8450\n",
      "Epoch 21/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3918 - acc: 0.8317 - val_loss: 0.4142 - val_acc: 0.8150\n",
      "Epoch 22/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3911 - acc: 0.8321 - val_loss: 0.3836 - val_acc: 0.8310\n",
      "Epoch 23/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3852 - acc: 0.8342 - val_loss: 0.3872 - val_acc: 0.8300\n",
      "Epoch 24/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3900 - acc: 0.8331 - val_loss: 0.3783 - val_acc: 0.8440\n",
      "Epoch 25/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3851 - acc: 0.8336 - val_loss: 0.3888 - val_acc: 0.8380\n",
      "Epoch 26/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3812 - acc: 0.8338 - val_loss: 0.4118 - val_acc: 0.8170\n",
      "Epoch 27/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3901 - acc: 0.8322 - val_loss: 0.3989 - val_acc: 0.8290\n",
      "Epoch 28/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3883 - acc: 0.8324 - val_loss: 0.4157 - val_acc: 0.8214\n",
      "Epoch 29/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3796 - acc: 0.8392 - val_loss: 0.4008 - val_acc: 0.8100\n",
      "Epoch 30/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3806 - acc: 0.8348 - val_loss: 0.4216 - val_acc: 0.8070\n",
      "Epoch 31/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3760 - acc: 0.8401 - val_loss: 0.3929 - val_acc: 0.8420\n",
      "Epoch 32/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3783 - acc: 0.8357 - val_loss: 0.3666 - val_acc: 0.8460\n",
      "Epoch 33/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3813 - acc: 0.8344 - val_loss: 0.3767 - val_acc: 0.8450\n",
      "Epoch 34/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3774 - acc: 0.8374 - val_loss: 0.3502 - val_acc: 0.8450\n",
      "Epoch 35/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3782 - acc: 0.8398 - val_loss: 0.4100 - val_acc: 0.8170\n",
      "Epoch 36/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3725 - acc: 0.8365 - val_loss: 0.3823 - val_acc: 0.8470\n",
      "Epoch 37/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3724 - acc: 0.8417 - val_loss: 0.3598 - val_acc: 0.8540\n",
      "Epoch 38/90\n",
      "130/130 [==============================] - 7s 55ms/step - loss: 0.3655 - acc: 0.8415 - val_loss: 0.3770 - val_acc: 0.8320\n",
      "Epoch 39/90\n",
      "130/130 [==============================] - 7s 57ms/step - loss: 0.3614 - acc: 0.8423 - val_loss: 0.3459 - val_acc: 0.8630\n",
      "Epoch 40/90\n",
      "130/130 [==============================] - 8s 58ms/step - loss: 0.3691 - acc: 0.8418 - val_loss: 0.3544 - val_acc: 0.8580\n",
      "Epoch 41/90\n",
      "130/130 [==============================] - 8s 59ms/step - loss: 0.3745 - acc: 0.8371 - val_loss: 0.4057 - val_acc: 0.8300\n",
      "Epoch 42/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3621 - acc: 0.8450 - val_loss: 0.3741 - val_acc: 0.8280\n",
      "Epoch 43/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3686 - acc: 0.8400 - val_loss: 0.3646 - val_acc: 0.8370\n",
      "Epoch 44/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3787 - acc: 0.8363 - val_loss: 0.4000 - val_acc: 0.8100\n",
      "Epoch 45/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3718 - acc: 0.8392 - val_loss: 0.3517 - val_acc: 0.8470\n",
      "Epoch 46/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3632 - acc: 0.8442 - val_loss: 0.3774 - val_acc: 0.8370\n",
      "Epoch 47/90\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.3797 - acc: 0.8361 - val_loss: 0.3450 - val_acc: 0.8490\n",
      "Epoch 48/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3541 - acc: 0.8520 - val_loss: 0.3592 - val_acc: 0.8420\n",
      "Epoch 49/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3563 - acc: 0.8492 - val_loss: 0.3704 - val_acc: 0.8470\n",
      "Epoch 50/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3593 - acc: 0.8460 - val_loss: 0.3676 - val_acc: 0.8490\n",
      "Epoch 51/90\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 0.3642 - acc: 0.8485 - val_loss: 0.3503 - val_acc: 0.8540\n",
      "Epoch 52/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3591 - acc: 0.8433 - val_loss: 0.3509 - val_acc: 0.8420\n",
      "Epoch 53/90\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.3610 - acc: 0.8463 - val_loss: 0.3539 - val_acc: 0.8540\n",
      "Epoch 54/90\n",
      "130/130 [==============================] - 6s 50ms/step - loss: 0.3599 - acc: 0.8451 - val_loss: 0.3582 - val_acc: 0.8600\n",
      "Epoch 55/90\n",
      "130/130 [==============================] - 6s 50ms/step - loss: 0.3564 - acc: 0.8465 - val_loss: 0.3313 - val_acc: 0.8680\n",
      "Epoch 56/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3576 - acc: 0.8479 - val_loss: 0.3299 - val_acc: 0.8508\n",
      "Epoch 57/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3473 - acc: 0.8538 - val_loss: 0.3283 - val_acc: 0.8620\n",
      "Epoch 58/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3573 - acc: 0.8500 - val_loss: 0.3676 - val_acc: 0.8450\n",
      "Epoch 59/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3546 - acc: 0.8440 - val_loss: 0.3715 - val_acc: 0.8510\n",
      "Epoch 60/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3564 - acc: 0.8526 - val_loss: 0.3710 - val_acc: 0.8350\n",
      "Epoch 61/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3461 - acc: 0.8542 - val_loss: 0.3557 - val_acc: 0.8540\n",
      "Epoch 62/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3477 - acc: 0.8547 - val_loss: 0.3418 - val_acc: 0.8520\n",
      "Epoch 63/90\n",
      "130/130 [==============================] - 7s 55ms/step - loss: 0.3546 - acc: 0.8530 - val_loss: 0.3583 - val_acc: 0.8470\n",
      "Epoch 64/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3508 - acc: 0.8485 - val_loss: 0.3431 - val_acc: 0.8580\n",
      "Epoch 65/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3455 - acc: 0.8550 - val_loss: 0.3502 - val_acc: 0.8440\n",
      "Epoch 66/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3501 - acc: 0.8494 - val_loss: 0.3477 - val_acc: 0.8570\n",
      "Epoch 67/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3408 - acc: 0.8519 - val_loss: 0.3418 - val_acc: 0.8570\n",
      "Epoch 68/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3571 - acc: 0.8475 - val_loss: 0.3156 - val_acc: 0.8670\n",
      "Epoch 69/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3412 - acc: 0.8545 - val_loss: 0.3641 - val_acc: 0.8480\n",
      "Epoch 70/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3503 - acc: 0.8514 - val_loss: 0.3509 - val_acc: 0.8570\n",
      "Epoch 71/90\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 0.3438 - acc: 0.8552 - val_loss: 0.3252 - val_acc: 0.8640\n",
      "Epoch 72/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3409 - acc: 0.8585 - val_loss: 0.3425 - val_acc: 0.8460\n",
      "Epoch 73/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3450 - acc: 0.8522 - val_loss: 0.3263 - val_acc: 0.8560\n",
      "Epoch 74/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3499 - acc: 0.8517 - val_loss: 0.3461 - val_acc: 0.8520\n",
      "Epoch 75/90\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 0.3347 - acc: 0.8560 - val_loss: 0.3439 - val_acc: 0.8510\n",
      "Epoch 76/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3355 - acc: 0.8553 - val_loss: 0.3532 - val_acc: 0.8480\n",
      "Epoch 77/90\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.3414 - acc: 0.8548 - val_loss: 0.3636 - val_acc: 0.8410\n",
      "Epoch 78/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3365 - acc: 0.8592 - val_loss: 0.3700 - val_acc: 0.8300\n",
      "Epoch 79/90\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.3541 - acc: 0.8475 - val_loss: 0.3750 - val_acc: 0.8400\n",
      "Epoch 80/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3482 - acc: 0.8524 - val_loss: 0.3174 - val_acc: 0.8730\n",
      "Epoch 81/90\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.3432 - acc: 0.8526 - val_loss: 0.3267 - val_acc: 0.8540\n",
      "Epoch 82/90\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3342 - acc: 0.8586 - val_loss: 0.3597 - val_acc: 0.8480\n",
      "Epoch 83/90\n",
      "130/130 [==============================] - 7s 53ms/step - loss: 0.3451 - acc: 0.8526 - val_loss: 0.3312 - val_acc: 0.8570\n",
      "Epoch 84/90\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.3282 - acc: 0.8628 - val_loss: 0.3290 - val_acc: 0.8498\n",
      "Epoch 85/90\n",
      "130/130 [==============================] - 6s 50ms/step - loss: 0.3452 - acc: 0.8520 - val_loss: 0.3547 - val_acc: 0.8420\n",
      "Epoch 86/90\n",
      "130/130 [==============================] - 7s 57ms/step - loss: 0.3518 - acc: 0.8480 - val_loss: 0.3364 - val_acc: 0.8570\n",
      "Epoch 87/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3305 - acc: 0.8618 - val_loss: 0.3261 - val_acc: 0.8620\n",
      "Epoch 88/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3295 - acc: 0.8603 - val_loss: 0.3339 - val_acc: 0.8580\n",
      "Epoch 89/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3419 - acc: 0.8518 - val_loss: 0.3638 - val_acc: 0.8490\n",
      "Epoch 90/90\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3286 - acc: 0.8627 - val_loss: 0.3437 - val_acc: 0.8590\n",
      "\n",
      "Training process completed in: 0 h 10 m 25 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1299.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1301 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_561 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_561 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_562 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_562 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_563 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_563 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_564 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_564 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_141 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 28s 149ms/step - loss: 0.5620 - acc: 0.7190 - val_loss: 0.4758 - val_acc: 0.8030\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.4294 - acc: 0.8143 - val_loss: 0.4157 - val_acc: 0.8195\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.4201 - acc: 0.8199 - val_loss: 0.4268 - val_acc: 0.8140\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4168 - acc: 0.8223 - val_loss: 0.4045 - val_acc: 0.8215\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.4031 - acc: 0.8282 - val_loss: 0.4146 - val_acc: 0.8175\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.4071 - acc: 0.8266 - val_loss: 0.3997 - val_acc: 0.8320\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3999 - acc: 0.8273 - val_loss: 0.3963 - val_acc: 0.8435\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.4001 - acc: 0.8273 - val_loss: 0.4244 - val_acc: 0.8145\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3932 - acc: 0.8316 - val_loss: 0.3880 - val_acc: 0.8280\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3883 - acc: 0.8336 - val_loss: 0.4021 - val_acc: 0.8410\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3890 - acc: 0.8333 - val_loss: 0.4452 - val_acc: 0.8100\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3844 - acc: 0.8345 - val_loss: 0.3851 - val_acc: 0.8440\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3835 - acc: 0.8363 - val_loss: 0.3834 - val_acc: 0.8390\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3785 - acc: 0.8385 - val_loss: 0.3978 - val_acc: 0.83769 - acc:\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3822 - acc: 0.8359 - val_loss: 0.3672 - val_acc: 0.8425\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3683 - acc: 0.8435 - val_loss: 0.3723 - val_acc: 0.8470\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3726 - acc: 0.8436 - val_loss: 0.3675 - val_acc: 0.8460\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3676 - acc: 0.8423 - val_loss: 0.3817 - val_acc: 0.8325\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3664 - acc: 0.8426 - val_loss: 0.3532 - val_acc: 0.8510\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3578 - acc: 0.8495 - val_loss: 0.3632 - val_acc: 0.8405\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3660 - acc: 0.8439 - val_loss: 0.3609 - val_acc: 0.8540\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3632 - acc: 0.8459 - val_loss: 0.3553 - val_acc: 0.8490\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3568 - acc: 0.8479 - val_loss: 0.3524 - val_acc: 0.8525\n",
      "Epoch 24/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3583 - acc: 0.8483 - val_loss: 0.3630 - val_acc: 0.8485\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3602 - acc: 0.8474 - val_loss: 0.3547 - val_acc: 0.8390\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3529 - acc: 0.8503 - val_loss: 0.3589 - val_acc: 0.8475\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3571 - acc: 0.8463 - val_loss: 0.3605 - val_acc: 0.8395\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3515 - acc: 0.8512 - val_loss: 0.3506 - val_acc: 0.8453\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3471 - acc: 0.8527 - val_loss: 0.3336 - val_acc: 0.8610\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3496 - acc: 0.8516 - val_loss: 0.3628 - val_acc: 0.8435\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3487 - acc: 0.8521 - val_loss: 0.3670 - val_acc: 0.8420\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3464 - acc: 0.8542 - val_loss: 0.3524 - val_acc: 0.8610\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3452 - acc: 0.8548 - val_loss: 0.3590 - val_acc: 0.8395\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3429 - acc: 0.8530 - val_loss: 0.3595 - val_acc: 0.8360\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3464 - acc: 0.8527 - val_loss: 0.3375 - val_acc: 0.8580\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3420 - acc: 0.8566 - val_loss: 0.3235 - val_acc: 0.8685\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3465 - acc: 0.8528 - val_loss: 0.3237 - val_acc: 0.8740\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3419 - acc: 0.8544 - val_loss: 0.3504 - val_acc: 0.8510\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3443 - acc: 0.8521 - val_loss: 0.3135 - val_acc: 0.8670\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3400 - acc: 0.8538 - val_loss: 0.3208 - val_acc: 0.8605\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3386 - acc: 0.8563 - val_loss: 0.3494 - val_acc: 0.8555\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3341 - acc: 0.8593 - val_loss: 0.3496 - val_acc: 0.8545\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3384 - acc: 0.8549 - val_loss: 0.3286 - val_acc: 0.8640\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3310 - acc: 0.8592 - val_loss: 0.3481 - val_acc: 0.8545\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3320 - acc: 0.8600 - val_loss: 0.3377 - val_acc: 0.8665\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3384 - acc: 0.8550 - val_loss: 0.3407 - val_acc: 0.8525\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3339 - acc: 0.8585 - val_loss: 0.3153 - val_acc: 0.8650\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3361 - acc: 0.8568 - val_loss: 0.3229 - val_acc: 0.8595\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3263 - acc: 0.8624 - val_loss: 0.3101 - val_acc: 0.8745\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3292 - acc: 0.8596 - val_loss: 0.3437 - val_acc: 0.8500\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3354 - acc: 0.8578 - val_loss: 0.3550 - val_acc: 0.8505\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3325 - acc: 0.8591 - val_loss: 0.3452 - val_acc: 0.8525\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3285 - acc: 0.8588 - val_loss: 0.3041 - val_acc: 0.8740\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3255 - acc: 0.8626 - val_loss: 0.3385 - val_acc: 0.8595\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3287 - acc: 0.8604 - val_loss: 0.3321 - val_acc: 0.8530\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3292 - acc: 0.8601 - val_loss: 0.3504 - val_acc: 0.8514\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3281 - acc: 0.8608 - val_loss: 0.3126 - val_acc: 0.8630\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3240 - acc: 0.8624 - val_loss: 0.3210 - val_acc: 0.8670loss:\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3185 - acc: 0.8666 - val_loss: 0.3513 - val_acc: 0.8400\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3260 - acc: 0.8596 - val_loss: 0.3339 - val_acc: 0.8540\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3244 - acc: 0.8628 - val_loss: 0.3231 - val_acc: 0.8650\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3183 - acc: 0.8656 - val_loss: 0.3352 - val_acc: 0.8545\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3226 - acc: 0.8641 - val_loss: 0.3283 - val_acc: 0.8575\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3211 - acc: 0.8641 - val_loss: 0.3102 - val_acc: 0.8705\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3212 - acc: 0.8650 - val_loss: 0.3242 - val_acc: 0.8615\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3153 - acc: 0.8653 - val_loss: 0.3333 - val_acc: 0.8600\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3171 - acc: 0.8668 - val_loss: 0.3121 - val_acc: 0.8700\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3243 - acc: 0.8610 - val_loss: 0.2991 - val_acc: 0.8830\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3129 - acc: 0.8676 - val_loss: 0.3093 - val_acc: 0.8740\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3168 - acc: 0.8637 - val_loss: 0.3134 - val_acc: 0.8648\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3110 - acc: 0.8684 - val_loss: 0.3387 - val_acc: 0.8540\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3173 - acc: 0.8663 - val_loss: 0.3058 - val_acc: 0.8790\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3115 - acc: 0.8685 - val_loss: 0.3158 - val_acc: 0.8760\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3139 - acc: 0.8666 - val_loss: 0.3225 - val_acc: 0.8610\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3141 - acc: 0.8665 - val_loss: 0.2844 - val_acc: 0.8840\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3108 - acc: 0.8679 - val_loss: 0.3010 - val_acc: 0.8725\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3080 - acc: 0.8693 - val_loss: 0.3294 - val_acc: 0.8660\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3111 - acc: 0.8673 - val_loss: 0.3069 - val_acc: 0.8710\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3167 - acc: 0.8648 - val_loss: 0.3270 - val_acc: 0.8560 - ETA: \n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3098 - acc: 0.8690 - val_loss: 0.3315 - val_acc: 0.8560\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3103 - acc: 0.8688 - val_loss: 0.3092 - val_acc: 0.8725\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3041 - acc: 0.8705 - val_loss: 0.3115 - val_acc: 0.8665\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3122 - acc: 0.8681 - val_loss: 0.3159 - val_acc: 0.8650\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3059 - acc: 0.8702 - val_loss: 0.3072 - val_acc: 0.8781\n",
      "Epoch 85/90\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.3051 - acc: 0.8703 - val_loss: 0.3074 - val_acc: 0.8670\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3118 - acc: 0.8668 - val_loss: 0.3003 - val_acc: 0.8735\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3090 - acc: 0.8697 - val_loss: 0.3075 - val_acc: 0.8725\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3008 - acc: 0.8732 - val_loss: 0.3067 - val_acc: 0.8660\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3068 - acc: 0.8713 - val_loss: 0.3046 - val_acc: 0.8785\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3061 - acc: 0.8703 - val_loss: 0.2917 - val_acc: 0.8735\n",
      "\n",
      "Training process completed in: 0 h 26 m 58 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1300.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1302 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_565 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_565 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_566 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_566 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_567 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_567 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_568 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_568 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_142 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 22s 166ms/step - loss: 0.5744 - acc: 0.7143 - val_loss: 0.4571 - val_acc: 0.7505\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.4365 - acc: 0.8070 - val_loss: 0.4257 - val_acc: 0.8200\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.4153 - acc: 0.8229 - val_loss: 0.4235 - val_acc: 0.8170\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 13s 98ms/step - loss: 0.4100 - acc: 0.8234 - val_loss: 0.4180 - val_acc: 0.8175\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.4030 - acc: 0.8257 - val_loss: 0.3970 - val_acc: 0.8315\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.4016 - acc: 0.8278 - val_loss: 0.4103 - val_acc: 0.8120\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3985 - acc: 0.8308 - val_loss: 0.4159 - val_acc: 0.8125\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 13s 98ms/step - loss: 0.4000 - acc: 0.8264 - val_loss: 0.4190 - val_acc: 0.8130\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 13s 98ms/step - loss: 0.3974 - acc: 0.8282 - val_loss: 0.3712 - val_acc: 0.8360\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3922 - acc: 0.8315 - val_loss: 0.4048 - val_acc: 0.8175\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3918 - acc: 0.8331 - val_loss: 0.3774 - val_acc: 0.8345\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3896 - acc: 0.8332 - val_loss: 0.3951 - val_acc: 0.8320\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3780 - acc: 0.8369 - val_loss: 0.3803 - val_acc: 0.8435\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3790 - acc: 0.8359 - val_loss: 0.3783 - val_acc: 0.8350\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3762 - acc: 0.8367 - val_loss: 0.3829 - val_acc: 0.8390\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3857 - acc: 0.8333 - val_loss: 0.3889 - val_acc: 0.8300\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3756 - acc: 0.8380 - val_loss: 0.3997 - val_acc: 0.8235\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3779 - acc: 0.8383 - val_loss: 0.3705 - val_acc: 0.8440\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3669 - acc: 0.8427 - val_loss: 0.3584 - val_acc: 0.8420\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 13s 96ms/step - loss: 0.3705 - acc: 0.8428 - val_loss: 0.3616 - val_acc: 0.8510\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3690 - acc: 0.8432 - val_loss: 0.3736 - val_acc: 0.8400\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3702 - acc: 0.8419 - val_loss: 0.3749 - val_acc: 0.8400\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 12s 96ms/step - loss: 0.3634 - acc: 0.8409 - val_loss: 0.3706 - val_acc: 0.8370\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3631 - acc: 0.8446 - val_loss: 0.3567 - val_acc: 0.8500\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.3650 - acc: 0.8443 - val_loss: 0.3597 - val_acc: 0.8435\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 13s 96ms/step - loss: 0.3579 - acc: 0.8493 - val_loss: 0.3520 - val_acc: 0.8535\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 12s 94ms/step - loss: 0.3559 - acc: 0.8468 - val_loss: 0.3565 - val_acc: 0.8430\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3595 - acc: 0.8479 - val_loss: 0.3680 - val_acc: 0.8412\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 12s 93ms/step - loss: 0.3484 - acc: 0.8505 - val_loss: 0.3426 - val_acc: 0.8485\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3525 - acc: 0.8503 - val_loss: 0.3363 - val_acc: 0.8570\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3557 - acc: 0.8488 - val_loss: 0.3590 - val_acc: 0.8530\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3466 - acc: 0.8539 - val_loss: 0.3599 - val_acc: 0.8440\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3506 - acc: 0.8495 - val_loss: 0.3551 - val_acc: 0.8565\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3483 - acc: 0.8533 - val_loss: 0.3599 - val_acc: 0.8465\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3482 - acc: 0.8548 - val_loss: 0.3410 - val_acc: 0.8515\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3433 - acc: 0.8554 - val_loss: 0.3574 - val_acc: 0.8450s - ETA: 1s - loss: 0\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3413 - acc: 0.8543 - val_loss: 0.3183 - val_acc: 0.8705\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3417 - acc: 0.8558 - val_loss: 0.3558 - val_acc: 0.8525\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3414 - acc: 0.8544 - val_loss: 0.3330 - val_acc: 0.8630\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3431 - acc: 0.8538 - val_loss: 0.3601 - val_acc: 0.8420\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3361 - acc: 0.8571 - val_loss: 0.3312 - val_acc: 0.8640\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 13s 96ms/step - loss: 0.3503 - acc: 0.8508 - val_loss: 0.3556 - val_acc: 0.8519\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 0.3414 - acc: 0.8551 - val_loss: 0.3632 - val_acc: 0.8445\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3423 - acc: 0.8555 - val_loss: 0.3123 - val_acc: 0.8740\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3363 - acc: 0.8563 - val_loss: 0.3432 - val_acc: 0.8425\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3366 - acc: 0.8576 - val_loss: 0.3326 - val_acc: 0.8565\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3378 - acc: 0.8600 - val_loss: 0.3568 - val_acc: 0.8430\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3316 - acc: 0.8578 - val_loss: 0.3646 - val_acc: 0.8480\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3291 - acc: 0.8612 - val_loss: 0.3164 - val_acc: 0.8605\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 12s 95ms/step - loss: 0.3369 - acc: 0.8562 - val_loss: 0.3476 - val_acc: 0.8540\n",
      "\n",
      "Training process completed in: 0 h 10 m 29 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1301.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1303 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_569 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_569 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_570 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_570 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_571 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_571 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_572 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_572 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_143 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 16s 125ms/step - loss: 0.5759 - acc: 0.7145 - val_loss: 0.5459 - val_acc: 0.7150\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 6s 48ms/step - loss: 0.4901 - acc: 0.7598 - val_loss: 0.4471 - val_acc: 0.8000\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4330 - acc: 0.8155 - val_loss: 0.4077 - val_acc: 0.8260\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4320 - acc: 0.8155 - val_loss: 0.4052 - val_acc: 0.8260\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4186 - acc: 0.8189 - val_loss: 0.4362 - val_acc: 0.8140\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4182 - acc: 0.8227 - val_loss: 0.4076 - val_acc: 0.8130\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4123 - acc: 0.8215 - val_loss: 0.4164 - val_acc: 0.8060\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4095 - acc: 0.8235 - val_loss: 0.4109 - val_acc: 0.8320\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4002 - acc: 0.8301 - val_loss: 0.3922 - val_acc: 0.8300\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4132 - acc: 0.8202 - val_loss: 0.4089 - val_acc: 0.8220\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4097 - acc: 0.8280 - val_loss: 0.4231 - val_acc: 0.8160\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4072 - acc: 0.8259 - val_loss: 0.4141 - val_acc: 0.8280\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4078 - acc: 0.8225 - val_loss: 0.3886 - val_acc: 0.8410\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.4067 - acc: 0.8212 - val_loss: 0.4055 - val_acc: 0.8200\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4065 - acc: 0.8265 - val_loss: 0.4136 - val_acc: 0.8120\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4009 - acc: 0.8277 - val_loss: 0.4460 - val_acc: 0.8080\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4067 - acc: 0.8263 - val_loss: 0.3853 - val_acc: 0.8370\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3989 - acc: 0.8288 - val_loss: 0.3870 - val_acc: 0.8340\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4003 - acc: 0.8275 - val_loss: 0.4200 - val_acc: 0.8160\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3863 - acc: 0.8361 - val_loss: 0.3793 - val_acc: 0.8360\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.4000 - acc: 0.8285 - val_loss: 0.3976 - val_acc: 0.8260\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3896 - acc: 0.8334 - val_loss: 0.3558 - val_acc: 0.8420\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3901 - acc: 0.8313 - val_loss: 0.4035 - val_acc: 0.8340\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3860 - acc: 0.8327 - val_loss: 0.4139 - val_acc: 0.8180\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3775 - acc: 0.8415 - val_loss: 0.3703 - val_acc: 0.8540\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3894 - acc: 0.8356 - val_loss: 0.3490 - val_acc: 0.8510\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3856 - acc: 0.8321 - val_loss: 0.4204 - val_acc: 0.8210\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3873 - acc: 0.8370 - val_loss: 0.4061 - val_acc: 0.8319\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3790 - acc: 0.8392 - val_loss: 0.4203 - val_acc: 0.8230\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3979 - acc: 0.8273 - val_loss: 0.3908 - val_acc: 0.8320\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3796 - acc: 0.8394 - val_loss: 0.3851 - val_acc: 0.8310\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3744 - acc: 0.8408 - val_loss: 0.3384 - val_acc: 0.8490\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3852 - acc: 0.8360 - val_loss: 0.3874 - val_acc: 0.8360\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3740 - acc: 0.8366 - val_loss: 0.3749 - val_acc: 0.8410\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3743 - acc: 0.8420 - val_loss: 0.3721 - val_acc: 0.8450\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3727 - acc: 0.8418 - val_loss: 0.3796 - val_acc: 0.8240\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3760 - acc: 0.8375 - val_loss: 0.3863 - val_acc: 0.8280\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3711 - acc: 0.8409 - val_loss: 0.3909 - val_acc: 0.8390\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3789 - acc: 0.8390 - val_loss: 0.3698 - val_acc: 0.8360\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3658 - acc: 0.8426 - val_loss: 0.3721 - val_acc: 0.8610\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3772 - acc: 0.8384 - val_loss: 0.3645 - val_acc: 0.8450\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3650 - acc: 0.8440 - val_loss: 0.3695 - val_acc: 0.8460\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3713 - acc: 0.8410 - val_loss: 0.3871 - val_acc: 0.8200\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3738 - acc: 0.8415 - val_loss: 0.3618 - val_acc: 0.8530\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3613 - acc: 0.8440 - val_loss: 0.3827 - val_acc: 0.8290\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3680 - acc: 0.8428 - val_loss: 0.3613 - val_acc: 0.8530\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3548 - acc: 0.8472 - val_loss: 0.3598 - val_acc: 0.8390\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3678 - acc: 0.8436 - val_loss: 0.3722 - val_acc: 0.8410\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 7s 51ms/step - loss: 0.3660 - acc: 0.8443 - val_loss: 0.3764 - val_acc: 0.8350\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 7s 52ms/step - loss: 0.3699 - acc: 0.8408 - val_loss: 0.3286 - val_acc: 0.8630\n",
      "\n",
      "Training process completed in: 0 h 5 m 43 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1302.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1304 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_573 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_573 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_574 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_574 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_575 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_575 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_576 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_576 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_144 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "190/190 [==============================] - 27s 143ms/step - loss: 0.4763 - acc: 0.7820 - val_loss: 0.4203 - val_acc: 0.8175\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.4140 - acc: 0.8218 - val_loss: 0.4222 - val_acc: 0.8260\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4051 - acc: 0.8255 - val_loss: 0.4316 - val_acc: 0.8145\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3899 - acc: 0.8344 - val_loss: 0.3929 - val_acc: 0.8375\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3816 - acc: 0.8356 - val_loss: 0.4153 - val_acc: 0.8305\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3841 - acc: 0.8361 - val_loss: 0.4053 - val_acc: 0.8195\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3730 - acc: 0.8389 - val_loss: 0.3970 - val_acc: 0.8410\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3823 - acc: 0.8341 - val_loss: 0.3774 - val_acc: 0.8365\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3680 - acc: 0.8444 - val_loss: 0.3840 - val_acc: 0.8390\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3707 - acc: 0.8413 - val_loss: 0.3866 - val_acc: 0.8400\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3696 - acc: 0.8424 - val_loss: 0.3839 - val_acc: 0.8320\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3634 - acc: 0.8460 - val_loss: 0.4072 - val_acc: 0.8540\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3608 - acc: 0.8459 - val_loss: 0.3624 - val_acc: 0.8395\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3555 - acc: 0.8472 - val_loss: 0.3596 - val_acc: 0.8489\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3450 - acc: 0.8516 - val_loss: 0.3752 - val_acc: 0.8525\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3525 - acc: 0.8503 - val_loss: 0.3851 - val_acc: 0.8500\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3503 - acc: 0.8516 - val_loss: 0.3784 - val_acc: 0.8420\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3471 - acc: 0.8530 - val_loss: 0.3448 - val_acc: 0.8590\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3508 - acc: 0.8514 - val_loss: 0.3687 - val_acc: 0.8470\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3375 - acc: 0.8566 - val_loss: 0.3378 - val_acc: 0.8700\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3367 - acc: 0.8566 - val_loss: 0.3575 - val_acc: 0.8500\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3351 - acc: 0.8566 - val_loss: 0.3344 - val_acc: 0.8650\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3331 - acc: 0.8590 - val_loss: 0.4108 - val_acc: 0.8280\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3328 - acc: 0.8590 - val_loss: 0.3462 - val_acc: 0.8615\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3315 - acc: 0.8586 - val_loss: 0.3535 - val_acc: 0.8590\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3241 - acc: 0.8638 - val_loss: 0.3470 - val_acc: 0.8665\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3315 - acc: 0.8593 - val_loss: 0.3343 - val_acc: 0.8615\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3285 - acc: 0.8601 - val_loss: 0.3703 - val_acc: 0.8484\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3308 - acc: 0.8605 - val_loss: 0.3595 - val_acc: 0.8415\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3179 - acc: 0.8662 - val_loss: 0.3111 - val_acc: 0.8720\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3153 - acc: 0.8664 - val_loss: 0.3480 - val_acc: 0.8615\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3229 - acc: 0.8638 - val_loss: 0.3639 - val_acc: 0.8565\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3230 - acc: 0.8630 - val_loss: 0.3356 - val_acc: 0.8670\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3215 - acc: 0.8646 - val_loss: 0.3411 - val_acc: 0.8715\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3239 - acc: 0.8626 - val_loss: 0.3225 - val_acc: 0.8685\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3148 - acc: 0.8666 - val_loss: 0.3440 - val_acc: 0.8500\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3190 - acc: 0.8657 - val_loss: 0.3138 - val_acc: 0.8715\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3169 - acc: 0.8665 - val_loss: 0.3379 - val_acc: 0.8670\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3157 - acc: 0.8674 - val_loss: 0.3401 - val_acc: 0.8645\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3182 - acc: 0.8662 - val_loss: 0.3606 - val_acc: 0.8605\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3118 - acc: 0.8686 - val_loss: 0.3291 - val_acc: 0.8700\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3145 - acc: 0.8665 - val_loss: 0.3026 - val_acc: 0.8770\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3222 - acc: 0.8633 - val_loss: 0.3363 - val_acc: 0.8620\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3057 - acc: 0.8703 - val_loss: 0.3235 - val_acc: 0.8640\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3096 - acc: 0.8715 - val_loss: 0.3495 - val_acc: 0.8540\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3123 - acc: 0.8703 - val_loss: 0.3399 - val_acc: 0.8600\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3109 - acc: 0.8676 - val_loss: 0.3331 - val_acc: 0.8715\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3087 - acc: 0.8714 - val_loss: 0.3532 - val_acc: 0.8455\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3110 - acc: 0.8687 - val_loss: 0.3441 - val_acc: 0.8620\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3085 - acc: 0.8711 - val_loss: 0.3356 - val_acc: 0.8610\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3090 - acc: 0.8693 - val_loss: 0.3126 - val_acc: 0.8735\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3039 - acc: 0.8731 - val_loss: 0.3375 - val_acc: 0.8675\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3020 - acc: 0.8735 - val_loss: 0.3152 - val_acc: 0.8740\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3071 - acc: 0.8711 - val_loss: 0.3247 - val_acc: 0.8745\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3095 - acc: 0.8708 - val_loss: 0.3390 - val_acc: 0.8560\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3032 - acc: 0.8729 - val_loss: 0.3001 - val_acc: 0.8811\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3037 - acc: 0.8714 - val_loss: 0.3172 - val_acc: 0.8750\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3033 - acc: 0.8716 - val_loss: 0.3527 - val_acc: 0.8490\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 95ms/step - loss: 0.3077 - acc: 0.8715 - val_loss: 0.3522 - val_acc: 0.8520\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3028 - acc: 0.8734 - val_loss: 0.3162 - val_acc: 0.8785\n",
      "Epoch 61/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3016 - acc: 0.8749 - val_loss: 0.3538 - val_acc: 0.8460\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2996 - acc: 0.8728 - val_loss: 0.3431 - val_acc: 0.8550\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2974 - acc: 0.8746 - val_loss: 0.3009 - val_acc: 0.8800\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.3010 - acc: 0.8733 - val_loss: 0.3230 - val_acc: 0.8675\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2997 - acc: 0.8753 - val_loss: 0.3767 - val_acc: 0.8540\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2990 - acc: 0.8751 - val_loss: 0.3186 - val_acc: 0.8760\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3005 - acc: 0.8744 - val_loss: 0.3093 - val_acc: 0.8745\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.3012 - acc: 0.8732 - val_loss: 0.3331 - val_acc: 0.8595\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 18s 92ms/step - loss: 0.3013 - acc: 0.8718 - val_loss: 0.3290 - val_acc: 0.8710\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.2919 - acc: 0.8777 - val_loss: 0.3213 - val_acc: 0.8673\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.2990 - acc: 0.8740 - val_loss: 0.3183 - val_acc: 0.8705\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2923 - acc: 0.8754 - val_loss: 0.3202 - val_acc: 0.8575\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2942 - acc: 0.8780 - val_loss: 0.3243 - val_acc: 0.8685\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2959 - acc: 0.8748 - val_loss: 0.3146 - val_acc: 0.8685\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2970 - acc: 0.8745 - val_loss: 0.3299 - val_acc: 0.8725\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2990 - acc: 0.8734 - val_loss: 0.3292 - val_acc: 0.8610\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2918 - acc: 0.8771 - val_loss: 0.3351 - val_acc: 0.8730\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2944 - acc: 0.8764 - val_loss: 0.3235 - val_acc: 0.8650\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2968 - acc: 0.8751 - val_loss: 0.2921 - val_acc: 0.8735\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2950 - acc: 0.8752 - val_loss: 0.3138 - val_acc: 0.8695\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2934 - acc: 0.8770 - val_loss: 0.3033 - val_acc: 0.8785\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2932 - acc: 0.8786 - val_loss: 0.2955 - val_acc: 0.8820\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2903 - acc: 0.8772 - val_loss: 0.3357 - val_acc: 0.8620\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.2891 - acc: 0.8785 - val_loss: 0.3374 - val_acc: 0.8550\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2922 - acc: 0.8790 - val_loss: 0.3189 - val_acc: 0.8685\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2907 - acc: 0.8770 - val_loss: 0.3331 - val_acc: 0.8645\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2938 - acc: 0.8774 - val_loss: 0.3497 - val_acc: 0.8635\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2873 - acc: 0.8792 - val_loss: 0.2940 - val_acc: 0.8800\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2986 - acc: 0.8744 - val_loss: 0.3344 - val_acc: 0.8670\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2845 - acc: 0.8811 - val_loss: 0.3283 - val_acc: 0.8605\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2915 - acc: 0.8781 - val_loss: 0.3022 - val_acc: 0.8785\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2894 - acc: 0.8799 - val_loss: 0.3292 - val_acc: 0.8705\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2928 - acc: 0.8762 - val_loss: 0.3217 - val_acc: 0.8665\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.2870 - acc: 0.8792 - val_loss: 0.3122 - val_acc: 0.8730\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2857 - acc: 0.8809 - val_loss: 0.3125 - val_acc: 0.8715\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2854 - acc: 0.8797 - val_loss: 0.3142 - val_acc: 0.8745\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.2879 - acc: 0.8784 - val_loss: 0.3138 - val_acc: 0.8740\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.2918 - acc: 0.8776 - val_loss: 0.2999 - val_acc: 0.8724\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 17s 91ms/step - loss: 0.2896 - acc: 0.8774 - val_loss: 0.3172 - val_acc: 0.8660\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.2831 - acc: 0.8822 - val_loss: 0.3181 - val_acc: 0.8695\n",
      "\n",
      "Training process completed in: 0 h 29 m 49 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1303.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1305 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_577 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_577 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_578 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_578 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_579 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_579 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_580 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_580 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_145 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "190/190 [==============================] - 28s 147ms/step - loss: 0.5512 - acc: 0.7227 - val_loss: 0.4423 - val_acc: 0.8085\n",
      "Epoch 2/100\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.4351 - acc: 0.8136 - val_loss: 0.4165 - val_acc: 0.8212 1s - loss: 0.4\n",
      "Epoch 3/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4184 - acc: 0.8213 - val_loss: 0.4198 - val_acc: 0.8200\n",
      "Epoch 4/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4193 - acc: 0.8214 - val_loss: 0.4244 - val_acc: 0.8148\n",
      "Epoch 5/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4165 - acc: 0.8218 - val_loss: 0.4122 - val_acc: 0.8275\n",
      "Epoch 6/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4150 - acc: 0.8214 - val_loss: 0.4096 - val_acc: 0.8245\n",
      "Epoch 7/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4092 - acc: 0.8243 - val_loss: 0.4146 - val_acc: 0.8203\n",
      "Epoch 8/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3974 - acc: 0.8318 - val_loss: 0.4121 - val_acc: 0.8217\n",
      "Epoch 9/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3954 - acc: 0.8292 - val_loss: 0.4035 - val_acc: 0.8323\n",
      "Epoch 10/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.4011 - acc: 0.8272 - val_loss: 0.3962 - val_acc: 0.8347\n",
      "Epoch 11/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3993 - acc: 0.8286 - val_loss: 0.3918 - val_acc: 0.8290\n",
      "Epoch 12/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3890 - acc: 0.8339 - val_loss: 0.3990 - val_acc: 0.8322\n",
      "Epoch 13/100\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3867 - acc: 0.8345 - val_loss: 0.3894 - val_acc: 0.8315\n",
      "Epoch 14/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3901 - acc: 0.8334 - val_loss: 0.3871 - val_acc: 0.8307\n",
      "Epoch 15/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3826 - acc: 0.8369 - val_loss: 0.3971 - val_acc: 0.8250\n",
      "Epoch 16/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3870 - acc: 0.8353 - val_loss: 0.3718 - val_acc: 0.8452\n",
      "Epoch 17/100\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3808 - acc: 0.8373 - val_loss: 0.3664 - val_acc: 0.8410\n",
      "Epoch 18/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3680 - acc: 0.8434 - val_loss: 0.3656 - val_acc: 0.8402\n",
      "Epoch 19/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3677 - acc: 0.8441 - val_loss: 0.3901 - val_acc: 0.8272\n",
      "Epoch 20/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3750 - acc: 0.8411 - val_loss: 0.3836 - val_acc: 0.8335\n",
      "Epoch 21/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3726 - acc: 0.8404 - val_loss: 0.3639 - val_acc: 0.8446\n",
      "Epoch 22/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3712 - acc: 0.8405 - val_loss: 0.3642 - val_acc: 0.8453\n",
      "Epoch 23/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3668 - acc: 0.8413 - val_loss: 0.3637 - val_acc: 0.8455\n",
      "Epoch 24/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3663 - acc: 0.8461 - val_loss: 0.3809 - val_acc: 0.8335\n",
      "Epoch 25/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3646 - acc: 0.8431 - val_loss: 0.3677 - val_acc: 0.8445\n",
      "Epoch 26/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3611 - acc: 0.8461 - val_loss: 0.3540 - val_acc: 0.8537\n",
      "Epoch 27/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3584 - acc: 0.8464 - val_loss: 0.3592 - val_acc: 0.8455\n",
      "Epoch 28/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3507 - acc: 0.8527 - val_loss: 0.3586 - val_acc: 0.8401\n",
      "Epoch 29/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3580 - acc: 0.8463 - val_loss: 0.3583 - val_acc: 0.8453\n",
      "Epoch 30/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3518 - acc: 0.8518 - val_loss: 0.3448 - val_acc: 0.8515\n",
      "Epoch 31/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3516 - acc: 0.8508 - val_loss: 0.3565 - val_acc: 0.8488\n",
      "Epoch 32/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3566 - acc: 0.8490 - val_loss: 0.3664 - val_acc: 0.8375\n",
      "Epoch 33/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3502 - acc: 0.8511 - val_loss: 0.3579 - val_acc: 0.8525\n",
      "Epoch 34/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3478 - acc: 0.8515 - val_loss: 0.3514 - val_acc: 0.8498\n",
      "Epoch 35/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3460 - acc: 0.8523 - val_loss: 0.3705 - val_acc: 0.8426\n",
      "Epoch 36/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3443 - acc: 0.8537 - val_loss: 0.3563 - val_acc: 0.8493\n",
      "Epoch 37/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3502 - acc: 0.8509 - val_loss: 0.3603 - val_acc: 0.8465\n",
      "Epoch 38/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3469 - acc: 0.8532 - val_loss: 0.3461 - val_acc: 0.8543\n",
      "Epoch 39/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3421 - acc: 0.8523 - val_loss: 0.3416 - val_acc: 0.8565\n",
      "Epoch 40/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3353 - acc: 0.8585 - val_loss: 0.3272 - val_acc: 0.8680\n",
      "Epoch 41/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3465 - acc: 0.8536 - val_loss: 0.3180 - val_acc: 0.8680\n",
      "Epoch 42/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3447 - acc: 0.8530 - val_loss: 0.3475 - val_acc: 0.8472\n",
      "Epoch 43/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3394 - acc: 0.8583 - val_loss: 0.3478 - val_acc: 0.8552\n",
      "Epoch 44/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3387 - acc: 0.8568 - val_loss: 0.3314 - val_acc: 0.8643\n",
      "Epoch 45/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3390 - acc: 0.8552 - val_loss: 0.3353 - val_acc: 0.8597\n",
      "Epoch 46/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3359 - acc: 0.8575 - val_loss: 0.3534 - val_acc: 0.8485\n",
      "Epoch 47/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3389 - acc: 0.8541 - val_loss: 0.3212 - val_acc: 0.8637\n",
      "Epoch 48/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3351 - acc: 0.8592 - val_loss: 0.3546 - val_acc: 0.8515\n",
      "Epoch 49/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3395 - acc: 0.8546 - val_loss: 0.3517 - val_acc: 0.8512\n",
      "Epoch 50/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3363 - acc: 0.8563 - val_loss: 0.3534 - val_acc: 0.8550\n",
      "Epoch 51/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3323 - acc: 0.8601 - val_loss: 0.3499 - val_acc: 0.8553\n",
      "Epoch 52/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3390 - acc: 0.8546 - val_loss: 0.3274 - val_acc: 0.8583\n",
      "Epoch 53/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3318 - acc: 0.8586 - val_loss: 0.3232 - val_acc: 0.8690\n",
      "Epoch 54/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3288 - acc: 0.8604 - val_loss: 0.3289 - val_acc: 0.8603\n",
      "Epoch 55/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3332 - acc: 0.8587 - val_loss: 0.3363 - val_acc: 0.8550\n",
      "Epoch 56/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3299 - acc: 0.8604 - val_loss: 0.3294 - val_acc: 0.8586\n",
      "Epoch 57/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3298 - acc: 0.8611 - val_loss: 0.3380 - val_acc: 0.8580\n",
      "Epoch 58/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3333 - acc: 0.8596 - val_loss: 0.3320 - val_acc: 0.8615\n",
      "Epoch 59/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3325 - acc: 0.8605 - val_loss: 0.3351 - val_acc: 0.8588\n",
      "Epoch 60/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3305 - acc: 0.8604 - val_loss: 0.3245 - val_acc: 0.8618\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3216 - acc: 0.8636 - val_loss: 0.3435 - val_acc: 0.8530\n",
      "Epoch 62/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3270 - acc: 0.8611 - val_loss: 0.3521 - val_acc: 0.8463\n",
      "Epoch 63/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3217 - acc: 0.8626 - val_loss: 0.3295 - val_acc: 0.8639\n",
      "Epoch 64/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3380 - acc: 0.8568 - val_loss: 0.3317 - val_acc: 0.8588\n",
      "Epoch 65/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3247 - acc: 0.8626 - val_loss: 0.3250 - val_acc: 0.8645\n",
      "Epoch 66/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3268 - acc: 0.8625 - val_loss: 0.3253 - val_acc: 0.8598\n",
      "Epoch 67/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3200 - acc: 0.8643 - val_loss: 0.3194 - val_acc: 0.8640\n",
      "Epoch 68/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3248 - acc: 0.8620 - val_loss: 0.3206 - val_acc: 0.8630\n",
      "Epoch 69/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3209 - acc: 0.8645 - val_loss: 0.3212 - val_acc: 0.8635\n",
      "Epoch 70/100\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3276 - acc: 0.8620 - val_loss: 0.3252 - val_acc: 0.8656\n",
      "Epoch 71/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3266 - acc: 0.8606 - val_loss: 0.3345 - val_acc: 0.8608\n",
      "Epoch 72/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3244 - acc: 0.8625 - val_loss: 0.3339 - val_acc: 0.8633\n",
      "Epoch 73/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3160 - acc: 0.8663 - val_loss: 0.3159 - val_acc: 0.8623\n",
      "Epoch 74/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3207 - acc: 0.8641 - val_loss: 0.3203 - val_acc: 0.8620\n",
      "Epoch 75/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3193 - acc: 0.8654 - val_loss: 0.3242 - val_acc: 0.8650\n",
      "Epoch 76/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3196 - acc: 0.8666 - val_loss: 0.3369 - val_acc: 0.8555\n",
      "Epoch 77/100\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3165 - acc: 0.8663 - val_loss: 0.3176 - val_acc: 0.8677\n",
      "Epoch 78/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3157 - acc: 0.8677 - val_loss: 0.3151 - val_acc: 0.8710\n",
      "Epoch 79/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3184 - acc: 0.8644 - val_loss: 0.3181 - val_acc: 0.8708\n",
      "Epoch 80/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3207 - acc: 0.8631 - val_loss: 0.3110 - val_acc: 0.8662\n",
      "Epoch 81/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3134 - acc: 0.8689 - val_loss: 0.3524 - val_acc: 0.8520\n",
      "Epoch 82/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3170 - acc: 0.8664 - val_loss: 0.3515 - val_acc: 0.8483\n",
      "Epoch 83/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3152 - acc: 0.8655 - val_loss: 0.3206 - val_acc: 0.8650\n",
      "Epoch 84/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3191 - acc: 0.8648 - val_loss: 0.2961 - val_acc: 0.8717\n",
      "Epoch 85/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3148 - acc: 0.8673 - val_loss: 0.3264 - val_acc: 0.8650\n",
      "Epoch 86/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3117 - acc: 0.8680 - val_loss: 0.3170 - val_acc: 0.8685\n",
      "Epoch 87/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3105 - acc: 0.8692 - val_loss: 0.3255 - val_acc: 0.8683\n",
      "Epoch 88/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3117 - acc: 0.8686 - val_loss: 0.3038 - val_acc: 0.8782\n",
      "Epoch 89/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3147 - acc: 0.8663 - val_loss: 0.3134 - val_acc: 0.8600\n",
      "Epoch 90/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3112 - acc: 0.8689 - val_loss: 0.3195 - val_acc: 0.8597\n",
      "Epoch 91/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3134 - acc: 0.8681 - val_loss: 0.3157 - val_acc: 0.8598\n",
      "Epoch 92/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3121 - acc: 0.8683 - val_loss: 0.3337 - val_acc: 0.8597\n",
      "Epoch 93/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3107 - acc: 0.8666 - val_loss: 0.3088 - val_acc: 0.8722\n",
      "Epoch 94/100\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3107 - acc: 0.8681 - val_loss: 0.3326 - val_acc: 0.8590\n",
      "Epoch 95/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3127 - acc: 0.8686 - val_loss: 0.3172 - val_acc: 0.8643\n",
      "Epoch 96/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3111 - acc: 0.8685 - val_loss: 0.2916 - val_acc: 0.8775\n",
      "Epoch 97/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3034 - acc: 0.8724 - val_loss: 0.3176 - val_acc: 0.8712\n",
      "Epoch 98/100\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3144 - acc: 0.8671 - val_loss: 0.3134 - val_acc: 0.8651\n",
      "Epoch 99/100\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3071 - acc: 0.8702 - val_loss: 0.3050 - val_acc: 0.8725\n",
      "Epoch 100/100\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3091 - acc: 0.8696 - val_loss: 0.3142 - val_acc: 0.8648\n",
      "\n",
      "Training process completed in: 0 h 30 m 48 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1304.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1306 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_581 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_581 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_582 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_582 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_583 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_583 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_584 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_584 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_146 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 28s 146ms/step - loss: 0.5339 - acc: 0.7421 - val_loss: 0.4378 - val_acc: 0.8045\n",
      "Epoch 2/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4186 - acc: 0.8208 - val_loss: 0.4138 - val_acc: 0.8182\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4170 - acc: 0.8210 - val_loss: 0.4158 - val_acc: 0.8133\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.4173 - acc: 0.8220 - val_loss: 0.4006 - val_acc: 0.8237\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4114 - acc: 0.8238 - val_loss: 0.4237 - val_acc: 0.8222\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 18s 95ms/step - loss: 0.4148 - acc: 0.8223 - val_loss: 0.4208 - val_acc: 0.8145\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.4066 - acc: 0.8243 - val_loss: 0.3858 - val_acc: 0.8355\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.4080 - acc: 0.8257 - val_loss: 0.4205 - val_acc: 0.8100\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3967 - acc: 0.8299 - val_loss: 0.4007 - val_acc: 0.8305\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3962 - acc: 0.8308 - val_loss: 0.4010 - val_acc: 0.8275\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3874 - acc: 0.8363 - val_loss: 0.3874 - val_acc: 0.8340\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3916 - acc: 0.8309 - val_loss: 0.3904 - val_acc: 0.8265\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3894 - acc: 0.8327 - val_loss: 0.3962 - val_acc: 0.8283\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3897 - acc: 0.8305 - val_loss: 0.3853 - val_acc: 0.8393\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3840 - acc: 0.8356 - val_loss: 0.3773 - val_acc: 0.8420\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3810 - acc: 0.8363 - val_loss: 0.3834 - val_acc: 0.8325\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3803 - acc: 0.8378 - val_loss: 0.3773 - val_acc: 0.8317\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3785 - acc: 0.8366 - val_loss: 0.3805 - val_acc: 0.8358\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3741 - acc: 0.8401 - val_loss: 0.3904 - val_acc: 0.8260\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3745 - acc: 0.8388 - val_loss: 0.3935 - val_acc: 0.8348\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3754 - acc: 0.8376 - val_loss: 0.3681 - val_acc: 0.8325\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3724 - acc: 0.8364 - val_loss: 0.3765 - val_acc: 0.8420\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3682 - acc: 0.8412 - val_loss: 0.3735 - val_acc: 0.8382\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3653 - acc: 0.8422 - val_loss: 0.3664 - val_acc: 0.8465\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3646 - acc: 0.8428 - val_loss: 0.3611 - val_acc: 0.8410\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3589 - acc: 0.8483 - val_loss: 0.3585 - val_acc: 0.8403\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3608 - acc: 0.8439 - val_loss: 0.3648 - val_acc: 0.8453\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3610 - acc: 0.8439 - val_loss: 0.3499 - val_acc: 0.8439\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3604 - acc: 0.8445 - val_loss: 0.3650 - val_acc: 0.8470\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3620 - acc: 0.8458 - val_loss: 0.3524 - val_acc: 0.8475\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3522 - acc: 0.8496 - val_loss: 0.3554 - val_acc: 0.8545\n",
      "Epoch 32/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3530 - acc: 0.8483 - val_loss: 0.3596 - val_acc: 0.8498\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3548 - acc: 0.8493 - val_loss: 0.3549 - val_acc: 0.8500\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3512 - acc: 0.8479 - val_loss: 0.3568 - val_acc: 0.8407\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3438 - acc: 0.8553 - val_loss: 0.3393 - val_acc: 0.8565\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3479 - acc: 0.8527 - val_loss: 0.3607 - val_acc: 0.8478\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3478 - acc: 0.8508 - val_loss: 0.3552 - val_acc: 0.8510\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3445 - acc: 0.8512 - val_loss: 0.3718 - val_acc: 0.8400\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3463 - acc: 0.8521 - val_loss: 0.3514 - val_acc: 0.8465\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3457 - acc: 0.8518 - val_loss: 0.3400 - val_acc: 0.8580\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 18s 96ms/step - loss: 0.3406 - acc: 0.8547 - val_loss: 0.3230 - val_acc: 0.8620\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3373 - acc: 0.8570 - val_loss: 0.3493 - val_acc: 0.8515\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3410 - acc: 0.8534 - val_loss: 0.3427 - val_acc: 0.8558\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3378 - acc: 0.8556 - val_loss: 0.3295 - val_acc: 0.8633\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3379 - acc: 0.8566 - val_loss: 0.3360 - val_acc: 0.8550\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3384 - acc: 0.8543 - val_loss: 0.3266 - val_acc: 0.8605\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3357 - acc: 0.8587 - val_loss: 0.3641 - val_acc: 0.8385\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3350 - acc: 0.8586 - val_loss: 0.3274 - val_acc: 0.8658\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3380 - acc: 0.8551 - val_loss: 0.3234 - val_acc: 0.8613\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3326 - acc: 0.8582 - val_loss: 0.3443 - val_acc: 0.8510\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3317 - acc: 0.8584 - val_loss: 0.3523 - val_acc: 0.8500\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3338 - acc: 0.8562 - val_loss: 0.3092 - val_acc: 0.8723\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3330 - acc: 0.8571 - val_loss: 0.3236 - val_acc: 0.8633\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3300 - acc: 0.8591 - val_loss: 0.3319 - val_acc: 0.8585\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3244 - acc: 0.8610 - val_loss: 0.3375 - val_acc: 0.8575\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3285 - acc: 0.8610 - val_loss: 0.3150 - val_acc: 0.8664\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3311 - acc: 0.8591 - val_loss: 0.3282 - val_acc: 0.8633\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3265 - acc: 0.8601 - val_loss: 0.3395 - val_acc: 0.8530\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3280 - acc: 0.8589 - val_loss: 0.3305 - val_acc: 0.8605\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3271 - acc: 0.8608 - val_loss: 0.3129 - val_acc: 0.8715\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3277 - acc: 0.8598 - val_loss: 0.3337 - val_acc: 0.8535\n",
      "Epoch 62/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3213 - acc: 0.8645 - val_loss: 0.3182 - val_acc: 0.8638\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3195 - acc: 0.8644 - val_loss: 0.3275 - val_acc: 0.8575\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3183 - acc: 0.8649 - val_loss: 0.3272 - val_acc: 0.8605\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3225 - acc: 0.8637 - val_loss: 0.3344 - val_acc: 0.8562\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 19s 97ms/step - loss: 0.3225 - acc: 0.8625 - val_loss: 0.3141 - val_acc: 0.8730\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3240 - acc: 0.8608 - val_loss: 0.3278 - val_acc: 0.8637\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3202 - acc: 0.8649 - val_loss: 0.3229 - val_acc: 0.8645\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 18s 97ms/step - loss: 0.3132 - acc: 0.8653 - val_loss: 0.3304 - val_acc: 0.8537\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3192 - acc: 0.8624 - val_loss: 0.3366 - val_acc: 0.8654\n",
      "\n",
      "Training process completed in: 0 h 21 m 37 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1305.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1307 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_585 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_585 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_586 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_586 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_587 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_587 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_588 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_588 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_147 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 200\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.4747 - acc: 0.7855 - val_loss: 0.4336 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4257 - acc: 0.8180 - val_loss: 0.4048 - val_acc: 0.8310\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.4026 - acc: 0.8282 - val_loss: 0.3877 - val_acc: 0.8337s: 0.4041 - acc: 0.827 - ETA: 1s - loss: \n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3970 - acc: 0.8291 - val_loss: 0.3837 - val_acc: 0.8327\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3884 - acc: 0.8332 - val_loss: 0.3874 - val_acc: 0.8369\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3807 - acc: 0.8379 - val_loss: 0.3887 - val_acc: 0.8300\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3826 - acc: 0.8353 - val_loss: 0.3869 - val_acc: 0.8303\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3761 - acc: 0.8400 - val_loss: 0.3662 - val_acc: 0.8447\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3727 - acc: 0.8417 - val_loss: 0.3681 - val_acc: 0.8427\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3593 - acc: 0.8469 - val_loss: 0.3609 - val_acc: 0.8511\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3620 - acc: 0.8449 - val_loss: 0.3628 - val_acc: 0.8445\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3617 - acc: 0.8461 - val_loss: 0.3745 - val_acc: 0.8480\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3581 - acc: 0.8490 - val_loss: 0.3818 - val_acc: 0.8495\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3615 - acc: 0.8466 - val_loss: 0.3858 - val_acc: 0.8357\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3490 - acc: 0.8516 - val_loss: 0.3693 - val_acc: 0.8508\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3537 - acc: 0.8484 - val_loss: 0.3758 - val_acc: 0.8492\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3477 - acc: 0.8512 - val_loss: 0.3449 - val_acc: 0.8573\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3419 - acc: 0.8542 - val_loss: 0.3542 - val_acc: 0.8520\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3321 - acc: 0.8593 - val_loss: 0.3564 - val_acc: 0.8449\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3443 - acc: 0.8535 - val_loss: 0.3749 - val_acc: 0.8482\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3411 - acc: 0.8541 - val_loss: 0.3629 - val_acc: 0.8535\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3374 - acc: 0.8562 - val_loss: 0.3380 - val_acc: 0.8652\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3290 - acc: 0.8604 - val_loss: 0.3282 - val_acc: 0.8628\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3347 - acc: 0.8575 - val_loss: 0.3291 - val_acc: 0.8664\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3412 - acc: 0.8550 - val_loss: 0.3518 - val_acc: 0.8530\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3325 - acc: 0.8585 - val_loss: 0.3579 - val_acc: 0.8492\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3238 - acc: 0.8622 - val_loss: 0.3440 - val_acc: 0.8613\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3202 - acc: 0.8650 - val_loss: 0.3313 - val_acc: 0.8616\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3259 - acc: 0.8614 - val_loss: 0.3188 - val_acc: 0.8725\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3247 - acc: 0.8629 - val_loss: 0.3473 - val_acc: 0.8622\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3222 - acc: 0.8635 - val_loss: 0.3319 - val_acc: 0.8580 4s - loss: 0.3236 - a - ETA: 3s - loss: 0.3225 - acc: 0 - E\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3296 - acc: 0.8600 - val_loss: 0.3307 - val_acc: 0.8658\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3203 - acc: 0.8658 - val_loss: 0.3300 - val_acc: 0.8604\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.3241 - acc: 0.8629 - val_loss: 0.3317 - val_acc: 0.8593\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3133 - acc: 0.8690 - val_loss: 0.3135 - val_acc: 0.8713\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3208 - acc: 0.8651 - val_loss: 0.3416 - val_acc: 0.8568\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3143 - acc: 0.8687 - val_loss: 0.3308 - val_acc: 0.8637\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.3147 - acc: 0.8668 - val_loss: 0.3140 - val_acc: 0.8695\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3187 - acc: 0.8651 - val_loss: 0.3126 - val_acc: 0.8725\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3128 - acc: 0.8677 - val_loss: 0.3588 - val_acc: 0.8518\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3163 - acc: 0.8659 - val_loss: 0.3206 - val_acc: 0.8668\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3165 - acc: 0.8663 - val_loss: 0.3147 - val_acc: 0.86840s - loss: 0.3170 - acc:\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3086 - acc: 0.8710 - val_loss: 0.3396 - val_acc: 0.8553\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3124 - acc: 0.8700 - val_loss: 0.3150 - val_acc: 0.8778\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3161 - acc: 0.8663 - val_loss: 0.3223 - val_acc: 0.8662\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3085 - acc: 0.8689 - val_loss: 0.3240 - val_acc: 0.8698\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3119 - acc: 0.8678 - val_loss: 0.3288 - val_acc: 0.8631\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3127 - acc: 0.8689 - val_loss: 0.3390 - val_acc: 0.8662\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3112 - acc: 0.8712 - val_loss: 0.3355 - val_acc: 0.8687\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3177 - acc: 0.8654 - val_loss: 0.3177 - val_acc: 0.8718\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3070 - acc: 0.8696 - val_loss: 0.3178 - val_acc: 0.8726\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3092 - acc: 0.8690 - val_loss: 0.3265 - val_acc: 0.8627\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3029 - acc: 0.8728 - val_loss: 0.3205 - val_acc: 0.8653\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3011 - acc: 0.8738 - val_loss: 0.3230 - val_acc: 0.8710\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3054 - acc: 0.8697 - val_loss: 0.3063 - val_acc: 0.8735\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3047 - acc: 0.8706 - val_loss: 0.3162 - val_acc: 0.8621\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3030 - acc: 0.8724 - val_loss: 0.3117 - val_acc: 0.8738\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3057 - acc: 0.8714 - val_loss: 0.3391 - val_acc: 0.8622\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3090 - acc: 0.8698 - val_loss: 0.3238 - val_acc: 0.8625\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3053 - acc: 0.8703 - val_loss: 0.3150 - val_acc: 0.8690\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3083 - acc: 0.8688 - val_loss: 0.3553 - val_acc: 0.8594\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2992 - acc: 0.8742 - val_loss: 0.3198 - val_acc: 0.8680\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3027 - acc: 0.8734 - val_loss: 0.3270 - val_acc: 0.8613\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2987 - acc: 0.8737 - val_loss: 0.2997 - val_acc: 0.8775\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3031 - acc: 0.8735 - val_loss: 0.3175 - val_acc: 0.8651\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3029 - acc: 0.8737 - val_loss: 0.3094 - val_acc: 0.8720\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.3002 - acc: 0.8747 - val_loss: 0.3057 - val_acc: 0.8782\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3010 - acc: 0.8738 - val_loss: 0.3088 - val_acc: 0.8682\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2979 - acc: 0.8745 - val_loss: 0.3277 - val_acc: 0.8762\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2955 - acc: 0.8753 - val_loss: 0.3124 - val_acc: 0.8745\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2971 - acc: 0.8755 - val_loss: 0.3229 - val_acc: 0.8650\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3019 - acc: 0.8729 - val_loss: 0.3105 - val_acc: 0.8717\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2966 - acc: 0.8752 - val_loss: 0.3204 - val_acc: 0.8705\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2955 - acc: 0.8763 - val_loss: 0.3109 - val_acc: 0.8708\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2989 - acc: 0.8760 - val_loss: 0.3137 - val_acc: 0.8772\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3048 - acc: 0.8725 - val_loss: 0.3144 - val_acc: 0.8660\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2943 - acc: 0.8748 - val_loss: 0.3065 - val_acc: 0.8763\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.3008 - acc: 0.8738 - val_loss: 0.3176 - val_acc: 0.8735\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2949 - acc: 0.8769 - val_loss: 0.3132 - val_acc: 0.8679\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2981 - acc: 0.8771 - val_loss: 0.3266 - val_acc: 0.8670\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2942 - acc: 0.8766 - val_loss: 0.3173 - val_acc: 0.8693\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2915 - acc: 0.8766 - val_loss: 0.3132 - val_acc: 0.8700\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2916 - acc: 0.8786 - val_loss: 0.3030 - val_acc: 0.8725\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2859 - acc: 0.8799 - val_loss: 0.3007 - val_acc: 0.8792\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2903 - acc: 0.8796 - val_loss: 0.2987 - val_acc: 0.8770\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2929 - acc: 0.8775 - val_loss: 0.3051 - val_acc: 0.8722\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2941 - acc: 0.8752 - val_loss: 0.3074 - val_acc: 0.8700\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 0.2923 - acc: 0.8792 - val_loss: 0.3161 - val_acc: 0.8733\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.2941 - acc: 0.8753 - val_loss: 0.3177 - val_acc: 0.8715\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2897 - acc: 0.8771 - val_loss: 0.3126 - val_acc: 0.8703\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2929 - acc: 0.8779 - val_loss: 0.3310 - val_acc: 0.8578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2873 - acc: 0.8793 - val_loss: 0.2908 - val_acc: 0.8813\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.2891 - acc: 0.8789 - val_loss: 0.2998 - val_acc: 0.8723\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 0.2949 - acc: 0.8775 - val_loss: 0.3075 - val_acc: 0.8730\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.2857 - acc: 0.8799 - val_loss: 0.3115 - val_acc: 0.8735\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2867 - acc: 0.8801 - val_loss: 0.3000 - val_acc: 0.8738\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2903 - acc: 0.8790 - val_loss: 0.3135 - val_acc: 0.8698\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2888 - acc: 0.8787 - val_loss: 0.3059 - val_acc: 0.8737\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2929 - acc: 0.8774 - val_loss: 0.3076 - val_acc: 0.8723\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 20s 102ms/step - loss: 0.2823 - acc: 0.8810 - val_loss: 0.3015 - val_acc: 0.8765\n",
      "\n",
      "Training process completed in: 0 h 34 m 8 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1306.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1308 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_589 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_589 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_590 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_590 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_591 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_591 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_592 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_592 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_148 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 70\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/70\n",
      "190/190 [==============================] - 29s 155ms/step - loss: 0.5386 - acc: 0.7378 - val_loss: 0.4645 - val_acc: 0.7938\n",
      "Epoch 2/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.4241 - acc: 0.8174 - val_loss: 0.4452 - val_acc: 0.8123\n",
      "Epoch 3/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.4150 - acc: 0.8207 - val_loss: 0.4112 - val_acc: 0.8195\n",
      "Epoch 4/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.4155 - acc: 0.8196 - val_loss: 0.4352 - val_acc: 0.8137\n",
      "Epoch 5/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.4102 - acc: 0.8234 - val_loss: 0.4238 - val_acc: 0.8157\n",
      "Epoch 6/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.4041 - acc: 0.8250 - val_loss: 0.3985 - val_acc: 0.8270\n",
      "Epoch 7/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3997 - acc: 0.8288 - val_loss: 0.3959 - val_acc: 0.8265\n",
      "Epoch 8/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3978 - acc: 0.8274 - val_loss: 0.4030 - val_acc: 0.8205\n",
      "Epoch 9/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3964 - acc: 0.8288 - val_loss: 0.4112 - val_acc: 0.8257\n",
      "Epoch 10/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3976 - acc: 0.8278 - val_loss: 0.3882 - val_acc: 0.8313\n",
      "Epoch 11/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3908 - acc: 0.8321 - val_loss: 0.3833 - val_acc: 0.8375\n",
      "Epoch 12/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3876 - acc: 0.8330 - val_loss: 0.4058 - val_acc: 0.8222\n",
      "Epoch 13/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3875 - acc: 0.8328 - val_loss: 0.3848 - val_acc: 0.8337\n",
      "Epoch 14/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3805 - acc: 0.8352 - val_loss: 0.3800 - val_acc: 0.8350\n",
      "Epoch 15/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3862 - acc: 0.8331 - val_loss: 0.3981 - val_acc: 0.8252\n",
      "Epoch 16/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3808 - acc: 0.8361 - val_loss: 0.3978 - val_acc: 0.8210\n",
      "Epoch 17/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3786 - acc: 0.8361 - val_loss: 0.3727 - val_acc: 0.8400 0.3787 - acc: 0.\n",
      "Epoch 18/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3733 - acc: 0.8392 - val_loss: 0.3755 - val_acc: 0.8387\n",
      "Epoch 19/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3766 - acc: 0.8356 - val_loss: 0.3633 - val_acc: 0.8474\n",
      "Epoch 20/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3712 - acc: 0.8405 - val_loss: 0.3677 - val_acc: 0.8388\n",
      "Epoch 21/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3715 - acc: 0.8419 - val_loss: 0.3776 - val_acc: 0.8327\n",
      "Epoch 22/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3666 - acc: 0.8411 - val_loss: 0.3686 - val_acc: 0.8405\n",
      "Epoch 23/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3689 - acc: 0.8406 - val_loss: 0.3648 - val_acc: 0.8475\n",
      "Epoch 24/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3631 - acc: 0.8463 - val_loss: 0.3506 - val_acc: 0.8515\n",
      "Epoch 25/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3634 - acc: 0.8435 - val_loss: 0.3690 - val_acc: 0.8378\n",
      "Epoch 26/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3589 - acc: 0.8475 - val_loss: 0.3848 - val_acc: 0.8402\n",
      "Epoch 27/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3555 - acc: 0.8496 - val_loss: 0.3678 - val_acc: 0.8415\n",
      "Epoch 28/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3576 - acc: 0.8461 - val_loss: 0.3528 - val_acc: 0.8493\n",
      "Epoch 29/70\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3545 - acc: 0.8487 - val_loss: 0.3528 - val_acc: 0.8498\n",
      "Epoch 30/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3538 - acc: 0.8491 - val_loss: 0.3564 - val_acc: 0.8480\n",
      "Epoch 31/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3452 - acc: 0.8519 - val_loss: 0.3542 - val_acc: 0.8525\n",
      "Epoch 32/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3506 - acc: 0.8521 - val_loss: 0.3432 - val_acc: 0.8512\n",
      "Epoch 33/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3466 - acc: 0.8524 - val_loss: 0.3579 - val_acc: 0.8411\n",
      "Epoch 34/70\n",
      "190/190 [==============================] - 19s 99ms/step - loss: 0.3552 - acc: 0.8489 - val_loss: 0.3522 - val_acc: 0.8455\n",
      "Epoch 35/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3526 - acc: 0.8484 - val_loss: 0.3384 - val_acc: 0.8613\n",
      "Epoch 36/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3430 - acc: 0.8535 - val_loss: 0.3545 - val_acc: 0.8543\n",
      "Epoch 37/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3415 - acc: 0.8558 - val_loss: 0.3401 - val_acc: 0.8593\n",
      "Epoch 38/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3537 - acc: 0.8497 - val_loss: 0.3496 - val_acc: 0.8480\n",
      "Epoch 39/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3452 - acc: 0.8514 - val_loss: 0.3466 - val_acc: 0.8512\n",
      "Epoch 40/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3397 - acc: 0.8551 - val_loss: 0.3317 - val_acc: 0.8620\n",
      "Epoch 41/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3367 - acc: 0.8562 - val_loss: 0.3362 - val_acc: 0.8572\n",
      "Epoch 42/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3366 - acc: 0.8561 - val_loss: 0.3370 - val_acc: 0.8606\n",
      "Epoch 43/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3394 - acc: 0.8537 - val_loss: 0.3444 - val_acc: 0.8553\n",
      "Epoch 44/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3407 - acc: 0.8553 - val_loss: 0.3458 - val_acc: 0.8527\n",
      "Epoch 45/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3374 - acc: 0.8558 - val_loss: 0.3252 - val_acc: 0.8650\n",
      "Epoch 46/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3365 - acc: 0.8587 - val_loss: 0.3435 - val_acc: 0.8567\n",
      "Epoch 47/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3362 - acc: 0.8563 - val_loss: 0.3609 - val_acc: 0.8446\n",
      "Epoch 48/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3397 - acc: 0.8537 - val_loss: 0.3294 - val_acc: 0.8602\n",
      "Epoch 49/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3347 - acc: 0.8572 - val_loss: 0.3316 - val_acc: 0.8585\n",
      "Epoch 50/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3276 - acc: 0.8613 - val_loss: 0.3431 - val_acc: 0.8577\n",
      "Epoch 51/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3404 - acc: 0.8553 - val_loss: 0.3237 - val_acc: 0.8611\n",
      "Epoch 52/70\n",
      "190/190 [==============================] - 19s 98ms/step - loss: 0.3297 - acc: 0.8594 - val_loss: 0.3263 - val_acc: 0.8618\n",
      "Epoch 53/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3273 - acc: 0.8618 - val_loss: 0.3432 - val_acc: 0.8517\n",
      "Epoch 54/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3306 - acc: 0.8608 - val_loss: 0.3305 - val_acc: 0.8625\n",
      "Epoch 55/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3302 - acc: 0.8580 - val_loss: 0.3252 - val_acc: 0.8605\n",
      "Epoch 56/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3300 - acc: 0.8600 - val_loss: 0.3294 - val_acc: 0.8641\n",
      "Epoch 57/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3284 - acc: 0.8601 - val_loss: 0.3405 - val_acc: 0.8558\n",
      "Epoch 58/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3265 - acc: 0.8606 - val_loss: 0.3248 - val_acc: 0.8595\n",
      "Epoch 59/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3283 - acc: 0.8598 - val_loss: 0.3264 - val_acc: 0.8650\n",
      "Epoch 60/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3286 - acc: 0.8594 - val_loss: 0.3253 - val_acc: 0.8598\n",
      "Epoch 61/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3198 - acc: 0.8653 - val_loss: 0.3114 - val_acc: 0.8696\n",
      "Epoch 62/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3250 - acc: 0.8618 - val_loss: 0.3150 - val_acc: 0.8693\n",
      "Epoch 63/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3269 - acc: 0.8610 - val_loss: 0.3240 - val_acc: 0.8597\n",
      "Epoch 64/70\n",
      "190/190 [==============================] - 19s 100ms/step - loss: 0.3212 - acc: 0.8622 - val_loss: 0.3281 - val_acc: 0.8617\n",
      "Epoch 65/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3232 - acc: 0.8641 - val_loss: 0.3402 - val_acc: 0.8535\n",
      "Epoch 66/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3214 - acc: 0.8617 - val_loss: 0.3136 - val_acc: 0.8690\n",
      "Epoch 67/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3231 - acc: 0.8617 - val_loss: 0.3193 - val_acc: 0.8700\n",
      "Epoch 68/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3215 - acc: 0.8629 - val_loss: 0.3328 - val_acc: 0.8617\n",
      "Epoch 69/70\n",
      "190/190 [==============================] - 19s 102ms/step - loss: 0.3219 - acc: 0.8618 - val_loss: 0.3242 - val_acc: 0.8630\n",
      "Epoch 70/70\n",
      "190/190 [==============================] - 19s 101ms/step - loss: 0.3165 - acc: 0.8666 - val_loss: 0.3249 - val_acc: 0.8614\n",
      "\n",
      "Training process completed in: 0 h 22 m 29 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1307.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1309 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_593 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_593 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_594 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_594 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_595 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_595 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_596 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_596 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_149 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 100\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 22s 187ms/step - loss: 0.5097 - acc: 0.7576 - val_loss: 0.4507 - val_acc: 0.8072\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.4352 - acc: 0.8131 - val_loss: 0.4239 - val_acc: 0.8110\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 12s 103ms/step - loss: 0.4113 - acc: 0.8248 - val_loss: 0.4095 - val_acc: 0.8158\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.4023 - acc: 0.8269 - val_loss: 0.4007 - val_acc: 0.8292\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.4086 - acc: 0.8237 - val_loss: 0.4207 - val_acc: 0.8246\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.4006 - acc: 0.8272 - val_loss: 0.3953 - val_acc: 0.8363\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.3743 - acc: 0.8376 - val_loss: 0.3825 - val_acc: 0.8388\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.3886 - acc: 0.8329 - val_loss: 0.3976 - val_acc: 0.8388\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.3753 - acc: 0.8394 - val_loss: 0.3826 - val_acc: 0.8293\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3829 - acc: 0.8349 - val_loss: 0.3665 - val_acc: 0.8380\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3807 - acc: 0.8338 - val_loss: 0.3693 - val_acc: 0.8363\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3776 - acc: 0.8366 - val_loss: 0.4181 - val_acc: 0.8335\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3696 - acc: 0.8411 - val_loss: 0.3728 - val_acc: 0.8430\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3662 - acc: 0.8428 - val_loss: 0.3773 - val_acc: 0.8411\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3646 - acc: 0.8445 - val_loss: 0.3955 - val_acc: 0.8183\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3595 - acc: 0.8449 - val_loss: 0.3723 - val_acc: 0.8457\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3587 - acc: 0.8455 - val_loss: 0.3575 - val_acc: 0.8485\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3599 - acc: 0.8477 - val_loss: 0.3566 - val_acc: 0.8537\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3502 - acc: 0.8521 - val_loss: 0.3536 - val_acc: 0.8498\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3486 - acc: 0.8506 - val_loss: 0.3649 - val_acc: 0.8452\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3614 - acc: 0.8438 - val_loss: 0.3424 - val_acc: 0.8513\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3510 - acc: 0.8498 - val_loss: 0.3547 - val_acc: 0.8490\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3451 - acc: 0.8530 - val_loss: 0.3451 - val_acc: 0.8608\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.3380 - acc: 0.8570 - val_loss: 0.3617 - val_acc: 0.8451s: 0\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3480 - acc: 0.8533 - val_loss: 0.3494 - val_acc: 0.8407\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3509 - acc: 0.8475 - val_loss: 0.3537 - val_acc: 0.8462\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3413 - acc: 0.8554 - val_loss: 0.3474 - val_acc: 0.8513\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3390 - acc: 0.8550 - val_loss: 0.3566 - val_acc: 0.8515\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3487 - acc: 0.8498 - val_loss: 0.3415 - val_acc: 0.8603\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3389 - acc: 0.8575 - val_loss: 0.3537 - val_acc: 0.8555\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3404 - acc: 0.8557 - val_loss: 0.3349 - val_acc: 0.8532\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3348 - acc: 0.8603 - val_loss: 0.3279 - val_acc: 0.8622\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 0.3370 - acc: 0.8573 - val_loss: 0.3452 - val_acc: 0.8651\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3350 - acc: 0.8580 - val_loss: 0.3337 - val_acc: 0.8557\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3326 - acc: 0.8591 - val_loss: 0.3313 - val_acc: 0.8565\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3317 - acc: 0.8582 - val_loss: 0.3337 - val_acc: 0.8645\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.3257 - acc: 0.8603 - val_loss: 0.3380 - val_acc: 0.8577\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.3284 - acc: 0.8596 - val_loss: 0.3528 - val_acc: 0.8456\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.3268 - acc: 0.8606 - val_loss: 0.3159 - val_acc: 0.8642\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3309 - acc: 0.8602 - val_loss: 0.3408 - val_acc: 0.8583\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3198 - acc: 0.8655 - val_loss: 0.3295 - val_acc: 0.8643\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.3243 - acc: 0.8587 - val_loss: 0.3234 - val_acc: 0.8679\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3222 - acc: 0.8636 - val_loss: 0.3329 - val_acc: 0.8617\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3322 - acc: 0.8588 - val_loss: 0.3206 - val_acc: 0.8630\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3262 - acc: 0.8640 - val_loss: 0.3371 - val_acc: 0.8622\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3295 - acc: 0.8593 - val_loss: 0.3368 - val_acc: 0.8612\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3197 - acc: 0.8642 - val_loss: 0.3457 - val_acc: 0.8582\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3201 - acc: 0.8631 - val_loss: 0.3469 - val_acc: 0.8545\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3230 - acc: 0.8610 - val_loss: 0.3385 - val_acc: 0.8662\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3295 - acc: 0.8593 - val_loss: 0.3423 - val_acc: 0.8648\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.3221 - acc: 0.8622 - val_loss: 0.3237 - val_acc: 0.8582\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3226 - acc: 0.8626 - val_loss: 0.3246 - val_acc: 0.8628\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3266 - acc: 0.8644 - val_loss: 0.3212 - val_acc: 0.8732\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3139 - acc: 0.8673 - val_loss: 0.3112 - val_acc: 0.8712\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3237 - acc: 0.8615 - val_loss: 0.3257 - val_acc: 0.8625\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 0.3176 - acc: 0.8678 - val_loss: 0.3292 - val_acc: 0.8617\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3183 - acc: 0.8628 - val_loss: 0.3159 - val_acc: 0.8695\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3181 - acc: 0.8644 - val_loss: 0.3468 - val_acc: 0.8647\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3195 - acc: 0.8634 - val_loss: 0.3228 - val_acc: 0.8620\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3121 - acc: 0.8680 - val_loss: 0.3153 - val_acc: 0.8733\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3124 - acc: 0.8681 - val_loss: 0.3153 - val_acc: 0.8669\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3134 - acc: 0.8676 - val_loss: 0.3339 - val_acc: 0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3120 - acc: 0.8704 - val_loss: 0.3401 - val_acc: 0.8533\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3095 - acc: 0.8701 - val_loss: 0.3092 - val_acc: 0.8732\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3078 - acc: 0.8704 - val_loss: 0.3188 - val_acc: 0.8735\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3102 - acc: 0.8680 - val_loss: 0.3076 - val_acc: 0.8755\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3066 - acc: 0.8693 - val_loss: 0.3193 - val_acc: 0.8692\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3104 - acc: 0.8698 - val_loss: 0.3175 - val_acc: 0.8625\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3153 - acc: 0.8665 - val_loss: 0.3258 - val_acc: 0.8592\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3092 - acc: 0.8701 - val_loss: 0.3238 - val_acc: 0.8686\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3055 - acc: 0.8743 - val_loss: 0.3166 - val_acc: 0.8670\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3125 - acc: 0.8673 - val_loss: 0.3304 - val_acc: 0.8657\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3172 - acc: 0.8669 - val_loss: 0.3362 - val_acc: 0.8655\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.3107 - acc: 0.8694 - val_loss: 0.3154 - val_acc: 0.8658\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.3090 - acc: 0.8716 - val_loss: 0.3150 - val_acc: 0.8690\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3116 - acc: 0.8695 - val_loss: 0.3173 - val_acc: 0.8660\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3034 - acc: 0.8737 - val_loss: 0.3092 - val_acc: 0.8738\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3033 - acc: 0.8714 - val_loss: 0.3042 - val_acc: 0.8730\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3021 - acc: 0.8711 - val_loss: 0.3249 - val_acc: 0.8629\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3048 - acc: 0.8719 - val_loss: 0.3026 - val_acc: 0.8757\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3085 - acc: 0.8686 - val_loss: 0.3192 - val_acc: 0.8653\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3106 - acc: 0.8716 - val_loss: 0.3137 - val_acc: 0.8713\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3057 - acc: 0.8736 - val_loss: 0.3271 - val_acc: 0.8570\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 0.3022 - acc: 0.8732 - val_loss: 0.3197 - val_acc: 0.8705\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3028 - acc: 0.8742 - val_loss: 0.3111 - val_acc: 0.8717ss: \n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3030 - acc: 0.8708 - val_loss: 0.3300 - val_acc: 0.8653\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3074 - acc: 0.8719 - val_loss: 0.3098 - val_acc: 0.8715\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.3028 - acc: 0.8701 - val_loss: 0.3129 - val_acc: 0.8690\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.3046 - acc: 0.8726 - val_loss: 0.3054 - val_acc: 0.8772\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3080 - acc: 0.8710 - val_loss: 0.3613 - val_acc: 0.8482\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3009 - acc: 0.8750 - val_loss: 0.3008 - val_acc: 0.8782\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3007 - acc: 0.8755 - val_loss: 0.3384 - val_acc: 0.8603\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 13s 104ms/step - loss: 0.3068 - acc: 0.8705 - val_loss: 0.3125 - val_acc: 0.8735\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.2938 - acc: 0.8771 - val_loss: 0.3018 - val_acc: 0.8782\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.2964 - acc: 0.8754 - val_loss: 0.3127 - val_acc: 0.8693\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3013 - acc: 0.8719 - val_loss: 0.3122 - val_acc: 0.8682\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3149 - val_acc: 0.8672\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.3042 - acc: 0.8740 - val_loss: 0.3200 - val_acc: 0.8656\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.2960 - acc: 0.8756 - val_loss: 0.3305 - val_acc: 0.8585 loss: 0.2957 - ac\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.3015 - acc: 0.8748 - val_loss: 0.3110 - val_acc: 0.876333 - acc: 0\n",
      "\n",
      "Training process completed in: 0 h 21 m 6 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1308.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1310 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_597 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_597 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_598 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_598 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_599 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_599 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_600 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_600 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_150 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4760 - acc: 0.7868 - val_loss: 0.4763 - val_acc: 0.7837\n",
      "Epoch 2/80\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.4408 - acc: 0.8141 - val_loss: 0.4714 - val_acc: 0.7713\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4252 - acc: 0.8180 - val_loss: 0.4393 - val_acc: 0.8137\n",
      "Epoch 4/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4219 - acc: 0.8229 - val_loss: 0.3911 - val_acc: 0.8300\n",
      "Epoch 5/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4154 - acc: 0.8207 - val_loss: 0.3848 - val_acc: 0.8425\n",
      "Epoch 6/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4083 - acc: 0.8225 - val_loss: 0.4240 - val_acc: 0.8137\n",
      "Epoch 7/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4059 - acc: 0.8268 - val_loss: 0.4221 - val_acc: 0.8113\n",
      "Epoch 8/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3939 - acc: 0.8350 - val_loss: 0.3970 - val_acc: 0.8237\n",
      "Epoch 9/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4046 - acc: 0.8250 - val_loss: 0.4152 - val_acc: 0.8337\n",
      "Epoch 10/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.4002 - acc: 0.8239 - val_loss: 0.3843 - val_acc: 0.8362\n",
      "Epoch 11/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3895 - acc: 0.8357 - val_loss: 0.3962 - val_acc: 0.8363\n",
      "Epoch 12/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3903 - acc: 0.8326 - val_loss: 0.4045 - val_acc: 0.8438\n",
      "Epoch 13/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3955 - acc: 0.8291 - val_loss: 0.4230 - val_acc: 0.8113\n",
      "Epoch 14/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3874 - acc: 0.8318 - val_loss: 0.3692 - val_acc: 0.8525\n",
      "Epoch 15/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3887 - acc: 0.8325 - val_loss: 0.3904 - val_acc: 0.8250\n",
      "Epoch 16/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3735 - acc: 0.8402 - val_loss: 0.3514 - val_acc: 0.8400\n",
      "Epoch 17/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3753 - acc: 0.8433 - val_loss: 0.3790 - val_acc: 0.8375\n",
      "Epoch 18/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3646 - acc: 0.8417 - val_loss: 0.3849 - val_acc: 0.8437\n",
      "Epoch 19/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3739 - acc: 0.8371 - val_loss: 0.4136 - val_acc: 0.8487\n",
      "Epoch 20/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3556 - acc: 0.8466 - val_loss: 0.3871 - val_acc: 0.8287\n",
      "Epoch 21/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3735 - acc: 0.8397 - val_loss: 0.3754 - val_acc: 0.8500\n",
      "Epoch 22/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3755 - acc: 0.8421 - val_loss: 0.3754 - val_acc: 0.8488\n",
      "Epoch 23/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3590 - acc: 0.8435 - val_loss: 0.3711 - val_acc: 0.8437\n",
      "Epoch 24/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3629 - acc: 0.8437 - val_loss: 0.4183 - val_acc: 0.8413\n",
      "Epoch 25/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3648 - acc: 0.8419 - val_loss: 0.4278 - val_acc: 0.8125\n",
      "Epoch 26/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3671 - acc: 0.8424 - val_loss: 0.3851 - val_acc: 0.8425\n",
      "Epoch 27/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3604 - acc: 0.8454 - val_loss: 0.3638 - val_acc: 0.8663\n",
      "Epoch 28/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3510 - acc: 0.8480 - val_loss: 0.3816 - val_acc: 0.8337\n",
      "Epoch 29/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3603 - acc: 0.8464 - val_loss: 0.3696 - val_acc: 0.8500\n",
      "Epoch 30/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3539 - acc: 0.8508 - val_loss: 0.3536 - val_acc: 0.8550\n",
      "Epoch 31/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3505 - acc: 0.8530 - val_loss: 0.3640 - val_acc: 0.8450\n",
      "Epoch 32/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3453 - acc: 0.8543 - val_loss: 0.3437 - val_acc: 0.8538\n",
      "Epoch 33/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3486 - acc: 0.8528 - val_loss: 0.3673 - val_acc: 0.8425\n",
      "Epoch 34/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3480 - acc: 0.8545 - val_loss: 0.3612 - val_acc: 0.8400\n",
      "Epoch 35/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3443 - acc: 0.8557 - val_loss: 0.3977 - val_acc: 0.8548\n",
      "Epoch 36/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3490 - acc: 0.8494 - val_loss: 0.3708 - val_acc: 0.8450\n",
      "Epoch 37/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3509 - acc: 0.8491 - val_loss: 0.3638 - val_acc: 0.8438\n",
      "Epoch 38/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3474 - acc: 0.8555 - val_loss: 0.3873 - val_acc: 0.8362\n",
      "Epoch 39/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3411 - acc: 0.8542 - val_loss: 0.4261 - val_acc: 0.8263\n",
      "Epoch 40/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3526 - acc: 0.8504 - val_loss: 0.3859 - val_acc: 0.8137\n",
      "Epoch 41/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3406 - acc: 0.8576 - val_loss: 0.3631 - val_acc: 0.8738\n",
      "Epoch 42/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3392 - acc: 0.8577 - val_loss: 0.3435 - val_acc: 0.8625\n",
      "Epoch 43/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3440 - acc: 0.8543 - val_loss: 0.3399 - val_acc: 0.8688\n",
      "Epoch 44/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3422 - acc: 0.8533 - val_loss: 0.3953 - val_acc: 0.8288\n",
      "Epoch 45/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3377 - acc: 0.8575 - val_loss: 0.3550 - val_acc: 0.8500\n",
      "Epoch 46/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3398 - acc: 0.8575 - val_loss: 0.3459 - val_acc: 0.8537\n",
      "Epoch 47/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3386 - acc: 0.8559 - val_loss: 0.3483 - val_acc: 0.8550\n",
      "Epoch 48/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3289 - acc: 0.8599 - val_loss: 0.3662 - val_acc: 0.8663\n",
      "Epoch 49/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3452 - acc: 0.8542 - val_loss: 0.3486 - val_acc: 0.8663\n",
      "Epoch 50/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3341 - acc: 0.8600 - val_loss: 0.3451 - val_acc: 0.8750\n",
      "Epoch 51/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3357 - acc: 0.8589 - val_loss: 0.3186 - val_acc: 0.8812\n",
      "Epoch 52/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3408 - acc: 0.8562 - val_loss: 0.4000 - val_acc: 0.8313\n",
      "Epoch 53/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3411 - acc: 0.8583 - val_loss: 0.3379 - val_acc: 0.8688\n",
      "Epoch 54/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3446 - acc: 0.8533 - val_loss: 0.3554 - val_acc: 0.8562\n",
      "Epoch 55/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3350 - acc: 0.8569 - val_loss: 0.3436 - val_acc: 0.8575\n",
      "Epoch 56/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3375 - acc: 0.8596 - val_loss: 0.3780 - val_acc: 0.8287\n",
      "Epoch 57/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3264 - acc: 0.8589 - val_loss: 0.3481 - val_acc: 0.8600\n",
      "Epoch 58/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3389 - acc: 0.8594 - val_loss: 0.3040 - val_acc: 0.8738\n",
      "Epoch 59/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3391 - acc: 0.8583 - val_loss: 0.3751 - val_acc: 0.8463\n",
      "Epoch 60/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3325 - acc: 0.8563 - val_loss: 0.3124 - val_acc: 0.8762\n",
      "Epoch 61/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3246 - acc: 0.8646 - val_loss: 0.3661 - val_acc: 0.8375\n",
      "Epoch 62/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3303 - acc: 0.8596 - val_loss: 0.3337 - val_acc: 0.8663\n",
      "Epoch 63/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3247 - acc: 0.8621 - val_loss: 0.3338 - val_acc: 0.8662\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3388 - acc: 0.8567 - val_loss: 0.3474 - val_acc: 0.8488\n",
      "Epoch 65/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3226 - acc: 0.8653 - val_loss: 0.3436 - val_acc: 0.8500\n",
      "Epoch 66/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3350 - acc: 0.8571 - val_loss: 0.3686 - val_acc: 0.8700\n",
      "Epoch 67/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3194 - acc: 0.8663 - val_loss: 0.3761 - val_acc: 0.8538\n",
      "Epoch 68/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3303 - acc: 0.8626 - val_loss: 0.3127 - val_acc: 0.8700\n",
      "Epoch 69/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3384 - acc: 0.8562 - val_loss: 0.3573 - val_acc: 0.8462\n",
      "Epoch 70/80\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.3330 - acc: 0.8613 - val_loss: 0.3404 - val_acc: 0.8497\n",
      "Epoch 71/80\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.3225 - acc: 0.8644 - val_loss: 0.3568 - val_acc: 0.8538\n",
      "Epoch 72/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3259 - acc: 0.8604 - val_loss: 0.2845 - val_acc: 0.8838\n",
      "Epoch 73/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3319 - acc: 0.8578 - val_loss: 0.3520 - val_acc: 0.8637\n",
      "Epoch 74/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3285 - acc: 0.8604 - val_loss: 0.3265 - val_acc: 0.8625\n",
      "Epoch 75/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3188 - acc: 0.8632 - val_loss: 0.3391 - val_acc: 0.8512\n",
      "Epoch 76/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3205 - acc: 0.8641 - val_loss: 0.3626 - val_acc: 0.8525\n",
      "Epoch 77/80\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.3202 - acc: 0.8648 - val_loss: 0.3338 - val_acc: 0.8588\n",
      "Epoch 78/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3316 - acc: 0.8611 - val_loss: 0.3617 - val_acc: 0.8525\n",
      "Epoch 79/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3300 - acc: 0.8610 - val_loss: 0.3736 - val_acc: 0.8575\n",
      "Epoch 80/80\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3356 - acc: 0.8570 - val_loss: 0.3392 - val_acc: 0.8625\n",
      "\n",
      "Training process completed in: 0 h 8 m 36 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1309.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1311 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_601 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_601 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_602 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_602 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_603 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_603 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_604 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_604 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_151 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "150/150 [==============================] - 25s 165ms/step - loss: 0.4893 - acc: 0.7721 - val_loss: 0.4135 - val_acc: 0.8222\n",
      "Epoch 2/80\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.4214 - acc: 0.8191 - val_loss: 0.4295 - val_acc: 0.8220\n",
      "Epoch 3/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.4114 - acc: 0.8243 - val_loss: 0.4097 - val_acc: 0.8345\n",
      "Epoch 4/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3977 - acc: 0.8297 - val_loss: 0.3987 - val_acc: 0.8242\n",
      "Epoch 5/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3893 - acc: 0.8322 - val_loss: 0.3938 - val_acc: 0.8343\n",
      "Epoch 6/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3836 - acc: 0.8363 - val_loss: 0.4023 - val_acc: 0.8200\n",
      "Epoch 7/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3844 - acc: 0.8323 - val_loss: 0.4065 - val_acc: 0.8340\n",
      "Epoch 8/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3693 - acc: 0.8405 - val_loss: 0.3925 - val_acc: 0.8383\n",
      "Epoch 9/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3706 - acc: 0.8422 - val_loss: 0.3827 - val_acc: 0.8413\n",
      "Epoch 10/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3673 - acc: 0.8447 - val_loss: 0.3887 - val_acc: 0.8470\n",
      "Epoch 11/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3587 - acc: 0.8487 - val_loss: 0.3636 - val_acc: 0.8553\n",
      "Epoch 12/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3645 - acc: 0.8440 - val_loss: 0.4069 - val_acc: 0.8368\n",
      "Epoch 13/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3578 - acc: 0.8451 - val_loss: 0.3900 - val_acc: 0.8425\n",
      "Epoch 14/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3608 - acc: 0.8453 - val_loss: 0.3551 - val_acc: 0.8568\n",
      "Epoch 15/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3600 - acc: 0.8462 - val_loss: 0.3578 - val_acc: 0.8502\n",
      "Epoch 16/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3551 - acc: 0.8504 - val_loss: 0.3820 - val_acc: 0.8585\n",
      "Epoch 17/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3494 - acc: 0.8534 - val_loss: 0.3617 - val_acc: 0.853834\n",
      "Epoch 18/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3442 - acc: 0.8524 - val_loss: 0.3605 - val_acc: 0.8468\n",
      "Epoch 19/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3480 - acc: 0.8519 - val_loss: 0.3433 - val_acc: 0.8567\n",
      "Epoch 20/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3477 - acc: 0.8524 - val_loss: 0.3657 - val_acc: 0.8505\n",
      "Epoch 21/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3449 - acc: 0.8516 - val_loss: 0.3582 - val_acc: 0.8459\n",
      "Epoch 22/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3470 - acc: 0.8505 - val_loss: 0.3546 - val_acc: 0.8585\n",
      "Epoch 23/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3389 - acc: 0.8560 - val_loss: 0.3566 - val_acc: 0.8530\n",
      "Epoch 24/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3434 - acc: 0.8541 - val_loss: 0.3542 - val_acc: 0.8567\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3315 - acc: 0.8598 - val_loss: 0.3492 - val_acc: 0.8570\n",
      "Epoch 26/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3347 - acc: 0.8549 - val_loss: 0.3303 - val_acc: 0.8640\n",
      "Epoch 27/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3393 - acc: 0.8559 - val_loss: 0.3395 - val_acc: 0.8533\n",
      "Epoch 28/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3327 - acc: 0.8590 - val_loss: 0.3656 - val_acc: 0.8376\n",
      "Epoch 29/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3370 - acc: 0.8562 - val_loss: 0.3330 - val_acc: 0.8598\n",
      "Epoch 30/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3346 - acc: 0.8583 - val_loss: 0.3456 - val_acc: 0.8585\n",
      "Epoch 31/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3275 - acc: 0.8622 - val_loss: 0.3300 - val_acc: 0.8647\n",
      "Epoch 32/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3370 - acc: 0.8569 - val_loss: 0.3491 - val_acc: 0.8568\n",
      "Epoch 33/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3307 - acc: 0.8567 - val_loss: 0.3656 - val_acc: 0.8500\n",
      "Epoch 34/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3252 - acc: 0.8614 - val_loss: 0.3501 - val_acc: 0.8625\n",
      "Epoch 35/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3203 - acc: 0.8645 - val_loss: 0.3302 - val_acc: 0.8661\n",
      "Epoch 36/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3282 - acc: 0.8615 - val_loss: 0.3336 - val_acc: 0.8590 \n",
      "Epoch 37/80\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3223 - acc: 0.8629 - val_loss: 0.3387 - val_acc: 0.8580\n",
      "Epoch 38/80\n",
      "150/150 [==============================] - 16s 103ms/step - loss: 0.3160 - acc: 0.8648 - val_loss: 0.3653 - val_acc: 0.8627\n",
      "Epoch 39/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3230 - acc: 0.8630 - val_loss: 0.3467 - val_acc: 0.8640\n",
      "Epoch 40/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3203 - acc: 0.8652 - val_loss: 0.3237 - val_acc: 0.8728\n",
      "Epoch 41/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3206 - acc: 0.8634 - val_loss: 0.3364 - val_acc: 0.8623\n",
      "Epoch 42/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3251 - acc: 0.8598 - val_loss: 0.3314 - val_acc: 0.8636\n",
      "Epoch 43/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3295 - acc: 0.8595 - val_loss: 0.3256 - val_acc: 0.8760\n",
      "Epoch 44/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3207 - acc: 0.8649 - val_loss: 0.3503 - val_acc: 0.8577\n",
      "Epoch 45/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3161 - acc: 0.8665 - val_loss: 0.3139 - val_acc: 0.8713\n",
      "Epoch 46/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3209 - acc: 0.8644 - val_loss: 0.3407 - val_acc: 0.8623\n",
      "Epoch 47/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3109 - acc: 0.8694 - val_loss: 0.3349 - val_acc: 0.8577\n",
      "Epoch 48/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3208 - acc: 0.8624 - val_loss: 0.3430 - val_acc: 0.8623\n",
      "Epoch 49/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3167 - acc: 0.8660 - val_loss: 0.3154 - val_acc: 0.8740\n",
      "Epoch 50/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3167 - acc: 0.8672 - val_loss: 0.3315 - val_acc: 0.8617\n",
      "Epoch 51/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3181 - acc: 0.8648 - val_loss: 0.3340 - val_acc: 0.8685\n",
      "Epoch 52/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3227 - acc: 0.8638 - val_loss: 0.3218 - val_acc: 0.8653\n",
      "Epoch 53/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3139 - acc: 0.8651 - val_loss: 0.3092 - val_acc: 0.8715\n",
      "Epoch 54/80\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3101 - acc: 0.8661 - val_loss: 0.3480 - val_acc: 0.8517\n",
      "Epoch 55/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3146 - acc: 0.8658 - val_loss: 0.3251 - val_acc: 0.8673\n",
      "Epoch 56/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3126 - acc: 0.8685 - val_loss: 0.3236 - val_acc: 0.8720\n",
      "Epoch 57/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3123 - acc: 0.8691 - val_loss: 0.3129 - val_acc: 0.8675\n",
      "Epoch 58/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3159 - acc: 0.8667 - val_loss: 0.3281 - val_acc: 0.8605\n",
      "Epoch 59/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3132 - acc: 0.8694 - val_loss: 0.3415 - val_acc: 0.8615\n",
      "Epoch 60/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3109 - acc: 0.8692 - val_loss: 0.3253 - val_acc: 0.8625\n",
      "Epoch 61/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3053 - acc: 0.8719 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 62/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3103 - acc: 0.8683 - val_loss: 0.3235 - val_acc: 0.8707\n",
      "Epoch 63/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3039 - acc: 0.8718 - val_loss: 0.3476 - val_acc: 0.8555\n",
      "Epoch 64/80\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3139 - acc: 0.8672 - val_loss: 0.3136 - val_acc: 0.8702\n",
      "Epoch 65/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3116 - acc: 0.8663 - val_loss: 0.3400 - val_acc: 0.8628\n",
      "Epoch 66/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3087 - acc: 0.8712 - val_loss: 0.3221 - val_acc: 0.8633\n",
      "Epoch 67/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3053 - acc: 0.8706 - val_loss: 0.3184 - val_acc: 0.8685\n",
      "Epoch 68/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3027 - acc: 0.8742 - val_loss: 0.3351 - val_acc: 0.8613\n",
      "Epoch 69/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3040 - acc: 0.8733 - val_loss: 0.3036 - val_acc: 0.8785\n",
      "Epoch 70/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3045 - acc: 0.8710 - val_loss: 0.3215 - val_acc: 0.8598\n",
      "Epoch 71/80\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3085 - acc: 0.8704 - val_loss: 0.3155 - val_acc: 0.8725\n",
      "Epoch 72/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3039 - acc: 0.8725 - val_loss: 0.3169 - val_acc: 0.8672\n",
      "Epoch 73/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3062 - acc: 0.8714 - val_loss: 0.3121 - val_acc: 0.8708\n",
      "Epoch 74/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3110 - acc: 0.8674 - val_loss: 0.3385 - val_acc: 0.8605\n",
      "Epoch 75/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3036 - acc: 0.8712 - val_loss: 0.3288 - val_acc: 0.8638\n",
      "Epoch 76/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2969 - acc: 0.8736 - val_loss: 0.3208 - val_acc: 0.8660\n",
      "Epoch 77/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2947 - acc: 0.8747 - val_loss: 0.3127 - val_acc: 0.8727\n",
      "Epoch 78/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3028 - acc: 0.8707 - val_loss: 0.3371 - val_acc: 0.8640\n",
      "Epoch 79/80\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3049 - acc: 0.8713 - val_loss: 0.3129 - val_acc: 0.8755\n",
      "Epoch 80/80\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3071 - acc: 0.8699 - val_loss: 0.2974 - val_acc: 0.8725\n",
      "\n",
      "Training process completed in: 0 h 20 m 16 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1310.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1312 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_605 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_605 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_606 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_606 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_607 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_607 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_608 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_608 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_152 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "150/150 [==============================] - 24s 161ms/step - loss: 0.4983 - acc: 0.7675 - val_loss: 0.4288 - val_acc: 0.8155\n",
      "Epoch 2/60\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.4212 - acc: 0.8194 - val_loss: 0.4163 - val_acc: 0.8240\n",
      "Epoch 3/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.4061 - acc: 0.8251 - val_loss: 0.4158 - val_acc: 0.8160\n",
      "Epoch 4/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3995 - acc: 0.8284 - val_loss: 0.4194 - val_acc: 0.8390\n",
      "Epoch 5/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3969 - acc: 0.8305 - val_loss: 0.4238 - val_acc: 0.8285\n",
      "Epoch 6/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3871 - acc: 0.8354 - val_loss: 0.3964 - val_acc: 0.8395\n",
      "Epoch 7/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3776 - acc: 0.8385 - val_loss: 0.4444 - val_acc: 0.8325\n",
      "Epoch 8/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3754 - acc: 0.8400 - val_loss: 0.3945 - val_acc: 0.8560\n",
      "Epoch 9/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3739 - acc: 0.8398 - val_loss: 0.3871 - val_acc: 0.8415\n",
      "Epoch 10/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3770 - acc: 0.8380 - val_loss: 0.3998 - val_acc: 0.8440\n",
      "Epoch 11/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3637 - acc: 0.8448 - val_loss: 0.4170 - val_acc: 0.8280\n",
      "Epoch 12/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3666 - acc: 0.8426 - val_loss: 0.3828 - val_acc: 0.8250\n",
      "Epoch 13/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3703 - acc: 0.8431 - val_loss: 0.4210 - val_acc: 0.8570\n",
      "Epoch 14/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3542 - acc: 0.8474 - val_loss: 0.3720 - val_acc: 0.8560\n",
      "Epoch 15/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3524 - acc: 0.8511 - val_loss: 0.3932 - val_acc: 0.8410\n",
      "Epoch 16/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3606 - acc: 0.8448 - val_loss: 0.3765 - val_acc: 0.8495\n",
      "Epoch 17/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3465 - acc: 0.8521 - val_loss: 0.3834 - val_acc: 0.8475\n",
      "Epoch 18/60\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3396 - acc: 0.8574 - val_loss: 0.3580 - val_acc: 0.8490\n",
      "Epoch 19/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3382 - acc: 0.8559 - val_loss: 0.3826 - val_acc: 0.8460\n",
      "Epoch 20/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3444 - acc: 0.8527 - val_loss: 0.3559 - val_acc: 0.8570\n",
      "Epoch 21/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3393 - acc: 0.8561 - val_loss: 0.3397 - val_acc: 0.8625\n",
      "Epoch 22/60\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3416 - acc: 0.8551 - val_loss: 0.3735 - val_acc: 0.8540\n",
      "Epoch 23/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3362 - acc: 0.8583 - val_loss: 0.3658 - val_acc: 0.8390\n",
      "Epoch 24/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3343 - acc: 0.8579 - val_loss: 0.3445 - val_acc: 0.8645\n",
      "Epoch 25/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3411 - acc: 0.8554 - val_loss: 0.3649 - val_acc: 0.8485\n",
      "Epoch 26/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3307 - acc: 0.8597 - val_loss: 0.3542 - val_acc: 0.8595\n",
      "Epoch 27/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3358 - acc: 0.8590 - val_loss: 0.3390 - val_acc: 0.8595\n",
      "Epoch 28/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3284 - acc: 0.8608 - val_loss: 0.3287 - val_acc: 0.8648\n",
      "Epoch 29/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3283 - acc: 0.8601 - val_loss: 0.3500 - val_acc: 0.8610\n",
      "Epoch 30/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3340 - acc: 0.8580 - val_loss: 0.3554 - val_acc: 0.8740\n",
      "Epoch 31/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3246 - acc: 0.8631 - val_loss: 0.3384 - val_acc: 0.8625\n",
      "Epoch 32/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3292 - acc: 0.8587 - val_loss: 0.3357 - val_acc: 0.8640\n",
      "Epoch 33/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3307 - acc: 0.8585 - val_loss: 0.3651 - val_acc: 0.8540\n",
      "Epoch 34/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3215 - acc: 0.8646 - val_loss: 0.3517 - val_acc: 0.8625\n",
      "Epoch 35/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3218 - acc: 0.8646 - val_loss: 0.3372 - val_acc: 0.8695\n",
      "Epoch 36/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3204 - acc: 0.8645 - val_loss: 0.3303 - val_acc: 0.8650\n",
      "Epoch 37/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3187 - acc: 0.8655 - val_loss: 0.3321 - val_acc: 0.8660\n",
      "Epoch 38/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3224 - acc: 0.8639 - val_loss: 0.3161 - val_acc: 0.8725\n",
      "Epoch 39/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3217 - acc: 0.8627 - val_loss: 0.3520 - val_acc: 0.8510\n",
      "Epoch 40/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3186 - acc: 0.8654 - val_loss: 0.3903 - val_acc: 0.8425\n",
      "Epoch 41/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3191 - acc: 0.8674 - val_loss: 0.3226 - val_acc: 0.8750\n",
      "Epoch 42/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3171 - acc: 0.8644 - val_loss: 0.3358 - val_acc: 0.8622\n",
      "Epoch 43/60\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3194 - acc: 0.8652 - val_loss: 0.3349 - val_acc: 0.8555\n",
      "Epoch 44/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3141 - acc: 0.8670 - val_loss: 0.3587 - val_acc: 0.8515\n",
      "Epoch 45/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3165 - acc: 0.8651 - val_loss: 0.3363 - val_acc: 0.8695\n",
      "Epoch 46/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3124 - acc: 0.8689 - val_loss: 0.3272 - val_acc: 0.8670\n",
      "Epoch 47/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3193 - acc: 0.8669 - val_loss: 0.3223 - val_acc: 0.8700\n",
      "Epoch 48/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3180 - acc: 0.8675 - val_loss: 0.3436 - val_acc: 0.8615\n",
      "Epoch 49/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3112 - acc: 0.8696 - val_loss: 0.3448 - val_acc: 0.8640\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3133 - acc: 0.8676 - val_loss: 0.2851 - val_acc: 0.8905\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3127 - acc: 0.8676 - val_loss: 0.3434 - val_acc: 0.8630\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3159 - acc: 0.8651 - val_loss: 0.3165 - val_acc: 0.8730\n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3042 - acc: 0.8706 - val_loss: 0.3179 - val_acc: 0.8720\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3117 - acc: 0.8677 - val_loss: 0.3355 - val_acc: 0.8480\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3142 - acc: 0.8698 - val_loss: 0.3232 - val_acc: 0.8720\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3106 - acc: 0.8693 - val_loss: 0.3609 - val_acc: 0.8391\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3075 - acc: 0.8705 - val_loss: 0.3590 - val_acc: 0.8455\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3131 - acc: 0.8672 - val_loss: 0.3383 - val_acc: 0.8675\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3074 - acc: 0.8703 - val_loss: 0.3088 - val_acc: 0.8710\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3069 - acc: 0.8702 - val_loss: 0.3422 - val_acc: 0.8580\n",
      "\n",
      "Training process completed in: 0 h 14 m 37 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1311.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1313 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_609 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_609 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_610 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_610 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_611 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_611 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_612 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_612 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_153 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "150/150 [==============================] - 25s 166ms/step - loss: 0.4852 - acc: 0.7761 - val_loss: 0.4891 - val_acc: 0.7847\n",
      "Epoch 2/60\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.4172 - acc: 0.8205 - val_loss: 0.4286 - val_acc: 0.8012\n",
      "Epoch 3/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.4058 - acc: 0.8254 - val_loss: 0.3943 - val_acc: 0.8255\n",
      "Epoch 4/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3900 - acc: 0.8309 - val_loss: 0.3803 - val_acc: 0.8385\n",
      "Epoch 5/60\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3899 - acc: 0.8326 - val_loss: 0.3848 - val_acc: 0.8338\n",
      "Epoch 6/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3753 - acc: 0.8379 - val_loss: 0.3719 - val_acc: 0.8290\n",
      "Epoch 7/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3737 - acc: 0.8371 - val_loss: 0.3678 - val_acc: 0.8373\n",
      "Epoch 8/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3614 - acc: 0.8437 - val_loss: 0.3616 - val_acc: 0.8455\n",
      "Epoch 9/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3671 - acc: 0.8426 - val_loss: 0.3719 - val_acc: 0.8438\n",
      "Epoch 10/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3549 - acc: 0.8476 - val_loss: 0.3647 - val_acc: 0.8390\n",
      "Epoch 11/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3529 - acc: 0.8497 - val_loss: 0.3320 - val_acc: 0.8640\n",
      "Epoch 12/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3501 - acc: 0.8514 - val_loss: 0.3489 - val_acc: 0.8515\n",
      "Epoch 13/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3550 - acc: 0.8484 - val_loss: 0.3656 - val_acc: 0.8290\n",
      "Epoch 14/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3465 - acc: 0.8517 - val_loss: 0.3486 - val_acc: 0.8553\n",
      "Epoch 15/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3422 - acc: 0.8560 - val_loss: 0.3714 - val_acc: 0.8350\n",
      "Epoch 16/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3450 - acc: 0.8529 - val_loss: 0.3475 - val_acc: 0.8565\n",
      "Epoch 17/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3446 - acc: 0.8533 - val_loss: 0.3540 - val_acc: 0.8460\n",
      "Epoch 18/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3410 - acc: 0.8565 - val_loss: 0.3427 - val_acc: 0.8593\n",
      "Epoch 19/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3355 - acc: 0.8583 - val_loss: 0.3393 - val_acc: 0.8543\n",
      "Epoch 20/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3371 - acc: 0.8556 - val_loss: 0.3469 - val_acc: 0.8463\n",
      "Epoch 21/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3380 - acc: 0.8555 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 22/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3359 - acc: 0.8562 - val_loss: 0.3221 - val_acc: 0.8678\n",
      "Epoch 23/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3339 - acc: 0.8577 - val_loss: 0.3539 - val_acc: 0.8512\n",
      "Epoch 24/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3254 - acc: 0.8640 - val_loss: 0.3407 - val_acc: 0.8597\n",
      "Epoch 25/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3271 - acc: 0.8627 - val_loss: 0.3463 - val_acc: 0.8508\n",
      "Epoch 26/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3267 - acc: 0.8620 - val_loss: 0.3551 - val_acc: 0.8435\n",
      "Epoch 27/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3348 - acc: 0.8580 - val_loss: 0.3342 - val_acc: 0.8583\n",
      "Epoch 28/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3308 - acc: 0.8587 - val_loss: 0.3339 - val_acc: 0.8548\n",
      "Epoch 29/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3265 - acc: 0.8603 - val_loss: 0.3323 - val_acc: 0.8613\n",
      "Epoch 30/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3235 - acc: 0.8630 - val_loss: 0.3296 - val_acc: 0.8637\n",
      "Epoch 31/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3218 - acc: 0.8636 - val_loss: 0.3363 - val_acc: 0.8638\n",
      "Epoch 32/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3216 - acc: 0.8643 - val_loss: 0.3152 - val_acc: 0.8633\n",
      "Epoch 33/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3194 - acc: 0.8650 - val_loss: 0.3234 - val_acc: 0.8593\n",
      "Epoch 34/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3228 - acc: 0.8636 - val_loss: 0.3292 - val_acc: 0.8685\n",
      "Epoch 35/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3219 - acc: 0.8631 - val_loss: 0.3197 - val_acc: 0.8727\n",
      "Epoch 36/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3180 - acc: 0.8669 - val_loss: 0.3315 - val_acc: 0.8603\n",
      "Epoch 37/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3147 - acc: 0.8689 - val_loss: 0.3272 - val_acc: 0.8613\n",
      "Epoch 38/60\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3139 - acc: 0.8690 - val_loss: 0.3224 - val_acc: 0.8690\n",
      "Epoch 39/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3169 - acc: 0.8664 - val_loss: 0.3244 - val_acc: 0.8685\n",
      "Epoch 40/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3131 - acc: 0.8674 - val_loss: 0.3251 - val_acc: 0.8620\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3116 - acc: 0.8683 - val_loss: 0.3051 - val_acc: 0.8740\n",
      "Epoch 42/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3051 - acc: 0.8727 - val_loss: 0.3268 - val_acc: 0.8621\n",
      "Epoch 43/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3209 - acc: 0.8661 - val_loss: 0.3438 - val_acc: 0.8592\n",
      "Epoch 44/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3260 - acc: 0.8612 - val_loss: 0.3246 - val_acc: 0.8658\n",
      "Epoch 45/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3136 - acc: 0.8688 - val_loss: 0.3211 - val_acc: 0.8630\n",
      "Epoch 46/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3157 - acc: 0.8663 - val_loss: 0.3156 - val_acc: 0.8710\n",
      "Epoch 47/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3140 - acc: 0.8660 - val_loss: 0.3223 - val_acc: 0.8617\n",
      "Epoch 48/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3046 - acc: 0.8727 - val_loss: 0.3281 - val_acc: 0.8605\n",
      "Epoch 49/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3136 - acc: 0.8682 - val_loss: 0.3065 - val_acc: 0.8753\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3029 - acc: 0.8731 - val_loss: 0.3316 - val_acc: 0.8620\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3115 - acc: 0.8694 - val_loss: 0.3020 - val_acc: 0.8750\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3108 - acc: 0.8703 - val_loss: 0.3305 - val_acc: 0.8577\n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3024 - acc: 0.8729 - val_loss: 0.3086 - val_acc: 0.8680\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3086 - acc: 0.8701 - val_loss: 0.3296 - val_acc: 0.8587\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3147 - acc: 0.8672 - val_loss: 0.3082 - val_acc: 0.8753\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3063 - acc: 0.8694 - val_loss: 0.3187 - val_acc: 0.8712\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3042 - acc: 0.8717 - val_loss: 0.3206 - val_acc: 0.8592\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3081 - acc: 0.8699 - val_loss: 0.3167 - val_acc: 0.8700\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3153 - acc: 0.8677 - val_loss: 0.3278 - val_acc: 0.8595\n",
      "Epoch 60/60\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3057 - acc: 0.8727 - val_loss: 0.3002 - val_acc: 0.8745\n",
      "\n",
      "Training process completed in: 0 h 15 m 11 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1312.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1314 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_613 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_613 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_614 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_614 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_615 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_615 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_616 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_616 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_154 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 130\n",
      "Validation Steps: 20\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.4930 - acc: 0.7677 - val_loss: 0.4139 - val_acc: 0.8210\n",
      "Epoch 2/80\n",
      "130/130 [==============================] - 13s 100ms/step - loss: 0.4250 - acc: 0.8175 - val_loss: 0.4420 - val_acc: 0.8202\n",
      "Epoch 3/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.4076 - acc: 0.8267 - val_loss: 0.4099 - val_acc: 0.8228\n",
      "Epoch 4/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.4020 - acc: 0.8283 - val_loss: 0.4054 - val_acc: 0.8318\n",
      "Epoch 5/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.4028 - acc: 0.8251 - val_loss: 0.4340 - val_acc: 0.8233\n",
      "Epoch 6/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3960 - acc: 0.8302 - val_loss: 0.4150 - val_acc: 0.8288\n",
      "Epoch 7/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3825 - acc: 0.8328 - val_loss: 0.4006 - val_acc: 0.8348\n",
      "Epoch 8/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3806 - acc: 0.8380 - val_loss: 0.3767 - val_acc: 0.8360\n",
      "Epoch 9/80\n",
      "130/130 [==============================] - 13s 103ms/step - loss: 0.3812 - acc: 0.8357 - val_loss: 0.4007 - val_acc: 0.8135\n",
      "Epoch 10/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3832 - acc: 0.8336 - val_loss: 0.3710 - val_acc: 0.8380\n",
      "Epoch 11/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3616 - acc: 0.8440 - val_loss: 0.3683 - val_acc: 0.8455\n",
      "Epoch 12/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3686 - acc: 0.8428 - val_loss: 0.3699 - val_acc: 0.8413\n",
      "Epoch 13/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3634 - acc: 0.8438 - val_loss: 0.3633 - val_acc: 0.8548\n",
      "Epoch 14/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3616 - acc: 0.8460 - val_loss: 0.3740 - val_acc: 0.8472\n",
      "Epoch 15/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3574 - acc: 0.8454 - val_loss: 0.3737 - val_acc: 0.8263\n",
      "Epoch 16/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3539 - acc: 0.8474 - val_loss: 0.3631 - val_acc: 0.8520\n",
      "Epoch 17/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3523 - acc: 0.8494 - val_loss: 0.3593 - val_acc: 0.8563\n",
      "Epoch 18/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3523 - acc: 0.8482 - val_loss: 0.3396 - val_acc: 0.8570\n",
      "Epoch 19/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3468 - acc: 0.8510 - val_loss: 0.3425 - val_acc: 0.8533\n",
      "Epoch 20/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3452 - acc: 0.8533 - val_loss: 0.3548 - val_acc: 0.8558\n",
      "Epoch 21/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3432 - acc: 0.8567 - val_loss: 0.3559 - val_acc: 0.8525\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3537 - acc: 0.8481 - val_loss: 0.3590 - val_acc: 0.8503\n",
      "Epoch 23/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3567 - acc: 0.8463 - val_loss: 0.3525 - val_acc: 0.8588\n",
      "Epoch 24/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3428 - acc: 0.8532 - val_loss: 0.3457 - val_acc: 0.8585\n",
      "Epoch 25/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3437 - acc: 0.8518 - val_loss: 0.3881 - val_acc: 0.8525\n",
      "Epoch 26/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3403 - acc: 0.8569 - val_loss: 0.3306 - val_acc: 0.8625\n",
      "Epoch 27/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3343 - acc: 0.8567 - val_loss: 0.3486 - val_acc: 0.8562\n",
      "Epoch 28/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3325 - acc: 0.8607 - val_loss: 0.3529 - val_acc: 0.8548loss: 0.3259 - a\n",
      "Epoch 29/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3312 - acc: 0.8603 - val_loss: 0.3389 - val_acc: 0.8572\n",
      "Epoch 30/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3332 - acc: 0.8578 - val_loss: 0.3255 - val_acc: 0.8667\n",
      "Epoch 31/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3289 - acc: 0.8591 - val_loss: 0.3559 - val_acc: 0.8477\n",
      "Epoch 32/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3355 - acc: 0.8552 - val_loss: 0.3436 - val_acc: 0.8567\n",
      "Epoch 33/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3352 - acc: 0.8579 - val_loss: 0.3576 - val_acc: 0.8448\n",
      "Epoch 34/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3318 - acc: 0.8587 - val_loss: 0.3310 - val_acc: 0.8667\n",
      "Epoch 35/80\n",
      "130/130 [==============================] - 13s 103ms/step - loss: 0.3339 - acc: 0.8568 - val_loss: 0.3327 - val_acc: 0.8666\n",
      "Epoch 36/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3277 - acc: 0.8608 - val_loss: 0.3270 - val_acc: 0.8625\n",
      "Epoch 37/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3275 - acc: 0.8620 - val_loss: 0.3287 - val_acc: 0.8677\n",
      "Epoch 38/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3307 - acc: 0.8604 - val_loss: 0.3411 - val_acc: 0.8508\n",
      "Epoch 39/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3244 - acc: 0.8629 - val_loss: 0.3327 - val_acc: 0.8615\n",
      "Epoch 40/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3288 - acc: 0.8588 - val_loss: 0.3527 - val_acc: 0.8562\n",
      "Epoch 41/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3258 - acc: 0.8625 - val_loss: 0.3261 - val_acc: 0.8585\n",
      "Epoch 42/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3200 - acc: 0.8661 - val_loss: 0.3396 - val_acc: 0.8560\n",
      "Epoch 43/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3203 - acc: 0.8646 - val_loss: 0.3649 - val_acc: 0.8382\n",
      "Epoch 44/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3246 - acc: 0.8630 - val_loss: 0.3235 - val_acc: 0.8625\n",
      "Epoch 45/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3227 - acc: 0.8648 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 46/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3214 - acc: 0.8653 - val_loss: 0.3167 - val_acc: 0.8688\n",
      "Epoch 47/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3175 - acc: 0.8646 - val_loss: 0.3526 - val_acc: 0.8562\n",
      "Epoch 48/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3193 - acc: 0.8662 - val_loss: 0.3142 - val_acc: 0.8672\n",
      "Epoch 49/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3183 - acc: 0.8668 - val_loss: 0.3358 - val_acc: 0.8712\n",
      "Epoch 50/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3193 - acc: 0.8667 - val_loss: 0.3311 - val_acc: 0.8647\n",
      "Epoch 51/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3238 - acc: 0.8625 - val_loss: 0.3395 - val_acc: 0.8545\n",
      "Epoch 52/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3133 - acc: 0.8680 - val_loss: 0.3128 - val_acc: 0.8705\n",
      "Epoch 53/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3220 - acc: 0.8640 - val_loss: 0.3245 - val_acc: 0.8632\n",
      "Epoch 54/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3163 - acc: 0.8669 - val_loss: 0.3526 - val_acc: 0.8553\n",
      "Epoch 55/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3204 - acc: 0.8639 - val_loss: 0.3345 - val_acc: 0.8623\n",
      "Epoch 56/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3145 - acc: 0.8655 - val_loss: 0.3076 - val_acc: 0.8710\n",
      "Epoch 57/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3192 - acc: 0.8640 - val_loss: 0.3226 - val_acc: 0.8653\n",
      "Epoch 58/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3184 - acc: 0.8644 - val_loss: 0.3268 - val_acc: 0.8650\n",
      "Epoch 59/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3112 - acc: 0.8695 - val_loss: 0.3197 - val_acc: 0.8685\n",
      "Epoch 60/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3209 - acc: 0.8653 - val_loss: 0.3531 - val_acc: 0.8630\n",
      "Epoch 61/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3118 - acc: 0.8692 - val_loss: 0.3213 - val_acc: 0.8638\n",
      "Epoch 62/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3046 - acc: 0.8718 - val_loss: 0.3156 - val_acc: 0.8710\n",
      "Epoch 63/80\n",
      "130/130 [==============================] - 13s 103ms/step - loss: 0.3149 - acc: 0.8652 - val_loss: 0.3299 - val_acc: 0.8613\n",
      "Epoch 64/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3121 - acc: 0.8677 - val_loss: 0.3275 - val_acc: 0.8643\n",
      "Epoch 65/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3128 - acc: 0.8685 - val_loss: 0.3318 - val_acc: 0.8700\n",
      "Epoch 66/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3097 - acc: 0.8695 - val_loss: 0.3158 - val_acc: 0.8753\n",
      "Epoch 67/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3064 - acc: 0.8693 - val_loss: 0.3214 - val_acc: 0.8617\n",
      "Epoch 68/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3114 - acc: 0.8688 - val_loss: 0.3300 - val_acc: 0.8670\n",
      "Epoch 69/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3064 - acc: 0.8727 - val_loss: 0.3137 - val_acc: 0.8730\n",
      "Epoch 70/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3067 - acc: 0.8721 - val_loss: 0.3150 - val_acc: 0.8707\n",
      "Epoch 71/80\n",
      "130/130 [==============================] - 13s 100ms/step - loss: 0.3092 - acc: 0.8678 - val_loss: 0.3214 - val_acc: 0.8627\n",
      "Epoch 72/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3048 - acc: 0.8713 - val_loss: 0.3006 - val_acc: 0.8745\n",
      "Epoch 73/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3130 - acc: 0.8678 - val_loss: 0.3182 - val_acc: 0.8732\n",
      "Epoch 74/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3107 - acc: 0.8696 - val_loss: 0.3309 - val_acc: 0.8673\n",
      "Epoch 75/80\n",
      "130/130 [==============================] - 13s 100ms/step - loss: 0.3077 - acc: 0.8716 - val_loss: 0.3296 - val_acc: 0.8630\n",
      "Epoch 76/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3196 - acc: 0.8660 - val_loss: 0.3209 - val_acc: 0.8690\n",
      "Epoch 77/80\n",
      "130/130 [==============================] - 13s 103ms/step - loss: 0.3064 - acc: 0.8725 - val_loss: 0.3226 - val_acc: 0.8651\n",
      "Epoch 78/80\n",
      "130/130 [==============================] - 13s 101ms/step - loss: 0.3012 - acc: 0.8705 - val_loss: 0.3252 - val_acc: 0.8648\n",
      "Epoch 79/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3039 - acc: 0.8741 - val_loss: 0.3212 - val_acc: 0.8655\n",
      "Epoch 80/80\n",
      "130/130 [==============================] - 13s 102ms/step - loss: 0.3038 - acc: 0.8742 - val_loss: 0.2993 - val_acc: 0.8767\n",
      "\n",
      "Training process completed in: 0 h 17 m 47 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1313.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1315 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_617 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_617 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_618 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_618 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_619 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_619 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_620 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_620 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_155 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 18s 123ms/step - loss: 0.5141 - acc: 0.7579 - val_loss: 0.4365 - val_acc: 0.8210\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 0.4396 - acc: 0.8109 - val_loss: 0.4199 - val_acc: 0.8300\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.4248 - acc: 0.8183 - val_loss: 0.4277 - val_acc: 0.8080\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.4122 - acc: 0.8245 - val_loss: 0.4434 - val_acc: 0.8000\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.4067 - acc: 0.8281 - val_loss: 0.3832 - val_acc: 0.8420\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.4018 - acc: 0.8290 - val_loss: 0.4612 - val_acc: 0.8000\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.4038 - acc: 0.8269 - val_loss: 0.4061 - val_acc: 0.8360\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3892 - acc: 0.8337 - val_loss: 0.4052 - val_acc: 0.8390\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3987 - acc: 0.8279 - val_loss: 0.4303 - val_acc: 0.8180\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3918 - acc: 0.8331 - val_loss: 0.4371 - val_acc: 0.8140\n",
      "Epoch 11/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3956 - acc: 0.8287 - val_loss: 0.4043 - val_acc: 0.8300\n",
      "Epoch 12/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3829 - acc: 0.8349 - val_loss: 0.3820 - val_acc: 0.8320\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3855 - acc: 0.8379 - val_loss: 0.3463 - val_acc: 0.8500\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3762 - acc: 0.8397 - val_loss: 0.3841 - val_acc: 0.8240\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3655 - acc: 0.8431 - val_loss: 0.3758 - val_acc: 0.8510\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3665 - acc: 0.8411 - val_loss: 0.3837 - val_acc: 0.8170\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3564 - acc: 0.8511 - val_loss: 0.3762 - val_acc: 0.8400\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3841 - acc: 0.8360 - val_loss: 0.3806 - val_acc: 0.8300\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3701 - acc: 0.8389 - val_loss: 0.3420 - val_acc: 0.8760\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3676 - acc: 0.8426 - val_loss: 0.3457 - val_acc: 0.8490\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3630 - acc: 0.8457 - val_loss: 0.3462 - val_acc: 0.8610\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3556 - acc: 0.8506 - val_loss: 0.3639 - val_acc: 0.8340\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3595 - acc: 0.8494 - val_loss: 0.3541 - val_acc: 0.8440\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3559 - acc: 0.8531 - val_loss: 0.3522 - val_acc: 0.8630\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3629 - acc: 0.8483 - val_loss: 0.3483 - val_acc: 0.8500\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3497 - acc: 0.8507 - val_loss: 0.3474 - val_acc: 0.8610\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3577 - acc: 0.8473 - val_loss: 0.3316 - val_acc: 0.8670\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3549 - acc: 0.8470 - val_loss: 0.3662 - val_acc: 0.8298\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 0.3591 - acc: 0.8499 - val_loss: 0.3082 - val_acc: 0.8700\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3483 - acc: 0.8509 - val_loss: 0.3367 - val_acc: 0.8770\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3483 - acc: 0.8503 - val_loss: 0.3619 - val_acc: 0.8390\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3420 - acc: 0.8555 - val_loss: 0.3952 - val_acc: 0.8170\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3520 - acc: 0.8533 - val_loss: 0.3658 - val_acc: 0.8590\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3447 - acc: 0.8504 - val_loss: 0.3689 - val_acc: 0.8370\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3299 - acc: 0.8619 - val_loss: 0.3550 - val_acc: 0.8620\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3429 - acc: 0.8543 - val_loss: 0.3845 - val_acc: 0.8410\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3483 - acc: 0.8512 - val_loss: 0.3630 - val_acc: 0.8580\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3447 - acc: 0.8552 - val_loss: 0.3265 - val_acc: 0.8710\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3332 - acc: 0.8585 - val_loss: 0.3430 - val_acc: 0.8540\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3421 - acc: 0.8585 - val_loss: 0.3606 - val_acc: 0.8530\n",
      "Epoch 41/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3487 - acc: 0.8516 - val_loss: 0.3553 - val_acc: 0.8490\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3378 - acc: 0.8593 - val_loss: 0.3205 - val_acc: 0.8690\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3382 - acc: 0.8567 - val_loss: 0.3013 - val_acc: 0.8840\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3360 - acc: 0.8569 - val_loss: 0.3489 - val_acc: 0.8530\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3385 - acc: 0.8569 - val_loss: 0.3651 - val_acc: 0.8520\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3342 - acc: 0.8565 - val_loss: 0.3520 - val_acc: 0.8420\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3360 - acc: 0.8595 - val_loss: 0.3278 - val_acc: 0.8520\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3321 - acc: 0.8591 - val_loss: 0.3460 - val_acc: 0.8480\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3343 - acc: 0.8581 - val_loss: 0.3550 - val_acc: 0.8590\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3366 - acc: 0.8583 - val_loss: 0.3301 - val_acc: 0.8640\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3472 - acc: 0.8529 - val_loss: 0.3445 - val_acc: 0.8600\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3339 - acc: 0.8575 - val_loss: 0.3583 - val_acc: 0.8500\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3288 - acc: 0.8628 - val_loss: 0.3328 - val_acc: 0.8630\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3332 - acc: 0.8581 - val_loss: 0.3378 - val_acc: 0.8610\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3278 - acc: 0.8629 - val_loss: 0.3394 - val_acc: 0.8500\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 8s 55ms/step - loss: 0.3219 - acc: 0.8645 - val_loss: 0.3510 - val_acc: 0.8414\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3282 - acc: 0.8568 - val_loss: 0.3668 - val_acc: 0.8570\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3422 - acc: 0.8583 - val_loss: 0.3157 - val_acc: 0.8850\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3313 - acc: 0.8587 - val_loss: 0.3452 - val_acc: 0.8510\n",
      "Epoch 60/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3254 - acc: 0.8637 - val_loss: 0.3227 - val_acc: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3285 - acc: 0.8631 - val_loss: 0.3222 - val_acc: 0.8590\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3305 - acc: 0.8594 - val_loss: 0.3322 - val_acc: 0.8640\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3322 - acc: 0.8613 - val_loss: 0.3138 - val_acc: 0.8710\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3258 - acc: 0.8601 - val_loss: 0.3723 - val_acc: 0.8360\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3324 - acc: 0.8569 - val_loss: 0.2997 - val_acc: 0.8810\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3240 - acc: 0.8638 - val_loss: 0.3241 - val_acc: 0.8830\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3274 - acc: 0.8628 - val_loss: 0.3382 - val_acc: 0.8460\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3214 - acc: 0.8616 - val_loss: 0.3411 - val_acc: 0.8540\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3203 - acc: 0.8673 - val_loss: 0.3507 - val_acc: 0.8490\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3179 - acc: 0.8669 - val_loss: 0.3648 - val_acc: 0.8430\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3179 - acc: 0.8665 - val_loss: 0.3474 - val_acc: 0.8470\n",
      "Epoch 72/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3275 - acc: 0.8640 - val_loss: 0.3391 - val_acc: 0.8540\n",
      "Epoch 73/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3220 - acc: 0.8596 - val_loss: 0.3467 - val_acc: 0.8680\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3209 - acc: 0.8647 - val_loss: 0.3295 - val_acc: 0.8680\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3272 - acc: 0.8601 - val_loss: 0.3481 - val_acc: 0.8490\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3151 - acc: 0.8681 - val_loss: 0.3332 - val_acc: 0.8490\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3334 - acc: 0.8589 - val_loss: 0.2997 - val_acc: 0.8860\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3234 - acc: 0.8625 - val_loss: 0.3169 - val_acc: 0.8770\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3243 - acc: 0.8601 - val_loss: 0.3342 - val_acc: 0.8630\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3152 - acc: 0.8683 - val_loss: 0.3339 - val_acc: 0.8690\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3180 - acc: 0.8671 - val_loss: 0.3206 - val_acc: 0.8630\n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3167 - acc: 0.8685 - val_loss: 0.3445 - val_acc: 0.8500\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3303 - acc: 0.8625 - val_loss: 0.3269 - val_acc: 0.8590\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 8s 55ms/step - loss: 0.3195 - acc: 0.8629 - val_loss: 0.3281 - val_acc: 0.8592\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 0.3223 - acc: 0.8597 - val_loss: 0.3056 - val_acc: 0.8710\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3229 - acc: 0.8648 - val_loss: 0.3277 - val_acc: 0.8590\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3184 - acc: 0.8645 - val_loss: 0.3542 - val_acc: 0.8530\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.3187 - acc: 0.8633 - val_loss: 0.3337 - val_acc: 0.8490\n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3192 - acc: 0.8643 - val_loss: 0.3484 - val_acc: 0.8590\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.3113 - acc: 0.8681 - val_loss: 0.2981 - val_acc: 0.8780\n",
      "\n",
      "Training process completed in: 0 h 12 m 12 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1314.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1316 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_621 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_621 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_622 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_622 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_623 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_623 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_624 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_624 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_156 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 200\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 150\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "150/150 [==============================] - 24s 163ms/step - loss: 0.5508 - acc: 0.7289 - val_loss: 0.4431 - val_acc: 0.8080\n",
      "Epoch 2/90\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.4271 - acc: 0.8150 - val_loss: 0.4272 - val_acc: 0.8040\n",
      "Epoch 3/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.4241 - acc: 0.8155 - val_loss: 0.4260 - val_acc: 0.8315\n",
      "Epoch 4/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.4090 - acc: 0.8242 - val_loss: 0.4134 - val_acc: 0.8245\n",
      "Epoch 5/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.4081 - acc: 0.8222 - val_loss: 0.3741 - val_acc: 0.8470\n",
      "Epoch 6/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.4083 - acc: 0.8249 - val_loss: 0.4010 - val_acc: 0.8300\n",
      "Epoch 7/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3997 - acc: 0.8285 - val_loss: 0.3983 - val_acc: 0.8250\n",
      "Epoch 8/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3998 - acc: 0.8292 - val_loss: 0.4175 - val_acc: 0.8125\n",
      "Epoch 9/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3995 - acc: 0.8297 - val_loss: 0.3961 - val_acc: 0.8330\n",
      "Epoch 10/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3913 - acc: 0.8321 - val_loss: 0.3991 - val_acc: 0.8240\n",
      "Epoch 11/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3915 - acc: 0.8284 - val_loss: 0.3997 - val_acc: 0.8210\n",
      "Epoch 12/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3844 - acc: 0.8349 - val_loss: 0.3959 - val_acc: 0.8300\n",
      "Epoch 13/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3811 - acc: 0.8345 - val_loss: 0.3873 - val_acc: 0.8350\n",
      "Epoch 14/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3844 - acc: 0.8334 - val_loss: 0.3768 - val_acc: 0.8350\n",
      "Epoch 15/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3811 - acc: 0.8360 - val_loss: 0.3922 - val_acc: 0.8285\n",
      "Epoch 16/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3716 - acc: 0.8386 - val_loss: 0.4043 - val_acc: 0.8125\n",
      "Epoch 17/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3725 - acc: 0.8401 - val_loss: 0.4103 - val_acc: 0.8155\n",
      "Epoch 18/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3806 - acc: 0.8373 - val_loss: 0.3599 - val_acc: 0.8430\n",
      "Epoch 19/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3717 - acc: 0.8409 - val_loss: 0.3618 - val_acc: 0.8480\n",
      "Epoch 20/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3765 - acc: 0.8376 - val_loss: 0.3476 - val_acc: 0.8575\n",
      "Epoch 21/90\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3688 - acc: 0.8432 - val_loss: 0.3527 - val_acc: 0.8440\n",
      "Epoch 22/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3660 - acc: 0.8435 - val_loss: 0.3417 - val_acc: 0.8635\n",
      "Epoch 23/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3654 - acc: 0.8421 - val_loss: 0.3539 - val_acc: 0.8530\n",
      "Epoch 24/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3601 - acc: 0.8444 - val_loss: 0.3807 - val_acc: 0.8380\n",
      "Epoch 25/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3578 - acc: 0.8469 - val_loss: 0.3578 - val_acc: 0.8485\n",
      "Epoch 26/90\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3557 - acc: 0.8501 - val_loss: 0.3647 - val_acc: 0.8440\n",
      "Epoch 27/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3654 - acc: 0.8435 - val_loss: 0.3730 - val_acc: 0.8330\n",
      "Epoch 28/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3545 - acc: 0.8483 - val_loss: 0.3456 - val_acc: 0.8601\n",
      "Epoch 29/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3587 - acc: 0.8482 - val_loss: 0.3558 - val_acc: 0.8595\n",
      "Epoch 30/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3551 - acc: 0.8493 - val_loss: 0.3558 - val_acc: 0.8460\n",
      "Epoch 31/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3473 - acc: 0.8522 - val_loss: 0.3460 - val_acc: 0.8565\n",
      "Epoch 32/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3546 - acc: 0.8493 - val_loss: 0.3641 - val_acc: 0.8405\n",
      "Epoch 33/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3448 - acc: 0.8545 - val_loss: 0.3432 - val_acc: 0.8570\n",
      "Epoch 34/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3503 - acc: 0.8521 - val_loss: 0.3501 - val_acc: 0.8505\n",
      "Epoch 35/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3474 - acc: 0.8520 - val_loss: 0.3199 - val_acc: 0.8720\n",
      "Epoch 36/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3506 - acc: 0.8500 - val_loss: 0.3522 - val_acc: 0.8515\n",
      "Epoch 37/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3479 - acc: 0.8512 - val_loss: 0.3509 - val_acc: 0.8510\n",
      "Epoch 38/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3473 - acc: 0.8525 - val_loss: 0.3399 - val_acc: 0.8655\n",
      "Epoch 39/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3411 - acc: 0.8557 - val_loss: 0.3347 - val_acc: 0.8650\n",
      "Epoch 40/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3433 - acc: 0.8566 - val_loss: 0.3613 - val_acc: 0.8495\n",
      "Epoch 41/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3411 - acc: 0.8540 - val_loss: 0.3425 - val_acc: 0.8515\n",
      "Epoch 42/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3352 - acc: 0.8589 - val_loss: 0.3790 - val_acc: 0.8397\n",
      "Epoch 43/90\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3401 - acc: 0.8553 - val_loss: 0.3394 - val_acc: 0.8595\n",
      "Epoch 44/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3472 - acc: 0.8517 - val_loss: 0.3497 - val_acc: 0.8485\n",
      "Epoch 45/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3461 - acc: 0.8526 - val_loss: 0.3397 - val_acc: 0.8670\n",
      "Epoch 46/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3375 - acc: 0.8570 - val_loss: 0.3557 - val_acc: 0.8370\n",
      "Epoch 47/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3345 - acc: 0.8574 - val_loss: 0.3645 - val_acc: 0.8405\n",
      "Epoch 48/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3374 - acc: 0.8573 - val_loss: 0.3449 - val_acc: 0.8570\n",
      "Epoch 49/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3395 - acc: 0.8557 - val_loss: 0.3209 - val_acc: 0.8720\n",
      "Epoch 50/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3342 - acc: 0.8585 - val_loss: 0.3147 - val_acc: 0.8770\n",
      "Epoch 51/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3295 - acc: 0.8604 - val_loss: 0.3476 - val_acc: 0.8535\n",
      "Epoch 52/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3363 - acc: 0.8573 - val_loss: 0.3529 - val_acc: 0.8505\n",
      "Epoch 53/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3295 - acc: 0.8609 - val_loss: 0.3255 - val_acc: 0.8685\n",
      "Epoch 54/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3326 - acc: 0.8594 - val_loss: 0.3191 - val_acc: 0.8645\n",
      "Epoch 55/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3333 - acc: 0.8568 - val_loss: 0.3496 - val_acc: 0.8525\n",
      "Epoch 56/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3363 - acc: 0.8567 - val_loss: 0.3212 - val_acc: 0.8612\n",
      "Epoch 57/90\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3316 - acc: 0.8589 - val_loss: 0.3268 - val_acc: 0.8625\n",
      "Epoch 58/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3253 - acc: 0.8620 - val_loss: 0.3251 - val_acc: 0.8630\n",
      "Epoch 59/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3294 - acc: 0.8602 - val_loss: 0.3419 - val_acc: 0.8565\n",
      "Epoch 60/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3279 - acc: 0.8620 - val_loss: 0.3615 - val_acc: 0.8375\n",
      "Epoch 61/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3298 - acc: 0.8607 - val_loss: 0.3197 - val_acc: 0.8620\n",
      "Epoch 62/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3285 - acc: 0.8583 - val_loss: 0.3387 - val_acc: 0.8605\n",
      "Epoch 63/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3285 - acc: 0.8577 - val_loss: 0.3390 - val_acc: 0.8535\n",
      "Epoch 64/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3296 - acc: 0.8606 - val_loss: 0.3082 - val_acc: 0.8735\n",
      "Epoch 65/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3212 - acc: 0.8638 - val_loss: 0.3233 - val_acc: 0.8705\n",
      "Epoch 66/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3273 - acc: 0.8611 - val_loss: 0.3198 - val_acc: 0.8695\n",
      "Epoch 67/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3312 - acc: 0.8601 - val_loss: 0.3184 - val_acc: 0.8725\n",
      "Epoch 68/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3252 - acc: 0.8617 - val_loss: 0.3155 - val_acc: 0.8640\n",
      "Epoch 69/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3298 - acc: 0.8585 - val_loss: 0.3293 - val_acc: 0.8645\n",
      "Epoch 70/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3254 - acc: 0.8628 - val_loss: 0.3511 - val_acc: 0.8596\n",
      "Epoch 71/90\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.3257 - acc: 0.8616 - val_loss: 0.3139 - val_acc: 0.8690\n",
      "Epoch 72/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3243 - acc: 0.8638 - val_loss: 0.3430 - val_acc: 0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/90\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3265 - acc: 0.8611 - val_loss: 0.3418 - val_acc: 0.8595\n",
      "Epoch 74/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3154 - acc: 0.8674 - val_loss: 0.3263 - val_acc: 0.8575\n",
      "Epoch 75/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3185 - acc: 0.8684 - val_loss: 0.3133 - val_acc: 0.8650\n",
      "Epoch 76/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3219 - acc: 0.8647 - val_loss: 0.3372 - val_acc: 0.8700\n",
      "Epoch 77/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3151 - acc: 0.8679 - val_loss: 0.3201 - val_acc: 0.8605\n",
      "Epoch 78/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3261 - acc: 0.8607 - val_loss: 0.3231 - val_acc: 0.8615\n",
      "Epoch 79/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3258 - acc: 0.8602 - val_loss: 0.3154 - val_acc: 0.8730\n",
      "Epoch 80/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3152 - acc: 0.8675 - val_loss: 0.3278 - val_acc: 0.8550\n",
      "Epoch 81/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3160 - acc: 0.8670 - val_loss: 0.3137 - val_acc: 0.8760\n",
      "Epoch 82/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3187 - acc: 0.8662 - val_loss: 0.3074 - val_acc: 0.8680\n",
      "Epoch 83/90\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 0.3163 - acc: 0.8671 - val_loss: 0.3428 - val_acc: 0.8600\n",
      "Epoch 84/90\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3205 - acc: 0.8644 - val_loss: 0.3131 - val_acc: 0.8704\n",
      "Epoch 85/90\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.3144 - acc: 0.8677 - val_loss: 0.3401 - val_acc: 0.8545\n",
      "Epoch 86/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3177 - acc: 0.8664 - val_loss: 0.3270 - val_acc: 0.8680\n",
      "Epoch 87/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3189 - acc: 0.8640 - val_loss: 0.3318 - val_acc: 0.8530\n",
      "Epoch 88/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3171 - acc: 0.8653 - val_loss: 0.3060 - val_acc: 0.8715\n",
      "Epoch 89/90\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 0.3100 - acc: 0.8704 - val_loss: 0.2820 - val_acc: 0.8765\n",
      "Epoch 90/90\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.3168 - acc: 0.8649 - val_loss: 0.3113 - val_acc: 0.8630\n",
      "\n",
      "Training process completed in: 0 h 22 m 7 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1315.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1317 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_625 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_625 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_626 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_626 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_627 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_627 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_628 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_628 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_157 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.0001\n",
      "Epochs: 90\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/90\n",
      "190/190 [==============================] - 21s 109ms/step - loss: 0.5552 - acc: 0.7262 - val_loss: 0.4767 - val_acc: 0.7860\n",
      "Epoch 2/90\n",
      "190/190 [==============================] - 10s 51ms/step - loss: 0.4313 - acc: 0.8147 - val_loss: 0.4199 - val_acc: 0.8090\n",
      "Epoch 3/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4201 - acc: 0.8182 - val_loss: 0.4263 - val_acc: 0.8160\n",
      "Epoch 4/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4129 - acc: 0.8248 - val_loss: 0.4223 - val_acc: 0.8080\n",
      "Epoch 5/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4124 - acc: 0.8238 - val_loss: 0.3919 - val_acc: 0.8240\n",
      "Epoch 6/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4105 - acc: 0.8254 - val_loss: 0.4338 - val_acc: 0.8090\n",
      "Epoch 7/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4140 - acc: 0.8213 - val_loss: 0.4214 - val_acc: 0.8230\n",
      "Epoch 8/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4034 - acc: 0.8272 - val_loss: 0.4030 - val_acc: 0.8330\n",
      "Epoch 9/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3985 - acc: 0.8293 - val_loss: 0.4155 - val_acc: 0.8140\n",
      "Epoch 10/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.4010 - acc: 0.8285 - val_loss: 0.4365 - val_acc: 0.8140\n",
      "Epoch 11/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3924 - acc: 0.8315 - val_loss: 0.4088 - val_acc: 0.8290\n",
      "Epoch 12/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3882 - acc: 0.8335 - val_loss: 0.4023 - val_acc: 0.8170\n",
      "Epoch 13/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3887 - acc: 0.8331 - val_loss: 0.3992 - val_acc: 0.8210\n",
      "Epoch 14/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3915 - acc: 0.8311 - val_loss: 0.3816 - val_acc: 0.8440\n",
      "Epoch 15/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3903 - acc: 0.8333 - val_loss: 0.3764 - val_acc: 0.8430\n",
      "Epoch 16/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3825 - acc: 0.8348 - val_loss: 0.3652 - val_acc: 0.8460\n",
      "Epoch 17/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3800 - acc: 0.8363 - val_loss: 0.3989 - val_acc: 0.8280\n",
      "Epoch 18/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3757 - acc: 0.8390 - val_loss: 0.3808 - val_acc: 0.8270\n",
      "Epoch 19/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3726 - acc: 0.8395 - val_loss: 0.3674 - val_acc: 0.8470\n",
      "Epoch 20/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3724 - acc: 0.8407 - val_loss: 0.4054 - val_acc: 0.8270\n",
      "Epoch 21/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3751 - acc: 0.8384 - val_loss: 0.3591 - val_acc: 0.8410\n",
      "Epoch 22/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3701 - acc: 0.8427 - val_loss: 0.3642 - val_acc: 0.8490\n",
      "Epoch 23/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3717 - acc: 0.8404 - val_loss: 0.3696 - val_acc: 0.8360\n",
      "Epoch 24/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3716 - acc: 0.8393 - val_loss: 0.3441 - val_acc: 0.8570\n",
      "Epoch 25/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3681 - acc: 0.8453 - val_loss: 0.3600 - val_acc: 0.8440\n",
      "Epoch 26/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3627 - acc: 0.8424 - val_loss: 0.3780 - val_acc: 0.8340\n",
      "Epoch 27/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3695 - acc: 0.8448 - val_loss: 0.3619 - val_acc: 0.8470\n",
      "Epoch 28/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3585 - acc: 0.8468 - val_loss: 0.3400 - val_acc: 0.8655\n",
      "Epoch 29/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3460 - acc: 0.8548 - val_loss: 0.3539 - val_acc: 0.8450\n",
      "Epoch 30/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3648 - acc: 0.8461 - val_loss: 0.3809 - val_acc: 0.8380\n",
      "Epoch 31/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3530 - acc: 0.8511 - val_loss: 0.3718 - val_acc: 0.8410\n",
      "Epoch 32/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3567 - acc: 0.8490 - val_loss: 0.3425 - val_acc: 0.8500\n",
      "Epoch 33/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3613 - acc: 0.8443 - val_loss: 0.3849 - val_acc: 0.8340\n",
      "Epoch 34/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3537 - acc: 0.8484 - val_loss: 0.3615 - val_acc: 0.8450\n",
      "Epoch 35/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3565 - acc: 0.8478 - val_loss: 0.3668 - val_acc: 0.8340\n",
      "Epoch 36/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3539 - acc: 0.8486 - val_loss: 0.3071 - val_acc: 0.8730\n",
      "Epoch 37/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3553 - acc: 0.8497 - val_loss: 0.3617 - val_acc: 0.8450\n",
      "Epoch 38/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3629 - acc: 0.8428 - val_loss: 0.3270 - val_acc: 0.8580\n",
      "Epoch 39/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3434 - acc: 0.8532 - val_loss: 0.3618 - val_acc: 0.8440\n",
      "Epoch 40/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3469 - acc: 0.8529 - val_loss: 0.3508 - val_acc: 0.8580\n",
      "Epoch 41/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3478 - acc: 0.8559 - val_loss: 0.3334 - val_acc: 0.8620\n",
      "Epoch 42/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3416 - acc: 0.8570 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 43/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3463 - acc: 0.8549 - val_loss: 0.3558 - val_acc: 0.8440\n",
      "Epoch 44/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3454 - acc: 0.8522 - val_loss: 0.3431 - val_acc: 0.8560\n",
      "Epoch 45/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3455 - acc: 0.8531 - val_loss: 0.3262 - val_acc: 0.8620\n",
      "Epoch 46/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3390 - acc: 0.8569 - val_loss: 0.3386 - val_acc: 0.8660\n",
      "Epoch 47/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3352 - acc: 0.8564 - val_loss: 0.3569 - val_acc: 0.8470\n",
      "Epoch 48/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3420 - acc: 0.8563 - val_loss: 0.3443 - val_acc: 0.8670\n",
      "Epoch 49/90\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.3374 - acc: 0.8593 - val_loss: 0.3595 - val_acc: 0.8430\n",
      "Epoch 50/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3361 - acc: 0.8581 - val_loss: 0.3689 - val_acc: 0.8380\n",
      "Epoch 51/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3394 - acc: 0.8554 - val_loss: 0.3874 - val_acc: 0.8340\n",
      "Epoch 52/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3433 - acc: 0.8551 - val_loss: 0.3008 - val_acc: 0.8720\n",
      "Epoch 53/90\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.3374 - acc: 0.8555 - val_loss: 0.3283 - val_acc: 0.8620\n",
      "Epoch 54/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3389 - acc: 0.8575 - val_loss: 0.3376 - val_acc: 0.8640\n",
      "Epoch 55/90\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.3312 - acc: 0.8576 - val_loss: 0.3313 - val_acc: 0.8580\n",
      "Epoch 56/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3382 - acc: 0.8548 - val_loss: 0.3703 - val_acc: 0.8403\n",
      "Epoch 57/90\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.3388 - acc: 0.8565 - val_loss: 0.3240 - val_acc: 0.8550\n",
      "Epoch 58/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3474 - acc: 0.8522 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 59/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3350 - acc: 0.8566 - val_loss: 0.3309 - val_acc: 0.8580\n",
      "Epoch 60/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3300 - acc: 0.8575 - val_loss: 0.3448 - val_acc: 0.8460\n",
      "Epoch 61/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3177 - acc: 0.8684 - val_loss: 0.3689 - val_acc: 0.8480\n",
      "Epoch 62/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3312 - acc: 0.8617 - val_loss: 0.3169 - val_acc: 0.8610\n",
      "Epoch 63/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3300 - acc: 0.8601 - val_loss: 0.3351 - val_acc: 0.8620\n",
      "Epoch 64/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3321 - acc: 0.8568 - val_loss: 0.3160 - val_acc: 0.8650\n",
      "Epoch 65/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3248 - acc: 0.8612 - val_loss: 0.3050 - val_acc: 0.8770\n",
      "Epoch 66/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3312 - acc: 0.8609 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 67/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3364 - acc: 0.8537 - val_loss: 0.3497 - val_acc: 0.8540\n",
      "Epoch 68/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3265 - acc: 0.8641 - val_loss: 0.3229 - val_acc: 0.8540\n",
      "Epoch 69/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3343 - acc: 0.8587 - val_loss: 0.3154 - val_acc: 0.8700\n",
      "Epoch 70/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3221 - acc: 0.8629 - val_loss: 0.3505 - val_acc: 0.8580\n",
      "Epoch 71/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3256 - acc: 0.8624 - val_loss: 0.3239 - val_acc: 0.8520\n",
      "Epoch 72/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3178 - acc: 0.8648 - val_loss: 0.3263 - val_acc: 0.8650\n",
      "Epoch 73/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3181 - acc: 0.8673 - val_loss: 0.3290 - val_acc: 0.8590\n",
      "Epoch 74/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3339 - acc: 0.8593 - val_loss: 0.3356 - val_acc: 0.8690\n",
      "Epoch 75/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3247 - acc: 0.8613 - val_loss: 0.3062 - val_acc: 0.8730\n",
      "Epoch 76/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3245 - acc: 0.8608 - val_loss: 0.3072 - val_acc: 0.8740\n",
      "Epoch 77/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3236 - acc: 0.8639 - val_loss: 0.3685 - val_acc: 0.8440\n",
      "Epoch 78/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3220 - acc: 0.8622 - val_loss: 0.3318 - val_acc: 0.8680\n",
      "Epoch 79/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3206 - acc: 0.8648 - val_loss: 0.3685 - val_acc: 0.8470\n",
      "Epoch 80/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3243 - acc: 0.8620 - val_loss: 0.3310 - val_acc: 0.8570\n",
      "Epoch 81/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3285 - acc: 0.8596 - val_loss: 0.3219 - val_acc: 0.8760\n",
      "Epoch 82/90\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3257 - acc: 0.8597 - val_loss: 0.3136 - val_acc: 0.8750\n",
      "Epoch 83/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3171 - acc: 0.8674 - val_loss: 0.3301 - val_acc: 0.8550\n",
      "Epoch 84/90\n",
      "190/190 [==============================] - 10s 55ms/step - loss: 0.3126 - acc: 0.8668 - val_loss: 0.2905 - val_acc: 0.8729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/90\n",
      "190/190 [==============================] - 10s 51ms/step - loss: 0.3199 - acc: 0.8664 - val_loss: 0.3187 - val_acc: 0.8720\n",
      "Epoch 86/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3323 - acc: 0.8596 - val_loss: 0.3561 - val_acc: 0.8380\n",
      "Epoch 87/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3222 - acc: 0.8616 - val_loss: 0.2836 - val_acc: 0.8820\n",
      "Epoch 88/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3165 - acc: 0.8662 - val_loss: 0.3510 - val_acc: 0.8410\n",
      "Epoch 89/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3171 - acc: 0.8645 - val_loss: 0.3500 - val_acc: 0.8570\n",
      "Epoch 90/90\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3200 - acc: 0.8657 - val_loss: 0.3425 - val_acc: 0.8660\n",
      "\n",
      "Training process completed in: 0 h 15 m 18 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1316.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1318 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_629 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_629 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_630 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_630 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_631 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_631 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_632 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_632 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_158 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 100\n",
      "Learning Rate: 0.001\n",
      "Epochs: 60\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/60\n",
      "190/190 [==============================] - 21s 110ms/step - loss: 0.5002 - acc: 0.7695 - val_loss: 0.5157 - val_acc: 0.7810\n",
      "Epoch 2/60\n",
      "190/190 [==============================] - 10s 51ms/step - loss: 0.4259 - acc: 0.8183 - val_loss: 0.4097 - val_acc: 0.8240\n",
      "Epoch 3/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.4192 - acc: 0.8221 - val_loss: 0.4530 - val_acc: 0.7960\n",
      "Epoch 4/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.4102 - acc: 0.8262 - val_loss: 0.3976 - val_acc: 0.8350\n",
      "Epoch 5/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3962 - acc: 0.8315 - val_loss: 0.3833 - val_acc: 0.8460\n",
      "Epoch 6/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.4036 - acc: 0.8267 - val_loss: 0.3582 - val_acc: 0.8480\n",
      "Epoch 7/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3952 - acc: 0.8311 - val_loss: 0.3851 - val_acc: 0.8410\n",
      "Epoch 8/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3843 - acc: 0.8371 - val_loss: 0.4096 - val_acc: 0.8120\n",
      "Epoch 9/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3833 - acc: 0.8372 - val_loss: 0.4417 - val_acc: 0.8150\n",
      "Epoch 10/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3842 - acc: 0.8332 - val_loss: 0.4405 - val_acc: 0.7910\n",
      "Epoch 11/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3793 - acc: 0.8357 - val_loss: 0.3792 - val_acc: 0.8400\n",
      "Epoch 12/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3851 - acc: 0.8333 - val_loss: 0.3855 - val_acc: 0.8380\n",
      "Epoch 13/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3732 - acc: 0.8397 - val_loss: 0.4362 - val_acc: 0.8260\n",
      "Epoch 14/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3678 - acc: 0.8433 - val_loss: 0.3639 - val_acc: 0.8540\n",
      "Epoch 15/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3712 - acc: 0.8410 - val_loss: 0.4256 - val_acc: 0.8300\n",
      "Epoch 16/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3727 - acc: 0.8415 - val_loss: 0.3983 - val_acc: 0.8330\n",
      "Epoch 17/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3586 - acc: 0.8473 - val_loss: 0.4005 - val_acc: 0.8470\n",
      "Epoch 18/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3622 - acc: 0.8443 - val_loss: 0.3720 - val_acc: 0.8420\n",
      "Epoch 19/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3621 - acc: 0.8458 - val_loss: 0.3596 - val_acc: 0.8650\n",
      "Epoch 20/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3629 - acc: 0.8474 - val_loss: 0.3665 - val_acc: 0.8420\n",
      "Epoch 21/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3504 - acc: 0.8531 - val_loss: 0.3374 - val_acc: 0.8610\n",
      "Epoch 22/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3489 - acc: 0.8528 - val_loss: 0.3397 - val_acc: 0.8690\n",
      "Epoch 23/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3539 - acc: 0.8506 - val_loss: 0.3744 - val_acc: 0.8370\n",
      "Epoch 24/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3447 - acc: 0.8546 - val_loss: 0.3321 - val_acc: 0.8700\n",
      "Epoch 25/60\n",
      "190/190 [==============================] - 10s 55ms/step - loss: 0.3473 - acc: 0.8542 - val_loss: 0.3331 - val_acc: 0.8660\n",
      "Epoch 26/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3433 - acc: 0.8539 - val_loss: 0.3624 - val_acc: 0.8520\n",
      "Epoch 27/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3421 - acc: 0.8557 - val_loss: 0.3529 - val_acc: 0.8410\n",
      "Epoch 28/60\n",
      "190/190 [==============================] - 10s 55ms/step - loss: 0.3456 - acc: 0.8534 - val_loss: 0.3585 - val_acc: 0.8487\n",
      "Epoch 29/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3447 - acc: 0.8558 - val_loss: 0.3415 - val_acc: 0.8570\n",
      "Epoch 30/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3473 - acc: 0.8528 - val_loss: 0.3708 - val_acc: 0.8460\n",
      "Epoch 31/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3713 - acc: 0.8431 - val_loss: 0.3418 - val_acc: 0.8600\n",
      "Epoch 32/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3409 - acc: 0.8561 - val_loss: 0.3563 - val_acc: 0.8560\n",
      "Epoch 33/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3379 - acc: 0.8577 - val_loss: 0.3159 - val_acc: 0.8700\n",
      "Epoch 34/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3379 - acc: 0.8564 - val_loss: 0.3415 - val_acc: 0.8520\n",
      "Epoch 35/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3420 - acc: 0.8538 - val_loss: 0.3691 - val_acc: 0.8470\n",
      "Epoch 36/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3322 - acc: 0.8614 - val_loss: 0.3464 - val_acc: 0.8570\n",
      "Epoch 37/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3293 - acc: 0.8587 - val_loss: 0.3319 - val_acc: 0.8750\n",
      "Epoch 38/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3397 - acc: 0.8532 - val_loss: 0.3106 - val_acc: 0.8750\n",
      "Epoch 39/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3334 - acc: 0.8607 - val_loss: 0.3535 - val_acc: 0.8560\n",
      "Epoch 40/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3287 - acc: 0.8616 - val_loss: 0.3454 - val_acc: 0.8620\n",
      "Epoch 41/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3300 - acc: 0.8632 - val_loss: 0.3492 - val_acc: 0.8640\n",
      "Epoch 42/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3305 - acc: 0.8619 - val_loss: 0.3380 - val_acc: 0.8640\n",
      "Epoch 43/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3213 - acc: 0.8638 - val_loss: 0.3332 - val_acc: 0.8500\n",
      "Epoch 44/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3344 - acc: 0.8585 - val_loss: 0.3176 - val_acc: 0.8810\n",
      "Epoch 45/60\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.3310 - acc: 0.8618 - val_loss: 0.3679 - val_acc: 0.8410\n",
      "Epoch 46/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3289 - acc: 0.8606 - val_loss: 0.3195 - val_acc: 0.8720\n",
      "Epoch 47/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3376 - acc: 0.8554 - val_loss: 0.3532 - val_acc: 0.8600\n",
      "Epoch 48/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3268 - acc: 0.8638 - val_loss: 0.3366 - val_acc: 0.8640\n",
      "Epoch 49/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3246 - acc: 0.8637 - val_loss: 0.3384 - val_acc: 0.8660\n",
      "Epoch 50/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3225 - acc: 0.8656 - val_loss: 0.3389 - val_acc: 0.8600\n",
      "Epoch 51/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3256 - acc: 0.8613 - val_loss: 0.3273 - val_acc: 0.8630\n",
      "Epoch 52/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3221 - acc: 0.8686 - val_loss: 0.3298 - val_acc: 0.8750\n",
      "Epoch 53/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3296 - acc: 0.8605 - val_loss: 0.3577 - val_acc: 0.8460\n",
      "Epoch 54/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3209 - acc: 0.8633 - val_loss: 0.3517 - val_acc: 0.8350\n",
      "Epoch 55/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3226 - acc: 0.8664 - val_loss: 0.3234 - val_acc: 0.8700\n",
      "Epoch 56/60\n",
      "190/190 [==============================] - 10s 55ms/step - loss: 0.3190 - acc: 0.8658 - val_loss: 0.3431 - val_acc: 0.8550\n",
      "Epoch 57/60\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.3102 - acc: 0.8692 - val_loss: 0.3506 - val_acc: 0.8680\n",
      "Epoch 58/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3283 - acc: 0.8601 - val_loss: 0.3032 - val_acc: 0.8820\n",
      "Epoch 59/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3208 - acc: 0.8637 - val_loss: 0.3165 - val_acc: 0.8730\n",
      "Epoch 60/60\n",
      "190/190 [==============================] - 10s 54ms/step - loss: 0.3106 - acc: 0.8683 - val_loss: 0.3220 - val_acc: 0.8700\n",
      "\n",
      "Training process completed in: 0 h 10 m 23 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1317.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1319 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_633 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_633 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_634 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_634 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_635 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_635 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_636 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_636 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_159 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "190/190 [==============================] - 27s 141ms/step - loss: 0.4752 - acc: 0.7824 - val_loss: 0.4546 - val_acc: 0.7919\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.4225 - acc: 0.8201 - val_loss: 0.4062 - val_acc: 0.8202\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.4008 - acc: 0.8299 - val_loss: 0.4185 - val_acc: 0.8333\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3994 - acc: 0.8263 - val_loss: 0.4025 - val_acc: 0.8350\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3921 - acc: 0.8307 - val_loss: 0.3831 - val_acc: 0.8381\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.3854 - acc: 0.8354 - val_loss: 0.4076 - val_acc: 0.8508\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3830 - acc: 0.8361 - val_loss: 0.3813 - val_acc: 0.8313\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3725 - acc: 0.8400 - val_loss: 0.3837 - val_acc: 0.8371\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3745 - acc: 0.8380 - val_loss: 0.4158 - val_acc: 0.8362\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3588 - acc: 0.8464 - val_loss: 0.3568 - val_acc: 0.8506\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3631 - acc: 0.8456 - val_loss: 0.3893 - val_acc: 0.8365\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3614 - acc: 0.8474 - val_loss: 0.3756 - val_acc: 0.8601\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3642 - acc: 0.8441 - val_loss: 0.3487 - val_acc: 0.8562\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3488 - acc: 0.8533 - val_loss: 0.3491 - val_acc: 0.8560\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3459 - acc: 0.8526 - val_loss: 0.3563 - val_acc: 0.8396\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3434 - acc: 0.8547 - val_loss: 0.3370 - val_acc: 0.8585\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3438 - acc: 0.8548 - val_loss: 0.3499 - val_acc: 0.8596\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3398 - acc: 0.8546 - val_loss: 0.3572 - val_acc: 0.8553\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3437 - acc: 0.8539 - val_loss: 0.3495 - val_acc: 0.8569\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3371 - acc: 0.8560 - val_loss: 0.3415 - val_acc: 0.8590\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3409 - acc: 0.8554 - val_loss: 0.3441 - val_acc: 0.8604\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3389 - acc: 0.8556 - val_loss: 0.3434 - val_acc: 0.8579\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3365 - acc: 0.8567 - val_loss: 0.3314 - val_acc: 0.8665\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3285 - acc: 0.8592 - val_loss: 0.3611 - val_acc: 0.8644\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3287 - acc: 0.8597 - val_loss: 0.3387 - val_acc: 0.8573\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3273 - acc: 0.8623 - val_loss: 0.3467 - val_acc: 0.8521\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3320 - acc: 0.8591 - val_loss: 0.3334 - val_acc: 0.8604\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3324 - acc: 0.8583 - val_loss: 0.3236 - val_acc: 0.8669\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3277 - acc: 0.8636 - val_loss: 0.3277 - val_acc: 0.8576\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3224 - acc: 0.8629 - val_loss: 0.3587 - val_acc: 0.8615\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3262 - acc: 0.8612 - val_loss: 0.3463 - val_acc: 0.8627\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3252 - acc: 0.8637 - val_loss: 0.3167 - val_acc: 0.8671\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3267 - acc: 0.8614 - val_loss: 0.3476 - val_acc: 0.8613\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3195 - acc: 0.8660 - val_loss: 0.3194 - val_acc: 0.8648\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3171 - acc: 0.8654 - val_loss: 0.3288 - val_acc: 0.8665\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3175 - acc: 0.8678 - val_loss: 0.3226 - val_acc: 0.8662\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3219 - acc: 0.8626 - val_loss: 0.3288 - val_acc: 0.8648\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3198 - acc: 0.8633 - val_loss: 0.3327 - val_acc: 0.8654\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3192 - acc: 0.8645 - val_loss: 0.3242 - val_acc: 0.8669\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3177 - acc: 0.8682 - val_loss: 0.3209 - val_acc: 0.8694\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3212 - acc: 0.8651 - val_loss: 0.3466 - val_acc: 0.8582\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3190 - acc: 0.8664 - val_loss: 0.3367 - val_acc: 0.8610\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3126 - acc: 0.8662 - val_loss: 0.3204 - val_acc: 0.8646\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3124 - acc: 0.8684 - val_loss: 0.3213 - val_acc: 0.8694\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3083 - acc: 0.8710 - val_loss: 0.3270 - val_acc: 0.8698\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3208 - acc: 0.8661 - val_loss: 0.3213 - val_acc: 0.8652\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3193 - acc: 0.8650 - val_loss: 0.3600 - val_acc: 0.8510\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3142 - acc: 0.8671 - val_loss: 0.3152 - val_acc: 0.8700\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3132 - acc: 0.8708 - val_loss: 0.3227 - val_acc: 0.8706\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3100 - acc: 0.8692 - val_loss: 0.3327 - val_acc: 0.8625\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3129 - acc: 0.8692 - val_loss: 0.3145 - val_acc: 0.8704\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3120 - acc: 0.8699 - val_loss: 0.3175 - val_acc: 0.8729\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3015 - acc: 0.8743 - val_loss: 0.3391 - val_acc: 0.8684\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3056 - acc: 0.8708 - val_loss: 0.3184 - val_acc: 0.8681\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3077 - acc: 0.8705 - val_loss: 0.3041 - val_acc: 0.8748\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3099 - acc: 0.8703 - val_loss: 0.3469 - val_acc: 0.8512\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3072 - acc: 0.8719 - val_loss: 0.3151 - val_acc: 0.8748\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3132 - acc: 0.8681 - val_loss: 0.3198 - val_acc: 0.8686\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3061 - acc: 0.8731 - val_loss: 0.3183 - val_acc: 0.8652\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3071 - acc: 0.8725 - val_loss: 0.3234 - val_acc: 0.8731\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3104 - acc: 0.8692 - val_loss: 0.3237 - val_acc: 0.8625\n",
      "Epoch 62/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3080 - acc: 0.8709 - val_loss: 0.3238 - val_acc: 0.8673\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3046 - acc: 0.8732 - val_loss: 0.3147 - val_acc: 0.8656\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3034 - acc: 0.8693 - val_loss: 0.3160 - val_acc: 0.8691\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2983 - acc: 0.8758 - val_loss: 0.3305 - val_acc: 0.8642\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 16s 87ms/step - loss: 0.3059 - acc: 0.8696 - val_loss: 0.3056 - val_acc: 0.8733\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2984 - acc: 0.8770 - val_loss: 0.3182 - val_acc: 0.8675\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2958 - acc: 0.8761 - val_loss: 0.3206 - val_acc: 0.8650\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3014 - acc: 0.8738 - val_loss: 0.3223 - val_acc: 0.8592\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3032 - acc: 0.8732 - val_loss: 0.3146 - val_acc: 0.8638\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3060 - acc: 0.8697 - val_loss: 0.3228 - val_acc: 0.8669\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3044 - acc: 0.8718 - val_loss: 0.3029 - val_acc: 0.8844\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.3010 - acc: 0.8725 - val_loss: 0.3221 - val_acc: 0.8731\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.2933 - acc: 0.8771 - val_loss: 0.3471 - val_acc: 0.8542\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3029 - acc: 0.8722 - val_loss: 0.3058 - val_acc: 0.8729\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2974 - acc: 0.8775 - val_loss: 0.3298 - val_acc: 0.8671\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.3011 - acc: 0.8737 - val_loss: 0.2932 - val_acc: 0.8817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2947 - acc: 0.8793 - val_loss: 0.3324 - val_acc: 0.8713\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2955 - acc: 0.8750 - val_loss: 0.3243 - val_acc: 0.8667\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.2985 - acc: 0.8757 - val_loss: 0.3108 - val_acc: 0.8698\n",
      "\n",
      "Training process completed in: 0 h 22 m 4 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1318.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1320 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_637 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_637 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_638 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_638 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_639 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_639 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_640 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_640 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_160 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 140\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "140/140 [==============================] - 17s 123ms/step - loss: 0.5159 - acc: 0.7539 - val_loss: 0.5183 - val_acc: 0.7787\n",
      "Epoch 2/80\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4348 - acc: 0.8172 - val_loss: 0.4232 - val_acc: 0.8288\n",
      "Epoch 3/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4270 - acc: 0.8163 - val_loss: 0.4240 - val_acc: 0.8212\n",
      "Epoch 4/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4209 - acc: 0.8223 - val_loss: 0.4361 - val_acc: 0.7925\n",
      "Epoch 5/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4098 - acc: 0.8282 - val_loss: 0.4094 - val_acc: 0.8137\n",
      "Epoch 6/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4200 - acc: 0.8210 - val_loss: 0.4140 - val_acc: 0.8250\n",
      "Epoch 7/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4063 - acc: 0.8254 - val_loss: 0.4494 - val_acc: 0.8038\n",
      "Epoch 8/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4087 - acc: 0.8220 - val_loss: 0.4396 - val_acc: 0.8363\n",
      "Epoch 9/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3916 - acc: 0.8327 - val_loss: 0.4136 - val_acc: 0.8262\n",
      "Epoch 10/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3926 - acc: 0.8303 - val_loss: 0.4194 - val_acc: 0.8225\n",
      "Epoch 11/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.4043 - acc: 0.8304 - val_loss: 0.3936 - val_acc: 0.8288\n",
      "Epoch 12/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3857 - acc: 0.8368 - val_loss: 0.4022 - val_acc: 0.8188\n",
      "Epoch 13/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3852 - acc: 0.8335 - val_loss: 0.3887 - val_acc: 0.8313\n",
      "Epoch 14/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3767 - acc: 0.8380 - val_loss: 0.3770 - val_acc: 0.8438\n",
      "Epoch 15/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3815 - acc: 0.8347 - val_loss: 0.3805 - val_acc: 0.8562\n",
      "Epoch 16/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3909 - acc: 0.8335 - val_loss: 0.4086 - val_acc: 0.8512\n",
      "Epoch 17/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3850 - acc: 0.8333 - val_loss: 0.4001 - val_acc: 0.8362\n",
      "Epoch 18/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3625 - acc: 0.8410 - val_loss: 0.4219 - val_acc: 0.8362\n",
      "Epoch 19/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3735 - acc: 0.8387 - val_loss: 0.4001 - val_acc: 0.8363\n",
      "Epoch 20/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3721 - acc: 0.8429 - val_loss: 0.4464 - val_acc: 0.8162\n",
      "Epoch 21/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3680 - acc: 0.8446 - val_loss: 0.3807 - val_acc: 0.8238\n",
      "Epoch 22/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3642 - acc: 0.8453 - val_loss: 0.3988 - val_acc: 0.8275\n",
      "Epoch 23/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3703 - acc: 0.8440 - val_loss: 0.3729 - val_acc: 0.8550\n",
      "Epoch 24/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3718 - acc: 0.8396 - val_loss: 0.3755 - val_acc: 0.8387\n",
      "Epoch 25/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3699 - acc: 0.8400 - val_loss: 0.3660 - val_acc: 0.8563\n",
      "Epoch 26/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3691 - acc: 0.8451 - val_loss: 0.3446 - val_acc: 0.8637\n",
      "Epoch 27/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3635 - acc: 0.8460 - val_loss: 0.4393 - val_acc: 0.8137\n",
      "Epoch 28/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3699 - acc: 0.8395 - val_loss: 0.3693 - val_acc: 0.8587\n",
      "Epoch 29/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3717 - acc: 0.8412 - val_loss: 0.4050 - val_acc: 0.8275\n",
      "Epoch 30/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3525 - acc: 0.8538 - val_loss: 0.3917 - val_acc: 0.8463\n",
      "Epoch 31/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3546 - acc: 0.8518 - val_loss: 0.3696 - val_acc: 0.8513\n",
      "Epoch 32/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3635 - acc: 0.8486 - val_loss: 0.3974 - val_acc: 0.8200\n",
      "Epoch 33/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3514 - acc: 0.8519 - val_loss: 0.3495 - val_acc: 0.8538\n",
      "Epoch 34/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3562 - acc: 0.8456 - val_loss: 0.3538 - val_acc: 0.8425\n",
      "Epoch 35/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3521 - acc: 0.8471 - val_loss: 0.3844 - val_acc: 0.8573: 1s - loss: 0.3511 -\n",
      "Epoch 36/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3422 - acc: 0.8528 - val_loss: 0.3364 - val_acc: 0.86503403 \n",
      "Epoch 37/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3483 - acc: 0.8538 - val_loss: 0.3388 - val_acc: 0.8637\n",
      "Epoch 38/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3429 - acc: 0.8534 - val_loss: 0.3560 - val_acc: 0.8512\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3409 - acc: 0.8587 - val_loss: 0.3464 - val_acc: 0.8500\n",
      "Epoch 40/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3310 - acc: 0.8602 - val_loss: 0.3690 - val_acc: 0.8525\n",
      "Epoch 41/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3379 - acc: 0.8588 - val_loss: 0.3618 - val_acc: 0.8500\n",
      "Epoch 42/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3470 - acc: 0.8521 - val_loss: 0.3519 - val_acc: 0.8538\n",
      "Epoch 43/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3344 - acc: 0.8568 - val_loss: 0.3535 - val_acc: 0.8575\n",
      "Epoch 44/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3480 - acc: 0.8499 - val_loss: 0.3931 - val_acc: 0.8600\n",
      "Epoch 45/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3503 - acc: 0.8490 - val_loss: 0.3611 - val_acc: 0.8650\n",
      "Epoch 46/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3386 - acc: 0.8547 - val_loss: 0.3334 - val_acc: 0.8625\n",
      "Epoch 47/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3413 - acc: 0.8531 - val_loss: 0.3384 - val_acc: 0.8700\n",
      "Epoch 48/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3376 - acc: 0.8586 - val_loss: 0.3420 - val_acc: 0.8700\n",
      "Epoch 49/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3487 - acc: 0.8529 - val_loss: 0.3576 - val_acc: 0.8312\n",
      "Epoch 50/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3497 - acc: 0.8515 - val_loss: 0.3910 - val_acc: 0.8562\n",
      "Epoch 51/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3476 - acc: 0.8494 - val_loss: 0.3420 - val_acc: 0.8675\n",
      "Epoch 52/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3380 - acc: 0.8602 - val_loss: 0.3246 - val_acc: 0.8637\n",
      "Epoch 53/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3462 - acc: 0.8573 - val_loss: 0.3602 - val_acc: 0.8525\n",
      "Epoch 54/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3364 - acc: 0.8604 - val_loss: 0.3540 - val_acc: 0.8650\n",
      "Epoch 55/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3404 - acc: 0.8553 - val_loss: 0.3556 - val_acc: 0.8487\n",
      "Epoch 56/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3390 - acc: 0.8529 - val_loss: 0.3456 - val_acc: 0.8675\n",
      "Epoch 57/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3365 - acc: 0.8563 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 58/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3360 - acc: 0.8593 - val_loss: 0.3309 - val_acc: 0.8600\n",
      "Epoch 59/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3181 - acc: 0.8655 - val_loss: 0.3323 - val_acc: 0.8737\n",
      "Epoch 60/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3322 - acc: 0.8646 - val_loss: 0.3326 - val_acc: 0.8650\n",
      "Epoch 61/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3341 - acc: 0.8593 - val_loss: 0.3731 - val_acc: 0.8613\n",
      "Epoch 62/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3339 - acc: 0.8571 - val_loss: 0.3752 - val_acc: 0.8263\n",
      "Epoch 63/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3283 - acc: 0.8633 - val_loss: 0.3388 - val_acc: 0.8613\n",
      "Epoch 64/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3295 - acc: 0.8629 - val_loss: 0.3487 - val_acc: 0.8562\n",
      "Epoch 65/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3338 - acc: 0.8588 - val_loss: 0.3577 - val_acc: 0.8625\n",
      "Epoch 66/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3267 - acc: 0.8612 - val_loss: 0.3345 - val_acc: 0.8600\n",
      "Epoch 67/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3433 - acc: 0.8521 - val_loss: 0.3460 - val_acc: 0.8675\n",
      "Epoch 68/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3164 - acc: 0.8683 - val_loss: 0.3607 - val_acc: 0.8500\n",
      "Epoch 69/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3299 - acc: 0.8632 - val_loss: 0.3365 - val_acc: 0.8525\n",
      "Epoch 70/80\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.3329 - acc: 0.8589 - val_loss: 0.3640 - val_acc: 0.8447\n",
      "Epoch 71/80\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 0.3353 - acc: 0.8579 - val_loss: 0.3553 - val_acc: 0.8662\n",
      "Epoch 72/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3196 - acc: 0.8665 - val_loss: 0.3630 - val_acc: 0.8425\n",
      "Epoch 73/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3230 - acc: 0.8586 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 74/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3307 - acc: 0.8608 - val_loss: 0.3086 - val_acc: 0.8812\n",
      "Epoch 75/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3282 - acc: 0.8631 - val_loss: 0.3423 - val_acc: 0.8525\n",
      "Epoch 76/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3364 - acc: 0.8554 - val_loss: 0.3106 - val_acc: 0.8675\n",
      "Epoch 77/80\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.3298 - acc: 0.8588 - val_loss: 0.3781 - val_acc: 0.8463\n",
      "Epoch 78/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3289 - acc: 0.8617 - val_loss: 0.3445 - val_acc: 0.8538\n",
      "Epoch 79/80\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.3308 - acc: 0.8597 - val_loss: 0.3653 - val_acc: 0.8512\n",
      "Epoch 80/80\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.3292 - acc: 0.8592 - val_loss: 0.3445 - val_acc: 0.8713\n",
      "\n",
      "Training process completed in: 0 h 8 m 30 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1319.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1321 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_641 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_641 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_642 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_642 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_643 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_643 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_644 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_644 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_161 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "190/190 [==============================] - 20s 106ms/step - loss: 0.4937 - acc: 0.7675 - val_loss: 0.4140 - val_acc: 0.8246\n",
      "Epoch 2/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4275 - acc: 0.8186 - val_loss: 0.4088 - val_acc: 0.8287\n",
      "Epoch 3/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4153 - acc: 0.8249 - val_loss: 0.4097 - val_acc: 0.8188\n",
      "Epoch 4/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4048 - acc: 0.8263 - val_loss: 0.3860 - val_acc: 0.8279\n",
      "Epoch 5/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.4075 - acc: 0.8279 - val_loss: 0.3849 - val_acc: 0.8246\n",
      "Epoch 6/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3954 - acc: 0.8286 - val_loss: 0.3965 - val_acc: 0.8325\n",
      "Epoch 7/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3808 - acc: 0.8378 - val_loss: 0.3868 - val_acc: 0.8321\n",
      "Epoch 8/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3850 - acc: 0.8361 - val_loss: 0.3775 - val_acc: 0.8425\n",
      "Epoch 9/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3880 - acc: 0.8310 - val_loss: 0.4147 - val_acc: 0.8383\n",
      "Epoch 10/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3874 - acc: 0.8354 - val_loss: 0.3890 - val_acc: 0.8283\n",
      "Epoch 11/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3819 - acc: 0.8363 - val_loss: 0.4095 - val_acc: 0.8408\n",
      "Epoch 12/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3853 - acc: 0.8370 - val_loss: 0.3862 - val_acc: 0.8374\n",
      "Epoch 13/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3834 - acc: 0.8387 - val_loss: 0.3779 - val_acc: 0.8317\n",
      "Epoch 14/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3757 - acc: 0.8412 - val_loss: 0.3974 - val_acc: 0.8400\n",
      "Epoch 15/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3707 - acc: 0.8422 - val_loss: 0.3600 - val_acc: 0.8350\n",
      "Epoch 16/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3673 - acc: 0.8444 - val_loss: 0.3637 - val_acc: 0.8529\n",
      "Epoch 17/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3669 - acc: 0.8469 - val_loss: 0.3628 - val_acc: 0.8500\n",
      "Epoch 18/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3523 - acc: 0.8517 - val_loss: 0.3751 - val_acc: 0.8350\n",
      "Epoch 19/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3670 - acc: 0.8439 - val_loss: 0.4150 - val_acc: 0.8233\n",
      "Epoch 20/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3589 - acc: 0.8513 - val_loss: 0.3633 - val_acc: 0.8525\n",
      "Epoch 21/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3565 - acc: 0.8495 - val_loss: 0.3587 - val_acc: 0.8571\n",
      "Epoch 22/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3633 - acc: 0.8484 - val_loss: 0.3850 - val_acc: 0.8392\n",
      "Epoch 23/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3583 - acc: 0.8464 - val_loss: 0.3502 - val_acc: 0.8625\n",
      "Epoch 24/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3586 - acc: 0.8480 - val_loss: 0.3817 - val_acc: 0.8395\n",
      "Epoch 25/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3590 - acc: 0.8498 - val_loss: 0.3602 - val_acc: 0.8454\n",
      "Epoch 26/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3568 - acc: 0.8473 - val_loss: 0.3954 - val_acc: 0.8512\n",
      "Epoch 27/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3420 - acc: 0.8592 - val_loss: 0.3565 - val_acc: 0.8433\n",
      "Epoch 28/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3580 - acc: 0.8481 - val_loss: 0.3433 - val_acc: 0.8604\n",
      "Epoch 29/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3482 - acc: 0.8518 - val_loss: 0.3628 - val_acc: 0.8504\n",
      "Epoch 30/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3453 - acc: 0.8536 - val_loss: 0.3348 - val_acc: 0.8663\n",
      "Epoch 31/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3471 - acc: 0.8520 - val_loss: 0.3513 - val_acc: 0.8500\n",
      "Epoch 32/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3427 - acc: 0.8540 - val_loss: 0.3515 - val_acc: 0.8575\n",
      "Epoch 33/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3515 - acc: 0.8524 - val_loss: 0.3444 - val_acc: 0.8608\n",
      "Epoch 34/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3391 - acc: 0.8572 - val_loss: 0.3481 - val_acc: 0.8575\n",
      "Epoch 35/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3398 - acc: 0.8582 - val_loss: 0.3544 - val_acc: 0.8595\n",
      "Epoch 36/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3422 - acc: 0.8522 - val_loss: 0.3462 - val_acc: 0.8612\n",
      "Epoch 37/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3310 - acc: 0.8617 - val_loss: 0.3318 - val_acc: 0.8650\n",
      "Epoch 38/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3339 - acc: 0.8592 - val_loss: 0.3421 - val_acc: 0.8737\n",
      "Epoch 39/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3516 - acc: 0.8515 - val_loss: 0.3538 - val_acc: 0.8508\n",
      "Epoch 40/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3381 - acc: 0.8580 - val_loss: 0.3537 - val_acc: 0.8567\n",
      "Epoch 41/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3351 - acc: 0.8573 - val_loss: 0.3703 - val_acc: 0.8538\n",
      "Epoch 42/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3345 - acc: 0.8613 - val_loss: 0.3376 - val_acc: 0.8546\n",
      "Epoch 43/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3425 - acc: 0.8539 - val_loss: 0.3272 - val_acc: 0.8575\n",
      "Epoch 44/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3309 - acc: 0.8613 - val_loss: 0.3383 - val_acc: 0.8517\n",
      "Epoch 45/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3302 - acc: 0.8587 - val_loss: 0.3492 - val_acc: 0.8533\n",
      "Epoch 46/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3342 - acc: 0.8596 - val_loss: 0.3464 - val_acc: 0.8550\n",
      "Epoch 47/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3339 - acc: 0.8564 - val_loss: 0.3412 - val_acc: 0.8541\n",
      "Epoch 48/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3312 - acc: 0.8599 - val_loss: 0.3554 - val_acc: 0.8533\n",
      "Epoch 49/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3284 - acc: 0.8636 - val_loss: 0.3160 - val_acc: 0.8646\n",
      "Epoch 50/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3407 - acc: 0.8553 - val_loss: 0.3441 - val_acc: 0.8575\n",
      "Epoch 51/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3298 - acc: 0.8607 - val_loss: 0.3552 - val_acc: 0.8475\n",
      "Epoch 52/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3325 - acc: 0.8614 - val_loss: 0.3521 - val_acc: 0.8550\n",
      "Epoch 53/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3410 - acc: 0.8538 - val_loss: 0.3438 - val_acc: 0.8579\n",
      "Epoch 54/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3272 - acc: 0.8647 - val_loss: 0.3269 - val_acc: 0.8596\n",
      "Epoch 55/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3264 - acc: 0.8647 - val_loss: 0.3585 - val_acc: 0.8421\n",
      "Epoch 56/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3316 - acc: 0.8587 - val_loss: 0.3482 - val_acc: 0.8546\n",
      "Epoch 57/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3289 - acc: 0.8630 - val_loss: 0.3218 - val_acc: 0.8667\n",
      "Epoch 58/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3320 - acc: 0.8614 - val_loss: 0.3365 - val_acc: 0.8662\n",
      "Epoch 59/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3164 - acc: 0.8649 - val_loss: 0.3109 - val_acc: 0.8767\n",
      "Epoch 60/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3297 - acc: 0.8586 - val_loss: 0.3274 - val_acc: 0.8617\n",
      "Epoch 61/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3196 - acc: 0.8637 - val_loss: 0.3189 - val_acc: 0.8629\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3252 - acc: 0.8636 - val_loss: 0.3466 - val_acc: 0.8479\n",
      "Epoch 63/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3203 - acc: 0.8643 - val_loss: 0.3645 - val_acc: 0.8412\n",
      "Epoch 64/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3199 - acc: 0.8641 - val_loss: 0.3322 - val_acc: 0.8613\n",
      "Epoch 65/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3264 - acc: 0.8598 - val_loss: 0.3587 - val_acc: 0.8587\n",
      "Epoch 66/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3233 - acc: 0.8662 - val_loss: 0.3453 - val_acc: 0.8617\n",
      "Epoch 67/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3294 - acc: 0.8601 - val_loss: 0.3314 - val_acc: 0.8675\n",
      "Epoch 68/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3298 - acc: 0.8591 - val_loss: 0.3395 - val_acc: 0.8642\n",
      "Epoch 69/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3212 - acc: 0.8623 - val_loss: 0.3121 - val_acc: 0.8783\n",
      "Epoch 70/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3217 - acc: 0.8644 - val_loss: 0.3359 - val_acc: 0.8562\n",
      "Epoch 71/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3263 - acc: 0.8606 - val_loss: 0.3212 - val_acc: 0.8629\n",
      "Epoch 72/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3257 - acc: 0.8643 - val_loss: 0.3121 - val_acc: 0.8733\n",
      "Epoch 73/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3142 - acc: 0.8667 - val_loss: 0.3323 - val_acc: 0.8713\n",
      "Epoch 74/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3234 - acc: 0.8626 - val_loss: 0.3487 - val_acc: 0.8533\n",
      "Epoch 75/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3199 - acc: 0.8649 - val_loss: 0.3174 - val_acc: 0.8762\n",
      "Epoch 76/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3206 - acc: 0.8658 - val_loss: 0.3103 - val_acc: 0.8646\n",
      "Epoch 77/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3234 - acc: 0.8630 - val_loss: 0.3295 - val_acc: 0.8663\n",
      "Epoch 78/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3238 - acc: 0.8669 - val_loss: 0.3669 - val_acc: 0.8425\n",
      "Epoch 79/80\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3208 - acc: 0.8664 - val_loss: 0.3079 - val_acc: 0.8875\n",
      "Epoch 80/80\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.3112 - acc: 0.8708 - val_loss: 0.3191 - val_acc: 0.8621\n",
      "\n",
      "Training process completed in: 0 h 12 m 11 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1320.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1322 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_645 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_645 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_646 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_646 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_647 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_647 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_648 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_648 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_162 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 160\n",
      "Learning Rate: 0.001\n",
      "Epochs: 50\n",
      "Steps per Epoch: 190\n",
      "Validation Steps: 10\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/50\n",
      "190/190 [==============================] - 26s 137ms/step - loss: 0.4801 - acc: 0.7797 - val_loss: 0.4339 - val_acc: 0.7956\n",
      "Epoch 2/50\n",
      "190/190 [==============================] - 15s 77ms/step - loss: 0.4142 - acc: 0.8237 - val_loss: 0.4160 - val_acc: 0.8400\n",
      "Epoch 3/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.4129 - acc: 0.8221 - val_loss: 0.4089 - val_acc: 0.8169\n",
      "Epoch 4/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3928 - acc: 0.8336 - val_loss: 0.4105 - val_acc: 0.8244\n",
      "Epoch 5/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3868 - acc: 0.8338 - val_loss: 0.4283 - val_acc: 0.8250\n",
      "Epoch 6/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3874 - acc: 0.8310 - val_loss: 0.4072 - val_acc: 0.8412\n",
      "Epoch 7/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3758 - acc: 0.8397 - val_loss: 0.3800 - val_acc: 0.8238\n",
      "Epoch 8/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3734 - acc: 0.8397 - val_loss: 0.3861 - val_acc: 0.8288\n",
      "Epoch 9/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3723 - acc: 0.8394 - val_loss: 0.3960 - val_acc: 0.8406\n",
      "Epoch 10/50\n",
      "190/190 [==============================] - 15s 79ms/step - loss: 0.3672 - acc: 0.8420 - val_loss: 0.3697 - val_acc: 0.8288\n",
      "Epoch 11/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3611 - acc: 0.8453 - val_loss: 0.3608 - val_acc: 0.8431\n",
      "Epoch 12/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3582 - acc: 0.8481 - val_loss: 0.3851 - val_acc: 0.8444\n",
      "Epoch 13/50\n",
      "190/190 [==============================] - 15s 79ms/step - loss: 0.3498 - acc: 0.8507 - val_loss: 0.3805 - val_acc: 0.8400\n",
      "Epoch 14/50\n",
      "190/190 [==============================] - 15s 79ms/step - loss: 0.3528 - acc: 0.8497 - val_loss: 0.3638 - val_acc: 0.8481\n",
      "Epoch 15/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3539 - acc: 0.8480 - val_loss: 0.3574 - val_acc: 0.8656\n",
      "Epoch 16/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3547 - acc: 0.8488 - val_loss: 0.3316 - val_acc: 0.8569\n",
      "Epoch 17/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3470 - acc: 0.8518 - val_loss: 0.3900 - val_acc: 0.8494\n",
      "Epoch 18/50\n",
      "190/190 [==============================] - 16s 82ms/step - loss: 0.3562 - acc: 0.8465 - val_loss: 0.3893 - val_acc: 0.8485\n",
      "Epoch 19/50\n",
      "190/190 [==============================] - 15s 78ms/step - loss: 0.3386 - acc: 0.8566 - val_loss: 0.3384 - val_acc: 0.8694\n",
      "Epoch 20/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3399 - acc: 0.8536 - val_loss: 0.3489 - val_acc: 0.8469\n",
      "Epoch 21/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3409 - acc: 0.8553 - val_loss: 0.3544 - val_acc: 0.8538\n",
      "Epoch 22/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3359 - acc: 0.8577 - val_loss: 0.3949 - val_acc: 0.8456\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3397 - acc: 0.8551 - val_loss: 0.3599 - val_acc: 0.8569\n",
      "Epoch 24/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3384 - acc: 0.8563 - val_loss: 0.3644 - val_acc: 0.8544\n",
      "Epoch 25/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3374 - acc: 0.8559 - val_loss: 0.3403 - val_acc: 0.8637\n",
      "Epoch 26/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3368 - acc: 0.8568 - val_loss: 0.3261 - val_acc: 0.8669\n",
      "Epoch 27/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3332 - acc: 0.8567 - val_loss: 0.3484 - val_acc: 0.8375\n",
      "Epoch 28/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3350 - acc: 0.8571 - val_loss: 0.3494 - val_acc: 0.8587\n",
      "Epoch 29/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3311 - acc: 0.8587 - val_loss: 0.3447 - val_acc: 0.8531\n",
      "Epoch 30/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3238 - acc: 0.8629 - val_loss: 0.3638 - val_acc: 0.8444\n",
      "Epoch 31/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3334 - acc: 0.8582 - val_loss: 0.3464 - val_acc: 0.8650\n",
      "Epoch 32/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3263 - acc: 0.8609 - val_loss: 0.3344 - val_acc: 0.8700\n",
      "Epoch 33/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3210 - acc: 0.8638 - val_loss: 0.3249 - val_acc: 0.8631\n",
      "Epoch 34/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3247 - acc: 0.8606 - val_loss: 0.3552 - val_acc: 0.8581\n",
      "Epoch 35/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3289 - acc: 0.8602 - val_loss: 0.3272 - val_acc: 0.8611\n",
      "Epoch 36/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3264 - acc: 0.8605 - val_loss: 0.3490 - val_acc: 0.8556\n",
      "Epoch 37/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3234 - acc: 0.8624 - val_loss: 0.3172 - val_acc: 0.8631\n",
      "Epoch 38/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3237 - acc: 0.8640 - val_loss: 0.3286 - val_acc: 0.8650\n",
      "Epoch 39/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3224 - acc: 0.8630 - val_loss: 0.3288 - val_acc: 0.8619\n",
      "Epoch 40/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3179 - acc: 0.8670 - val_loss: 0.3293 - val_acc: 0.8738\n",
      "Epoch 41/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3220 - acc: 0.8640 - val_loss: 0.3213 - val_acc: 0.8706\n",
      "Epoch 42/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3181 - acc: 0.8657 - val_loss: 0.3385 - val_acc: 0.8581\n",
      "Epoch 43/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3217 - acc: 0.8613 - val_loss: 0.3186 - val_acc: 0.8700\n",
      "Epoch 44/50\n",
      "190/190 [==============================] - 15s 81ms/step - loss: 0.3173 - acc: 0.8654 - val_loss: 0.3269 - val_acc: 0.8556\n",
      "Epoch 45/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3151 - acc: 0.8682 - val_loss: 0.3232 - val_acc: 0.8669\n",
      "Epoch 46/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3127 - acc: 0.8675 - val_loss: 0.3450 - val_acc: 0.8438\n",
      "Epoch 47/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3195 - acc: 0.8637 - val_loss: 0.3400 - val_acc: 0.8475\n",
      "Epoch 48/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3160 - acc: 0.8675 - val_loss: 0.3400 - val_acc: 0.8656\n",
      "Epoch 49/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3131 - acc: 0.8677 - val_loss: 0.3403 - val_acc: 0.8581\n",
      "Epoch 50/50\n",
      "190/190 [==============================] - 15s 80ms/step - loss: 0.3205 - acc: 0.8638 - val_loss: 0.3170 - val_acc: 0.8706\n",
      "\n",
      "Training process completed in: 0 h 12 m 52 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1321.h5 \"\n",
      "######################################################################################################################## \n",
      "\n",
      "Processing Model 1323 of 1323\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_649 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_649 (MaxPoolin (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_650 (Conv2D)          (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_650 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_651 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_651 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_652 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_652 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_163 (Flatten)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: <function model_7 at 0x00000157A872F950>\n",
      "Batch Size: 80\n",
      "Learning Rate: 0.001\n",
      "Epochs: 80\n",
      "Steps per Epoch: 120\n",
      "Validation Steps: 30\n",
      "Image Size: (50, 50)\n",
      "_________________________________________________________________ \n",
      "\n",
      "Training Set:\n",
      "Found 222020 images belonging to 2 classes.\n",
      "Validation Set:\n",
      "Found 27752 images belonging to 2 classes.\n",
      "_________________________________________________________________ \n",
      "\n",
      "Model training started...\n",
      "\n",
      "Epoch 1/80\n",
      "120/120 [==============================] - 17s 145ms/step - loss: 0.5460 - acc: 0.7334 - val_loss: 0.4862 - val_acc: 0.7887\n",
      "Epoch 2/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4321 - acc: 0.8215 - val_loss: 0.4088 - val_acc: 0.8358\n",
      "Epoch 3/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4288 - acc: 0.8224 - val_loss: 0.4534 - val_acc: 0.8317\n",
      "Epoch 4/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4239 - acc: 0.8221 - val_loss: 0.4670 - val_acc: 0.8225\n",
      "Epoch 5/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4149 - acc: 0.8244 - val_loss: 0.4195 - val_acc: 0.8308\n",
      "Epoch 6/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4104 - acc: 0.8269 - val_loss: 0.4006 - val_acc: 0.8354\n",
      "Epoch 7/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4096 - acc: 0.8300 - val_loss: 0.4154 - val_acc: 0.8288\n",
      "Epoch 8/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4130 - acc: 0.8249 - val_loss: 0.4295 - val_acc: 0.8250\n",
      "Epoch 9/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4083 - acc: 0.8196 - val_loss: 0.3976 - val_acc: 0.8300\n",
      "Epoch 10/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4064 - acc: 0.8240 - val_loss: 0.3904 - val_acc: 0.8287\n",
      "Epoch 11/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.4049 - acc: 0.8243 - val_loss: 0.4187 - val_acc: 0.8163\n",
      "Epoch 12/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3890 - acc: 0.8372 - val_loss: 0.3798 - val_acc: 0.8336\n",
      "Epoch 13/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3862 - acc: 0.8365 - val_loss: 0.3801 - val_acc: 0.8387\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3905 - acc: 0.8335 - val_loss: 0.3999 - val_acc: 0.8233\n",
      "Epoch 15/80\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.3822 - acc: 0.8366 - val_loss: 0.3704 - val_acc: 0.8396\n",
      "Epoch 16/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3875 - acc: 0.8330 - val_loss: 0.3799 - val_acc: 0.8392\n",
      "Epoch 17/80\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.3995 - acc: 0.8310 - val_loss: 0.3908 - val_acc: 0.8371\n",
      "Epoch 18/80\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.3897 - acc: 0.8343 - val_loss: 0.3682 - val_acc: 0.8483\n",
      "Epoch 19/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3838 - acc: 0.8390 - val_loss: 0.3683 - val_acc: 0.8442\n",
      "Epoch 20/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3709 - acc: 0.8445 - val_loss: 0.3999 - val_acc: 0.8367\n",
      "Epoch 21/80\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.3770 - acc: 0.8375 - val_loss: 0.3744 - val_acc: 0.8462\n",
      "Epoch 22/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3689 - acc: 0.8409 - val_loss: 0.3719 - val_acc: 0.8425\n",
      "Epoch 23/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3633 - acc: 0.8466 - val_loss: 0.3911 - val_acc: 0.8471\n",
      "Epoch 24/80\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.3769 - acc: 0.8355 - val_loss: 0.3695 - val_acc: 0.8495\n",
      "Epoch 25/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3769 - acc: 0.8400 - val_loss: 0.4034 - val_acc: 0.8192\n",
      "Epoch 26/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3707 - acc: 0.8429 - val_loss: 0.3620 - val_acc: 0.8500\n",
      "Epoch 27/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3596 - acc: 0.8473 - val_loss: 0.3460 - val_acc: 0.8533\n",
      "Epoch 28/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3774 - acc: 0.8378 - val_loss: 0.3708 - val_acc: 0.8438\n",
      "Epoch 29/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3605 - acc: 0.8472 - val_loss: 0.3398 - val_acc: 0.8604\n",
      "Epoch 30/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3606 - acc: 0.8509 - val_loss: 0.3616 - val_acc: 0.8458\n",
      "Epoch 31/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3589 - acc: 0.8465 - val_loss: 0.3682 - val_acc: 0.8408\n",
      "Epoch 32/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3690 - acc: 0.8421 - val_loss: 0.3699 - val_acc: 0.8475\n",
      "Epoch 33/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3613 - acc: 0.8479 - val_loss: 0.3586 - val_acc: 0.8575\n",
      "Epoch 34/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3430 - acc: 0.8532 - val_loss: 0.3422 - val_acc: 0.8608\n",
      "Epoch 35/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3563 - acc: 0.8495 - val_loss: 0.3475 - val_acc: 0.8508\n",
      "Epoch 36/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3652 - acc: 0.8414 - val_loss: 0.3679 - val_acc: 0.8350\n",
      "Epoch 37/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3621 - acc: 0.8441 - val_loss: 0.3498 - val_acc: 0.8437\n",
      "Epoch 38/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3616 - acc: 0.8474 - val_loss: 0.3389 - val_acc: 0.8592\n",
      "Epoch 39/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3472 - acc: 0.8521 - val_loss: 0.3627 - val_acc: 0.8525\n",
      "Epoch 40/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3487 - acc: 0.8553 - val_loss: 0.3735 - val_acc: 0.8467\n",
      "Epoch 41/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3490 - acc: 0.8489 - val_loss: 0.3525 - val_acc: 0.8517\n",
      "Epoch 42/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3414 - acc: 0.8545 - val_loss: 0.3549 - val_acc: 0.8496\n",
      "Epoch 43/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3635 - acc: 0.8415 - val_loss: 0.3578 - val_acc: 0.8512\n",
      "Epoch 44/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3513 - acc: 0.8479 - val_loss: 0.3715 - val_acc: 0.8421\n",
      "Epoch 45/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3537 - acc: 0.8501 - val_loss: 0.3526 - val_acc: 0.8608\n",
      "Epoch 46/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3507 - acc: 0.8496 - val_loss: 0.3494 - val_acc: 0.8483\n",
      "Epoch 47/80\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.3638 - acc: 0.8424 - val_loss: 0.3647 - val_acc: 0.8528\n",
      "Epoch 48/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3533 - acc: 0.8492 - val_loss: 0.3851 - val_acc: 0.8333\n",
      "Epoch 49/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3429 - acc: 0.8534 - val_loss: 0.3447 - val_acc: 0.8500\n",
      "Epoch 50/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3504 - acc: 0.8511 - val_loss: 0.3607 - val_acc: 0.8400\n",
      "Epoch 51/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3390 - acc: 0.8570 - val_loss: 0.3265 - val_acc: 0.86588\n",
      "Epoch 52/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3482 - acc: 0.8495 - val_loss: 0.3384 - val_acc: 0.8583\n",
      "Epoch 53/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3392 - acc: 0.8593 - val_loss: 0.3421 - val_acc: 0.8604\n",
      "Epoch 54/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3380 - acc: 0.8597 - val_loss: 0.3577 - val_acc: 0.8429\n",
      "Epoch 55/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3482 - acc: 0.8509 - val_loss: 0.3465 - val_acc: 0.8517\n",
      "Epoch 56/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3439 - acc: 0.8550 - val_loss: 0.3502 - val_acc: 0.8525\n",
      "Epoch 57/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3292 - acc: 0.8570 - val_loss: 0.3325 - val_acc: 0.8621\n",
      "Epoch 58/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3459 - acc: 0.8555 - val_loss: 0.3398 - val_acc: 0.8608\n",
      "Epoch 59/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3490 - acc: 0.8500 - val_loss: 0.3423 - val_acc: 0.8558\n",
      "Epoch 60/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3437 - acc: 0.8558 - val_loss: 0.3506 - val_acc: 0.8654\n",
      "Epoch 61/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3312 - acc: 0.8605 - val_loss: 0.3327 - val_acc: 0.8567\n",
      "Epoch 62/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3441 - acc: 0.8535 - val_loss: 0.3392 - val_acc: 0.8571\n",
      "Epoch 63/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3540 - acc: 0.8481 - val_loss: 0.3857 - val_acc: 0.8367\n",
      "Epoch 64/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3535 - acc: 0.8499 - val_loss: 0.3596 - val_acc: 0.8483\n",
      "Epoch 65/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3441 - acc: 0.8535 - val_loss: 0.3430 - val_acc: 0.8496\n",
      "Epoch 66/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3307 - acc: 0.8623 - val_loss: 0.3542 - val_acc: 0.8504\n",
      "Epoch 67/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3454 - acc: 0.8546 - val_loss: 0.3366 - val_acc: 0.8617\n",
      "Epoch 68/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3290 - acc: 0.8651 - val_loss: 0.3435 - val_acc: 0.8629\n",
      "Epoch 69/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3335 - acc: 0.8581 - val_loss: 0.3166 - val_acc: 0.8708\n",
      "Epoch 70/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3284 - acc: 0.8597 - val_loss: 0.3309 - val_acc: 0.8608\n",
      "Epoch 71/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3410 - acc: 0.8551 - val_loss: 0.3394 - val_acc: 0.8567\n",
      "Epoch 72/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3356 - acc: 0.8575 - val_loss: 0.3482 - val_acc: 0.8479\n",
      "Epoch 73/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3352 - acc: 0.8563 - val_loss: 0.3523 - val_acc: 0.8446\n",
      "Epoch 74/80\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.3368 - acc: 0.8549 - val_loss: 0.3269 - val_acc: 0.8583\n",
      "Epoch 75/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3346 - acc: 0.8568 - val_loss: 0.3303 - val_acc: 0.8646\n",
      "Epoch 76/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3319 - acc: 0.8590 - val_loss: 0.3613 - val_acc: 0.8467\n",
      "Epoch 77/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3282 - acc: 0.8608 - val_loss: 0.3207 - val_acc: 0.8646\n",
      "Epoch 78/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3312 - acc: 0.8566 - val_loss: 0.3461 - val_acc: 0.8550\n",
      "Epoch 79/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3362 - acc: 0.8544 - val_loss: 0.3530 - val_acc: 0.8521\n",
      "Epoch 80/80\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3238 - acc: 0.8613 - val_loss: 0.3218 - val_acc: 0.8654\n",
      "\n",
      "Training process completed in: 0 h 8 m 19 s\n",
      "Model saved as: \" MODELS / model_breast_cancer_1322.h5 \"\n",
      "######################################################################################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596284</td>\n",
       "      <td>0.717086</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.424821</td>\n",
       "      <td>0.824666</td>\n",
       "      <td>0:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.400397</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.821459</td>\n",
       "      <td>0:02:56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.342393</td>\n",
       "      <td>0.854934</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0:03:59</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.61192</td>\n",
       "      <td>0.713867</td>\n",
       "      <td>4.51508</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0:11:35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.57984</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>4.66014</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>0:04:34</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.414818</td>\n",
       "      <td>0.818889</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.355077</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0:11:37</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.598234</td>\n",
       "      <td>0.714492</td>\n",
       "      <td>0.587283</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0:11:21</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.415619</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.415587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0:03:26</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355923</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.340781</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0:04:54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.386344</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>0.38406</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0:01:19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.578921</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.572354</td>\n",
       "      <td>0.707286</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.386086</td>\n",
       "      <td>0.829286</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.406065</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.821349</td>\n",
       "      <td>0:09:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.343212</td>\n",
       "      <td>0.854563</td>\n",
       "      <td>0.333918</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0:11:05</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.366198</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.378055</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0:02:27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.36458</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>0.842172</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.398393</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.593772</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.418344</td>\n",
       "      <td>0.815605</td>\n",
       "      <td>0:06:57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>160</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.369263</td>\n",
       "      <td>0.838594</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.846597</td>\n",
       "      <td>0:05:47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.720147</td>\n",
       "      <td>0.593732</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0:03:39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.481815</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.503438</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0:01:15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.60906</td>\n",
       "      <td>0.714044</td>\n",
       "      <td>4.5453</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0:20:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.63599</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>4.53844</td>\n",
       "      <td>0.718426</td>\n",
       "      <td>0:01:44</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>4.66619</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>4.60252</td>\n",
       "      <td>0.71445</td>\n",
       "      <td>0:06:20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.401561</td>\n",
       "      <td>0.824792</td>\n",
       "      <td>0.387844</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0:03:24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.602757</td>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.592917</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0:07:09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.485893</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>0.79175</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.376809</td>\n",
       "      <td>0.835273</td>\n",
       "      <td>0:22:14</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.321127</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.325096</td>\n",
       "      <td>0.864889</td>\n",
       "      <td>0:22:58</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.296176</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.341947</td>\n",
       "      <td>0.85963</td>\n",
       "      <td>0:23:46</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.293916</td>\n",
       "      <td>0.877396</td>\n",
       "      <td>0.298404</td>\n",
       "      <td>0.876864</td>\n",
       "      <td>0:27:08</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.319407</td>\n",
       "      <td>0.866937</td>\n",
       "      <td>0.341723</td>\n",
       "      <td>0.857833</td>\n",
       "      <td>0:13:42</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.380374</td>\n",
       "      <td>0.837222</td>\n",
       "      <td>0.386942</td>\n",
       "      <td>0.828061</td>\n",
       "      <td>0:07:27</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.328581</td>\n",
       "      <td>0.862692</td>\n",
       "      <td>0.343721</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0:10:25</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.306145</td>\n",
       "      <td>0.870289</td>\n",
       "      <td>0.291742</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0:26:58</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.336852</td>\n",
       "      <td>0.856231</td>\n",
       "      <td>0.34764</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0:10:29</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.840846</td>\n",
       "      <td>0.328633</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0:05:43</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.282741</td>\n",
       "      <td>0.882126</td>\n",
       "      <td>0.318102</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0:29:49</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.309136</td>\n",
       "      <td>0.869605</td>\n",
       "      <td>0.314154</td>\n",
       "      <td>0.86475</td>\n",
       "      <td>0:30:48</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>0.86293</td>\n",
       "      <td>0.336591</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0:21:37</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.282267</td>\n",
       "      <td>0.880975</td>\n",
       "      <td>0.301469</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0:34:08</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.316471</td>\n",
       "      <td>0.866605</td>\n",
       "      <td>0.324876</td>\n",
       "      <td>0.861391</td>\n",
       "      <td>0:22:29</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.301489</td>\n",
       "      <td>0.874792</td>\n",
       "      <td>0.311009</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0:21:06</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>80</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.335616</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.33923</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0:08:36</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.307056</td>\n",
       "      <td>0.869933</td>\n",
       "      <td>0.297371</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0:20:16</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.306912</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>0.34219</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0:14:37</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.305699</td>\n",
       "      <td>0.872733</td>\n",
       "      <td>0.300182</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0:15:11</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.303821</td>\n",
       "      <td>0.874192</td>\n",
       "      <td>0.299319</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>0:17:47</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311339</td>\n",
       "      <td>0.868067</td>\n",
       "      <td>0.298141</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0:12:12</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.316187</td>\n",
       "      <td>0.865292</td>\n",
       "      <td>0.31132</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0:22:07</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.319992</td>\n",
       "      <td>0.865684</td>\n",
       "      <td>0.342453</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0:15:18</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.310593</td>\n",
       "      <td>0.868316</td>\n",
       "      <td>0.321973</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0:10:23</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.298488</td>\n",
       "      <td>0.875658</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.869792</td>\n",
       "      <td>0:22:04</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.329171</td>\n",
       "      <td>0.859196</td>\n",
       "      <td>0.344539</td>\n",
       "      <td>0.87125</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.870789</td>\n",
       "      <td>0.319067</td>\n",
       "      <td>0.862083</td>\n",
       "      <td>0:12:11</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.320451</td>\n",
       "      <td>0.86375</td>\n",
       "      <td>0.317034</td>\n",
       "      <td>0.870625</td>\n",
       "      <td>0:12:52</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.323793</td>\n",
       "      <td>0.86125</td>\n",
       "      <td>0.321813</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0:08:19</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1323 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate train_loss train_acc  val_loss   val_acc     time  gen  alive\n",
       "0            160               60                50      30        0.01000   0.596284  0.717086  0.602438  0.710375  0:02:47    1  False\n",
       "1            140              200                20      80        0.01000   0.419026  0.819964  0.424821  0.824666  0:14:00    1  False\n",
       "2            200               30                70      30        0.00010   0.400397  0.828667  0.407492  0.821459  0:02:56    1  False\n",
       "3             80              190                30      40        0.00100   0.342393  0.854934    0.3493     0.855  0:03:59    1  False\n",
       "4            100              150                80      90        0.10000    4.61192  0.713867   4.51508  0.719875  0:11:35    1  False\n",
       "5            200               70                40      40        0.10000    4.57984  0.715857   4.66014  0.710875  0:04:34    1  False\n",
       "6             60               30                80      40        0.00010   0.414818  0.818889  0.516359  0.784375  0:01:24    1  False\n",
       "7            200              110                70      60        0.00010   0.351962  0.852273  0.355077  0.848624  0:11:37    1  False\n",
       "8            160              160                20      70        0.01000   0.598234  0.714492  0.587283  0.726542  0:11:21    1  False\n",
       "9            120              110                20      40        0.00001   0.415619  0.823788  0.415587  0.819167  0:03:26    1  False\n",
       "10            40              130               100      90        0.00100   0.355923  0.847692  0.340781     0.862  0:04:54    1  False\n",
       "11           140              120                50      10        0.00100   0.386344   0.83375   0.38406  0.837714  0:01:19    1  False\n",
       "12           140               10                50      10        0.00010   0.578921  0.707143  0.572354  0.707286  0:00:27    1  False\n",
       "13            20              130                70      30        0.00100   0.396505  0.838462  0.386086  0.829286  0:00:46    1  False\n",
       "14           140              160                90      50        0.00001   0.406065  0.825893  0.408935  0.821349  0:09:57    1  False\n",
       "15           160              100                80      70        0.00010   0.343212  0.854563  0.333918  0.855412  0:11:05    1  False\n",
       "16           140               90                10      30        0.00100   0.366198  0.840635  0.378055  0.837143  0:02:27    1  False\n",
       "17            80               80                10      70        0.00100    0.36458  0.840156   0.34817  0.842172  0:03:00    1  False\n",
       "18           120               30                20      40        0.00100   0.398393  0.832778  0.461081  0.833333  0:01:07    1  False\n",
       "19            60              120                40      40        0.01000   0.596109  0.716944  0.593772  0.719167  0:02:15    1  False\n",
       "20           160               10                70     100        0.00010   0.409997    0.8225  0.418344  0.815605  0:06:57    1  False\n",
       "21           160              120                90      30        0.00010   0.369263  0.838594  0.359941  0.846597  0:05:47    1  False\n",
       "22           120              170                90      20        0.01000   0.593047  0.720147  0.593732  0.719444  0:03:39    1  False\n",
       "23            40               70                20      60        0.01000   0.481815      0.79  0.503438    0.7525  0:01:15    1  False\n",
       "24           160              170                50     100        0.10000    4.60906  0.714044    4.5453     0.718  0:20:24    1  False\n",
       "25           180              110                60      10        0.10000    4.63599  0.712374   4.53844  0.718426  0:01:44    1  False\n",
       "26           200               20               100      50        0.10000    4.66619    0.7105   4.60252   0.71445  0:06:20    1  False\n",
       "27            60               80                30      90        0.00001   0.401561  0.824792  0.387844     0.835  0:03:24    1  False\n",
       "28            80              120                30     100        0.01000   0.602757  0.709479  0.592917  0.720833  0:07:09    1  False\n",
       "29            80               70                50      20        0.00001   0.485893  0.765714  0.457634   0.79175  0:01:06    1  False\n",
       "...          ...              ...               ...     ...            ...        ...       ...       ...       ...      ...  ...    ...\n",
       "1293         200              200                20      70        0.00001   0.384464    0.8327  0.376809  0.835273  0:22:14    3  False\n",
       "1294         180              170                50      80        0.00010   0.321127  0.864346  0.325096  0.864889  0:22:58    3  False\n",
       "1295         180              170                60      80        0.00100   0.296176  0.876667  0.341947   0.85963  0:23:46    3  False\n",
       "1296         180              160                50     100        0.00100   0.293916  0.877396  0.298404  0.876864  0:27:08    3  False\n",
       "1297         100              160                60      80        0.00100   0.319407  0.866937  0.341723  0.857833  0:13:42    3  False\n",
       "1298         180               10                50     100        0.00100   0.380374  0.837222  0.386942  0.828061  0:07:27    3  False\n",
       "1299         100              130                10      90        0.00010   0.328581  0.862692  0.343721     0.859  0:10:25    4   True\n",
       "1300         200              190                10      90        0.00010   0.306145  0.870289  0.291742    0.8735  0:26:58    4   True\n",
       "1301         200              130                10      50        0.00010   0.336852  0.856231   0.34764     0.854  0:10:29    4   True\n",
       "1302         100              130                10      50        0.00010   0.369931  0.840846  0.328633     0.863  0:05:43    4   True\n",
       "1303         200              190                10     100        0.00100   0.282741  0.882126  0.318102    0.8695  0:29:49    4   True\n",
       "1304         200              190                20     100        0.00010   0.309136  0.869605  0.314154   0.86475  0:30:48    4   True\n",
       "1305         200              190                20      70        0.00010   0.319313   0.86293  0.336591  0.865385  0:21:37    4   True\n",
       "1306         200              200                30     100        0.00100   0.282267  0.880975  0.301469    0.8765  0:34:08    4   True\n",
       "1307         200              190                30      70        0.00010   0.316471  0.866605  0.324876  0.861391  0:22:29    4   True\n",
       "1308         200              120                30     100        0.00100   0.301489  0.874792  0.311009  0.876333  0:21:06    4   True\n",
       "1309          80              150                10      80        0.00100   0.335616     0.857   0.33923    0.8625  0:08:36    4   True\n",
       "1310         200              150                20      80        0.00100   0.307056  0.869933  0.297371    0.8725  0:20:16    4   True\n",
       "1311         200              150                10      60        0.00100   0.306912    0.8702   0.34219     0.858  0:14:37    4   True\n",
       "1312         200              150                20      60        0.00100   0.305699  0.872733  0.300182    0.8745  0:15:11    4   True\n",
       "1313         200              130                20      80        0.00100   0.303821  0.874192  0.299319   0.87675  0:17:47    4   True\n",
       "1314         100              150                10      90        0.00100   0.311339  0.868067  0.298141     0.878  0:12:12    4   True\n",
       "1315         200              150                10      90        0.00010   0.316187  0.865292   0.31132     0.863  0:22:07    4   True\n",
       "1316         100              190                10      90        0.00010   0.319992  0.865684  0.342453     0.866  0:15:18    4   True\n",
       "1317         100              190                10      60        0.00100   0.310593  0.868316  0.321973      0.87  0:10:23    4   True\n",
       "1318         160              190                30      80        0.00100   0.298488  0.875658  0.310833  0.869792  0:22:04    4   True\n",
       "1319          80              140                10      80        0.00100   0.329171  0.859196  0.344539   0.87125  0:08:30    4   True\n",
       "1320          80              190                30      80        0.00100   0.311155  0.870789  0.319067  0.862083  0:12:11    4   True\n",
       "1321         160              190                10      50        0.00100   0.320451   0.86375  0.317034  0.870625  0:12:52    4   True\n",
       "1322          80              120                30      80        0.00100   0.323793   0.86125  0.321813  0.865417  0:08:19    4   True\n",
       "\n",
       "[1323 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate\n",
    "train_generation(model=model_7, image_size=(50,50), gen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of current live algorithms\n",
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "len(df_generations[df_generations.alive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.865789</td>\n",
       "      <td>0.292571</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0:11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0:12:35</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.333464</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>0:05:13</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.302942</td>\n",
       "      <td>0.873192</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0:17:44</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.311461</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.295427</td>\n",
       "      <td>0.881832</td>\n",
       "      <td>0:29:50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.321133</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0:10:42</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.306632</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0:14:31</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.284835</td>\n",
       "      <td>0.881026</td>\n",
       "      <td>0.298489</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0:28:42</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.310335</td>\n",
       "      <td>0.870633</td>\n",
       "      <td>0.298475</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>0:13:40</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.344512</td>\n",
       "      <td>0.852526</td>\n",
       "      <td>0.317177</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0:07:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "653          100              190                10      90         0.0001    0.317655   0.865789  0.292571  0.894000  0:11:41    1   True\n",
       "1240         160              140                10      80         0.0010    0.309508   0.870714  0.298903  0.886250  0:12:35    3   True\n",
       "1178          80              190                30      50         0.0010    0.333464   0.858750  0.292957  0.884583  0:05:13    2   True\n",
       "1278         200              130                10      90         0.0010    0.302942   0.873192  0.296192  0.882000  0:17:44    3   True\n",
       "1129         200              200                20      70         0.0001    0.311461   0.867375  0.295427  0.881832  0:29:50    2   True\n",
       "1107          80              160                10      80         0.0010    0.321133   0.866250  0.336637  0.881250  0:10:42    2   True\n",
       "1038         100              200                10      90         0.0010    0.306632   0.870800  0.317246  0.881000  0:14:31    2   True\n",
       "1250         200              190                30     100         0.0010    0.284835   0.881026  0.298489  0.878500  0:28:42    3   True\n",
       "1267         200              150                20      60         0.0010    0.310335   0.870633  0.298475  0.878250  0:13:40    3   True\n",
       "1039         100              190                10      50         0.0001    0.344512   0.852526  0.317177  0.878000  0:07:40    2   True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep top performing algorithms\n",
    "df_fittest = select_fittest(top_percent=50)\n",
    "df_fittest.nlargest(10, 'val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>validation_steps</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>time</th>\n",
       "      <th>gen</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.865789</td>\n",
       "      <td>0.292571</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0:11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0:12:35</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.333464</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>0:05:13</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.302942</td>\n",
       "      <td>0.873192</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0:17:44</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.311461</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.295427</td>\n",
       "      <td>0.881832</td>\n",
       "      <td>0:29:50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.321133</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0:10:42</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.306632</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0:14:31</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.284835</td>\n",
       "      <td>0.881026</td>\n",
       "      <td>0.298489</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0:28:42</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.310335</td>\n",
       "      <td>0.870633</td>\n",
       "      <td>0.298475</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>0:13:40</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.344512</td>\n",
       "      <td>0.852526</td>\n",
       "      <td>0.317177</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0:07:40</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.311339</td>\n",
       "      <td>0.868067</td>\n",
       "      <td>0.298141</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0:12:12</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.294208</td>\n",
       "      <td>0.877200</td>\n",
       "      <td>0.308905</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0:21:22</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>140</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.316372</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.288847</td>\n",
       "      <td>0.876935</td>\n",
       "      <td>0:21:26</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.301332</td>\n",
       "      <td>0.874420</td>\n",
       "      <td>0.303735</td>\n",
       "      <td>0.876875</td>\n",
       "      <td>0:14:22</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>180</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.293916</td>\n",
       "      <td>0.877396</td>\n",
       "      <td>0.298404</td>\n",
       "      <td>0.876864</td>\n",
       "      <td>0:27:08</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.303821</td>\n",
       "      <td>0.874192</td>\n",
       "      <td>0.299319</td>\n",
       "      <td>0.876750</td>\n",
       "      <td>0:17:47</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.282267</td>\n",
       "      <td>0.880975</td>\n",
       "      <td>0.301469</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0:34:08</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.299698</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0:40:10</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.301489</td>\n",
       "      <td>0.874792</td>\n",
       "      <td>0.311009</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0:21:06</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>160</td>\n",
       "      <td>130</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.307891</td>\n",
       "      <td>0.870048</td>\n",
       "      <td>0.302075</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>0:16:49</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.295809</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.306206</td>\n",
       "      <td>0.875430</td>\n",
       "      <td>0:26:17</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>160</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.311293</td>\n",
       "      <td>0.870008</td>\n",
       "      <td>0.348018</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0:17:19</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>140</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.320372</td>\n",
       "      <td>0.864048</td>\n",
       "      <td>0.315853</td>\n",
       "      <td>0.874857</td>\n",
       "      <td>0:10:14</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.289503</td>\n",
       "      <td>0.878263</td>\n",
       "      <td>0.309483</td>\n",
       "      <td>0.874750</td>\n",
       "      <td>0:26:39</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.315224</td>\n",
       "      <td>0.867411</td>\n",
       "      <td>0.319296</td>\n",
       "      <td>0.874613</td>\n",
       "      <td>0:13:23</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.305699</td>\n",
       "      <td>0.872733</td>\n",
       "      <td>0.300182</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0:15:11</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>0.880450</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0:29:11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>140</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.291092</td>\n",
       "      <td>0.878609</td>\n",
       "      <td>0.307930</td>\n",
       "      <td>0.874053</td>\n",
       "      <td>0:22:01</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.326009</td>\n",
       "      <td>0.861417</td>\n",
       "      <td>0.316879</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0:19:31</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.308384</td>\n",
       "      <td>0.869611</td>\n",
       "      <td>0.306077</td>\n",
       "      <td>0.873875</td>\n",
       "      <td>0:25:00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  steps_per_epoch  validation_steps  epochs  learning_rate  train_loss  train_acc  val_loss   val_acc     time  gen  alive\n",
       "653          100              190                10      90         0.0001    0.317655   0.865789  0.292571  0.894000  0:11:41    1   True\n",
       "1240         160              140                10      80         0.0010    0.309508   0.870714  0.298903  0.886250  0:12:35    3   True\n",
       "1178          80              190                30      50         0.0010    0.333464   0.858750  0.292957  0.884583  0:05:13    2   True\n",
       "1278         200              130                10      90         0.0010    0.302942   0.873192  0.296192  0.882000  0:17:44    3   True\n",
       "1129         200              200                20      70         0.0001    0.311461   0.867375  0.295427  0.881832  0:29:50    2   True\n",
       "1107          80              160                10      80         0.0010    0.321133   0.866250  0.336637  0.881250  0:10:42    2   True\n",
       "1038         100              200                10      90         0.0010    0.306632   0.870800  0.317246  0.881000  0:14:31    2   True\n",
       "1250         200              190                30     100         0.0010    0.284835   0.881026  0.298489  0.878500  0:28:42    3   True\n",
       "1267         200              150                20      60         0.0010    0.310335   0.870633  0.298475  0.878250  0:13:40    3   True\n",
       "1039         100              190                10      50         0.0001    0.344512   0.852526  0.317177  0.878000  0:07:40    2   True\n",
       "1314         100              150                10      90         0.0010    0.311339   0.868067  0.298141  0.878000  0:12:12    4   True\n",
       "1029         200              150                20      90         0.0010    0.294208   0.877200  0.308905  0.877500  0:21:22    2   True\n",
       "1106         140              200                10      80         0.0001    0.316372   0.865000  0.288847  0.876935  0:21:26    2  False\n",
       "1047         160              140                10      80         0.0010    0.301332   0.874420  0.303735  0.876875  0:14:22    2  False\n",
       "1296         180              160                50     100         0.0010    0.293916   0.877396  0.298404  0.876864  0:27:08    3  False\n",
       "1313         200              130                20      80         0.0010    0.303821   0.874192  0.299319  0.876750  0:17:47    4   True\n",
       "1306         200              200                30     100         0.0010    0.282267   0.880975  0.301469  0.876500  0:34:08    4   True\n",
       "1125         200              120                90     100         0.0010    0.299698   0.874125  0.298709  0.876500  0:40:10    2  False\n",
       "1308         200              120                30     100         0.0010    0.301489   0.874792  0.311009  0.876333  0:21:06    4   True\n",
       "1279         160              130                40      90         0.0010    0.307891   0.870048  0.302075  0.875469  0:16:49    3  False\n",
       "1016         200              130                70     100         0.0010    0.295809   0.876000  0.306206  0.875430  0:26:17    2  False\n",
       "1142         160              150                20      60         0.0010    0.311293   0.870008  0.348018  0.875000  0:17:19    2  False\n",
       "994          140              180                50      50         0.0010    0.320372   0.864048  0.315853  0.874857  0:10:14    1  False\n",
       "1032         200              190                20      90         0.0010    0.289503   0.878263  0.309483  0.874750  0:26:39    2  False\n",
       "693          140              160                10      80         0.0010    0.315224   0.867411  0.319296  0.874613  0:13:23    1  False\n",
       "1312         200              150                20      60         0.0010    0.305699   0.872733  0.300182  0.874500  0:15:11    4   True\n",
       "1207         200              200                70      90         0.0010    0.281896   0.880450  0.304133  0.874427  0:29:11    2  False\n",
       "1176         140              190                80     100         0.0010    0.291092   0.878609  0.307930  0.874053  0:22:01    2  False\n",
       "605           60              200                30      80         0.0010    0.326009   0.861417  0.316879  0.873889  0:19:31    1  False\n",
       "1150         200               90                40      90         0.0010    0.308384   0.869611  0.306077  0.873875  0:25:00    2  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read generations file\n",
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "\n",
    "# check performance of top performing algorithms (dead and alive)\n",
    "df_generations.sort_values('val_acc', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Training Time of All Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.54 hours\n"
     ]
    }
   ],
   "source": [
    "df_generations = pd.read_csv(os.path.join(path_project, 'generations.csv')).fillna('')\n",
    "\n",
    "times = df_generations.time.tolist()\n",
    "times = list(map(lambda x: re.sub(r'^0:', '', x), times))\n",
    "\n",
    "minutes = sum(list(map(lambda x: int(x.split(':')[0]), times))) + sum(list(map(lambda x: int(x.split(':')[1]), times))) / 60\n",
    "hours = minutes/60\n",
    "print(round(hours, 2), 'hours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
